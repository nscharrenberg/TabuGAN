{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:04.723576Z",
     "start_time": "2024-05-07T13:17:04.708Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-07 15:17:04--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘input.txt.1’\r\n",
      "\r\n",
      "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \r\n",
      "\r\n",
      "2024-05-07 15:17:05 (19.9 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# we will make a transforemer based model on shakespear \n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.193343Z",
     "start_time": "2024-05-07T13:17:04.712802Z"
    }
   },
   "id": "665f5c0d46f0c1bd"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\r\n",
      "Before we proceed any further, hear me speak.\r\n",
      "\r\n",
      "All:\r\n",
      "Speak, speak.\r\n",
      "\r\n",
      "First Citizen:\r\n",
      "You are all resolved rather to die than to famish?\r\n",
      "\r\n",
      "All:\r\n"
     ]
    }
   ],
   "source": [
    "!head input.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.316108Z",
     "start_time": "2024-05-07T13:17:05.194235Z"
    }
   },
   "id": "834cce9947bb823"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "with open(\"input.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(text[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.322244Z",
     "start_time": "2024-05-07T13:17:05.317204Z"
    }
   },
   "id": "3162eb81f6a7abe6"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters : 1_115_394\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of dataset in characters : {len(text):_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.328005Z",
     "start_time": "2024-05-07T13:17:05.324374Z"
    }
   },
   "id": "9d9d80a0cef9aeb5"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# vocab size\n",
    "vocab = sorted( list(set(text)))\n",
    "print(vocab,sep=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.356524Z",
     "start_time": "2024-05-07T13:17:05.340391Z"
    }
   },
   "id": "628dce7ecb7bb774"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "65"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.356944Z",
     "start_time": "2024-05-07T13:17:05.342981Z"
    }
   },
   "id": "54324c7b3df8d26e"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# since we never terminate this .. we dont need special tokens\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "encode = lambda word : [stoi[c] for c in word]\n",
    "decode = lambda code : \"\".join(itos[s] for s in code)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.357015Z",
     "start_time": "2024-05-07T13:17:05.348196Z"
    }
   },
   "id": "937ffe4883ede2e3"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 63, 50, 53]\n",
      "Heylo\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"Heylo\"))\n",
    "print(decode(encode(\"Heylo\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.357201Z",
     "start_time": "2024-05-07T13:17:05.350710Z"
    }
   },
   "id": "7d06482a440836bd"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1115394]), torch.int64)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text))\n",
    "data.shape, data.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.499178Z",
     "start_time": "2024-05-07T13:17:05.492239Z"
    }
   },
   "id": "7eafd6174927f5c1"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([892315]) torch.Size([111539]) torch.Size([111540])\n"
     ]
    }
   ],
   "source": [
    "# lets split the data into train , valid and test split\n",
    "n1 = int (0.8 * len(data))\n",
    "n2 = int (0.9 * len(data))\n",
    "# obviously dont shuffle the data.\n",
    "data_tr = data[:n1]\n",
    "data_val = data[n1:n2]\n",
    "data_test = data[n2:]\n",
    "print(data_tr.shape , data_val.shape, data_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.504036Z",
     "start_time": "2024-05-07T13:17:05.498685Z"
    }
   },
   "id": "d9ac6a71fb6c491a"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_ex=tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "tensor([], dtype=torch.int64) -> tensor(18)\n",
      "tensor([18]) -> tensor(47)\n",
      "tensor([18, 47]) -> tensor(56)\n",
      "tensor([18, 47, 56]) -> tensor(57)\n",
      "tensor([18, 47, 56, 57]) -> tensor(58)\n",
      "tensor([18, 47, 56, 57, 58]) -> tensor(1)\n",
      "tensor([18, 47, 56, 57, 58,  1]) -> tensor(15)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) -> tensor(47)\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "X_ex = data_tr[:block_size]\n",
    "print(f\"{X_ex=}\")\n",
    "for i,c in enumerate(X_ex):\n",
    "    print(X_ex[:i],\"->\",X_ex[i])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.508610Z",
     "start_time": "2024-05-07T13:17:05.502949Z"
    }
   },
   "id": "3f0d8ab818970ff7"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[61, 47, 58, 46,  1, 57, 50, 53],\n         [52,  1, 40, 39, 41, 49,  8,  0],\n         [ 0, 21, 58,  1, 58, 46, 43, 52],\n         [53, 59, 56,  1, 60, 43, 56, 57]]),\n tensor([[47, 58, 46,  1, 57, 50, 53, 61],\n         [ 1, 40, 39, 41, 49,  8,  0,  0],\n         [21, 58,  1, 58, 46, 43, 52,  1],\n         [59, 56,  1, 60, 43, 56, 57, 43]]))"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4 \n",
    "\n",
    "def mini_batch(split):\n",
    "    data = data_tr if split == \"train\" else data_val\n",
    "    # jump to any point in mini shakespeare \n",
    "    ix = torch.randint(0,data.shape[0], (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix],dim=0) # we want examples to be stacked vertically\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix],dim=0) # we want examples to be stacked vertically\n",
    "    return  x,y \n",
    "\n",
    "Xb,yb = mini_batch(\"train\")\n",
    "Xb,yb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:05.517292Z",
     "start_time": "2024-05-07T13:17:05.508846Z"
    }
   },
   "id": "7f85d7b778833913"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], dtype=torch.int64) -> tensor(61)\n",
      "tensor([61]) -> tensor(47)\n",
      "tensor([61, 47]) -> tensor(58)\n",
      "tensor([61, 47, 58]) -> tensor(46)\n",
      "tensor([61, 47, 58, 46]) -> tensor(1)\n",
      "tensor([61, 47, 58, 46,  1]) -> tensor(57)\n",
      "tensor([61, 47, 58, 46,  1, 57]) -> tensor(50)\n",
      "tensor([61, 47, 58, 46,  1, 57, 50]) -> tensor(53)\n",
      "tensor([], dtype=torch.int64) -> tensor(52)\n",
      "tensor([52]) -> tensor(1)\n",
      "tensor([52,  1]) -> tensor(40)\n",
      "tensor([52,  1, 40]) -> tensor(39)\n",
      "tensor([52,  1, 40, 39]) -> tensor(41)\n",
      "tensor([52,  1, 40, 39, 41]) -> tensor(49)\n",
      "tensor([52,  1, 40, 39, 41, 49]) -> tensor(8)\n",
      "tensor([52,  1, 40, 39, 41, 49,  8]) -> tensor(0)\n",
      "tensor([], dtype=torch.int64) -> tensor(0)\n",
      "tensor([0]) -> tensor(21)\n",
      "tensor([ 0, 21]) -> tensor(58)\n",
      "tensor([ 0, 21, 58]) -> tensor(1)\n",
      "tensor([ 0, 21, 58,  1]) -> tensor(58)\n",
      "tensor([ 0, 21, 58,  1, 58]) -> tensor(46)\n",
      "tensor([ 0, 21, 58,  1, 58, 46]) -> tensor(43)\n",
      "tensor([ 0, 21, 58,  1, 58, 46, 43]) -> tensor(52)\n",
      "tensor([], dtype=torch.int64) -> tensor(53)\n",
      "tensor([53]) -> tensor(59)\n",
      "tensor([53, 59]) -> tensor(56)\n",
      "tensor([53, 59, 56]) -> tensor(1)\n",
      "tensor([53, 59, 56,  1]) -> tensor(60)\n",
      "tensor([53, 59, 56,  1, 60]) -> tensor(43)\n",
      "tensor([53, 59, 56,  1, 60, 43]) -> tensor(56)\n",
      "tensor([53, 59, 56,  1, 60, 43, 56]) -> tensor(57)\n"
     ]
    }
   ],
   "source": [
    "for batch in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "       context = Xb[batch, :t]\n",
    "       target = Xb[batch, t]\n",
    "       print(context,\"->\",target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:17:40.828482Z",
     "start_time": "2024-05-07T13:17:40.822371Z"
    }
   },
   "id": "30ee61a0402eff33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compile_dataset(data):\n",
    "    context_window = torch.z\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89b5f2f1f7cc91ef"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([32, 65]),\n tensor([ 0.6733, -0.2337, -0.5862, -0.4561,  0.9994, -1.1085,  1.7156, -0.8135,\n          0.0650,  0.0469,  0.9859, -0.7959, -0.2922, -0.8291, -0.5552,  0.7637,\n          0.6981, -2.2819, -0.2452, -3.4533, -3.0722,  0.1733, -0.0176, -0.4889,\n          2.1990, -0.2319,  0.1248,  0.0940,  0.8477, -1.4172,  0.2188,  2.2037,\n          1.4194,  0.2399,  1.1591, -0.2237,  0.5132,  0.6383, -0.1745,  0.5610,\n          0.6953,  0.6277,  0.1643, -0.7114,  1.8253,  0.8615,  0.4973,  0.3916,\n         -1.2814,  0.4732, -2.2927, -0.4348,  0.7450, -1.2404, -0.7729, -1.5647,\n         -0.3501,  1.5520, -1.7492,  0.6099,  1.2775,  0.5749,  1.4199,  0.3876,\n          1.9517], grad_fn=<SelectBackward0>))"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BiGram(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        # allowing each cat to have one hot representation for the worst case\n",
    "        self.embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "        \n",
    "    def forward(self,x , y):\n",
    "        logits = self.embedding_table(x)\n",
    "        # logits are batch_examples , tokens\n",
    "        # but now tokens after embedding table are vocab_size\n",
    "        # so logits are batch, (context , vocab_size)\n",
    "        B, T , R = logits.shape\n",
    "        # pytorch wants B*T to be the first dimension and R to be the second\n",
    "        logits = logits.view(B*T,R)\n",
    "        \n",
    "        # loss = nn.functional.cross_entropy(x,y)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "biGram = BiGram(vocab_size)\n",
    "out = biGram(Xb,yb) # __call__ -> forward\n",
    "out.shape , out[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T13:41:20.436081Z",
     "start_time": "2024-05-07T13:41:20.429045Z"
    }
   },
   "id": "eb3ce0c933311769"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f63286744cae9be0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
