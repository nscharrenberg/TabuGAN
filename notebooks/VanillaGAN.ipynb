{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tabular GAN from Scratch using Pytorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78888a8d2eb45b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below code is a modifications of the [Pytorch DCGAN tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8359edc5086ef1c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:02.831888900Z",
     "start_time": "2024-04-09T13:43:02.812703300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/income/adult.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:03.163105700Z",
     "start_time": "2024-04-09T13:43:03.084392600Z"
    }
   },
   "id": "7215817614e19dcb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_dropped = df.drop('income', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:03.451641800Z",
     "start_time": "2024-04-09T13:43:03.433619400Z"
    }
   },
   "id": "c452b272599bb83d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in df_dropped.columns if df_dropped[col].dtype == 'object']\n",
    "numerical_columns = [col for col in df_dropped.columns if df_dropped[col].dtype in ['int64', 'float64']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:03.836823300Z",
     "start_time": "2024-04-09T13:43:03.828771Z"
    }
   },
   "id": "baca430a109df3b9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(sparse_output=False), categorical_columns),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:04.181400800Z",
     "start_time": "2024-04-09T13:43:04.165181400Z"
    }
   },
   "id": "b1e71308797768f8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(df_dropped)\n",
    "y = df['income'].apply(lambda x: 1 if x == '>50K' else 0).values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:05.158180300Z",
     "start_time": "2024-04-09T13:43:04.975123100Z"
    }
   },
   "id": "279a71df79cd1cd"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "y_torch = torch.tensor(y, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:05.186269600Z",
     "start_time": "2024-04-09T13:43:05.137720500Z"
    }
   },
   "id": "4fc4589e8280906d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_torch, y_torch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:05.478640600Z",
     "start_time": "2024-04-09T13:43:05.453263800Z"
    }
   },
   "id": "3bd4aabf26efb478"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:08.619058600Z",
     "start_time": "2024-04-09T13:43:08.598490Z"
    }
   },
   "id": "4a5ff03ed254f18b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:09.013753800Z",
     "start_time": "2024-04-09T13:43:09.001033100Z"
    }
   },
   "id": "b78794e4a19c36b5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:09.549708700Z",
     "start_time": "2024-04-09T13:43:09.537588Z"
    }
   },
   "id": "47aa30973c0b0166"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "generator = Generator(input_dim=noise_dim, output_dim=X.shape[1])\n",
    "discriminator = Discriminator(input_dim=X.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:10.676778100Z",
     "start_time": "2024-04-09T13:43:10.665035700Z"
    }
   },
   "id": "8b99837ac206af9a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=0.00040376804222956743)\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=2.019033675863192e-05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:43:15.082722500Z",
     "start_time": "2024-04-09T13:43:13.231787100Z"
    }
   },
   "id": "d47ab4a4c43c8272"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The basic training loop for the GAN should look as following"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f169b1f70d5903"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/1018]\tLoss_D: 1.3913\tLoss_G: 0.7077\tD(x): 0.4905\tD(G(z)): 0.4928 / 0.4928\n",
      "[0/25][50/1018]\tLoss_D: 1.3893\tLoss_G: 0.6945\tD(x): 0.5002\tD(G(z)): 0.5017 / 0.4993\n",
      "[0/25][100/1018]\tLoss_D: 1.3198\tLoss_G: 0.7575\tD(x): 0.5055\tD(G(z)): 0.4714 / 0.4688\n",
      "[0/25][150/1018]\tLoss_D: 1.4028\tLoss_G: 0.6735\tD(x): 0.5046\tD(G(z)): 0.5127 / 0.5099\n",
      "[0/25][200/1018]\tLoss_D: 1.3412\tLoss_G: 0.7395\tD(x): 0.5040\tD(G(z)): 0.4811 / 0.4774\n",
      "[0/25][250/1018]\tLoss_D: 1.2660\tLoss_G: 0.8323\tD(x): 0.5024\tD(G(z)): 0.4388 / 0.4351\n",
      "[0/25][300/1018]\tLoss_D: 1.3231\tLoss_G: 0.7644\tD(x): 0.5014\tD(G(z)): 0.4689 / 0.4656\n",
      "[0/25][350/1018]\tLoss_D: 1.1843\tLoss_G: 0.9513\tD(x): 0.5014\tD(G(z)): 0.3898 / 0.3862\n",
      "[0/25][400/1018]\tLoss_D: 1.2385\tLoss_G: 0.8703\tD(x): 0.5028\tD(G(z)): 0.4234 / 0.4188\n",
      "[0/25][450/1018]\tLoss_D: 1.0793\tLoss_G: 1.1404\tD(x): 0.5042\tD(G(z)): 0.3256 / 0.3202\n",
      "[0/25][500/1018]\tLoss_D: 1.2110\tLoss_G: 0.9272\tD(x): 0.4984\tD(G(z)): 0.4016 / 0.3965\n",
      "[0/25][550/1018]\tLoss_D: 1.1870\tLoss_G: 1.0104\tD(x): 0.5086\tD(G(z)): 0.3860 / 0.3832\n",
      "[0/25][600/1018]\tLoss_D: 1.1630\tLoss_G: 1.0771\tD(x): 0.5079\tD(G(z)): 0.3681 / 0.3648\n",
      "[0/25][650/1018]\tLoss_D: 1.1793\tLoss_G: 1.0182\tD(x): 0.5051\tD(G(z)): 0.3802 / 0.3772\n",
      "[0/25][700/1018]\tLoss_D: 1.2700\tLoss_G: 0.8992\tD(x): 0.5019\tD(G(z)): 0.4276 / 0.4260\n",
      "[0/25][750/1018]\tLoss_D: 1.3741\tLoss_G: 0.6893\tD(x): 0.5140\tD(G(z)): 0.5054 / 0.5043\n",
      "[0/25][800/1018]\tLoss_D: 1.4215\tLoss_G: 0.6622\tD(x): 0.5021\tD(G(z)): 0.5176 / 0.5161\n",
      "[0/25][850/1018]\tLoss_D: 1.4321\tLoss_G: 0.6473\tD(x): 0.5018\tD(G(z)): 0.5238 / 0.5235\n",
      "[0/25][900/1018]\tLoss_D: 1.4225\tLoss_G: 0.6382\tD(x): 0.5114\tD(G(z)): 0.5284 / 0.5282\n",
      "[0/25][950/1018]\tLoss_D: 1.4221\tLoss_G: 0.6385\tD(x): 0.5120\tD(G(z)): 0.5284 / 0.5281\n",
      "[0/25][1000/1018]\tLoss_D: 1.4047\tLoss_G: 0.6465\tD(x): 0.5160\tD(G(z)): 0.5242 / 0.5239\n",
      "[1/25][0/1018]\tLoss_D: 1.4148\tLoss_G: 0.6436\tD(x): 0.5127\tD(G(z)): 0.5257 / 0.5254\n",
      "[1/25][50/1018]\tLoss_D: 1.3960\tLoss_G: 0.6632\tD(x): 0.5112\tD(G(z)): 0.5157 / 0.5152\n",
      "[1/25][100/1018]\tLoss_D: 1.3995\tLoss_G: 0.6614\tD(x): 0.5100\tD(G(z)): 0.5162 / 0.5161\n",
      "[1/25][150/1018]\tLoss_D: 1.3984\tLoss_G: 0.6522\tD(x): 0.5157\tD(G(z)): 0.5211 / 0.5209\n",
      "[1/25][200/1018]\tLoss_D: 1.4002\tLoss_G: 0.6460\tD(x): 0.5187\tD(G(z)): 0.5247 / 0.5241\n",
      "[1/25][250/1018]\tLoss_D: 1.3881\tLoss_G: 0.6738\tD(x): 0.5100\tD(G(z)): 0.5107 / 0.5098\n",
      "[1/25][300/1018]\tLoss_D: 1.3922\tLoss_G: 0.6698\tD(x): 0.5095\tD(G(z)): 0.5122 / 0.5118\n",
      "[1/25][350/1018]\tLoss_D: 1.4053\tLoss_G: 0.6609\tD(x): 0.5081\tD(G(z)): 0.5171 / 0.5164\n",
      "[1/25][400/1018]\tLoss_D: 1.4029\tLoss_G: 0.6743\tD(x): 0.5024\tD(G(z)): 0.5106 / 0.5095\n",
      "[1/25][450/1018]\tLoss_D: 1.3949\tLoss_G: 0.6793\tD(x): 0.5030\tD(G(z)): 0.5071 / 0.5070\n",
      "[1/25][500/1018]\tLoss_D: 1.4037\tLoss_G: 0.6600\tD(x): 0.5088\tD(G(z)): 0.5170 / 0.5169\n",
      "[1/25][550/1018]\tLoss_D: 1.3896\tLoss_G: 0.6786\tD(x): 0.5062\tD(G(z)): 0.5078 / 0.5073\n",
      "[1/25][600/1018]\tLoss_D: 1.3908\tLoss_G: 0.6817\tD(x): 0.5037\tD(G(z)): 0.5059 / 0.5058\n",
      "[1/25][650/1018]\tLoss_D: 1.3936\tLoss_G: 0.6704\tD(x): 0.5082\tD(G(z)): 0.5117 / 0.5115\n",
      "[1/25][700/1018]\tLoss_D: 1.3906\tLoss_G: 0.6745\tD(x): 0.5078\tD(G(z)): 0.5098 / 0.5094\n",
      "[1/25][750/1018]\tLoss_D: 1.3968\tLoss_G: 0.6766\tD(x): 0.5037\tD(G(z)): 0.5089 / 0.5083\n",
      "[1/25][800/1018]\tLoss_D: 1.3954\tLoss_G: 0.6795\tD(x): 0.5027\tD(G(z)): 0.5072 / 0.5069\n",
      "[1/25][850/1018]\tLoss_D: 1.3889\tLoss_G: 0.6782\tD(x): 0.5066\tD(G(z)): 0.5077 / 0.5075\n",
      "[1/25][900/1018]\tLoss_D: 1.3977\tLoss_G: 0.6663\tD(x): 0.5086\tD(G(z)): 0.5140 / 0.5136\n",
      "[1/25][950/1018]\tLoss_D: 1.3891\tLoss_G: 0.6853\tD(x): 0.5032\tD(G(z)): 0.5046 / 0.5040\n",
      "[1/25][1000/1018]\tLoss_D: 1.3893\tLoss_G: 0.6824\tD(x): 0.5041\tD(G(z)): 0.5055 / 0.5054\n",
      "[2/25][0/1018]\tLoss_D: 1.3905\tLoss_G: 0.6785\tD(x): 0.5054\tD(G(z)): 0.5074 / 0.5074\n",
      "[2/25][50/1018]\tLoss_D: 1.3885\tLoss_G: 0.6713\tD(x): 0.5104\tD(G(z)): 0.5113 / 0.5110\n",
      "[2/25][100/1018]\tLoss_D: 1.3886\tLoss_G: 0.6856\tD(x): 0.5033\tD(G(z)): 0.5044 / 0.5038\n",
      "[2/25][150/1018]\tLoss_D: 1.3846\tLoss_G: 0.6867\tD(x): 0.5043\tD(G(z)): 0.5034 / 0.5032\n",
      "[2/25][200/1018]\tLoss_D: 1.3978\tLoss_G: 0.6631\tD(x): 0.5103\tD(G(z)): 0.5157 / 0.5153\n",
      "[2/25][250/1018]\tLoss_D: 1.3845\tLoss_G: 0.6920\tD(x): 0.5025\tD(G(z)): 0.5015 / 0.5006\n",
      "[2/25][300/1018]\tLoss_D: 1.3844\tLoss_G: 0.6933\tD(x): 0.5012\tD(G(z)): 0.5002 / 0.5000\n",
      "[2/25][350/1018]\tLoss_D: 1.4003\tLoss_G: 0.6688\tD(x): 0.5058\tD(G(z)): 0.5126 / 0.5124\n",
      "[2/25][400/1018]\tLoss_D: 1.3858\tLoss_G: 0.6878\tD(x): 0.5037\tD(G(z)): 0.5034 / 0.5027\n",
      "[2/25][450/1018]\tLoss_D: 1.3829\tLoss_G: 0.6902\tD(x): 0.5035\tD(G(z)): 0.5017 / 0.5015\n",
      "[2/25][500/1018]\tLoss_D: 1.3990\tLoss_G: 0.6712\tD(x): 0.5054\tD(G(z)): 0.5116 / 0.5111\n",
      "[2/25][550/1018]\tLoss_D: 1.3857\tLoss_G: 0.6906\tD(x): 0.5023\tD(G(z)): 0.5019 / 0.5013\n",
      "[2/25][600/1018]\tLoss_D: 1.3954\tLoss_G: 0.6891\tD(x): 0.4978\tD(G(z)): 0.5023 / 0.5020\n",
      "[2/25][650/1018]\tLoss_D: 1.3882\tLoss_G: 0.6875\tD(x): 0.5027\tD(G(z)): 0.5036 / 0.5028\n",
      "[2/25][700/1018]\tLoss_D: 1.3924\tLoss_G: 0.6873\tD(x): 0.5006\tD(G(z)): 0.5036 / 0.5029\n",
      "[2/25][750/1018]\tLoss_D: 1.3916\tLoss_G: 0.6814\tD(x): 0.5034\tD(G(z)): 0.5060 / 0.5059\n",
      "[2/25][800/1018]\tLoss_D: 1.3869\tLoss_G: 0.6843\tD(x): 0.5045\tD(G(z)): 0.5048 / 0.5044\n",
      "[2/25][850/1018]\tLoss_D: 1.3820\tLoss_G: 0.6884\tD(x): 0.5048\tD(G(z)): 0.5026 / 0.5024\n",
      "[2/25][900/1018]\tLoss_D: 1.3920\tLoss_G: 0.6763\tD(x): 0.5062\tD(G(z)): 0.5089 / 0.5085\n",
      "[2/25][950/1018]\tLoss_D: 1.3829\tLoss_G: 0.7038\tD(x): 0.4973\tD(G(z)): 0.4956 / 0.4947\n",
      "[2/25][1000/1018]\tLoss_D: 1.3887\tLoss_G: 0.6994\tD(x): 0.4966\tD(G(z)): 0.4977 / 0.4969\n",
      "[3/25][0/1018]\tLoss_D: 1.3984\tLoss_G: 0.6857\tD(x): 0.4979\tD(G(z)): 0.5039 / 0.5037\n",
      "[3/25][50/1018]\tLoss_D: 1.3878\tLoss_G: 0.6886\tD(x): 0.5017\tD(G(z)): 0.5025 / 0.5023\n",
      "[3/25][100/1018]\tLoss_D: 1.3900\tLoss_G: 0.6782\tD(x): 0.5060\tD(G(z)): 0.5077 / 0.5075\n",
      "[3/25][150/1018]\tLoss_D: 1.3818\tLoss_G: 0.6930\tD(x): 0.5026\tD(G(z)): 0.5004 / 0.5001\n",
      "[3/25][200/1018]\tLoss_D: 1.3924\tLoss_G: 0.6838\tD(x): 0.5020\tD(G(z)): 0.5050 / 0.5047\n",
      "[3/25][250/1018]\tLoss_D: 1.3874\tLoss_G: 0.6943\tD(x): 0.4992\tD(G(z)): 0.4997 / 0.4994\n",
      "[3/25][300/1018]\tLoss_D: 1.3864\tLoss_G: 0.6889\tD(x): 0.5023\tD(G(z)): 0.5023 / 0.5021\n",
      "[3/25][350/1018]\tLoss_D: 1.3904\tLoss_G: 0.6847\tD(x): 0.5029\tD(G(z)): 0.5049 / 0.5042\n",
      "[3/25][400/1018]\tLoss_D: 1.3838\tLoss_G: 0.6885\tD(x): 0.5039\tD(G(z)): 0.5026 / 0.5023\n",
      "[3/25][450/1018]\tLoss_D: 1.3890\tLoss_G: 0.6893\tD(x): 0.5011\tD(G(z)): 0.5024 / 0.5019\n",
      "[3/25][500/1018]\tLoss_D: 1.3802\tLoss_G: 0.6992\tD(x): 0.5003\tD(G(z)): 0.4971 / 0.4970\n",
      "[3/25][550/1018]\tLoss_D: 1.3911\tLoss_G: 0.6794\tD(x): 0.5052\tD(G(z)): 0.5075 / 0.5069\n",
      "[3/25][600/1018]\tLoss_D: 1.3860\tLoss_G: 0.6943\tD(x): 0.4999\tD(G(z)): 0.4997 / 0.4994\n",
      "[3/25][650/1018]\tLoss_D: 1.3928\tLoss_G: 0.6794\tD(x): 0.5039\tD(G(z)): 0.5070 / 0.5069\n",
      "[3/25][700/1018]\tLoss_D: 1.3857\tLoss_G: 0.6881\tD(x): 0.5034\tD(G(z)): 0.5030 / 0.5025\n",
      "[3/25][750/1018]\tLoss_D: 1.3885\tLoss_G: 0.6955\tD(x): 0.4983\tD(G(z)): 0.4993 / 0.4989\n",
      "[3/25][800/1018]\tLoss_D: 1.3891\tLoss_G: 0.6852\tD(x): 0.5028\tD(G(z)): 0.5042 / 0.5040\n",
      "[3/25][850/1018]\tLoss_D: 1.3824\tLoss_G: 0.6905\tD(x): 0.5036\tD(G(z)): 0.5016 / 0.5013\n",
      "[3/25][900/1018]\tLoss_D: 1.4000\tLoss_G: 0.6782\tD(x): 0.5011\tD(G(z)): 0.5079 / 0.5075\n",
      "[3/25][950/1018]\tLoss_D: 1.3821\tLoss_G: 0.6940\tD(x): 0.5020\tD(G(z)): 0.4999 / 0.4996\n",
      "[3/25][1000/1018]\tLoss_D: 1.3902\tLoss_G: 0.6800\tD(x): 0.5052\tD(G(z)): 0.5071 / 0.5066\n",
      "[4/25][0/1018]\tLoss_D: 1.3827\tLoss_G: 0.6878\tD(x): 0.5053\tD(G(z)): 0.5034 / 0.5027\n",
      "[4/25][50/1018]\tLoss_D: 1.3893\tLoss_G: 0.6825\tD(x): 0.5043\tD(G(z)): 0.5056 / 0.5054\n",
      "[4/25][100/1018]\tLoss_D: 1.3896\tLoss_G: 0.6897\tD(x): 0.5004\tD(G(z)): 0.5020 / 0.5017\n",
      "[4/25][150/1018]\tLoss_D: 1.3869\tLoss_G: 0.6954\tD(x): 0.4988\tD(G(z)): 0.4991 / 0.4989\n",
      "[4/25][200/1018]\tLoss_D: 1.3844\tLoss_G: 0.6892\tD(x): 0.5031\tD(G(z)): 0.5021 / 0.5020\n",
      "[4/25][250/1018]\tLoss_D: 1.3823\tLoss_G: 0.6903\tD(x): 0.5038\tD(G(z)): 0.5018 / 0.5014\n",
      "[4/25][300/1018]\tLoss_D: 1.3756\tLoss_G: 0.7069\tD(x): 0.4992\tD(G(z)): 0.4937 / 0.4932\n",
      "[4/25][350/1018]\tLoss_D: 1.3950\tLoss_G: 0.6826\tD(x): 0.5021\tD(G(z)): 0.5062 / 0.5053\n",
      "[4/25][400/1018]\tLoss_D: 1.3870\tLoss_G: 0.6952\tD(x): 0.4991\tD(G(z)): 0.4993 / 0.4990\n",
      "[4/25][450/1018]\tLoss_D: 1.3906\tLoss_G: 0.6846\tD(x): 0.5026\tD(G(z)): 0.5047 / 0.5043\n",
      "[4/25][500/1018]\tLoss_D: 1.3764\tLoss_G: 0.6999\tD(x): 0.5019\tD(G(z)): 0.4969 / 0.4967\n",
      "[4/25][550/1018]\tLoss_D: 1.3965\tLoss_G: 0.6796\tD(x): 0.5021\tD(G(z)): 0.5072 / 0.5068\n",
      "[4/25][600/1018]\tLoss_D: 1.3742\tLoss_G: 0.6985\tD(x): 0.5039\tD(G(z)): 0.4977 / 0.4973\n",
      "[4/25][650/1018]\tLoss_D: 1.3853\tLoss_G: 0.6845\tD(x): 0.5056\tD(G(z)): 0.5049 / 0.5044\n",
      "[4/25][700/1018]\tLoss_D: 1.3811\tLoss_G: 0.6907\tD(x): 0.5043\tD(G(z)): 0.5015 / 0.5012\n",
      "[4/25][750/1018]\tLoss_D: 1.3826\tLoss_G: 0.6982\tD(x): 0.4997\tD(G(z)): 0.4978 / 0.4975\n",
      "[4/25][800/1018]\tLoss_D: 1.3810\tLoss_G: 0.6905\tD(x): 0.5048\tD(G(z)): 0.5019 / 0.5013\n",
      "[4/25][850/1018]\tLoss_D: 1.3780\tLoss_G: 0.6953\tD(x): 0.5037\tD(G(z)): 0.4993 / 0.4989\n",
      "[4/25][900/1018]\tLoss_D: 1.3877\tLoss_G: 0.6877\tD(x): 0.5032\tD(G(z)): 0.5036 / 0.5027\n",
      "[4/25][950/1018]\tLoss_D: 1.3893\tLoss_G: 0.6916\tD(x): 0.4997\tD(G(z)): 0.5012 / 0.5008\n",
      "[4/25][1000/1018]\tLoss_D: 1.3671\tLoss_G: 0.6976\tD(x): 0.5083\tD(G(z)): 0.4980 / 0.4978\n",
      "[5/25][0/1018]\tLoss_D: 1.3858\tLoss_G: 0.6987\tD(x): 0.4980\tD(G(z)): 0.4977 / 0.4973\n",
      "[5/25][50/1018]\tLoss_D: 1.3909\tLoss_G: 0.6914\tD(x): 0.4990\tD(G(z)): 0.5011 / 0.5009\n",
      "[5/25][100/1018]\tLoss_D: 1.3911\tLoss_G: 0.6829\tD(x): 0.5032\tD(G(z)): 0.5055 / 0.5052\n",
      "[5/25][150/1018]\tLoss_D: 1.3804\tLoss_G: 0.6934\tD(x): 0.5031\tD(G(z)): 0.5000 / 0.4999\n",
      "[5/25][200/1018]\tLoss_D: 1.3855\tLoss_G: 0.6897\tD(x): 0.5031\tD(G(z)): 0.5024 / 0.5017\n",
      "[5/25][250/1018]\tLoss_D: 1.3793\tLoss_G: 0.6932\tD(x): 0.5045\tD(G(z)): 0.5007 / 0.5000\n",
      "[5/25][300/1018]\tLoss_D: 1.3686\tLoss_G: 0.7046\tD(x): 0.5045\tD(G(z)): 0.4952 / 0.4943\n",
      "[5/25][350/1018]\tLoss_D: 1.3857\tLoss_G: 0.6879\tD(x): 0.5037\tD(G(z)): 0.5031 / 0.5026\n",
      "[5/25][400/1018]\tLoss_D: 1.3772\tLoss_G: 0.6900\tD(x): 0.5070\tD(G(z)): 0.5018 / 0.5016\n",
      "[5/25][450/1018]\tLoss_D: 1.3752\tLoss_G: 0.6981\tD(x): 0.5049\tD(G(z)): 0.4984 / 0.4975\n",
      "[5/25][500/1018]\tLoss_D: 1.3555\tLoss_G: 0.6899\tD(x): 0.5195\tD(G(z)): 0.5023 / 0.5016\n",
      "[5/25][550/1018]\tLoss_D: 1.3710\tLoss_G: 0.6924\tD(x): 0.5091\tD(G(z)): 0.5009 / 0.5004\n",
      "[5/25][600/1018]\tLoss_D: 1.3682\tLoss_G: 0.6985\tD(x): 0.5081\tD(G(z)): 0.4982 / 0.4973\n",
      "[5/25][650/1018]\tLoss_D: 1.3893\tLoss_G: 0.6967\tD(x): 0.4971\tD(G(z)): 0.4985 / 0.4983\n",
      "[5/25][700/1018]\tLoss_D: 1.3746\tLoss_G: 0.6868\tD(x): 0.5104\tD(G(z)): 0.5036 / 0.5032\n",
      "[5/25][750/1018]\tLoss_D: 1.3754\tLoss_G: 0.7119\tD(x): 0.4978\tD(G(z)): 0.4920 / 0.4907\n",
      "[5/25][800/1018]\tLoss_D: 1.3853\tLoss_G: 0.6915\tD(x): 0.5026\tD(G(z)): 0.5016 / 0.5008\n",
      "[5/25][850/1018]\tLoss_D: 1.3665\tLoss_G: 0.7034\tD(x): 0.5065\tD(G(z)): 0.4952 / 0.4949\n",
      "[5/25][900/1018]\tLoss_D: 1.3495\tLoss_G: 0.7290\tD(x): 0.5034\tD(G(z)): 0.4834 / 0.4825\n",
      "[5/25][950/1018]\tLoss_D: 1.3659\tLoss_G: 0.6847\tD(x): 0.5165\tD(G(z)): 0.5048 / 0.5043\n",
      "[5/25][1000/1018]\tLoss_D: 1.3618\tLoss_G: 0.7032\tD(x): 0.5101\tD(G(z)): 0.4956 / 0.4950\n",
      "[6/25][0/1018]\tLoss_D: 1.3863\tLoss_G: 0.7036\tD(x): 0.4951\tD(G(z)): 0.4951 / 0.4948\n",
      "[6/25][50/1018]\tLoss_D: 1.3510\tLoss_G: 0.6976\tD(x): 0.5198\tD(G(z)): 0.4990 / 0.4978\n",
      "[6/25][100/1018]\tLoss_D: 1.3680\tLoss_G: 0.6953\tD(x): 0.5104\tD(G(z)): 0.5005 / 0.4991\n",
      "[6/25][150/1018]\tLoss_D: 1.3790\tLoss_G: 0.7002\tD(x): 0.5015\tD(G(z)): 0.4978 / 0.4965\n",
      "[6/25][200/1018]\tLoss_D: 1.3798\tLoss_G: 0.7035\tD(x): 0.4993\tD(G(z)): 0.4951 / 0.4948\n",
      "[6/25][250/1018]\tLoss_D: 1.3918\tLoss_G: 0.6703\tD(x): 0.5101\tD(G(z)): 0.5118 / 0.5116\n",
      "[6/25][300/1018]\tLoss_D: 1.3426\tLoss_G: 0.7172\tD(x): 0.5148\tD(G(z)): 0.4889 / 0.4882\n",
      "[6/25][350/1018]\tLoss_D: 1.3772\tLoss_G: 0.6955\tD(x): 0.5052\tD(G(z)): 0.4996 / 0.4988\n",
      "[6/25][400/1018]\tLoss_D: 1.3506\tLoss_G: 0.7171\tD(x): 0.5100\tD(G(z)): 0.4894 / 0.4882\n",
      "[6/25][450/1018]\tLoss_D: 1.3884\tLoss_G: 0.6957\tD(x): 0.4993\tD(G(z)): 0.4990 / 0.4988\n",
      "[6/25][500/1018]\tLoss_D: 1.3886\tLoss_G: 0.6915\tD(x): 0.5012\tD(G(z)): 0.5014 / 0.5008\n",
      "[6/25][550/1018]\tLoss_D: 1.4119\tLoss_G: 0.6846\tD(x): 0.5033\tD(G(z)): 0.5147 / 0.5043\n",
      "[6/25][600/1018]\tLoss_D: 1.4107\tLoss_G: 0.6519\tD(x): 0.5113\tD(G(z)): 0.5225 / 0.5211\n",
      "[6/25][650/1018]\tLoss_D: 1.3633\tLoss_G: 0.7047\tD(x): 0.5082\tD(G(z)): 0.4945 / 0.4943\n",
      "[6/25][700/1018]\tLoss_D: 1.3745\tLoss_G: 0.6977\tD(x): 0.5052\tD(G(z)): 0.4984 / 0.4977\n",
      "[6/25][750/1018]\tLoss_D: 1.3770\tLoss_G: 0.7033\tD(x): 0.5014\tD(G(z)): 0.4958 / 0.4949\n",
      "[6/25][800/1018]\tLoss_D: 1.3919\tLoss_G: 0.6811\tD(x): 0.5059\tD(G(z)): 0.5064 / 0.5061\n",
      "[6/25][850/1018]\tLoss_D: 1.3538\tLoss_G: 0.7047\tD(x): 0.5162\tD(G(z)): 0.4948 / 0.4943\n",
      "[6/25][900/1018]\tLoss_D: 1.3659\tLoss_G: 0.7124\tD(x): 0.5045\tD(G(z)): 0.4910 / 0.4905\n",
      "[6/25][950/1018]\tLoss_D: 1.3262\tLoss_G: 0.7086\tD(x): 0.5304\tD(G(z)): 0.4932 / 0.4923\n",
      "[6/25][1000/1018]\tLoss_D: 1.3869\tLoss_G: 0.7038\tD(x): 0.4958\tD(G(z)): 0.4960 / 0.4947\n",
      "[7/25][0/1018]\tLoss_D: 1.3660\tLoss_G: 0.6999\tD(x): 0.5121\tD(G(z)): 0.4974 / 0.4966\n",
      "[7/25][50/1018]\tLoss_D: 1.3555\tLoss_G: 0.7153\tD(x): 0.5100\tD(G(z)): 0.4895 / 0.4891\n",
      "[7/25][100/1018]\tLoss_D: 1.3612\tLoss_G: 0.7131\tD(x): 0.5057\tD(G(z)): 0.4904 / 0.4901\n",
      "[7/25][150/1018]\tLoss_D: 1.3209\tLoss_G: 0.6956\tD(x): 0.5433\tD(G(z)): 0.5001 / 0.4988\n",
      "[7/25][200/1018]\tLoss_D: 1.3491\tLoss_G: 0.7157\tD(x): 0.5135\tD(G(z)): 0.4898 / 0.4889\n",
      "[7/25][250/1018]\tLoss_D: 1.4194\tLoss_G: 0.6585\tD(x): 0.5063\tD(G(z)): 0.5194 / 0.5176\n",
      "[7/25][300/1018]\tLoss_D: 1.3779\tLoss_G: 0.6814\tD(x): 0.5214\tD(G(z)): 0.5136 / 0.5059\n",
      "[7/25][350/1018]\tLoss_D: 1.3994\tLoss_G: 0.6547\tD(x): 0.5148\tD(G(z)): 0.5206 / 0.5196\n",
      "[7/25][400/1018]\tLoss_D: 1.3658\tLoss_G: 0.7295\tD(x): 0.4946\tD(G(z)): 0.4834 / 0.4821\n",
      "[7/25][450/1018]\tLoss_D: 1.3433\tLoss_G: 0.7074\tD(x): 0.5185\tD(G(z)): 0.4932 / 0.4929\n",
      "[7/25][500/1018]\tLoss_D: 1.3424\tLoss_G: 0.7218\tD(x): 0.5101\tD(G(z)): 0.4867 / 0.4859\n",
      "[7/25][550/1018]\tLoss_D: 1.3962\tLoss_G: 0.6680\tD(x): 0.5108\tD(G(z)): 0.5142 / 0.5128\n",
      "[7/25][600/1018]\tLoss_D: 1.3828\tLoss_G: 0.6940\tD(x): 0.5027\tD(G(z)): 0.5002 / 0.4996\n",
      "[7/25][650/1018]\tLoss_D: 1.4084\tLoss_G: 0.6831\tD(x): 0.4949\tD(G(z)): 0.5058 / 0.5050\n",
      "[7/25][700/1018]\tLoss_D: 1.3478\tLoss_G: 0.7055\tD(x): 0.5194\tD(G(z)): 0.4948 / 0.4938\n",
      "[7/25][750/1018]\tLoss_D: 1.3395\tLoss_G: 0.7100\tD(x): 0.5241\tD(G(z)): 0.4928 / 0.4917\n",
      "[7/25][800/1018]\tLoss_D: 1.3915\tLoss_G: 0.7158\tD(x): 0.4870\tD(G(z)): 0.4893 / 0.4888\n",
      "[7/25][850/1018]\tLoss_D: 1.3791\tLoss_G: 0.7112\tD(x): 0.4973\tD(G(z)): 0.4920 / 0.4911\n",
      "[7/25][900/1018]\tLoss_D: 1.3728\tLoss_G: 0.7142\tD(x): 0.4988\tD(G(z)): 0.4899 / 0.4896\n",
      "[7/25][950/1018]\tLoss_D: 1.3925\tLoss_G: 0.7071\tD(x): 0.4909\tD(G(z)): 0.4938 / 0.4931\n",
      "[7/25][1000/1018]\tLoss_D: 1.3240\tLoss_G: 0.7222\tD(x): 0.5270\tD(G(z)): 0.4866 / 0.4857\n",
      "[8/25][0/1018]\tLoss_D: 1.3603\tLoss_G: 0.7366\tD(x): 0.4931\tD(G(z)): 0.4796 / 0.4788\n",
      "[8/25][50/1018]\tLoss_D: 1.3640\tLoss_G: 0.6806\tD(x): 0.5275\tD(G(z)): 0.5074 / 0.5063\n",
      "[8/25][100/1018]\tLoss_D: 1.3157\tLoss_G: 0.7184\tD(x): 0.5358\tD(G(z)): 0.4885 / 0.4875\n",
      "[8/25][150/1018]\tLoss_D: 1.3906\tLoss_G: 0.7058\tD(x): 0.4918\tD(G(z)): 0.4938 / 0.4937\n",
      "[8/25][200/1018]\tLoss_D: 1.3209\tLoss_G: 0.7062\tD(x): 0.5373\tD(G(z)): 0.4952 / 0.4935\n",
      "[8/25][250/1018]\tLoss_D: 1.3200\tLoss_G: 0.6895\tD(x): 0.5470\tD(G(z)): 0.5029 / 0.5018\n",
      "[8/25][300/1018]\tLoss_D: 1.4109\tLoss_G: 0.6851\tD(x): 0.4932\tD(G(z)): 0.5054 / 0.5040\n",
      "[8/25][350/1018]\tLoss_D: 1.3766\tLoss_G: 0.7088\tD(x): 0.5008\tD(G(z)): 0.4926 / 0.4922\n",
      "[8/25][400/1018]\tLoss_D: 1.3378\tLoss_G: 0.7040\tD(x): 0.5300\tD(G(z)): 0.4965 / 0.4946\n",
      "[8/25][450/1018]\tLoss_D: 1.3672\tLoss_G: 0.7104\tD(x): 0.5057\tD(G(z)): 0.4922 / 0.4915\n",
      "[8/25][500/1018]\tLoss_D: 1.4063\tLoss_G: 0.6979\tD(x): 0.4900\tD(G(z)): 0.4998 / 0.4976\n",
      "[8/25][550/1018]\tLoss_D: 1.3628\tLoss_G: 0.7013\tD(x): 0.5150\tD(G(z)): 0.4963 / 0.4959\n",
      "[8/25][600/1018]\tLoss_D: 1.3567\tLoss_G: 0.7102\tD(x): 0.5144\tD(G(z)): 0.4922 / 0.4915\n",
      "[8/25][650/1018]\tLoss_D: 1.3802\tLoss_G: 0.7192\tD(x): 0.4911\tD(G(z)): 0.4878 / 0.4871\n",
      "[8/25][700/1018]\tLoss_D: 1.3399\tLoss_G: 0.7031\tD(x): 0.5314\tD(G(z)): 0.4960 / 0.4950\n",
      "[8/25][750/1018]\tLoss_D: 1.3175\tLoss_G: 0.7870\tD(x): 0.4972\tD(G(z)): 0.4582 / 0.4552\n",
      "[8/25][800/1018]\tLoss_D: 1.3707\tLoss_G: 0.6936\tD(x): 0.5130\tD(G(z)): 0.5007 / 0.4998\n",
      "[8/25][850/1018]\tLoss_D: 1.3212\tLoss_G: 0.7290\tD(x): 0.5231\tD(G(z)): 0.4836 / 0.4824\n",
      "[8/25][900/1018]\tLoss_D: 1.3864\tLoss_G: 0.6881\tD(x): 0.5069\tD(G(z)): 0.5032 / 0.5025\n",
      "[8/25][950/1018]\tLoss_D: 1.3510\tLoss_G: 0.7220\tD(x): 0.5114\tD(G(z)): 0.4871 / 0.4858\n",
      "[8/25][1000/1018]\tLoss_D: 1.3821\tLoss_G: 0.6971\tD(x): 0.5049\tD(G(z)): 0.4990 / 0.4980\n",
      "[9/25][0/1018]\tLoss_D: 1.3040\tLoss_G: 0.7152\tD(x): 0.5461\tD(G(z)): 0.4904 / 0.4891\n",
      "[9/25][50/1018]\tLoss_D: 1.3756\tLoss_G: 0.6940\tD(x): 0.5100\tD(G(z)): 0.5002 / 0.4996\n",
      "[9/25][100/1018]\tLoss_D: 1.3977\tLoss_G: 0.7050\tD(x): 0.4898\tD(G(z)): 0.4953 / 0.4941\n",
      "[9/25][150/1018]\tLoss_D: 1.4073\tLoss_G: 0.7086\tD(x): 0.4827\tD(G(z)): 0.4928 / 0.4924\n",
      "[9/25][200/1018]\tLoss_D: 1.3543\tLoss_G: 0.7072\tD(x): 0.5138\tD(G(z)): 0.4940 / 0.4930\n",
      "[9/25][250/1018]\tLoss_D: 1.3953\tLoss_G: 0.6981\tD(x): 0.4947\tD(G(z)): 0.4990 / 0.4975\n",
      "[9/25][300/1018]\tLoss_D: 1.3334\tLoss_G: 0.7220\tD(x): 0.5261\tD(G(z)): 0.4864 / 0.4858\n",
      "[9/25][350/1018]\tLoss_D: 1.3995\tLoss_G: 0.7141\tD(x): 0.4843\tD(G(z)): 0.4906 / 0.4896\n",
      "[9/25][400/1018]\tLoss_D: 1.3620\tLoss_G: 0.7210\tD(x): 0.5029\tD(G(z)): 0.4864 / 0.4863\n",
      "[9/25][450/1018]\tLoss_D: 1.3155\tLoss_G: 0.7184\tD(x): 0.5361\tD(G(z)): 0.4879 / 0.4875\n",
      "[9/25][500/1018]\tLoss_D: 1.3694\tLoss_G: 0.7068\tD(x): 0.5067\tD(G(z)): 0.4941 / 0.4932\n",
      "[9/25][550/1018]\tLoss_D: 1.3083\tLoss_G: 0.7402\tD(x): 0.5309\tD(G(z)): 0.4781 / 0.4770\n",
      "[9/25][600/1018]\tLoss_D: 1.3596\tLoss_G: 0.7208\tD(x): 0.5058\tD(G(z)): 0.4875 / 0.4864\n",
      "[9/25][650/1018]\tLoss_D: 1.4275\tLoss_G: 0.6517\tD(x): 0.5103\tD(G(z)): 0.5255 / 0.5212\n",
      "[9/25][700/1018]\tLoss_D: 1.4126\tLoss_G: 0.6985\tD(x): 0.5140\tD(G(z)): 0.5228 / 0.4973\n",
      "[9/25][750/1018]\tLoss_D: 1.3764\tLoss_G: 0.6990\tD(x): 0.5046\tD(G(z)): 0.4989 / 0.4971\n",
      "[9/25][800/1018]\tLoss_D: 1.3646\tLoss_G: 0.6930\tD(x): 0.5153\tD(G(z)): 0.5011 / 0.5001\n",
      "[9/25][850/1018]\tLoss_D: 1.3093\tLoss_G: 0.7268\tD(x): 0.5310\tD(G(z)): 0.4845 / 0.4835\n",
      "[9/25][900/1018]\tLoss_D: 1.3562\tLoss_G: 0.7244\tD(x): 0.5023\tD(G(z)): 0.4853 / 0.4846\n",
      "[9/25][950/1018]\tLoss_D: 1.3700\tLoss_G: 0.7163\tD(x): 0.5019\tD(G(z)): 0.4906 / 0.4886\n",
      "[9/25][1000/1018]\tLoss_D: 1.3905\tLoss_G: 0.7012\tD(x): 0.4976\tD(G(z)): 0.4967 / 0.4960\n",
      "[10/25][0/1018]\tLoss_D: 1.3892\tLoss_G: 0.7028\tD(x): 0.4968\tD(G(z)): 0.4957 / 0.4952\n",
      "[10/25][50/1018]\tLoss_D: 1.3235\tLoss_G: 0.7065\tD(x): 0.5363\tD(G(z)): 0.4937 / 0.4933\n",
      "[10/25][100/1018]\tLoss_D: 1.3816\tLoss_G: 0.7140\tD(x): 0.4930\tD(G(z)): 0.4904 / 0.4897\n",
      "[10/25][150/1018]\tLoss_D: 1.2878\tLoss_G: 0.7429\tD(x): 0.5386\tD(G(z)): 0.4766 / 0.4758\n",
      "[10/25][200/1018]\tLoss_D: 1.3339\tLoss_G: 0.7358\tD(x): 0.5160\tD(G(z)): 0.4828 / 0.4791\n",
      "[10/25][250/1018]\tLoss_D: 1.4091\tLoss_G: 0.6660\tD(x): 0.5068\tD(G(z)): 0.5147 / 0.5138\n",
      "[10/25][300/1018]\tLoss_D: 1.3860\tLoss_G: 0.7219\tD(x): 0.4870\tD(G(z)): 0.4865 / 0.4858\n",
      "[10/25][350/1018]\tLoss_D: 1.3447\tLoss_G: 0.7199\tD(x): 0.5166\tD(G(z)): 0.4873 / 0.4868\n",
      "[10/25][400/1018]\tLoss_D: 1.3583\tLoss_G: 0.7325\tD(x): 0.4992\tD(G(z)): 0.4812 / 0.4807\n",
      "[10/25][450/1018]\tLoss_D: 1.3641\tLoss_G: 0.7052\tD(x): 0.5100\tD(G(z)): 0.4947 / 0.4940\n",
      "[10/25][500/1018]\tLoss_D: 1.3074\tLoss_G: 0.7105\tD(x): 0.5498\tD(G(z)): 0.4934 / 0.4914\n",
      "[10/25][550/1018]\tLoss_D: 1.3887\tLoss_G: 0.7124\tD(x): 0.4903\tD(G(z)): 0.4909 / 0.4905\n",
      "[10/25][600/1018]\tLoss_D: 1.4061\tLoss_G: 0.6867\tD(x): 0.4999\tD(G(z)): 0.5058 / 0.5033\n",
      "[10/25][650/1018]\tLoss_D: 1.3647\tLoss_G: 0.7385\tD(x): 0.4909\tD(G(z)): 0.4795 / 0.4778\n",
      "[10/25][700/1018]\tLoss_D: 1.4074\tLoss_G: 0.6878\tD(x): 0.4938\tD(G(z)): 0.5042 / 0.5027\n",
      "[10/25][750/1018]\tLoss_D: 1.3676\tLoss_G: 0.7100\tD(x): 0.5101\tD(G(z)): 0.4926 / 0.4916\n",
      "[10/25][800/1018]\tLoss_D: 1.3446\tLoss_G: 0.7324\tD(x): 0.5113\tD(G(z)): 0.4810 / 0.4807\n",
      "[10/25][850/1018]\tLoss_D: 1.3792\tLoss_G: 0.7209\tD(x): 0.4907\tD(G(z)): 0.4864 / 0.4863\n",
      "[10/25][900/1018]\tLoss_D: 1.3305\tLoss_G: 0.7164\tD(x): 0.5261\tD(G(z)): 0.4894 / 0.4885\n",
      "[10/25][950/1018]\tLoss_D: 1.3343\tLoss_G: 0.7450\tD(x): 0.5059\tD(G(z)): 0.4756 / 0.4747\n",
      "[10/25][1000/1018]\tLoss_D: 1.4380\tLoss_G: 0.6596\tD(x): 0.4929\tD(G(z)): 0.5183 / 0.5171\n",
      "[11/25][0/1018]\tLoss_D: 1.4081\tLoss_G: 0.6850\tD(x): 0.4966\tD(G(z)): 0.5070 / 0.5041\n",
      "[11/25][50/1018]\tLoss_D: 1.3443\tLoss_G: 0.7227\tD(x): 0.5144\tD(G(z)): 0.4857 / 0.4854\n",
      "[11/25][100/1018]\tLoss_D: 1.3648\tLoss_G: 0.7141\tD(x): 0.5061\tD(G(z)): 0.4908 / 0.4896\n",
      "[11/25][150/1018]\tLoss_D: 1.3044\tLoss_G: 0.7141\tD(x): 0.5483\tD(G(z)): 0.4901 / 0.4896\n",
      "[11/25][200/1018]\tLoss_D: 1.3461\tLoss_G: 0.7410\tD(x): 0.5026\tD(G(z)): 0.4780 / 0.4766\n",
      "[11/25][250/1018]\tLoss_D: 1.3495\tLoss_G: 0.6885\tD(x): 0.5311\tD(G(z)): 0.5047 / 0.5023\n",
      "[11/25][300/1018]\tLoss_D: 1.4122\tLoss_G: 0.6857\tD(x): 0.4951\tD(G(z)): 0.5076 / 0.5037\n",
      "[11/25][350/1018]\tLoss_D: 1.4105\tLoss_G: 0.6896\tD(x): 0.4955\tD(G(z)): 0.5029 / 0.5018\n",
      "[11/25][400/1018]\tLoss_D: 1.3208\tLoss_G: 0.7102\tD(x): 0.5424\tD(G(z)): 0.4922 / 0.4915\n",
      "[11/25][450/1018]\tLoss_D: 1.3723\tLoss_G: 0.7338\tD(x): 0.4884\tD(G(z)): 0.4806 / 0.4801\n",
      "[11/25][500/1018]\tLoss_D: 1.3177\tLoss_G: 0.7119\tD(x): 0.5395\tD(G(z)): 0.4916 / 0.4907\n",
      "[11/25][550/1018]\tLoss_D: 1.3863\tLoss_G: 0.6822\tD(x): 0.5158\tD(G(z)): 0.5063 / 0.5055\n",
      "[11/25][600/1018]\tLoss_D: 1.3704\tLoss_G: 0.6964\tD(x): 0.5167\tD(G(z)): 0.4996 / 0.4984\n",
      "[11/25][650/1018]\tLoss_D: 1.3320\tLoss_G: 0.7186\tD(x): 0.5296\tD(G(z)): 0.4880 / 0.4874\n",
      "[11/25][700/1018]\tLoss_D: 1.3288\tLoss_G: 0.7206\tD(x): 0.5299\tD(G(z)): 0.4876 / 0.4865\n",
      "[11/25][750/1018]\tLoss_D: 1.3857\tLoss_G: 0.7269\tD(x): 0.4847\tD(G(z)): 0.4838 / 0.4834\n",
      "[11/25][800/1018]\tLoss_D: 1.3524\tLoss_G: 0.7285\tD(x): 0.5055\tD(G(z)): 0.4834 / 0.4826\n",
      "[11/25][850/1018]\tLoss_D: 1.3854\tLoss_G: 0.7202\tD(x): 0.4881\tD(G(z)): 0.4872 / 0.4866\n",
      "[11/25][900/1018]\tLoss_D: 1.3626\tLoss_G: 0.7023\tD(x): 0.5176\tD(G(z)): 0.4963 / 0.4955\n",
      "[11/25][950/1018]\tLoss_D: 1.3577\tLoss_G: 0.7115\tD(x): 0.5154\tD(G(z)): 0.4915 / 0.4909\n",
      "[11/25][1000/1018]\tLoss_D: 1.3343\tLoss_G: 0.7243\tD(x): 0.5200\tD(G(z)): 0.4855 / 0.4847\n",
      "[12/25][0/1018]\tLoss_D: 1.3291\tLoss_G: 0.7419\tD(x): 0.5112\tD(G(z)): 0.4769 / 0.4762\n",
      "[12/25][50/1018]\tLoss_D: 1.3810\tLoss_G: 0.6996\tD(x): 0.5062\tD(G(z)): 0.4995 / 0.4968\n",
      "[12/25][100/1018]\tLoss_D: 1.3508\tLoss_G: 0.7454\tD(x): 0.4949\tD(G(z)): 0.4765 / 0.4745\n",
      "[12/25][150/1018]\tLoss_D: 1.4205\tLoss_G: 0.6417\tD(x): 0.5164\tD(G(z)): 0.5276 / 0.5264\n",
      "[12/25][200/1018]\tLoss_D: 1.3856\tLoss_G: 0.7128\tD(x): 0.5147\tD(G(z)): 0.5088 / 0.4903\n",
      "[12/25][250/1018]\tLoss_D: 1.4483\tLoss_G: 0.6137\tD(x): 0.5181\tD(G(z)): 0.5452 / 0.5414\n",
      "[12/25][300/1018]\tLoss_D: 1.3542\tLoss_G: 0.7313\tD(x): 0.5031\tD(G(z)): 0.4814 / 0.4814\n",
      "[12/25][350/1018]\tLoss_D: 1.3260\tLoss_G: 0.7051\tD(x): 0.5327\tD(G(z)): 0.4945 / 0.4940\n",
      "[12/25][400/1018]\tLoss_D: 1.3128\tLoss_G: 0.7197\tD(x): 0.5352\tD(G(z)): 0.4875 / 0.4869\n",
      "[12/25][450/1018]\tLoss_D: 1.3436\tLoss_G: 0.7313\tD(x): 0.5097\tD(G(z)): 0.4838 / 0.4813\n",
      "[12/25][500/1018]\tLoss_D: 1.3775\tLoss_G: 0.7210\tD(x): 0.4956\tD(G(z)): 0.4862 / 0.4863\n",
      "[12/25][550/1018]\tLoss_D: 1.4144\tLoss_G: 0.6599\tD(x): 0.5096\tD(G(z)): 0.5196 / 0.5169\n",
      "[12/25][600/1018]\tLoss_D: 1.3595\tLoss_G: 0.7255\tD(x): 0.5039\tD(G(z)): 0.4859 / 0.4841\n",
      "[12/25][650/1018]\tLoss_D: 1.3847\tLoss_G: 0.7001\tD(x): 0.5028\tD(G(z)): 0.4993 / 0.4965\n",
      "[12/25][700/1018]\tLoss_D: 1.3596\tLoss_G: 0.7240\tD(x): 0.4994\tD(G(z)): 0.4857 / 0.4848\n",
      "[12/25][750/1018]\tLoss_D: 1.3879\tLoss_G: 0.6702\tD(x): 0.5216\tD(G(z)): 0.5136 / 0.5116\n",
      "[12/25][800/1018]\tLoss_D: 1.3759\tLoss_G: 0.7422\tD(x): 0.4833\tD(G(z)): 0.4770 / 0.4761\n",
      "[12/25][850/1018]\tLoss_D: 1.3437\tLoss_G: 0.7401\tD(x): 0.5078\tD(G(z)): 0.4781 / 0.4771\n",
      "[12/25][900/1018]\tLoss_D: 1.3754\tLoss_G: 0.7601\tD(x): 0.4756\tD(G(z)): 0.4684 / 0.4676\n",
      "[12/25][950/1018]\tLoss_D: 1.3873\tLoss_G: 0.6829\tD(x): 0.5099\tD(G(z)): 0.5059 / 0.5052\n",
      "[12/25][1000/1018]\tLoss_D: 1.3366\tLoss_G: 0.7398\tD(x): 0.5086\tD(G(z)): 0.4788 / 0.4772\n",
      "[13/25][0/1018]\tLoss_D: 1.3328\tLoss_G: 0.7353\tD(x): 0.5123\tD(G(z)): 0.4804 / 0.4794\n",
      "[13/25][50/1018]\tLoss_D: 1.3137\tLoss_G: 0.7579\tD(x): 0.5108\tD(G(z)): 0.4696 / 0.4687\n",
      "[13/25][100/1018]\tLoss_D: 1.4354\tLoss_G: 0.6460\tD(x): 0.5066\tD(G(z)): 0.5257 / 0.5242\n",
      "[13/25][150/1018]\tLoss_D: 1.3691\tLoss_G: 0.7359\tD(x): 0.4940\tD(G(z)): 0.4802 / 0.4791\n",
      "[13/25][200/1018]\tLoss_D: 1.3278\tLoss_G: 0.7423\tD(x): 0.5153\tD(G(z)): 0.4767 / 0.4760\n",
      "[13/25][250/1018]\tLoss_D: 1.4073\tLoss_G: 0.6665\tD(x): 0.5091\tD(G(z)): 0.5147 / 0.5135\n",
      "[13/25][300/1018]\tLoss_D: 1.3204\tLoss_G: 0.7125\tD(x): 0.5373\tD(G(z)): 0.4915 / 0.4904\n",
      "[13/25][350/1018]\tLoss_D: 1.3720\tLoss_G: 0.6921\tD(x): 0.5122\tD(G(z)): 0.5010 / 0.5005\n",
      "[13/25][400/1018]\tLoss_D: 1.3409\tLoss_G: 0.6941\tD(x): 0.5377\tD(G(z)): 0.5011 / 0.4995\n",
      "[13/25][450/1018]\tLoss_D: 1.3030\tLoss_G: 0.7641\tD(x): 0.5188\tD(G(z)): 0.4666 / 0.4657\n",
      "[13/25][500/1018]\tLoss_D: 1.3981\tLoss_G: 0.7104\tD(x): 0.4878\tD(G(z)): 0.4924 / 0.4915\n",
      "[13/25][550/1018]\tLoss_D: 1.3651\tLoss_G: 0.7174\tD(x): 0.5054\tD(G(z)): 0.4886 / 0.4880\n",
      "[13/25][600/1018]\tLoss_D: 1.3628\tLoss_G: 0.7152\tD(x): 0.5078\tD(G(z)): 0.4911 / 0.4891\n",
      "[13/25][650/1018]\tLoss_D: 1.3211\tLoss_G: 0.7032\tD(x): 0.5417\tD(G(z)): 0.4952 / 0.4950\n",
      "[13/25][700/1018]\tLoss_D: 1.3609\tLoss_G: 0.6971\tD(x): 0.5176\tD(G(z)): 0.5002 / 0.4980\n",
      "[13/25][750/1018]\tLoss_D: 1.3375\tLoss_G: 0.7668\tD(x): 0.4921\tD(G(z)): 0.4658 / 0.4645\n",
      "[13/25][800/1018]\tLoss_D: 1.3990\tLoss_G: 0.6654\tD(x): 0.5147\tD(G(z)): 0.5158 / 0.5141\n",
      "[13/25][850/1018]\tLoss_D: 1.3792\tLoss_G: 0.7035\tD(x): 0.5051\tD(G(z)): 0.4967 / 0.4948\n",
      "[13/25][900/1018]\tLoss_D: 1.3517\tLoss_G: 0.7044\tD(x): 0.5210\tD(G(z)): 0.4950 / 0.4944\n",
      "[13/25][950/1018]\tLoss_D: 1.3701\tLoss_G: 0.7158\tD(x): 0.5042\tD(G(z)): 0.4912 / 0.4888\n",
      "[13/25][1000/1018]\tLoss_D: 1.3273\tLoss_G: 0.7502\tD(x): 0.5086\tD(G(z)): 0.4738 / 0.4723\n",
      "[14/25][0/1018]\tLoss_D: 1.3570\tLoss_G: 0.6990\tD(x): 0.5145\tD(G(z)): 0.4987 / 0.4971\n",
      "[14/25][50/1018]\tLoss_D: 1.4208\tLoss_G: 0.6954\tD(x): 0.4841\tD(G(z)): 0.5008 / 0.4989\n",
      "[14/25][100/1018]\tLoss_D: 1.3719\tLoss_G: 0.7076\tD(x): 0.5113\tD(G(z)): 0.4942 / 0.4928\n",
      "[14/25][150/1018]\tLoss_D: 1.2798\tLoss_G: 0.7495\tD(x): 0.5452\tD(G(z)): 0.4728 / 0.4726\n",
      "[14/25][200/1018]\tLoss_D: 1.3370\tLoss_G: 0.7147\tD(x): 0.5239\tD(G(z)): 0.4900 / 0.4893\n",
      "[14/25][250/1018]\tLoss_D: 1.3100\tLoss_G: 0.7209\tD(x): 0.5392\tD(G(z)): 0.4878 / 0.4863\n",
      "[14/25][300/1018]\tLoss_D: 1.3934\tLoss_G: 0.6977\tD(x): 0.4955\tD(G(z)): 0.4988 / 0.4977\n",
      "[14/25][350/1018]\tLoss_D: 1.4090\tLoss_G: 0.7038\tD(x): 0.4852\tD(G(z)): 0.4962 / 0.4947\n",
      "[14/25][400/1018]\tLoss_D: 1.3216\tLoss_G: 0.7511\tD(x): 0.5154\tD(G(z)): 0.4725 / 0.4718\n",
      "[14/25][450/1018]\tLoss_D: 1.3246\tLoss_G: 0.7243\tD(x): 0.5271\tD(G(z)): 0.4852 / 0.4847\n",
      "[14/25][500/1018]\tLoss_D: 1.3096\tLoss_G: 0.7420\tD(x): 0.5257\tD(G(z)): 0.4781 / 0.4762\n",
      "[14/25][550/1018]\tLoss_D: 1.3161\tLoss_G: 0.7296\tD(x): 0.5254\tD(G(z)): 0.4839 / 0.4821\n",
      "[14/25][600/1018]\tLoss_D: 1.3622\tLoss_G: 0.7193\tD(x): 0.5067\tD(G(z)): 0.4892 / 0.4871\n",
      "[14/25][650/1018]\tLoss_D: 1.3421\tLoss_G: 0.7328\tD(x): 0.5139\tD(G(z)): 0.4817 / 0.4805\n",
      "[14/25][700/1018]\tLoss_D: 1.3386\tLoss_G: 0.7331\tD(x): 0.5097\tD(G(z)): 0.4807 / 0.4804\n",
      "[14/25][750/1018]\tLoss_D: 1.3993\tLoss_G: 0.7123\tD(x): 0.4854\tD(G(z)): 0.4913 / 0.4905\n",
      "[14/25][800/1018]\tLoss_D: 1.3414\tLoss_G: 0.7432\tD(x): 0.5054\tD(G(z)): 0.4771 / 0.4756\n",
      "[14/25][850/1018]\tLoss_D: 1.3777\tLoss_G: 0.7093\tD(x): 0.5041\tD(G(z)): 0.4946 / 0.4920\n",
      "[14/25][900/1018]\tLoss_D: 1.3969\tLoss_G: 0.6808\tD(x): 0.5028\tD(G(z)): 0.5076 / 0.5062\n",
      "[14/25][950/1018]\tLoss_D: 1.3906\tLoss_G: 0.6984\tD(x): 0.4976\tD(G(z)): 0.4989 / 0.4974\n",
      "[14/25][1000/1018]\tLoss_D: 1.3421\tLoss_G: 0.7380\tD(x): 0.5113\tD(G(z)): 0.4790 / 0.4781\n",
      "[15/25][0/1018]\tLoss_D: 1.3412\tLoss_G: 0.7290\tD(x): 0.5124\tD(G(z)): 0.4826 / 0.4824\n",
      "[15/25][50/1018]\tLoss_D: 1.3367\tLoss_G: 0.7239\tD(x): 0.5206\tD(G(z)): 0.4859 / 0.4849\n",
      "[15/25][100/1018]\tLoss_D: 1.3471\tLoss_G: 0.7746\tD(x): 0.4831\tD(G(z)): 0.4615 / 0.4609\n",
      "[15/25][150/1018]\tLoss_D: 1.3285\tLoss_G: 0.7077\tD(x): 0.5369\tD(G(z)): 0.4941 / 0.4928\n",
      "[15/25][200/1018]\tLoss_D: 1.3638\tLoss_G: 0.7021\tD(x): 0.5133\tD(G(z)): 0.4970 / 0.4956\n",
      "[15/25][250/1018]\tLoss_D: 1.2910\tLoss_G: 0.7057\tD(x): 0.5623\tD(G(z)): 0.4952 / 0.4938\n",
      "[15/25][300/1018]\tLoss_D: 1.3309\tLoss_G: 0.7203\tD(x): 0.5257\tD(G(z)): 0.4880 / 0.4866\n",
      "[15/25][350/1018]\tLoss_D: 1.2970\tLoss_G: 0.7552\tD(x): 0.5228\tD(G(z)): 0.4721 / 0.4700\n",
      "[15/25][400/1018]\tLoss_D: 1.4055\tLoss_G: 0.6918\tD(x): 0.4959\tD(G(z)): 0.5045 / 0.5007\n",
      "[15/25][450/1018]\tLoss_D: 1.3727\tLoss_G: 0.7225\tD(x): 0.4941\tD(G(z)): 0.4859 / 0.4855\n",
      "[15/25][500/1018]\tLoss_D: 1.1434\tLoss_G: 0.9298\tD(x): 0.5488\tD(G(z)): 0.4057 / 0.3948\n",
      "[15/25][550/1018]\tLoss_D: 1.3978\tLoss_G: 0.6813\tD(x): 0.5056\tD(G(z)): 0.5088 / 0.5060\n",
      "[15/25][600/1018]\tLoss_D: 1.2963\tLoss_G: 0.7290\tD(x): 0.5448\tD(G(z)): 0.4835 / 0.4824\n",
      "[15/25][650/1018]\tLoss_D: 1.3713\tLoss_G: 0.7252\tD(x): 0.4972\tD(G(z)): 0.4849 / 0.4843\n",
      "[15/25][700/1018]\tLoss_D: 1.3589\tLoss_G: 0.7437\tD(x): 0.4914\tD(G(z)): 0.4765 / 0.4754\n",
      "[15/25][750/1018]\tLoss_D: 1.3649\tLoss_G: 0.6606\tD(x): 0.5392\tD(G(z)): 0.5171 / 0.5166\n",
      "[15/25][800/1018]\tLoss_D: 1.3670\tLoss_G: 0.7201\tD(x): 0.5090\tD(G(z)): 0.4948 / 0.4867\n",
      "[15/25][850/1018]\tLoss_D: 1.3400\tLoss_G: 0.7469\tD(x): 0.4991\tD(G(z)): 0.4751 / 0.4738\n",
      "[15/25][900/1018]\tLoss_D: 1.3748\tLoss_G: 0.7278\tD(x): 0.4929\tD(G(z)): 0.4853 / 0.4830\n",
      "[15/25][950/1018]\tLoss_D: 1.2986\tLoss_G: 0.7576\tD(x): 0.5293\tD(G(z)): 0.4706 / 0.4688\n",
      "[15/25][1000/1018]\tLoss_D: 1.3703\tLoss_G: 0.6827\tD(x): 0.5239\tD(G(z)): 0.5067 / 0.5052\n",
      "[16/25][0/1018]\tLoss_D: 1.4128\tLoss_G: 0.6734\tD(x): 0.5008\tD(G(z)): 0.5130 / 0.5100\n",
      "[16/25][50/1018]\tLoss_D: 1.3068\tLoss_G: 0.7631\tD(x): 0.5091\tD(G(z)): 0.4679 / 0.4662\n",
      "[16/25][100/1018]\tLoss_D: 1.4023\tLoss_G: 0.6420\tD(x): 0.5324\tD(G(z)): 0.5295 / 0.5263\n",
      "[16/25][150/1018]\tLoss_D: 1.3949\tLoss_G: 0.7282\tD(x): 0.4804\tD(G(z)): 0.4839 / 0.4828\n",
      "[16/25][200/1018]\tLoss_D: 1.3422\tLoss_G: 0.7206\tD(x): 0.5198\tD(G(z)): 0.4867 / 0.4865\n",
      "[16/25][250/1018]\tLoss_D: 1.3096\tLoss_G: 0.7393\tD(x): 0.5321\tD(G(z)): 0.4784 / 0.4775\n",
      "[16/25][300/1018]\tLoss_D: 1.3151\tLoss_G: 0.7808\tD(x): 0.5015\tD(G(z)): 0.4589 / 0.4581\n",
      "[16/25][350/1018]\tLoss_D: 1.3461\tLoss_G: 0.6902\tD(x): 0.5339\tD(G(z)): 0.5029 / 0.5015\n",
      "[16/25][400/1018]\tLoss_D: 1.3223\tLoss_G: 0.7174\tD(x): 0.5334\tD(G(z)): 0.4898 / 0.4880\n",
      "[16/25][450/1018]\tLoss_D: 1.3139\tLoss_G: 0.7424\tD(x): 0.5250\tD(G(z)): 0.4780 / 0.4760\n",
      "[16/25][500/1018]\tLoss_D: 1.3292\tLoss_G: 0.7063\tD(x): 0.5413\tD(G(z)): 0.4968 / 0.4934\n",
      "[16/25][550/1018]\tLoss_D: 1.3188\tLoss_G: 0.6932\tD(x): 0.5485\tD(G(z)): 0.5005 / 0.5000\n",
      "[16/25][600/1018]\tLoss_D: 1.3217\tLoss_G: 0.7413\tD(x): 0.5178\tD(G(z)): 0.4778 / 0.4765\n",
      "[16/25][650/1018]\tLoss_D: 1.3852\tLoss_G: 0.6787\tD(x): 0.5196\tD(G(z)): 0.5094 / 0.5073\n",
      "[16/25][700/1018]\tLoss_D: 1.3096\tLoss_G: 0.7476\tD(x): 0.5279\tD(G(z)): 0.4740 / 0.4735\n",
      "[16/25][750/1018]\tLoss_D: 1.3417\tLoss_G: 0.7216\tD(x): 0.5173\tD(G(z)): 0.4883 / 0.4860\n",
      "[16/25][800/1018]\tLoss_D: 1.3396\tLoss_G: 0.7278\tD(x): 0.5135\tD(G(z)): 0.4849 / 0.4830\n",
      "[16/25][850/1018]\tLoss_D: 1.4039\tLoss_G: 0.6946\tD(x): 0.4915\tD(G(z)): 0.4998 / 0.4993\n",
      "[16/25][900/1018]\tLoss_D: 1.3604\tLoss_G: 0.7204\tD(x): 0.5064\tD(G(z)): 0.4877 / 0.4866\n",
      "[16/25][950/1018]\tLoss_D: 1.3567\tLoss_G: 0.7412\tD(x): 0.4991\tD(G(z)): 0.4782 / 0.4766\n",
      "[16/25][1000/1018]\tLoss_D: 1.3038\tLoss_G: 0.7731\tD(x): 0.5107\tD(G(z)): 0.4635 / 0.4616\n",
      "[17/25][0/1018]\tLoss_D: 1.2557\tLoss_G: 0.8017\tD(x): 0.5282\tD(G(z)): 0.4506 / 0.4486\n",
      "[17/25][50/1018]\tLoss_D: 1.3775\tLoss_G: 0.6583\tD(x): 0.5425\tD(G(z)): 0.5227 / 0.5178\n",
      "[17/25][100/1018]\tLoss_D: 1.2751\tLoss_G: 0.7315\tD(x): 0.5634\tD(G(z)): 0.4826 / 0.4812\n",
      "[17/25][150/1018]\tLoss_D: 1.3381\tLoss_G: 0.7501\tD(x): 0.5043\tD(G(z)): 0.4725 / 0.4723\n",
      "[17/25][200/1018]\tLoss_D: 1.2745\tLoss_G: 0.7586\tD(x): 0.5458\tD(G(z)): 0.4734 / 0.4683\n",
      "[17/25][250/1018]\tLoss_D: 1.3902\tLoss_G: 0.7368\tD(x): 0.4842\tD(G(z)): 0.4846 / 0.4787\n",
      "[17/25][300/1018]\tLoss_D: 1.3852\tLoss_G: 0.6857\tD(x): 0.5186\tD(G(z)): 0.5080 / 0.5038\n",
      "[17/25][350/1018]\tLoss_D: 1.3633\tLoss_G: 0.6767\tD(x): 0.5298\tD(G(z)): 0.5087 / 0.5083\n",
      "[17/25][400/1018]\tLoss_D: 1.4035\tLoss_G: 0.6807\tD(x): 0.4991\tD(G(z)): 0.5070 / 0.5062\n",
      "[17/25][450/1018]\tLoss_D: 1.2662\tLoss_G: 0.7424\tD(x): 0.5577\tD(G(z)): 0.4775 / 0.4760\n",
      "[17/25][500/1018]\tLoss_D: 1.3286\tLoss_G: 0.7609\tD(x): 0.4985\tD(G(z)): 0.4675 / 0.4673\n",
      "[17/25][550/1018]\tLoss_D: 1.3614\tLoss_G: 0.6627\tD(x): 0.5478\tD(G(z)): 0.5182 / 0.5154\n",
      "[17/25][600/1018]\tLoss_D: 1.3565\tLoss_G: 0.7277\tD(x): 0.5054\tD(G(z)): 0.4837 / 0.4830\n",
      "[17/25][650/1018]\tLoss_D: 1.3333\tLoss_G: 0.7884\tD(x): 0.4901\tD(G(z)): 0.4556 / 0.4546\n",
      "[17/25][700/1018]\tLoss_D: 1.3963\tLoss_G: 0.7279\tD(x): 0.4875\tD(G(z)): 0.4884 / 0.4829\n",
      "[17/25][750/1018]\tLoss_D: 1.3735\tLoss_G: 0.7320\tD(x): 0.4895\tD(G(z)): 0.4823 / 0.4809\n",
      "[17/25][800/1018]\tLoss_D: 1.3491\tLoss_G: 0.7242\tD(x): 0.5101\tD(G(z)): 0.4862 / 0.4847\n",
      "[17/25][850/1018]\tLoss_D: 1.3608\tLoss_G: 0.6751\tD(x): 0.5334\tD(G(z)): 0.5105 / 0.5091\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "# Lists to keep track of progress\n",
    "record_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        # Update Discriminator with Real Data\n",
    "        discriminator.zero_grad()\n",
    "        real_data, _ = batch\n",
    "        real_labels = torch.ones(real_data.size(0), 1)\n",
    "        output_real = discriminator(real_data)\n",
    "        loss_real = criterion(output_real, real_labels)\n",
    "        \n",
    "        # Update Discriminator with Fake Data\n",
    "        noise = torch.randn(real_data.size(0), noise_dim)\n",
    "        fake_data = generator(noise)\n",
    "        fake_labels = torch.zeros(real_data.size(0), 1)\n",
    "        output_fake = discriminator(fake_data.detach())\n",
    "        loss_fake = criterion(output_fake, fake_labels)\n",
    "        \n",
    "        # Combine Losses for discriminator and Update\n",
    "        loss_disc = loss_real + loss_fake\n",
    "        loss_disc.backward()\n",
    "        optimizer_discriminator.step()\n",
    "        \n",
    "        # Update Generator\n",
    "        generator.zero_grad()\n",
    "        output = discriminator(fake_data)\n",
    "        loss_gen = criterion(output, real_labels)\n",
    "        loss_gen.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' \n",
    "                  % (epoch, epochs, i, len(dataloader), loss_disc.item(), loss_gen.item(), output_real.mean().item(), output_fake.mean().item(), output.mean().item()))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(loss_gen.item())\n",
    "        D_losses.append(loss_disc.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = generator(noise).detach().cpu()\n",
    "            record_list.append(fake)\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "# Save models for each trial temporarily\n",
    "model_dir = f'../experiments/vanilla_gan/model/vanillaGAN'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "torch.save(generator.state_dict(), os.path.join(model_dir, 'generator.pth'))\n",
    "torch.save(discriminator.state_dict(), os.path.join(model_dir, 'discriminator.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-09T13:43:19.295824900Z"
    }
   },
   "id": "870a5828d36d7689"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4898e0dfb6022175"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Finetuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfbaeb8ba22ee9d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initial experiments on 50 epochs with some initial parameters show a lot of the expected behaviours such as early fluctations in losses.\n",
    "\n",
    "However, the discriminator loss seems to decrease, while the generator loss seems to increase most of the times (though, not necessarily in an oscillation manner, which would somewhat be expected). The discriminator loss reaches a point where it becomes really small, like the generator loss increases towards a loss of 5.\n",
    "\n",
    "As a way to experiment with other parameters to see its performance, we'll utilize Optuma's Hyperparameter optimizer to potentially find better hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7db614e56ccff6e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: Do not run when implementing basic"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c3ac3667dc118ea"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def optuna_optimize(trial, X, dataloader):\n",
    "    # Define Hyperparameters to optimize\n",
    "    lr_gen = trial.suggest_float('lr_gen', 1e-5, 1e-3)\n",
    "    lr_disc = trial.suggest_float('lr_disc', 1e-5, 1e-3)\n",
    "\n",
    "    # Initialize Models\n",
    "    generator = Generator(input_dim=100, output_dim=X.shape[1])\n",
    "    discriminator = Discriminator(input_dim=X.shape[1])\n",
    "    \n",
    "    # Optimizers\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_gen = optim.Adam(generator.parameters(), lr=lr_gen)\n",
    "    optimizer_disc = optim.Adam(discriminator.parameters(), lr=lr_disc)\n",
    "\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, _) in enumerate(dataloader):\n",
    "            # Number of data points\n",
    "            n_data = data.size(0)\n",
    "\n",
    "            # Train Discriminator\n",
    "            real_data = data\n",
    "            real_labels = torch.ones(n_data, 1)\n",
    "            fake_labels = torch.zeros(n_data, 1)\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            output_real = discriminator(real_data)\n",
    "            loss_real = criterion(output_real, real_labels)\n",
    "\n",
    "            noise = torch.randn(n_data, 100)\n",
    "            fake_data = generator(noise)\n",
    "            output_fake = discriminator(fake_data.detach())\n",
    "            loss_fake = criterion(output_fake, fake_labels)\n",
    "\n",
    "            loss_d = loss_real + loss_fake\n",
    "            loss_d.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            output = discriminator(fake_data)\n",
    "            loss_g = criterion(output, real_labels)\n",
    "            loss_g.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "    # Example metric to optimize could be the last generator loss\n",
    "    metric_to_optimize = loss_g.item()\n",
    "\n",
    "    # Save models for each trial temporarily\n",
    "    trial_model_dir = f'../experiments/vanilla_gan/hyperparam/trial_{trial.number}_models'\n",
    "    os.makedirs(trial_model_dir, exist_ok=True)\n",
    "    torch.save(generator.state_dict(), os.path.join(trial_model_dir, 'generator.pth'))\n",
    "    torch.save(discriminator.state_dict(), os.path.join(trial_model_dir, 'discriminator.pth'))\n",
    "\n",
    "    return metric_to_optimize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T09:36:09.921511500Z",
     "start_time": "2024-04-09T09:36:09.908099100Z"
    }
   },
   "id": "3202a4468fa819ba"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# After optimization, save best models more permanently\n",
    "def save_best_models(study, temporary_dir_base='../experiments/vanilla_gan/hyperparam/trial_'):\n",
    "    best_trial = study.best_trial.number\n",
    "    best_model_dir = f'{temporary_dir_base}{best_trial}_models'\n",
    "    permanent_model_dir = '../experiments/vanilla_gan/hyperparam/best_models'\n",
    "    os.makedirs(permanent_model_dir, exist_ok=True)\n",
    "\n",
    "    for filename in ['generator.pth', 'discriminator.pth']:\n",
    "        os.rename(os.path.join(best_model_dir, filename), os.path.join(permanent_model_dir, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T09:38:05.437979400Z",
     "start_time": "2024-04-09T09:38:05.421920600Z"
    }
   },
   "id": "f48ea505f9887d8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 11:39:01,595] A new study created in memory with name: no-name-c6e01eb7-64e8-48d2-9c69-ff55177fcbc6\n",
      "[I 2024-04-09 11:41:33,780] Trial 0 finished with value: 3.9634597301483154 and parameters: {'lr_gen': 0.0005823623488330192, 'lr_disc': 0.0005330975301795992}. Best is trial 0 with value: 3.9634597301483154.\n",
      "[I 2024-04-09 11:45:16,675] Trial 1 finished with value: 0.7557632923126221 and parameters: {'lr_gen': 0.00040376804222956743, 'lr_disc': 2.019033675863192e-05}. Best is trial 1 with value: 0.7557632923126221.\n",
      "[I 2024-04-09 11:49:17,799] Trial 2 finished with value: 6.742520809173584 and parameters: {'lr_gen': 9.557589328417663e-05, 'lr_disc': 0.0007941945708970818}. Best is trial 1 with value: 0.7557632923126221.\n",
      "[I 2024-04-09 11:53:03,011] Trial 3 finished with value: 8.19099235534668 and parameters: {'lr_gen': 0.0003946931431209802, 'lr_disc': 0.0008924853452325022}. Best is trial 1 with value: 0.7557632923126221.\n",
      "[I 2024-04-09 11:55:23,580] Trial 4 finished with value: 15.078088760375977 and parameters: {'lr_gen': 0.0007834994028226539, 'lr_disc': 0.0004383492032951644}. Best is trial 1 with value: 0.7557632923126221.\n",
      "[I 2024-04-09 11:57:38,242] Trial 5 finished with value: 14.594559669494629 and parameters: {'lr_gen': 0.0008849310079883301, 'lr_disc': 4.2466320171249054e-05}. Best is trial 1 with value: 0.7557632923126221.\n",
      "[I 2024-04-09 12:31:22,602] Trial 6 finished with value: 4.808167457580566 and parameters: {'lr_gen': 0.00045505122464101905, 'lr_disc': 0.0004623319687466765}. Best is trial 1 with value: 0.7557632923126221.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: optuna_optimize(trial, X, dataloader), n_trials=20)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-09T09:39:01.595997700Z"
    }
   },
   "id": "c7ba4aef2d9c01d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the best models after optimization\n",
    "save_best_models(study)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bd4dc1ecba2a48c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_parallel_coordinate\n",
    "\n",
    "# Generate the plot\n",
    "fig = plot_parallel_coordinate(study)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4c2e7f18c87c0d56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66e672f474cfdbe5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
