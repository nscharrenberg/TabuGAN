{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa4nnkdUKwWj",
        "outputId": "b0b87869-7040-487d-d55b-57f863db7af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ],
      "source": [
        "pip install ucimlrepo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh0R_vmTKyTg",
        "outputId": "262bf0b6-5200-45dd-cc05-63a71851cf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 20, 'name': 'Census Income', 'repository_url': 'https://archive.ics.uci.edu/dataset/20/census+income', 'data_url': 'https://archive.ics.uci.edu/static/public/20/data.csv', 'abstract': 'Predict whether income exceeds $50K/yr based on census data.  Also known as Adult dataset.', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5GP7S', 'creators': ['Ron Kohavi'], 'intro_paper': None, 'additional_info': {'summary': 'Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\r\\n\\r\\nPrediction task is to determine whether a person makes over 50K a year.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
            "              name     role         type      demographic  \\\n",
            "0              age  Feature      Integer              Age   \n",
            "1        workclass  Feature  Categorical           Income   \n",
            "2           fnlwgt  Feature      Integer             None   \n",
            "3        education  Feature  Categorical  Education Level   \n",
            "4    education-num  Feature      Integer  Education Level   \n",
            "5   marital-status  Feature  Categorical            Other   \n",
            "6       occupation  Feature  Categorical            Other   \n",
            "7     relationship  Feature  Categorical            Other   \n",
            "8             race  Feature  Categorical             Race   \n",
            "9              sex  Feature       Binary              Sex   \n",
            "10    capital-gain  Feature      Integer             None   \n",
            "11    capital-loss  Feature      Integer             None   \n",
            "12  hours-per-week  Feature      Integer             None   \n",
            "13  native-country  Feature  Categorical            Other   \n",
            "14          income   Target       Binary           Income   \n",
            "\n",
            "                                          description units missing_values  \n",
            "0                                                 N/A  None             no  \n",
            "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
            "2                                                None  None             no  \n",
            "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
            "4                                                None  None             no  \n",
            "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
            "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
            "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
            "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
            "9                                       Female, Male.  None             no  \n",
            "10                                               None  None             no  \n",
            "11                                               None  None             no  \n",
            "12                                               None  None             no  \n",
            "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
            "14                                       >50K, <=50K.  None             no  \n",
            "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "48842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e56af3f46060>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y['income'] = y['income'].replace('<=50K.', '<=50K', regex=True)\n",
            "<ipython-input-2-e56af3f46060>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y['income'] = y['income'].replace('>50K.', '>50K', regex=True)\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "# fetch dataset\n",
        "census_income = fetch_ucirepo(id=20)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = census_income.data.features\n",
        "y = census_income.data.targets\n",
        "y['income'] = y['income'].replace('<=50K.', '<=50K', regex=True)\n",
        "y['income'] = y['income'].replace('>50K.', '>50K', regex=True)\n",
        "X = pd.concat([X, pd.DataFrame(y)], axis=1)\n",
        "# metadata\n",
        "print(census_income.metadata)\n",
        "\n",
        "# variable information\n",
        "print(census_income.variables)\n",
        "print(X.columns)\n",
        "print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xDFMF2BDLRuu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "def preprocess_data(data, categorical_columns, numerical_columns):\n",
        "    # Separate categorical and numerical columns\n",
        "    X_cat = data[categorical_columns]\n",
        "    X_num = data[numerical_columns]\n",
        "\n",
        "    # One-hot encode categorical columns\n",
        "    cat_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "    X_cat = cat_encoder.fit_transform(X_cat)\n",
        "\n",
        "    # Standardize numerical columns\n",
        "    num_scaler = StandardScaler()\n",
        "    X_num = num_scaler.fit_transform(X_num)\n",
        "\n",
        "    return X_num, X_cat, cat_encoder, num_scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1DhCnFMeKw_4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects.packages import importr\n",
        "import pyarrow as pa\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, attention_hidden_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(attention_hidden_size, attention_hidden_size).to(device)\n",
        "\n",
        "    def forward(self, encoder_outputs):\n",
        "      # Transform x using a linear layer; output shape will be (sq, b, hidden_size)\n",
        "      x_transformed = self.linear(encoder_outputs)\n",
        "      # Step 2: Compute attention scores using softmax across the sequence dimension (sq)\n",
        "      # Attention scores shape: (sq, b, hidden_size) -> (b, sq, hidden_size) for softmax\n",
        "      x_transposed = x_transformed.transpose(0, 1)  # Transposing for softmax operation\n",
        "      attention_scores = F.softmax(x_transposed, dim=1)  # Applying softmax; shape remains (b, sq, hidden_size)\n",
        "      # Step 3: Apply attention scores to the original input tensor\n",
        "      # For weighted sum, first transpose x back: (sq, b, hidden_size) -> (b, sq, hidden_size)\n",
        "      x = encoder_outputs.transpose(0, 1)  # Transposing x to match attention_scores shape\n",
        "      # Compute the context vector as the weighted sum of the input vectors\n",
        "      # (b, sq, hidden_size) * (b, sq, hidden_size) -> (b, hidden_size) after summing over sq dimension\n",
        "      context_vector = torch.sum(attention_scores * x, dim=1)\n",
        "      return context_vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, latent_size,only_z=False):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear5 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear6 = nn.Linear(hidden_size, latent_size)\n",
        "        self.linear_mu = nn.Linear(latent_size, latent_size)\n",
        "        self.linear_logvar = nn.Linear(latent_size, latent_size)\n",
        "        self.only_z = only_z\n",
        "        self.relu1 = nn.GELU()\n",
        "        self.relu2 = nn.GELU()\n",
        "        self.relu3 = nn.GELU()\n",
        "        self.relu4 = nn.GELU()\n",
        "        self.relu5 = nn.GELU()\n",
        "        self.relu6 = nn.GELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.linear1(x))\n",
        "        out = self.relu2(self.linear2(out))\n",
        "        out = self.relu3(self.linear3(out))\n",
        "        out = self.relu4(self.linear4(out))\n",
        "        out = self.relu5(self.linear5(out))\n",
        "        out = self.relu6(self.linear6(out))\n",
        "        mu = self.linear_mu(out)\n",
        "        logvar = self.linear_logvar(out)\n",
        "\n",
        "        # Reparameterization trick (as before)\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = eps.mul(std).add_(mu)\n",
        "        if self.only_z:\n",
        "          return z\n",
        "        return z, mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(latent_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.relu1 = nn.GELU()\n",
        "        self.relu2 = nn.GELU()\n",
        "        self.relu3 = nn.GELU()\n",
        "        self.relu4 = nn.GELU()\n",
        "        self.output=None\n",
        "\n",
        "    def forward(self, z, sig=False):\n",
        "        #print(\"decoder 1: \",z.shape)\n",
        "        #print(\"decoder 1: \",z)\n",
        "        out = self.relu1(self.linear1(z))\n",
        "        out = self.relu2(self.linear2(out))\n",
        "        out = self.relu3(self.linear3(out))\n",
        "        out = self.relu4(self.linear4(out))\n",
        "        out = self.output_layer(out)\n",
        "        self.output=out\n",
        "        return out\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, latent_size, cat=False):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size, latent_size).to(device)\n",
        "        self.decoder = Decoder(latent_size, hidden_size, input_size).to(device)\n",
        "        self.cat=cat\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.cat:\n",
        "          z, logits = self.encoder(x,True)\n",
        "          recon = self.decoder(z,True)\n",
        "          return recon, logits\n",
        "        else:\n",
        "          z, mu, logvar = self.encoder(x)\n",
        "          recon = self.decoder(z)\n",
        "          return recon, mu, logvar\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVNvFy0Opu_x",
        "outputId": "d6557476-06a0-4d82-9d29-0976557f979d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48842, 107)\n",
            "torch.Size([2, 5671])\n",
            "torch.Size([5671, 131])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "rbf_hsic_matrix = torch.load('rbf_hsic_matrix_updated.pt')\n",
        "linear_hsic_matrix = torch.load('linear_hsic_matrix_updated.pt')\n",
        "mutual_information_matrix = torch.load('mutual_information_matrix.pt')\n",
        "distance_correlation_matrix = torch.load('distance_correlation_matrix.pt')\n",
        "chi2_matrix = torch.load('chi2_matrix.pt')\n",
        "theils_u_matrix = torch.load('theils_u_matrix.pt')\n",
        "cramers_v_matrix = torch.load('cramers_v_matrix.pt')\n",
        "\n",
        "def load_measure_matrix(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data['matrix'], data['feature_names']\n",
        "\n",
        "agreement_matrix, agreement_feature_names = load_measure_matrix('agreement_matrix.pkl')\n",
        "binary_matrix, binary_feature_names = load_measure_matrix('binary_matrix.pkl')\n",
        "categorical_matrix, categorical_feature_names = load_measure_matrix('categorical_matrix.pkl')\n",
        "confusion_matrix, confusion_feature_names = load_measure_matrix('confusion_matrix.pkl')\n",
        "\n",
        "num_features = rbf_hsic_matrix.shape[0]\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country','income']\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "X_encoded = encoder.fit_transform(X[categorical_columns])\n",
        "feature_names = encoder.get_feature_names_out(categorical_columns)\n",
        "\n",
        "column_mapping = {}\n",
        "start_index = 0\n",
        "for col in categorical_columns:\n",
        "    column_mapping[col] = start_index\n",
        "    start_index += len(encoder.categories_[categorical_columns.index(col)])\n",
        "\n",
        "print(X_encoded.shape)\n",
        "\n",
        "index = []\n",
        "attr = []\n",
        "\n",
        "for i in range(num_features):\n",
        "    for j in range(i + 1, num_features):\n",
        "        index.append([i, j])\n",
        "\n",
        "        # Find the categorical columns associated with features i and j\n",
        "        col_i = next(col for col, start_idx in column_mapping.items() if start_idx <= i < start_idx + len(encoder.categories_[categorical_columns.index(col)]))\n",
        "        col_j = next(col for col, start_idx in column_mapping.items() if start_idx <= j < start_idx + len(encoder.categories_[categorical_columns.index(col)]))\n",
        "\n",
        "        # Create the categorical column vector (1 for the corresponding column, 0 otherwise)\n",
        "        categorical_col_vec = np.zeros(len(categorical_columns))\n",
        "        categorical_col_vec[categorical_columns.index(col_i)] = 1\n",
        "        categorical_col_vec[categorical_columns.index(col_j)] = 1\n",
        "\n",
        "        list1 = [linear_hsic_matrix[i, j],\n",
        "            rbf_hsic_matrix[i, j],\n",
        "            mutual_information_matrix[i, j],\n",
        "            distance_correlation_matrix[i, j],\n",
        "            chi2_matrix[i, j],\n",
        "            theils_u_matrix[i, j],\n",
        "            cramers_v_matrix[i, j]]\n",
        "       # print(agreement_matrix[i][j])\n",
        "        for measure in agreement_matrix[i][j].keys():\n",
        "          list1.append(agreement_matrix[i][j][measure])\n",
        "      #  print(binary_matrix[i][j])\n",
        "        for measure in binary_matrix[i][j].keys():\n",
        "          if measure == 'mcnemar_test':\n",
        "            list1.append(binary_matrix[i][j][measure][0])\n",
        "          else:\n",
        "            list1.append(binary_matrix[i][j][measure])\n",
        "       # print(categorical_matrix[i][j])\n",
        "        for measure in categorical_matrix[i][j].keys():\n",
        "          list1.append(categorical_matrix[i][j][measure])\n",
        "       # print(confusion_matrix[i][j])\n",
        "        for measure in confusion_matrix[i][j].keys():\n",
        "          list1.append(confusion_matrix[i][j][measure])\n",
        "        list1.extend(categorical_col_vec)\n",
        "        #for ele in list1:\n",
        "          #  print(ele, type(ele))\n",
        "      #  print(list1)\n",
        "        attr.append(list1)\n",
        "\n",
        "\n",
        "index = torch.tensor(index, dtype=torch.long).t().contiguous()\n",
        "attr = torch.tensor(attr, dtype=torch.float).to(device)\n",
        "print(index.shape)\n",
        "print(attr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV8ZZHK56qhs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch\n",
        "index1 = index[0]\n",
        "index2 = index[1]\n",
        "\n",
        "X_encoded = torch.tensor(X_encoded)\n",
        "# Optimization using torch.expand and torch.gather\n",
        "index1_expanded = index1.expand(X_encoded.shape[0], -1)\n",
        "index2_expanded = index2.expand(X_encoded.shape[0], -1)\n",
        "print(index1_expanded.shape)\n",
        "# Efficiently gather feature pairs using indexing\n",
        "features1 = torch.gather(X_encoded, dim=1, index=index1_expanded)\n",
        "features2 = torch.gather(X_encoded, dim=1, index=index2_expanded)\n",
        "\n",
        "dataset = list(zip(torch.stack([features1, features2], dim=2),X_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLjGwJ9jYgU5"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "neighborhoods = defaultdict(list)\n",
        "for i in range(index.shape[1]):\n",
        "    n1_index = index1[i].item()\n",
        "    n2_index = index2[i].item()\n",
        "    neighborhoods[n1_index].append(i)\n",
        "    neighborhoods[n2_index].append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJWvNSnBlXWp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Bernoulli\n",
        "class ConditionalBatchNorm1d(nn.Module):\n",
        "    def __init__(self, num_features, num_conditions):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.gamma_layer = nn.Linear(num_conditions, num_features)\n",
        "        self.beta_layer = nn.Linear(num_conditions, num_features)\n",
        "\n",
        "    def forward(self, input, condition):\n",
        "\n",
        "        out = F.batch_norm(input, None, None, training=True).to(device)  # Standard batch normalization\n",
        "        gamma = self.gamma_layer(condition).to(device)\n",
        "        beta = self.beta_layer(condition).to(device)\n",
        "\n",
        "        out = gamma * out + beta\n",
        "\n",
        "        return out\n",
        "\n",
        "class DeepLinear(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond=None):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DeepConv(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_output_shape, neighbourhoods):\n",
        "        super().__init__()\n",
        "        self.num_variables = 107\n",
        "        self.e_features = attr.shape[1]\n",
        "        self.e_scoring_network = DeepLinear(self.num_variables+self.e_features, hidden_dim, output_dim=1)\n",
        "        self.neighborhood_agg_network = DeepLinear(len(neighbourhoods[0]),hidden_dim, n_output_shape)\n",
        "        self.output_dim = n_output_shape * len(neighbourhoods)\n",
        "        max_neighborhood_size = max(len(v) for v in neighborhoods.values())\n",
        "        neighborhood_edge_indices = torch.zeros((len(neighborhoods), max_neighborhood_size), dtype=torch.long)\n",
        "        for node_index, edge_list in neighborhoods.items():\n",
        "          neighborhood_edge_indices[node_index] = torch.tensor(edge_list)\n",
        "        self.neighbourhoods = neighborhood_edge_indices.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.requires_grad=True\n",
        "        batch_size = x.shape[0]\n",
        "        # Save original values\n",
        "        original_x0 = x[:, :, 0] # .clone() necessary here\n",
        "        original_x1 = x[:, :, 1]\n",
        "        x_mod = torch.zeros(batch_size, x.shape[1], self.num_variables,requires_grad=True).to(device)\n",
        "        index1_expanded = index1.unsqueeze(0).expand(x_mod.shape[0], -1).to(device)\n",
        "        index2_expanded = index2.unsqueeze(0).expand(x_mod.shape[0], -1).to(device)\n",
        "\n",
        "        x_mod = torch.scatter(x_mod, 2, index1_expanded.unsqueeze(2), original_x0.unsqueeze(2))\n",
        "        x_mod = torch.scatter(x_mod, 2, index2_expanded.unsqueeze(2), original_x1.unsqueeze(2))\n",
        "        broadcasted_attr = attr.unsqueeze(0).expand(x_mod.shape[0], -1, -1)\n",
        "        final_tensor = torch.cat([x_mod, broadcasted_attr], dim=2)\n",
        "        all_edge_scores = self.e_scoring_network(final_tensor).squeeze()\n",
        "        neighborhood_edge_indices = self.neighbourhoods[None, :, :]\n",
        "        neighborhood_edge_indices=neighborhood_edge_indices.expand(all_edge_scores.shape[0],-1,-1)\n",
        "        batch_size, v, r = neighborhood_edge_indices.shape\n",
        "        e = all_edge_scores.shape[1]\n",
        "        vector1_expanded = all_edge_scores.unsqueeze(1).expand(-1, v, -1)\n",
        "        neighborhood_scores = torch.gather(vector1_expanded, 2, neighborhood_edge_indices)\n",
        "        neighborhood_outputs = self.neighborhood_agg_network(neighborhood_scores)\n",
        "        output = neighborhood_outputs.flatten(start_dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "h_i = torch.tensor([[1.0, 2.0, 3.0, 4.0], [10.0, 20.0, 30.0, 40.0], [9.0,8.0,7.0,6.0],[-7.0,-2.3,-5.3,-4.2]])\n",
        "odd = torch.tensor([False, True,False,True])\n",
        "new_values = torch.tensor([[5.0, 5.6,5.8,5.9],[0.6,0.8,0.4,0.2]])\n",
        "\n",
        "index = odd.nonzero().repeat(1,h_i.shape[1])\n",
        "print(index)\n",
        "# 3. Perform the scattering\n",
        "updated_h_i = torch.scatter(h_i, dim=0, index=odd.nonzero().repeat(1,h_i.shape[1]), src=new_values)\n",
        "\n",
        "print(updated_h_i)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eif3e07gygmI",
        "outputId": "c2792e05-428c-4eb8-9b9d-ce5fab02d751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1],\n",
            "        [3, 3, 3, 3]])\n",
            "tensor([[1.0000, 2.0000, 3.0000, 4.0000],\n",
            "        [5.0000, 5.6000, 5.8000, 5.9000],\n",
            "        [9.0000, 8.0000, 7.0000, 6.0000],\n",
            "        [0.6000, 0.8000, 0.4000, 0.2000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGIG2eEiRQPJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "class BernoulliApproximator(nn.Module):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(2, hidden_dim)\n",
        "    self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.linear4 = nn.Linear(hidden_dim, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.x=None\n",
        "    self.out1 = None\n",
        "    self.out2 = None\n",
        "    self.out3 = None\n",
        "    self.out4 = None\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.x=x\n",
        "    out = self.relu(self.linear1(x))\n",
        "    self.out1 = out\n",
        "    out = self.relu(self.linear2(out))\n",
        "    self.out2 = out\n",
        "    out = self.relu(self.linear3(out))\n",
        "    self.out3 = out\n",
        "    out = torch.sigmoid(self.linear4(out))\n",
        "    self.out4 = out\n",
        "    return out\n",
        "\n",
        "class ComparatorNetwork(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            nn.Linear(2, hidden_dim),  # Input dimension changed to 2\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1)  # Output remains the same\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.layers(x))\n",
        "\n",
        "model = torch.load('bernoullimodel4.pth')\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.data = param.data.double()\n",
        "\n",
        "class BernoulliSampleFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, probabilities):\n",
        "        result = torch.zeros_like(probabilities)\n",
        "        out4 = []\n",
        "        out3 = []\n",
        "        out2 = []\n",
        "        out1 = []\n",
        "        for i in range(probabilities.shape[1]):\n",
        "          randomNumber =  (torch.rand((probabilities.shape[0]))*16).double()\n",
        "          result[:,i] = model(torch.concat((probabilities[:,i].unsqueeze(1),randomNumber.unsqueeze(1)),dim=1)).squeeze().double()\n",
        "          out4.append(model.out4)\n",
        "          out3.append(model.out3)\n",
        "          out2.append(model.out2)\n",
        "          out1.append(model.out1)\n",
        "        out1 = torch.stack(out1, dim=0)\n",
        "        out2 = torch.stack(out2, dim=0)\n",
        "        out3 = torch.stack(out3, dim=0)\n",
        "        out4 = torch.stack(out4, dim=0)\n",
        "        ctx.save_for_backward(result,out4,out3,out2,out1) # Store for backward pass\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      result, out4, out3, out2, out1= ctx.saved_tensors\n",
        "      print(\"result: \",result)\n",
        "      toReturn = torch.zeros_like(result)\n",
        "      for i in range(result.shape[1]):\n",
        "        print(\"linear 4:\" ,model.linear4.in_features, \" : \",model.linear4.out_features)\n",
        "        linear4_copy = nn.Linear(model.linear4.in_features, model.linear4.out_features).to(device)\n",
        "        linear4_copy.weight.data.copy_(model.linear4.weight.data.clone().detach().double())\n",
        "        linear4_copy.bias.data.copy_(model.linear4.bias.data.clone().detach().double())\n",
        "        print(\"grad_output i : \",out4[i,:,:].shape)\n",
        "        print(out4[i,:,:])\n",
        "        delta = out4[i,:,:].double()  # Sigmoid derivative\n",
        "        print(\"l4 w: \",linear4_copy.weight.shape)\n",
        "        delta = torch.mm(delta, linear4_copy.weight.double())\n",
        "\n",
        "        # Backpropagation through hidden layers (ReLU)\n",
        "        linear3_copy = nn.Linear(model.linear3.in_features, model.linear3.out_features).to(device)\n",
        "        linear3_copy.weight.data.copy_(model.linear3.weight.data.clone().detach().double())\n",
        "        linear3_copy.bias.data.copy_(model.linear3.bias.data.clone().detach().double())\n",
        "        delta = delta * torch.where(out3[i,:,:] > 0, 1, 0)  # Derivative of ReLU\n",
        "        delta = torch.mm(delta, linear3_copy.weight.double())\n",
        "\n",
        "\n",
        "        linear2_copy = nn.Linear(model.linear2.in_features, model.linear2.out_features).to(device)\n",
        "        linear2_copy.weight.data.copy_(model.linear2.weight.data.clone().detach().double())\n",
        "        linear2_copy.bias.data.copy_(model.linear2.bias.data.clone().detach().double())\n",
        "        delta = delta * torch.where(out2[i,:,:] > 0, 1, 0)  # Derivative of ReLU\n",
        "        delta = torch.mm(delta, linear2_copy.weight.double())\n",
        "\n",
        "\n",
        "        # Backpropagate through first layer (ReLU)\n",
        "        linear1_copy = nn.Linear(model.linear1.in_features, model.linear1.out_features).to(device)\n",
        "        linear1_copy.weight.data.copy_(model.linear1.weight.data.clone().detach().double())\n",
        "        linear1_copy.bias.data.copy_(model.linear1.bias.data.clone().detach().double())\n",
        "        delta = delta * torch.where(out1[i,:,:] > 0, 1, 0)  # Derivative of ReLU w.r.t. input x\n",
        "        delta = torch.mm(delta, linear1_copy.weight.double())\n",
        "        print(\"delta: \",delta)\n",
        "        print(delta.shape)\n",
        "        toReturn[:,i] = delta[:,0]\n",
        "      print(\"toReturn: \",toReturn)\n",
        "      return toReturn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model2 = torch.load('greater_than_model.pth')\n",
        "\n",
        "class DBM(nn.Module):\n",
        "    def __init__(self, nv, hidden_layers, ComparatorNetwork):\n",
        "        super().__init__()\n",
        "        self.input_layer = DeepConv(128,1,neighborhoods)\n",
        "        self.weight = nn.ParameterList([nn.Parameter(torch.Tensor(hidden_layers[0], nv))])\n",
        "        for i in range(len(hidden_layers)-1):\n",
        "          self.weight.append(nn.Parameter(torch.Tensor(hidden_layers[i+1], hidden_layers[i])))\n",
        "        self.bias = nn.ParameterList([nn.Parameter(torch.Tensor(nv))])\n",
        "        for i in range(len(hidden_layers)):\n",
        "          self.bias.append(nn.Parameter(torch.Tensor(hidden_layers[i])))\n",
        "\n",
        "        self.nv = nv\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.L = len(hidden_layers)\n",
        "\n",
        "        self.output_layer = Decoder(hidden_layers[-1],128,nv)\n",
        "\n",
        "        self.reset_parameters()\n",
        "        self.greaterThanApprox = ComparatorNetwork\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for w in self.weight:\n",
        "            nn.init.orthogonal_(w)\n",
        "\n",
        "        for b in self.bias:\n",
        "            nn.init.zeros_(b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        v_prob = torch.sigmoid(self.input_layer(x).squeeze())\n",
        "        N = v_prob.size(0)\n",
        "        device = x.device\n",
        "        input = v_prob.clone()\n",
        "        assert self.L != 1\n",
        "        print(\"Gradients of v_prob1:\", v_prob)\n",
        "        energy_pos_samples = self.positive_phase(1, N, v_prob)\n",
        "        print(\"energy_pos: \",torch.mean(torch.stack(energy_pos_samples)))\n",
        "        energy_neg_samples = self.negative_phase(1, N)\n",
        "        print(\"energy_neg: \",torch.mean(torch.stack(energy_neg_samples)))\n",
        "        energy_loss = torch.mean(torch.stack(energy_pos_samples)) - torch.mean(torch.stack(energy_neg_samples))\n",
        "        for i in range(self.L):\n",
        "          if i==0:\n",
        "            input = F.linear(input+self.bias[0], self.weight[i], self.bias[i+1])\n",
        "          else:\n",
        "            input = F.linear(input, self.weight[i], self.bias[i+1])\n",
        "        return energy_loss, self.output_layer(input,True)\n",
        "    def positive_phase(self, num_samples, N, v_prob):\n",
        "      energy_pos_samples = []  # Store energy samples\n",
        "      for _ in range(num_samples):\n",
        "        v = self.bernoulli_sample(v_prob)\n",
        "        print(\"gradinets of v: \",v)\n",
        "        h = []\n",
        "        for i in range(self.L):\n",
        "          h_i = torch.full((N, self.hidden_layers[i]), 0.5, device=device,requires_grad=True)\n",
        "          print(\"Gradients of h_i:\", h_i.grad)\n",
        "          h_i = self.bernoulli_sample(h_i)\n",
        "          print(\"Gradients of h_i 1:\", h_i.grad)\n",
        "          h.append(h_i)\n",
        "        v, h = self.local_search(v, h, True)\n",
        "        print(\"Gradients of v1:\", v.grad)\n",
        "        print(\"Gradients of h1:\", [h_i.grad for h_i in h])\n",
        "        v, h = self.gibbs_step(v, h, True)\n",
        "        print(\"Gradients of v2:\", v.grad)\n",
        "        print(\"Gradients of h2:\", [h_i.grad for h_i in h])\n",
        "        energy_pos, v, h = self.coupling(v, h, True)\n",
        "        print(\"Gradients of v3:\", v.grad)\n",
        "        print(\"Gradients of h3:\", [h_i.grad for h_i in h])\n",
        "        energy_pos_samples.append(energy_pos)\n",
        "      return energy_pos_samples\n",
        "\n",
        "    def negative_phase(self, num_samples, N):\n",
        "      energy_neg_samples = []  # Store energy samples\n",
        "\n",
        "      for _ in range(num_samples):\n",
        "        v = self.bernoulli_sample(torch.full((N, self.nv), 0.5, device=device, requires_grad=True))\n",
        "        h = []\n",
        "        for i in range(self.L):\n",
        "            probs = torch.full((N, self.hidden_layers[i]), 0.5, device=device, requires_grad=True)\n",
        "            h_i = self.bernoulli_sample(probs)\n",
        "            h.append(h_i)\n",
        "        v, h = self.local_search(v, h)\n",
        "        v, h = self.gibbs_step(v, h)\n",
        "        energy_neg, v, h = self.coupling(v, h)\n",
        "        energy_neg_samples.append(energy_neg)\n",
        "      return energy_neg_samples\n",
        "\n",
        "\n",
        "    def local_search(self, v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device= v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        rand_u = torch.rand(N, device=device)\n",
        "        print(\"gradinets of v2: \",v)\n",
        "        print(\"Gradients of h2:\", [h_i.grad for h_i in h])\n",
        "        v, h = self.gibbs_step(v, h, fix_v, rand_u=rand_u, T=0)\n",
        "        print(\"gradinets of v21: \",v)\n",
        "        print(\"Gradients of h21:\", [h_i.grad for h_i in h])\n",
        "        converged = torch.ones(N, dtype=torch.bool, device=device) if fix_v \\\n",
        "                    else self.equals(v, _v)\n",
        "        for i in range(self.L):\n",
        "            converged = converged.logical_and(self.equals(h[i], _h[i]))\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(self.L)]\n",
        "            M = _v.size(0)\n",
        "            print(\"gradinets of v3: \",v)\n",
        "            print(\"Gradients of h3:\", [h_i.grad for h_i in h])\n",
        "            v_, h_ = self.gibbs_step(_v, _h, fix_v,\n",
        "                                     rand_u=rand_u[not_converged], T=0)\n",
        "            print(\"gradinets of v31: \",v)\n",
        "            print(\"Gradients of h31:\", [h_i.grad for h_i in h])\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = self.equals(v_, _v)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(self.L):\n",
        "                converged_ = converged_.logical_and(self.equals(h_[i], _h[i]))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "\n",
        "        return v, h\n",
        "\n",
        "    def equals(self, a, b):\n",
        "      similarity_scores = abs(a-b)\n",
        "      return torch.all(similarity_scores < 0.4, dim=1)\n",
        "\n",
        "    def coupling(self, v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        v, h = self.mh_step(v, h, fix_v)\n",
        "        energy = self.energy(v, h)\n",
        "        if fix_v:\n",
        "          converged = torch.ones(N, dtype=torch.bool, device=device)\n",
        "        else:\n",
        "          converged = self.equals(v, _v)\n",
        "        for i in range(self.L):\n",
        "            converged = converged.logical_and(self.equals(h[i], _h[i]))\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(self.L)]\n",
        "            M = _v.size(0)\n",
        "            rand_v = None if fix_v else torch.rand_like(_v)\n",
        "            rand_h = [torch.rand_like(_h[i]) for i in range(self.L)]\n",
        "            rand_u = torch.rand(M, device=device)\n",
        "            v_, h_ = self.mh_step(_v, _h, fix_v, rand_v, rand_h, rand_u)\n",
        "            aaa = self.energy(v_, h_)\n",
        "            bbb = self.energy(_v, _h)\n",
        "            energy[not_converged] = energy[not_converged] + (aaa - bbb)\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = self.equals(v_, _v)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(self.L):\n",
        "                converged_ = converged_.logical_and(self.equals(h_[i], _h[i]))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "        return energy, v, h\n",
        "\n",
        "    def energy(self, v, h):\n",
        "        energy = - torch.sum(v * self.bias[0].unsqueeze(0), 1)\n",
        "        for i in range(self.L):\n",
        "            logits = F.linear(v if i==0 else h[i-1], self.weight[i], self.bias[i+1])\n",
        "\n",
        "            energy = energy - torch.sum(h[i] * logits, 1)\n",
        "        return energy\n",
        "\n",
        "    def greaterThan(self,a,b):\n",
        "      if len(a.shape)>1:\n",
        "        result = torch.zeros_like(a)\n",
        "        for i in range(a.shape[1]):\n",
        "          result[:,i] = self.greaterThanApprox(torch.concat((a[:,i].unsqueeze(1),b[:,i].unsqueeze(1)),dim=1)).squeeze()\n",
        "        return result\n",
        "      else:\n",
        "        return self.greaterThanApprox(torch.concat((a.unsqueeze(1),b.unsqueeze(1)),dim=1)).squeeze()\n",
        "\n",
        "    def bernoulli_sample(self,probabilities):\n",
        "      return BernoulliSampleFunction.apply(probabilities)\n",
        "\n",
        "    def gibbs_step(self, v, h, fix_v=False,\n",
        "                   rand_v=None, rand_h=None, rand_u=None, rand_z=None, T=1):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "\n",
        "        v_ = v\n",
        "        h_ = h\n",
        "\n",
        "        if rand_u is None:\n",
        "            rand_u = torch.rand(N, device=device)\n",
        "\n",
        "        even = rand_u < 0.5\n",
        "        odd = even.logical_not()\n",
        "        if even.sum() > 0:\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h_[0][even],\n",
        "                                  self.weight[0].t(), self.bias[0])\n",
        "\n",
        "                if T == 0:\n",
        "                    v_ = torch.scatter(v_,0,even.nonzero().repeat(1,v_.shape[1]),self.greaterThan(logits,torch.full_like(logits,0.0,requires_grad=True)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v_ = torch.scatter(v_,0,even.nonzero().repeat(1,v_.shape[1]),self.bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        v_ = torch.scatter(v_,0,even.nonzero().repeat(1,v_.shape[1]),self.greaterThan(logits.sigmoid(),rand_v[even]))\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h_[i-1][even], self.weight[i], self.bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h_[i+1][even], self.weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i] =  torch.scatter(h_[i], 0, even.nonzero().repeat(1,h_[i].shape[1]),self.greaterThan(logits,torch.full_like(logits,0.0,requires_grad=True)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, even.nonzero().repeat(1,h_[i].shape[1]),self.bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, even.nonzero().repeat(1,h_[i].shape[1]),self.greaterThan(logits.sigmoid(),rand_h[i][even]))\n",
        "\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v_[even] if i==0 else h_[i-1][even],\n",
        "                                  self.weight[i], self.bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h_[i+1][even], self.weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i] = torch.scatter(h_[i], 0, even.nonzero().repeat(1,h_[i].shape[1]),self.greaterThan(logits,torch.full_like(logits,0.0,requires_grad=True)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, even.nonzero().repeat(1,h_[i].shape[1]),self.bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, even.nonzero().repeat(1,h_[i].shape[1]),self.greaterThan(logits.sigmoid(),rand_h[i][even]))\n",
        "\n",
        "        if odd.sum() > 0:\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v_[odd] if i==0 else h_[i-1][odd], self.weight[i], self.bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h_[i+1][odd], self.weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i] =  torch.scatter(h_[i], 0, odd.nonzero().repeat(1,h_[i].shape[1]),self.greaterThan(logits,torch.full_like(logits,0.0,requires_grad=True)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, odd.nonzero().repeat(1,h_[i].shape[1]),self.bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, odd.nonzero().repeat(1,h_[i].shape[1]),self.greaterThan(logits.sigmoid(),rand_h[i][odd]))\n",
        "\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h_[0][odd], self.weight[0].t(), self.bias[0])\n",
        "\n",
        "                if T == 0:\n",
        "                    v_ =  torch.scatter(v_,0,odd.nonzero().repeat(1,v_.shape[1]),self.greaterThan(logits,torch.full_like(logits,0.0,requires_grad=True)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v_ = torch.scatter(v_,0,odd.nonzero().repeat(1,v_.shape[1]),self.bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        v_ = torch.scatter(v_,0,odd.nonzero().repeat(1,v_.shape[1]),self.greaterThan(logits.sigmoid(),rand_v[odd]))\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h_[i-1][odd], self.weight[i], self.bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h_[i+1][odd], self.weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i] = torch.scatter(h_[i], 0, odd.nonzero().repeat(1,h_[i].shape[1]), self.greaterThan(logits,torch.full_like(logits,0.0,requires_grad=True)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, odd.nonzero().repeat(1,h_[i].shape[1]), self.bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h_[i] = torch.scatter(h_[i], 0, odd.nonzero().repeat(1,h_[i].shape[1]), self.greaterThan(logits.sigmoid(),rand_h[i][odd]))\n",
        "        return v_, h_\n",
        "\n",
        "\n",
        "    def mh_step(self, v, h, fix_v=False,\n",
        "                rand_v=None, rand_h=None, rand_u=None):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        print(\"Gradients of v before bernoulli_sample:\", v.grad)\n",
        "        if fix_v:\n",
        "            v_ = v\n",
        "        else:\n",
        "            if rand_v is None:\n",
        "                v_ = self.bernoulli_sample(torch.sigmoid(torch.full_like(v,0.5,requires_grad=True)))\n",
        "            else:\n",
        "                v_ = self.greaterThan(torch.full_like(rand_v,0.5, requires_grad=True),rand_v)\n",
        "        print(\"Gradients of v_ after bernoulli_sample/greaterThan:\", v_.grad)\n",
        "        print(\"Gradients of h before bernoulli_sample/greaterThan:\", [h_i.grad for h_i in h])\n",
        "        if rand_h is None:\n",
        "\n",
        "            h_ = [torch.full_like(h[i],0.5,requires_grad=True) for i in range(self.L)]\n",
        "            for i in range(self.L):\n",
        "              h_[i] = self.bernoulli_sample(torch.sigmoid(h_[i]))\n",
        "        else:\n",
        "            h_ = [torch.ones_like(h[i],requires_grad=True) for i in range(self.L)]\n",
        "            for i in range(self.L):\n",
        "              h_[i]=self.greaterThan(torch.full_like(rand_h[i],0.5,requires_grad=True),rand_h[i])\n",
        "        print(\"Gradients of h_ after bernoulli_sample/greaterThan:\", [h_i.grad for h_i in h_])\n",
        "        log_ratio = self.energy(v, h) - self.energy(v_, h_)\n",
        "\n",
        "        if rand_u is None:\n",
        "            accepted = log_ratio.exp().clamp(0, 1).bernoulli().bool()\n",
        "        else:\n",
        "            accepted = rand_u < log_ratio.exp()\n",
        "        if not fix_v:\n",
        "            v = torch.where(accepted.unsqueeze(1), v_, v)\n",
        "        h = [torch.where(accepted.unsqueeze(1), h_[i], h[i]) for i in range(self.L)]\n",
        "        return v, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HFvxdEz_urz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3591181d-d91d-4af2-fa8f-cc4704299aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients of v_prob1: tensor([[1.0000, 0.5666, 0.5662,  ..., 0.5598, 0.5510, 0.5311],\n",
            "        [1.0000, 0.5666, 0.5662,  ..., 0.5598, 0.5510, 0.5311],\n",
            "        [1.0000, 0.5666, 0.5662,  ..., 0.5598, 0.5510, 0.5311],\n",
            "        ...,\n",
            "        [1.0000, 0.5666, 0.5662,  ..., 0.5598, 0.5510, 0.5311],\n",
            "        [1.0000, 0.5666, 0.5662,  ..., 0.5598, 0.5510, 0.5311],\n",
            "        [1.0000, 0.5666, 0.5662,  ..., 0.5598, 0.5510, 0.5311]],\n",
            "       grad_fn=<SigmoidBackward0>)\n",
            "gradinets of v:  tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [3.7021e-23, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         2.0443e-39],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        ...,\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 9.9664e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         6.7391e-22],\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "Gradients of h_i: None\n",
            "Gradients of h_i 1: None\n",
            "Gradients of h_i: None\n",
            "Gradients of h_i 1: None\n",
            "Gradients of h_i: None\n",
            "Gradients of h_i 1: None\n",
            "gradinets of v2:  tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [3.7021e-23, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         2.0443e-39],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        ...,\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 9.9664e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         6.7391e-22],\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "Gradients of h2: [None, None, None]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-104-704ba5d98df3>:181: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h_i 1:\", h_i.grad)\n",
            "<ipython-input-104-704ba5d98df3>:221: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h2:\", [h_i.grad for h_i in h])\n",
            "<ipython-input-104-704ba5d98df3>:224: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h21:\", [h_i.grad for h_i in h])\n",
            "<ipython-input-104-704ba5d98df3>:235: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h3:\", [h_i.grad for h_i in h])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradinets of v21:  tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [3.7021e-23, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         2.0443e-39],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        ...,\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 9.9664e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         6.7391e-22],\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "Gradients of h21: [None, None, None]\n",
            "gradinets of v3:  tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [3.7021e-23, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         2.0443e-39],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        ...,\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 9.9664e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         6.7391e-22],\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "Gradients of h3: [None, None, None]\n",
            "gradinets of v31:  tensor([[0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [3.7021e-23, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         2.0443e-39],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        ...,\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 9.9664e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         6.7391e-22],\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "Gradients of h31: [None, None, None]\n",
            "Gradients of v1: None\n",
            "Gradients of h1: [None, None, None]\n",
            "Gradients of v2: None\n",
            "Gradients of h2: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-104-704ba5d98df3>:239: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h31:\", [h_i.grad for h_i in h])\n",
            "<ipython-input-104-704ba5d98df3>:184: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of v1:\", v.grad)\n",
            "<ipython-input-104-704ba5d98df3>:185: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h1:\", [h_i.grad for h_i in h])\n",
            "<ipython-input-104-704ba5d98df3>:187: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of v2:\", v.grad)\n",
            "<ipython-input-104-704ba5d98df3>:188: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h2:\", [h_i.grad for h_i in h])\n",
            "<ipython-input-104-704ba5d98df3>:423: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of v before bernoulli_sample:\", v.grad)\n",
            "<ipython-input-104-704ba5d98df3>:431: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of v_ after bernoulli_sample/greaterThan:\", v_.grad)\n",
            "<ipython-input-104-704ba5d98df3>:432: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h before bernoulli_sample/greaterThan:\", [h_i.grad for h_i in h])\n",
            "<ipython-input-104-704ba5d98df3>:442: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h_ after bernoulli_sample/greaterThan:\", [h_i.grad for h_i in h_])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v before bernoulli_sample: None\n",
            "Gradients of v_ after bernoulli_sample/greaterThan: None\n",
            "Gradients of h before bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of h_ after bernoulli_sample/greaterThan: [None, None, None]\n",
            "Gradients of v3: None\n",
            "Gradients of h3: [None, None, None]\n",
            "energy_pos:  tensor(-0.8771, grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-104-704ba5d98df3>:190: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of v3:\", v.grad)\n",
            "<ipython-input-104-704ba5d98df3>:191: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"Gradients of h3:\", [h_i.grad for h_i in h])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [ 7.5542e-238, -8.1585e-239],\n",
            "        [ 7.6670e-165, -8.1767e-166],\n",
            "        [  5.7836e+02,  -1.2097e+02],\n",
            "        [ 7.4320e-211, -8.0265e-212],\n",
            "        [  4.9249e+02,  -7.6992e+01],\n",
            "        [  4.9249e+02,  -7.6992e+01],\n",
            "        [ 4.8112e-205, -5.1960e-206],\n",
            "        [ 1.0514e-174, -1.1212e-175],\n",
            "        [  8.5311e-54,  -9.0163e-55],\n",
            "        [ 2.2830e-236, -2.4656e-237],\n",
            "        [  3.6456e+02,  -3.5477e+01]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 9.9627e-01],\n",
            "        [3.5464e-178],\n",
            "        [3.3041e-140],\n",
            "        [1.0342e-258],\n",
            "        [ 1.4958e-38],\n",
            "        [2.2141e-115],\n",
            "        [9.7644e-236],\n",
            "        [8.7816e-173],\n",
            "        [ 1.0000e+00],\n",
            "        [7.1270e-205],\n",
            "        [ 1.0000e+00],\n",
            "        [2.6986e-191]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.1311e+03,  -1.1543e+02],\n",
            "        [ 1.5732e-175, -1.6777e-176],\n",
            "        [ 1.5044e-137, -1.6121e-138],\n",
            "        [ 4.3567e-256, -4.7046e-257],\n",
            "        [  8.2034e-36,  -8.3418e-37],\n",
            "        [ 1.0522e-112, -1.0997e-113],\n",
            "        [ 4.1128e-233, -4.4418e-234],\n",
            "        [ 3.8955e-170, -4.1544e-171],\n",
            "        [  5.1483e+02,  -5.0428e+01],\n",
            "        [ 3.0564e-202, -3.2968e-203],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 1.1573e-188, -1.2483e-189]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[5.8372e-127],\n",
            "        [ 1.0000e+00],\n",
            "        [3.2406e-184],\n",
            "        [ 1.1555e-07],\n",
            "        [ 4.2079e-51],\n",
            "        [ 4.3047e-68],\n",
            "        [ 4.0933e-54],\n",
            "        [4.0584e-133],\n",
            "        [ 6.0543e-92],\n",
            "        [ 8.5360e-93],\n",
            "        [ 2.9953e-64],\n",
            "        [ 1.0969e-60]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.6416e-124, -2.8344e-125],\n",
            "        [  5.8894e+02,  -1.2314e+02],\n",
            "        [ 1.3900e-181, -1.4999e-182],\n",
            "        [  1.1429e-04,  -1.1626e-05],\n",
            "        [  2.2148e-48,  -2.0450e-49],\n",
            "        [  2.2361e-65,  -2.0787e-66],\n",
            "        [  2.1545e-51,  -1.9893e-52],\n",
            "        [ 1.8366e-130, -1.9706e-131],\n",
            "        [  2.8770e-89,  -3.0071e-90],\n",
            "        [  4.4341e-90,  -4.1220e-91],\n",
            "        [  1.4234e-61,  -1.4878e-62],\n",
            "        [  5.6980e-58,  -5.2970e-59]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.0494e-92],\n",
            "        [ 7.2670e-70],\n",
            "        [ 9.6204e-66],\n",
            "        [7.7280e-111],\n",
            "        [ 2.7398e-80],\n",
            "        [ 1.2467e-17],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.2919e-45],\n",
            "        [1.6840e-200],\n",
            "        [ 2.8053e-45]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.5194e+02,  -6.4949e+01],\n",
            "        [  7.3931e+02,  -8.4884e+01],\n",
            "        [  1.8820e-89,  -2.0013e-90],\n",
            "        [  3.4213e-67,  -3.6159e-68],\n",
            "        [  4.5293e-63,  -4.7869e-64],\n",
            "        [ 3.5855e-108, -3.8263e-109],\n",
            "        [  1.2733e-77,  -1.3541e-78],\n",
            "        [  7.9628e-15,  -7.9275e-16],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [  2.3118e-42,  -2.3615e-43],\n",
            "        [ 7.2221e-198, -7.7900e-199],\n",
            "        [  1.5110e-42,  -1.5435e-43]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [9.4689e-117],\n",
            "        [ 1.0000e+00],\n",
            "        [2.9222e-192],\n",
            "        [1.7614e-114],\n",
            "        [1.2141e-227],\n",
            "        [ 1.0000e+00],\n",
            "        [4.6512e-206],\n",
            "        [3.9872e-110],\n",
            "        [2.1637e-102],\n",
            "        [ 5.3341e-65],\n",
            "        [ 4.2960e-57]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.8966e+02,  -7.6293e+01],\n",
            "        [ 4.4270e-114, -4.6624e-115],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [ 1.2532e-189, -1.3517e-190],\n",
            "        [ 8.3702e-112, -8.7488e-113],\n",
            "        [ 5.1140e-225, -5.5231e-226],\n",
            "        [  5.9025e+02,  -1.1900e+02],\n",
            "        [ 1.9591e-203, -2.1158e-204],\n",
            "        [ 1.8947e-107, -1.9804e-108],\n",
            "        [  1.0282e-99, -1.0747e-100],\n",
            "        [  2.5113e-62,  -2.6541e-63],\n",
            "        [  2.0226e-54,  -2.1376e-55]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 9.9999e-01],\n",
            "        [7.5432e-222],\n",
            "        [4.9624e-102],\n",
            "        [ 2.0984e-18],\n",
            "        [8.1224e-200],\n",
            "        [ 7.5290e-57],\n",
            "        [ 1.4014e-71],\n",
            "        [6.0257e-212],\n",
            "        [3.9206e-130],\n",
            "        [2.5582e-237]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.4871e+02,  -1.0633e+02],\n",
            "        [  5.8479e+02,  -1.2238e+02],\n",
            "        [  1.4667e+03,  -1.5103e+02],\n",
            "        [ 3.1772e-219, -3.4314e-220],\n",
            "        [  2.3581e-99, -2.4648e-100],\n",
            "        [  1.3263e-15,  -1.3362e-16],\n",
            "        [ 3.4833e-197, -3.7573e-198],\n",
            "        [  3.6233e-54,  -3.7648e-55],\n",
            "        [  6.6594e-69,  -6.9607e-70],\n",
            "        [ 2.5381e-209, -2.7411e-210],\n",
            "        [ 1.7884e-127, -1.9091e-128],\n",
            "        [ 1.0775e-234, -1.1637e-235]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[9.3828e-159],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.4752e-78],\n",
            "        [1.0090e-210],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5252e-232],\n",
            "        [ 7.6071e-73],\n",
            "        [3.2854e-205],\n",
            "        [4.2213e-226],\n",
            "        [ 2.1674e-76],\n",
            "        [ 7.4491e-16],\n",
            "        [3.8310e-110]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 4.1621e-156, -4.4388e-157],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [  6.8562e-76,  -7.2910e-77],\n",
            "        [ 4.2499e-208, -4.5898e-209],\n",
            "        [  3.5643e+02,  -2.3914e+01],\n",
            "        [ 6.4254e-230, -6.9386e-231],\n",
            "        [  3.5354e-70,  -3.7596e-71],\n",
            "        [ 1.4089e-202, -1.5198e-203],\n",
            "        [ 1.7781e-223, -1.9203e-224],\n",
            "        [  1.0299e-73,  -1.0765e-74],\n",
            "        [  4.8810e-13,  -4.9064e-14],\n",
            "        [ 1.8205e-107, -1.9028e-108]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 4.1781e-24],\n",
            "        [ 1.7793e-53],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 8.6923e-15],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.0576e-16],\n",
            "        [1.5986e-131],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [7.0750e-142],\n",
            "        [4.5961e-213]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  2.5545e-21,  -2.5537e-22],\n",
            "        [  8.9720e-51,  -9.2901e-52],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  5.1483e+02,  -5.0428e+01],\n",
            "        [  6.4737e-12,  -5.7017e-13],\n",
            "        [  3.8605e+02,  -3.9216e+01],\n",
            "        [  1.3216e-13,  -1.3309e-14],\n",
            "        [ 7.4606e-129, -7.8865e-130],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [  7.0161e+02,  -7.2315e+01],\n",
            "        [ 3.2214e-139, -3.4519e-140],\n",
            "        [ 1.9359e-210, -2.0908e-211]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[2.8827e-166],\n",
            "        [ 1.8988e-47],\n",
            "        [6.3494e-248],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [4.0469e-228],\n",
            "        [ 1.0000e+00],\n",
            "        [3.0804e-137],\n",
            "        [ 3.4474e-29],\n",
            "        [1.2699e-184],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.3601e-36]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.2787e-163, -1.3637e-164],\n",
            "        [  9.9971e-45,  -1.0262e-45],\n",
            "        [ 2.6748e-245, -2.8885e-246],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [  3.6966e+02,  -3.6279e+01],\n",
            "        [ 1.7046e-225, -1.8409e-226],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [ 1.4026e-134, -1.5030e-135],\n",
            "        [  1.8906e-26,  -1.9225e-27],\n",
            "        [ 5.4458e-182, -5.8741e-183],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [  8.0474e-34,  -7.2589e-35]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 2.0242e-46],\n",
            "        [ 1.0000e+00],\n",
            "        [4.6961e-175],\n",
            "        [ 8.3880e-76],\n",
            "        [ 1.0000e+00],\n",
            "        [3.8910e-158],\n",
            "        [ 1.7117e-71],\n",
            "        [4.1044e-236],\n",
            "        [ 1.0936e-15],\n",
            "        [ 1.0000e+00],\n",
            "        [4.6602e-207],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.1104e-43,  -1.0172e-44],\n",
            "        [  4.8696e+02,  -7.4455e+01],\n",
            "        [ 2.0831e-172, -2.2216e-173],\n",
            "        [  3.9859e-73,  -4.1662e-74],\n",
            "        [  6.7486e+02,  -7.5669e+01],\n",
            "        [ 1.7293e-155, -1.8370e-156],\n",
            "        [  8.1339e-69,  -8.5018e-70],\n",
            "        [ 1.7291e-233, -1.8672e-234],\n",
            "        [  7.7475e-13,  -6.8485e-14],\n",
            "        [  5.8895e+02,  -1.2315e+02],\n",
            "        [ 1.9629e-204, -2.1199e-205],\n",
            "        [  6.3237e+02,  -7.0199e+01]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[5.3060e-112],\n",
            "        [ 2.7421e-39],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [8.6433e-218],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.7663e-221],\n",
            "        [1.5743e-143],\n",
            "        [1.8364e-253],\n",
            "        [5.5825e-225],\n",
            "        [ 4.7167e-67]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.5214e-109, -2.6355e-110],\n",
            "        [  1.5038e-36,  -1.5292e-37],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [  5.0436e+02,  -4.9180e+01],\n",
            "        [ 3.6406e-215, -3.9318e-216],\n",
            "        [  3.6872e+02,  -2.9925e+01],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [ 7.4399e-219, -8.0350e-220],\n",
            "        [ 7.1679e-141, -7.6809e-142],\n",
            "        [ 7.7349e-251, -8.3536e-252],\n",
            "        [ 2.3514e-222, -2.5395e-223],\n",
            "        [  2.2206e-64,  -2.3469e-65]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [4.8004e-162],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.3245e-17],\n",
            "        [ 9.2175e-51],\n",
            "        [4.1885e-148],\n",
            "        [2.1592e-183],\n",
            "        [ 6.1158e-15],\n",
            "        [1.6022e-211],\n",
            "        [1.1008e-241],\n",
            "        [3.1633e-201],\n",
            "        [ 1.1390e-33]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  7.5952e+02,  -8.7303e+01],\n",
            "        [ 2.1294e-159, -2.2710e-160],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [  1.4930e-14,  -1.5035e-15],\n",
            "        [  4.8336e-48,  -4.9709e-49],\n",
            "        [ 1.8920e-145, -2.0379e-146],\n",
            "        [ 9.5761e-181, -1.0209e-181],\n",
            "        [  4.1269e-12,  -4.1450e-13],\n",
            "        [ 6.7485e-209, -7.2883e-210],\n",
            "        [ 4.6375e-239, -5.0079e-240],\n",
            "        [ 1.3566e-198, -1.4633e-199],\n",
            "        [  6.2466e-31,  -6.3520e-32]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 2.7271e-56],\n",
            "        [1.2808e-101],\n",
            "        [2.3383e-206],\n",
            "        [ 1.0000e+00],\n",
            "        [9.4739e-105],\n",
            "        [ 3.8858e-45],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1587e-119],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.5612e-172],\n",
            "        [ 7.6060e-47]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.2839e-53,  -1.3570e-54],\n",
            "        [  6.0864e-99, -6.3617e-100],\n",
            "        [ 9.8489e-204, -1.0637e-204],\n",
            "        [  5.8689e+02,  -1.2101e+02],\n",
            "        [ 4.5020e-102, -4.7056e-103],\n",
            "        [  2.0377e-42,  -2.0956e-43],\n",
            "        [  6.8485e+02,  -9.6430e+01],\n",
            "        [ 5.4171e-117, -5.7051e-118],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  8.4802e+02,  -8.7843e+01],\n",
            "        [ 1.1361e-169, -1.2116e-170],\n",
            "        [  4.3755e-44,  -3.9813e-45]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 6.6297e-90],\n",
            "        [1.4089e-257],\n",
            "        [2.1938e-146],\n",
            "        [1.5285e-187],\n",
            "        [ 1.5595e-44],\n",
            "        [3.5407e-185],\n",
            "        [ 1.0000e+00],\n",
            "        [1.6463e-180],\n",
            "        [ 4.6107e-64],\n",
            "        [3.8177e-151],\n",
            "        [1.6394e-266]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.0374e+02,  -5.7989e+01],\n",
            "        [  3.1504e-87,  -3.2929e-88],\n",
            "        [ 5.9354e-255, -6.4095e-256],\n",
            "        [ 9.9098e-144, -1.0674e-144],\n",
            "        [ 6.5550e-185, -7.0706e-186],\n",
            "        [  9.1570e-42,  -8.1944e-43],\n",
            "        [ 1.5188e-182, -1.6388e-183],\n",
            "        [  5.9240e+02,  -1.2184e+02],\n",
            "        [ 7.3027e-178, -7.7881e-179],\n",
            "        [  2.1910e-61,  -2.2901e-62],\n",
            "        [ 1.6935e-148, -1.8061e-149],\n",
            "        [ 6.7447e-264, -7.4181e-265]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[1.0136e-151],\n",
            "        [1.4591e-150],\n",
            "        [4.5889e-191],\n",
            "        [4.9046e-230],\n",
            "        [1.0671e-140],\n",
            "        [ 5.3885e-15],\n",
            "        [9.1720e-245],\n",
            "        [ 4.8832e-34],\n",
            "        [2.8818e-245],\n",
            "        [2.2700e-159],\n",
            "        [1.0187e-124],\n",
            "        [1.4413e-119]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 4.5327e-149, -4.8088e-150],\n",
            "        [ 6.5244e-148, -6.9219e-149],\n",
            "        [ 1.9680e-188, -2.1227e-189],\n",
            "        [ 2.0659e-227, -2.2311e-228],\n",
            "        [ 4.8587e-138, -5.2064e-139],\n",
            "        [  4.0132e-12,  -3.5346e-13],\n",
            "        [ 3.8446e-242, -4.1682e-243],\n",
            "        [  2.6780e-31,  -2.7232e-32],\n",
            "        [ 1.2140e-242, -1.3110e-243],\n",
            "        [ 1.0069e-156, -1.0739e-157],\n",
            "        [ 4.7629e-122, -5.0162e-123],\n",
            "        [ 6.7383e-117, -7.0966e-118]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.9970e-76],\n",
            "        [ 2.4803e-74],\n",
            "        [6.4692e-230],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.3342e-84],\n",
            "        [ 1.9167e-52],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.4901e-58],\n",
            "        [1.8574e-150]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  9.2810e-74,  -9.8696e-75],\n",
            "        [  1.1677e-71,  -1.2341e-72],\n",
            "        [ 2.7249e-227, -2.9428e-228],\n",
            "        [  3.4981e+02,  -3.0207e+01],\n",
            "        [  3.5157e+02,  -3.1621e+01],\n",
            "        [  2.5073e-81,  -2.6589e-82],\n",
            "        [  1.0051e-49,  -1.0337e-50],\n",
            "        [  5.8689e+02,  -1.2101e+02],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [  5.2976e+02,  -5.5497e+01],\n",
            "        [  7.0152e-56,  -7.4142e-57],\n",
            "        [ 8.5142e-148, -8.9081e-149]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.1417e-32],\n",
            "        [7.6066e-244],\n",
            "        [ 2.2652e-66],\n",
            "        [1.5291e-159],\n",
            "        [1.6590e-106],\n",
            "        [ 1.0000e+00],\n",
            "        [5.3079e-178],\n",
            "        [4.9808e-250],\n",
            "        [6.6619e-247],\n",
            "        [1.3571e-188],\n",
            "        [9.6516e-248],\n",
            "        [1.5092e-154]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.8804e-30,  -6.1736e-31],\n",
            "        [ 3.2045e-241, -3.4604e-242],\n",
            "        [  1.0764e-63,  -1.1251e-64],\n",
            "        [ 6.7830e-157, -7.2339e-158],\n",
            "        [ 7.8835e-104, -8.2401e-105],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 2.3545e-175, -2.5110e-176],\n",
            "        [ 2.0489e-247, -2.2537e-248],\n",
            "        [ 2.7925e-244, -3.0275e-245],\n",
            "        [ 5.8201e-186, -6.2778e-187],\n",
            "        [ 4.0457e-245, -4.3862e-246],\n",
            "        [ 6.6947e-152, -7.1397e-153]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.5999e-29],\n",
            "        [1.0143e-112],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.5536e-76],\n",
            "        [1.2117e-148],\n",
            "        [7.8151e-225],\n",
            "        [ 1.7189e-10],\n",
            "        [ 1.0000e+00],\n",
            "        [1.2744e-161],\n",
            "        [1.0276e-110],\n",
            "        [1.2260e-238],\n",
            "        [ 3.8788e-86]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  8.7739e-27,  -8.9219e-28],\n",
            "        [ 4.8201e-110, -5.0382e-111],\n",
            "        [  3.5124e+02,  -3.1585e+01],\n",
            "        [  3.0458e-73,  -3.2390e-74],\n",
            "        [ 5.3750e-146, -5.7323e-147],\n",
            "        [ 3.2923e-222, -3.5552e-223],\n",
            "        [  1.4306e-07,  -1.2527e-08],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 5.6530e-159, -6.0288e-160],\n",
            "        [ 4.8045e-108, -5.0599e-109],\n",
            "        [ 5.1641e-236, -5.5772e-237],\n",
            "        [  1.8432e-83,  -1.9266e-84]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([12, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.1116e-20],\n",
            "        [ 8.5523e-38],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.1262e-13],\n",
            "        [ 4.5519e-42],\n",
            "        [ 2.9767e-96],\n",
            "        [1.6059e-136],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.2343e-88],\n",
            "        [ 7.9842e-15],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.7495e+02,  -1.1654e+02],\n",
            "        [  7.5354e-18,  -6.6900e-19],\n",
            "        [  4.6066e-35,  -4.7056e-36],\n",
            "        [  5.7495e+02,  -1.1654e+02],\n",
            "        [  8.3879e-11,  -7.3876e-12],\n",
            "        [  2.6185e-39,  -2.3826e-40],\n",
            "        [  1.4145e-93,  -1.4785e-94],\n",
            "        [ 7.3256e-134, -7.8198e-135],\n",
            "        [  6.4537e+02,  -1.0145e+02],\n",
            "        [  1.0617e-85,  -1.1097e-86],\n",
            "        [  5.8597e-12,  -5.1665e-13],\n",
            "        [  5.3872e+02,  -5.4285e+01]], dtype=torch.float64)\n",
            "torch.Size([12, 2])\n",
            "toReturn:  tensor([[0.0000e+00, 7.0581e+02, 0.0000e+00,  ..., 6.8804e-30, 8.7739e-27,\n",
            "         5.7495e+02],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         7.5354e-18],\n",
            "        [0.0000e+00, 5.5792e+02, 0.0000e+00,  ..., 0.0000e+00, 3.5124e+02,\n",
            "         4.6066e-35],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [2.5002e-34, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         5.8597e-12],\n",
            "        [0.0000e+00, 7.1989e-29, 1.9381e-35,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         5.3872e+02]])\n",
            "result:  tensor([[1.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [1.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [4.1078e-16],\n",
            "        [1.0000e+00],\n",
            "        [1.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [8.1988e-116],\n",
            "        [3.9028e-221],\n",
            "        [ 1.0000e+00],\n",
            "        [3.4070e-240],\n",
            "        [1.5207e-183],\n",
            "        [3.0732e-236],\n",
            "        [4.4416e-184],\n",
            "        [ 2.3629e-70],\n",
            "        [ 4.1078e-16],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.9660e-213],\n",
            "        [ 2.9489e-84],\n",
            "        [3.1401e-220],\n",
            "        [ 3.6741e-58]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.8479e+02,  -1.2238e+02],\n",
            "        [ 3.8961e-113, -4.0723e-114],\n",
            "        [ 1.6439e-218, -1.7754e-219],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [ 1.4353e-237, -1.5499e-238],\n",
            "        [ 6.5214e-181, -7.0343e-182],\n",
            "        [ 1.2944e-233, -1.3980e-234],\n",
            "        [ 1.9048e-181, -2.0546e-182],\n",
            "        [  1.0982e-67,  -1.1678e-68],\n",
            "        [  2.6384e-13,  -2.6570e-14],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  1.2021e+03,  -1.0612e+02],\n",
            "        [ 1.2493e-210, -1.3492e-211],\n",
            "        [  1.4013e-81,  -1.4647e-82],\n",
            "        [ 1.3226e-217, -1.4284e-218],\n",
            "        [  1.7298e-55,  -1.8281e-56]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "toReturn:  tensor([[5.8479e+02],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [3.6456e+02],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [2.6384e-13],\n",
            "        [3.6456e+02],\n",
            "        [1.2021e+03],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00]])\n",
            "result:  tensor([[0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [1.1166e-38, 0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00],\n",
            "        [1.0000e+00, 2.3071e-33],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.2066e-13],\n",
            "        [1.0000e+00, 6.1232e-33],\n",
            "        [0.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [4.3485e-26, 0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[6.0354e-228],\n",
            "        [7.2382e-155],\n",
            "        [ 5.1085e-62],\n",
            "        [ 7.3598e-82],\n",
            "        [ 1.0000e+00],\n",
            "        [4.5730e-199],\n",
            "        [ 1.1166e-38],\n",
            "        [ 4.1157e-81],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.3699e-154],\n",
            "        [2.9056e-146],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.3485e-26]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.5421e-225, -2.7455e-226],\n",
            "        [ 3.2108e-152, -3.4242e-153],\n",
            "        [  2.4051e-59,  -2.5419e-60],\n",
            "        [  3.4973e-79,  -3.6555e-80],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [ 1.9612e-196, -2.1154e-197],\n",
            "        [  6.0142e-36,  -6.1434e-37],\n",
            "        [  1.9558e-78,  -2.0442e-79],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [  3.4981e+02,  -3.0207e+01],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 1.0513e-151, -1.1211e-152],\n",
            "        [ 1.3125e-143, -1.4137e-144],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [  2.6587e-23,  -2.6578e-24]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.8879e-193],\n",
            "        [1.5907e-237],\n",
            "        [ 1.0000e+00],\n",
            "        [7.4702e-140],\n",
            "        [3.1436e-139],\n",
            "        [1.9406e-232],\n",
            "        [1.2634e-247],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.3071e-33],\n",
            "        [4.2599e-129],\n",
            "        [ 1.2066e-13],\n",
            "        [ 6.1232e-33],\n",
            "        [ 1.0000e+00],\n",
            "        [1.8362e-248],\n",
            "        [1.0085e-260],\n",
            "        [8.3913e-119]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 8.0962e-191, -8.7329e-192],\n",
            "        [ 6.7011e-235, -7.2363e-236],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 3.4013e-137, -3.6448e-138],\n",
            "        [ 1.4314e-136, -1.5338e-137],\n",
            "        [ 8.1741e-230, -8.8280e-231],\n",
            "        [ 5.3224e-245, -5.7475e-246],\n",
            "        [  5.9240e+02,  -1.2184e+02],\n",
            "        [  1.2653e-30,  -1.2866e-31],\n",
            "        [ 1.9916e-126, -2.0975e-127],\n",
            "        [  9.1134e-11,  -8.0178e-12],\n",
            "        [  3.3580e-30,  -3.4147e-31],\n",
            "        [  5.8689e+02,  -1.2101e+02],\n",
            "        [ 7.7355e-246, -8.3533e-247],\n",
            "        [ 4.2485e-258, -4.5879e-259],\n",
            "        [ 3.9232e-116, -4.1318e-117]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "toReturn:  tensor([[0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 8.0770e+02],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [5.8722e+02, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [6.0142e-36, 0.0000e+00],\n",
            "        [0.0000e+00, 5.9240e+02],\n",
            "        [7.8845e+02, 1.2653e-30],\n",
            "        [5.5792e+02, 0.0000e+00],\n",
            "        [3.4981e+02, 9.1134e-11],\n",
            "        [8.0770e+02, 3.3580e-30],\n",
            "        [0.0000e+00, 5.8689e+02],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [4.8734e+02, 0.0000e+00],\n",
            "        [2.6587e-23, 0.0000e+00]])\n",
            "result:  tensor([[4.0638e-22, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 6.1760e-26, 0.0000e+00, 0.0000e+00],\n",
            "        [6.4151e-36, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.7429e-24, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 7.5878e-09],\n",
            "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.9229e-27, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
            "       grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 4.0638e-22],\n",
            "        [ 1.0000e+00],\n",
            "        [6.6134e-246],\n",
            "        [ 6.4151e-36],\n",
            "        [3.6225e-159],\n",
            "        [9.3068e-193],\n",
            "        [1.1436e-226],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1347e-158],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5159e-225],\n",
            "        [1.9689e-149],\n",
            "        [ 7.3485e-93],\n",
            "        [ 4.3932e-66]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  2.5109e-19,  -2.5366e-20],\n",
            "        [  6.9260e+02,  -7.0197e+01],\n",
            "        [ 2.7861e-243, -3.0086e-244],\n",
            "        [  3.5181e-33,  -3.5775e-34],\n",
            "        [ 1.6069e-156, -1.7137e-157],\n",
            "        [ 3.9912e-190, -4.3051e-191],\n",
            "        [ 4.8170e-224, -5.2023e-225],\n",
            "        [  3.4981e+02,  -3.0207e+01],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [  5.8974e+02,  -1.1938e+02],\n",
            "        [ 5.0335e-156, -5.3681e-157],\n",
            "        [  6.4867e+02,  -1.0630e+02],\n",
            "        [ 6.3850e-223, -6.8958e-224],\n",
            "        [ 8.7338e-147, -9.3143e-148],\n",
            "        [  3.4920e-90,  -3.6499e-91],\n",
            "        [  2.0683e-63,  -2.1860e-64]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.9025e-225],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.1760e-26],\n",
            "        [3.2440e-116],\n",
            "        [3.3160e-164],\n",
            "        [2.1795e-215],\n",
            "        [ 6.5036e-67],\n",
            "        [1.7930e-153],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1617e-182],\n",
            "        [1.1182e-147],\n",
            "        [1.4879e-180],\n",
            "        [ 7.7247e-90],\n",
            "        [1.5936e-243],\n",
            "        [8.6717e-173],\n",
            "        [9.9638e-169]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.2225e-222, -1.3203e-223],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [  3.7761e-23,  -3.7748e-24],\n",
            "        [ 1.5415e-113, -1.6113e-114],\n",
            "        [ 1.4709e-161, -1.5687e-162],\n",
            "        [ 9.1800e-213, -9.9143e-214],\n",
            "        [  3.0619e-64,  -3.2360e-65],\n",
            "        [ 7.9537e-151, -8.4824e-152],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 5.1523e-180, -5.4927e-181],\n",
            "        [ 5.0510e-145, -5.4403e-146],\n",
            "        [ 6.6002e-178, -7.0389e-179],\n",
            "        [  3.6707e-87,  -3.8368e-88],\n",
            "        [ 6.7134e-241, -7.2496e-242],\n",
            "        [ 3.8467e-170, -4.1024e-171],\n",
            "        [ 4.4199e-166, -4.7137e-167]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[7.2157e-117],\n",
            "        [2.1395e-194],\n",
            "        [1.6691e-110],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.7429e-24],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5275e-218],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [6.1187e-163],\n",
            "        [5.9540e-110],\n",
            "        [1.2990e-246],\n",
            "        [ 2.9229e-27],\n",
            "        [1.6025e-200],\n",
            "        [8.7298e-130]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.4289e-114, -3.5840e-115],\n",
            "        [ 9.1751e-192, -9.8967e-193],\n",
            "        [ 7.9315e-108, -8.2902e-109],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  1.6771e-21,  -1.6765e-22],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 6.4340e-216, -6.9486e-217],\n",
            "        [  5.7836e+02,  -1.2097e+02],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [ 2.7142e-160, -2.8946e-161],\n",
            "        [ 2.8293e-107, -2.9573e-108],\n",
            "        [ 5.4722e-244, -5.9093e-245],\n",
            "        [  1.7871e-24,  -1.7865e-25],\n",
            "        [ 6.8722e-198, -7.4127e-199],\n",
            "        [ 4.0814e-127, -4.2984e-128]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.2291e-151],\n",
            "        [3.2698e-168],\n",
            "        [1.0778e-148],\n",
            "        [2.2890e-139],\n",
            "        [4.5522e-157],\n",
            "        [ 7.5878e-09],\n",
            "        [1.1603e-170],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.6056e-96],\n",
            "        [1.3330e-164],\n",
            "        [2.4566e-236],\n",
            "        [4.5446e-185],\n",
            "        [6.5897e-130],\n",
            "        [2.3833e-180],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 9.8882e-149, -1.0545e-149],\n",
            "        [ 1.4505e-165, -1.5469e-166],\n",
            "        [ 4.7809e-146, -5.0987e-147],\n",
            "        [ 1.0422e-136, -1.1168e-137],\n",
            "        [ 2.0193e-154, -2.1535e-155],\n",
            "        [  6.3596e-06,  -5.5787e-07],\n",
            "        [ 5.1472e-168, -5.4893e-169],\n",
            "        [  4.4460e+02,  -4.7974e+01],\n",
            "        [  5.7836e+02,  -1.2097e+02],\n",
            "        [  1.2382e-93,  -1.2942e-94],\n",
            "        [ 5.9129e-162, -6.3060e-163],\n",
            "        [ 1.0347e-233, -1.1175e-234],\n",
            "        [ 1.9490e-182, -2.1022e-183],\n",
            "        [ 3.0809e-127, -3.2447e-128],\n",
            "        [ 1.0572e-177, -1.1275e-178],\n",
            "        [  6.4871e+02,  -1.0633e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "toReturn:  tensor([[2.5109e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [6.9260e+02, 5.9278e+02, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 3.7761e-23, 0.0000e+00, 0.0000e+00],\n",
            "        [3.5181e-33, 0.0000e+00, 3.6456e+02, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 1.6771e-21, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 5.8068e+02, 6.3596e-06],\n",
            "        [0.0000e+00, 0.0000e+00, 8.0770e+02, 0.0000e+00],\n",
            "        [3.4981e+02, 0.0000e+00, 0.0000e+00, 4.4460e+02],\n",
            "        [5.8722e+02, 8.0770e+02, 5.7836e+02, 5.7836e+02],\n",
            "        [5.8974e+02, 0.0000e+00, 5.8722e+02, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [6.4867e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 1.7871e-24, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4871e+02]])\n",
            "result:  tensor([[0.0000e+00, 0.0000e+00, 6.1198e-13,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        [3.3931e-20, 1.0000e+00, 1.1644e-29,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        [0.0000e+00, 5.3785e-41, 1.0000e+00,  ..., 1.4862e-10, 0.0000e+00,\n",
            "         1.0000e+00],\n",
            "        ...,\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 6.5463e-32,\n",
            "         1.0000e+00],\n",
            "        [0.0000e+00, 5.6052e-45, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[8.2361e-174],\n",
            "        [ 3.3931e-20],\n",
            "        [ 6.2724e-73],\n",
            "        [ 9.9991e-01],\n",
            "        [8.3403e-205],\n",
            "        [5.0239e-177],\n",
            "        [1.6419e-236],\n",
            "        [7.7948e-249],\n",
            "        [ 2.6254e-22],\n",
            "        [1.3832e-249],\n",
            "        [2.4196e-192],\n",
            "        [ 1.0000e+00],\n",
            "        [2.6768e-152],\n",
            "        [ 1.0000e+00],\n",
            "        [2.0521e-118],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.6535e-171, -3.8963e-172],\n",
            "        [  2.1132e-17,  -2.1325e-18],\n",
            "        [  2.9806e-70,  -3.1155e-71],\n",
            "        [  1.3571e+03,  -1.1986e+02],\n",
            "        [ 3.5768e-202, -3.8581e-203],\n",
            "        [ 2.2286e-174, -2.3767e-175],\n",
            "        [ 6.9159e-234, -7.4691e-235],\n",
            "        [ 3.2837e-246, -3.5460e-247],\n",
            "        [  1.6140e-19,  -1.6317e-20],\n",
            "        [ 5.8271e-247, -6.2925e-248],\n",
            "        [ 1.0377e-189, -1.1193e-190],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 1.1874e-149, -1.2663e-150],\n",
            "        [  6.9527e+02,  -7.1611e+01],\n",
            "        [ 9.7517e-116, -1.0193e-116],\n",
            "        [  3.6463e+02,  -3.5452e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 2.1709e-60],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.3785e-41],\n",
            "        [9.1977e-160],\n",
            "        [1.6214e-222],\n",
            "        [2.6236e-208],\n",
            "        [4.0651e-228],\n",
            "        [5.1823e-198],\n",
            "        [2.7128e-254],\n",
            "        [ 2.9479e-16],\n",
            "        [3.1583e-147],\n",
            "        [ 1.0000e+00],\n",
            "        [6.1128e-140],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.7510e-45],\n",
            "        [ 7.2537e-71]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.0221e-57,  -1.0802e-58],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [  2.8971e-38,  -2.9593e-39],\n",
            "        [ 4.0800e-157, -4.3512e-158],\n",
            "        [ 6.8295e-220, -7.3758e-221],\n",
            "        [ 1.1051e-205, -1.1935e-206],\n",
            "        [ 1.7122e-225, -1.8492e-226],\n",
            "        [ 2.2224e-195, -2.3972e-196],\n",
            "        [ 1.1428e-251, -1.2341e-252],\n",
            "        [  1.8934e-13,  -1.9067e-14],\n",
            "        [ 1.4266e-144, -1.5366e-145],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 2.7832e-137, -2.9824e-138],\n",
            "        [  3.7401e+02,  -3.7159e+01],\n",
            "        [  3.0158e-42,  -3.1014e-43],\n",
            "        [  3.3712e-68,  -3.5850e-69]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 6.1198e-13],\n",
            "        [ 1.1644e-29],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [4.3480e-177],\n",
            "        [2.9702e-111],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0757e-80],\n",
            "        [1.4373e-218],\n",
            "        [4.8026e-251],\n",
            "        [6.0947e-252],\n",
            "        [ 4.9642e-76],\n",
            "        [1.7486e-220],\n",
            "        [1.0037e-223],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.7996e-10,  -4.2110e-11],\n",
            "        [  6.3858e-27,  -6.4935e-28],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  3.7401e+02,  -3.7159e+01],\n",
            "        [  5.9151e+02,  -1.2118e+02],\n",
            "        [ 1.9287e-174, -2.0569e-175],\n",
            "        [ 1.4114e-108, -1.4753e-109],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [  5.1118e-78,  -5.3430e-79],\n",
            "        [ 6.0540e-216, -6.5383e-217],\n",
            "        [ 2.0232e-248, -2.1848e-249],\n",
            "        [ 2.5675e-249, -2.7726e-250],\n",
            "        [  2.3590e-73,  -2.4657e-74],\n",
            "        [ 7.3654e-218, -7.9546e-219],\n",
            "        [ 4.2275e-221, -4.5657e-222],\n",
            "        [  4.3549e+02,  -5.2263e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 8.8413e-15],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.6280e-70],\n",
            "        [1.0538e-198],\n",
            "        [3.3223e-112],\n",
            "        [ 5.3451e-63],\n",
            "        [1.1072e-118],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [3.7499e-165],\n",
            "        [4.7507e-217],\n",
            "        [3.8142e-150],\n",
            "        [4.4153e-137],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.5847e-12,  -5.7994e-13],\n",
            "        [  6.4537e+02,  -1.0145e+02],\n",
            "        [  3.7601e+02,  -3.7538e+01],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [  7.5661e-68,  -8.0460e-69],\n",
            "        [ 4.5194e-196, -4.8748e-197],\n",
            "        [ 1.5788e-109, -1.6502e-110],\n",
            "        [  2.5165e-60,  -2.6596e-61],\n",
            "        [ 5.1765e-116, -5.4518e-117],\n",
            "        [  5.8479e+02,  -1.2238e+02],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [ 1.6634e-162, -1.7740e-163],\n",
            "        [ 2.0010e-214, -2.1611e-215],\n",
            "        [ 1.6919e-147, -1.8044e-148],\n",
            "        [ 2.0104e-134, -2.1542e-135],\n",
            "        [  5.7678e+02,  -1.1955e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[8.3852e-159],\n",
            "        [3.6708e-152],\n",
            "        [2.7973e-228],\n",
            "        [ 9.9979e-01],\n",
            "        [1.1996e-228],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.5133e-93],\n",
            "        [ 1.4481e-62],\n",
            "        [1.5051e-257],\n",
            "        [2.2383e-111],\n",
            "        [1.1264e-200],\n",
            "        [5.5157e-219],\n",
            "        [3.9776e-148],\n",
            "        [ 9.5135e-13],\n",
            "        [1.4684e-242],\n",
            "        [2.5559e-251]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.7196e-156, -3.9668e-157],\n",
            "        [ 1.6283e-149, -1.7366e-150],\n",
            "        [ 1.1782e-225, -1.2725e-226],\n",
            "        [  1.3672e+03,  -1.2075e+02],\n",
            "        [ 5.0528e-226, -5.4570e-227],\n",
            "        [  3.6463e+02,  -3.5452e+01],\n",
            "        [  7.1911e-91,  -7.5164e-92],\n",
            "        [  6.8176e-60,  -7.2053e-61],\n",
            "        [ 6.3405e-255, -6.8469e-256],\n",
            "        [ 1.0637e-108, -1.1118e-109],\n",
            "        [ 4.8306e-198, -5.2105e-199],\n",
            "        [ 2.3233e-216, -2.5091e-217],\n",
            "        [ 1.7968e-145, -1.9353e-146],\n",
            "        [  7.4612e-10,  -6.5462e-11],\n",
            "        [ 6.1860e-240, -6.6801e-241],\n",
            "        [ 1.0767e-248, -1.1627e-249]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[9.8531e-232],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [8.1695e-135],\n",
            "        [2.8173e-194],\n",
            "        [4.5796e-164],\n",
            "        [2.0758e-203],\n",
            "        [ 8.8394e-54],\n",
            "        [ 1.7844e-31],\n",
            "        [4.2671e-247],\n",
            "        [1.6891e-215],\n",
            "        [2.0866e-113],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.8617e-51],\n",
            "        [1.4499e-198],\n",
            "        [1.0098e-164]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 4.1502e-229, -4.4822e-230],\n",
            "        [  5.9240e+02,  -1.2184e+02],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [ 3.7197e-132, -3.9859e-133],\n",
            "        [ 1.2082e-191, -1.3032e-192],\n",
            "        [ 2.0315e-161, -2.1665e-162],\n",
            "        [ 8.9021e-201, -9.6022e-202],\n",
            "        [  4.1616e-51,  -4.3983e-52],\n",
            "        [  9.7858e-29,  -9.9509e-30],\n",
            "        [ 1.7976e-244, -1.9412e-245],\n",
            "        [ 7.1147e-213, -7.6838e-214],\n",
            "        [ 9.9153e-111, -1.0364e-111],\n",
            "        [  3.7601e+02,  -3.7538e+01],\n",
            "        [  2.0251e-48,  -2.0826e-49],\n",
            "        [ 6.2178e-196, -6.7068e-197],\n",
            "        [ 4.4794e-162, -4.7772e-163]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[3.2436e-216],\n",
            "        [5.0667e-194],\n",
            "        [1.9917e-130],\n",
            "        [1.8653e-163],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.5115e-89],\n",
            "        [ 6.3384e-66],\n",
            "        [3.9633e-192],\n",
            "        [3.6860e-261],\n",
            "        [1.5439e-100],\n",
            "        [2.3656e-169],\n",
            "        [1.4605e-103],\n",
            "        [4.7823e-206],\n",
            "        [ 2.5163e-50],\n",
            "        [ 1.0000e+00],\n",
            "        [1.8218e-218]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.3662e-213, -1.4755e-214],\n",
            "        [ 2.1729e-191, -2.3438e-192],\n",
            "        [ 9.3117e-128, -9.8068e-129],\n",
            "        [ 8.2745e-161, -8.8245e-162],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [  7.1825e-87,  -7.5074e-88],\n",
            "        [  2.9841e-63,  -3.1539e-64],\n",
            "        [ 1.6997e-189, -1.8333e-190],\n",
            "        [ 1.5528e-258, -1.6768e-259],\n",
            "        [  7.3368e-98,  -7.6687e-99],\n",
            "        [ 1.0493e-166, -1.1191e-167],\n",
            "        [ 6.9403e-101, -7.2542e-102],\n",
            "        [ 2.0143e-203, -2.1755e-204],\n",
            "        [  1.3196e-47,  -1.3570e-48],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 7.6735e-216, -8.2873e-217]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.7058e-11],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9233e-117],\n",
            "        [ 1.2980e-54],\n",
            "        [ 5.6449e-75],\n",
            "        [ 1.0000e+00],\n",
            "        [1.3416e-176],\n",
            "        [5.3836e-184],\n",
            "        [5.6583e-144],\n",
            "        [ 6.1194e-34],\n",
            "        [ 3.6977e-55],\n",
            "        [9.0183e-202],\n",
            "        [ 1.0000e+00],\n",
            "        [2.6488e-209],\n",
            "        [ 3.9416e-27],\n",
            "        [ 1.2303e-37]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.4148e-08,  -1.2373e-09],\n",
            "        [  5.5109e+02,  -9.3525e+01],\n",
            "        [ 9.1397e-115, -9.5531e-116],\n",
            "        [  6.1109e-52,  -6.4585e-53],\n",
            "        [  2.6824e-72,  -2.8038e-73],\n",
            "        [  4.7015e+02,  -6.5526e+01],\n",
            "        [ 5.9512e-174, -6.3467e-175],\n",
            "        [ 2.3088e-181, -2.4903e-182],\n",
            "        [ 2.5560e-141, -2.7530e-142],\n",
            "        [  3.3560e-31,  -3.4126e-32],\n",
            "        [  1.7409e-52,  -1.8399e-53],\n",
            "        [ 3.8675e-199, -4.1717e-200],\n",
            "        [  3.4418e+02,  -2.7783e+01],\n",
            "        [ 1.1157e-206, -1.2049e-207],\n",
            "        [  2.4099e-24,  -2.4092e-25],\n",
            "        [  6.7470e-35,  -6.8609e-36]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 3.2799e-74],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.4085e-44],\n",
            "        [ 2.7576e-73],\n",
            "        [ 6.1711e-19],\n",
            "        [2.2807e-148],\n",
            "        [1.7735e-206],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [5.7885e-225],\n",
            "        [ 1.0000e+00],\n",
            "        [5.5649e-148],\n",
            "        [ 4.4375e-73],\n",
            "        [1.9094e-252],\n",
            "        [6.3681e-133],\n",
            "        [5.9246e-128]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.5586e-71,  -1.6291e-72],\n",
            "        [  5.7012e+02,  -1.1699e+02],\n",
            "        [  1.2630e-41,  -1.2989e-42],\n",
            "        [  1.3104e-70,  -1.3697e-71],\n",
            "        [  3.8630e-16,  -3.8958e-17],\n",
            "        [ 1.0303e-145, -1.1097e-146],\n",
            "        [ 7.4700e-204, -8.0675e-205],\n",
            "        [  6.6342e+02,  -6.6218e+01],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [ 2.4381e-222, -2.6332e-223],\n",
            "        [  6.0836e+02,  -1.1237e+02],\n",
            "        [ 2.5138e-145, -2.7075e-146],\n",
            "        [  2.1087e-70,  -2.2041e-71],\n",
            "        [ 8.0439e-250, -8.6864e-251],\n",
            "        [ 2.8995e-130, -3.1070e-131],\n",
            "        [ 2.7699e-125, -2.9172e-126]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.6871e-156],\n",
            "        [ 1.4831e-10],\n",
            "        [2.0318e-208],\n",
            "        [ 8.4050e-61],\n",
            "        [ 6.1998e-07],\n",
            "        [ 7.0993e-55],\n",
            "        [1.7392e-208],\n",
            "        [ 1.0000e+00],\n",
            "        [1.0829e-123],\n",
            "        [5.3040e-114],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.1071e-89],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9215e-123],\n",
            "        [6.6680e-122]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.0792e-153, -2.2173e-154],\n",
            "        [  1.2532e-07,  -1.0967e-08],\n",
            "        [ 8.5581e-206, -9.2427e-207],\n",
            "        [  3.9571e-58,  -4.1821e-59],\n",
            "        [  5.6689e-04,  -4.9682e-05],\n",
            "        [  3.3423e-52,  -3.5324e-53],\n",
            "        [ 7.3254e-206, -7.9114e-207],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [ 5.0629e-121, -5.3321e-122],\n",
            "        [ 2.5204e-111, -2.6344e-112],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  5.2611e-87,  -5.4991e-88],\n",
            "        [  3.8375e+02,  -3.8766e+01],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 8.9835e-121, -9.4612e-122],\n",
            "        [ 3.1175e-119, -3.2833e-120]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.4596e-232],\n",
            "        [ 1.2766e-69],\n",
            "        [1.0281e-210],\n",
            "        [ 1.0000e+00],\n",
            "        [1.2773e-147],\n",
            "        [5.8518e-257],\n",
            "        [2.6425e-242],\n",
            "        [ 1.0000e+00],\n",
            "        [4.9716e-149],\n",
            "        [ 7.4021e-42],\n",
            "        [ 1.4008e-40],\n",
            "        [2.0280e-145],\n",
            "        [2.1301e-237],\n",
            "        [ 8.9318e-82],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4230e-107]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.8784e-229, -2.0287e-230],\n",
            "        [  5.9330e-67,  -6.3093e-68],\n",
            "        [ 4.3306e-208, -4.6770e-209],\n",
            "        [  4.9249e+02,  -7.6992e+01],\n",
            "        [ 5.7697e-145, -6.2143e-146],\n",
            "        [ 2.4652e-254, -2.6621e-255],\n",
            "        [ 1.1132e-239, -1.2021e-240],\n",
            "        [  5.5111e+02,  -9.3532e+01],\n",
            "        [ 2.2054e-146, -2.3519e-147],\n",
            "        [  3.9870e-39,  -4.0727e-40],\n",
            "        [  7.5450e-38,  -7.7071e-39],\n",
            "        [ 9.1610e-143, -9.8671e-144],\n",
            "        [ 8.9737e-235, -9.6904e-236],\n",
            "        [  4.2444e-79,  -4.4364e-80],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [ 6.7619e-105, -7.0677e-106]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4686e-254],\n",
            "        [4.0701e-204],\n",
            "        [ 3.1190e-57],\n",
            "        [1.8563e-153],\n",
            "        [4.1745e-233],\n",
            "        [3.2209e-222],\n",
            "        [ 4.1623e-21],\n",
            "        [ 1.4400e-20],\n",
            "        [6.3677e-162],\n",
            "        [ 1.8734e-33],\n",
            "        [8.0071e-108],\n",
            "        [2.7042e-199],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0240e-75]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  8.2608e+02,  -9.1654e+01],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [ 6.1867e-252, -6.6808e-253],\n",
            "        [ 1.7455e-201, -1.8827e-202],\n",
            "        [  1.4684e-54,  -1.5519e-55],\n",
            "        [ 8.2345e-151, -8.7818e-152],\n",
            "        [ 1.7583e-230, -1.8990e-231],\n",
            "        [ 1.3566e-219, -1.4652e-220],\n",
            "        [  2.5922e-18,  -2.6158e-19],\n",
            "        [  8.9677e-18,  -9.0497e-19],\n",
            "        [ 2.8247e-159, -3.0124e-160],\n",
            "        [  1.0274e-30,  -1.0447e-31],\n",
            "        [ 3.8049e-105, -3.9770e-106],\n",
            "        [ 1.1597e-196, -1.2509e-197],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  4.8659e-73,  -5.0860e-74]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 3.3638e-68],\n",
            "        [ 1.2610e-09],\n",
            "        [ 1.0000e+00],\n",
            "        [5.7365e-142],\n",
            "        [ 2.2531e-87],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5583e-167],\n",
            "        [4.7996e-157],\n",
            "        [1.2912e-160],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.3305e-09],\n",
            "        [1.5571e-145],\n",
            "        [2.8601e-151],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.8732e+02,  -7.4469e+01],\n",
            "        [  1.5634e-65,  -1.6625e-66],\n",
            "        [  1.0656e-06,  -9.3255e-08],\n",
            "        [  6.4537e+02,  -1.0145e+02],\n",
            "        [ 2.6119e-139, -2.7989e-140],\n",
            "        [  1.0707e-84,  -1.1191e-85],\n",
            "        [  8.0956e+02,  -8.9309e+01],\n",
            "        [ 6.9127e-165, -7.3721e-166],\n",
            "        [ 2.1291e-154, -2.2706e-155],\n",
            "        [ 5.7275e-158, -6.1082e-159],\n",
            "        [  5.9151e+02,  -1.2118e+02],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  1.1243e-06,  -9.8389e-08],\n",
            "        [ 7.0337e-143, -7.5758e-144],\n",
            "        [ 1.2687e-148, -1.3531e-149],\n",
            "        [  4.3794e+02,  -3.8492e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[3.3471e-208],\n",
            "        [5.1970e-126],\n",
            "        [ 5.3627e-09],\n",
            "        [2.2317e-246],\n",
            "        [3.0349e-159],\n",
            "        [5.0522e-144],\n",
            "        [3.2141e-103],\n",
            "        [2.5429e-230],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.9150e-52],\n",
            "        [ 1.8725e-81],\n",
            "        [9.1273e-261],\n",
            "        [ 1.0940e-48],\n",
            "        [2.1629e-257],\n",
            "        [2.6874e-162],\n",
            "        [3.4290e-226]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.4098e-205, -1.5226e-206],\n",
            "        [ 2.4298e-123, -2.5589e-124],\n",
            "        [  4.4947e-06,  -3.9428e-07],\n",
            "        [ 9.4015e-244, -1.0152e-244],\n",
            "        [ 1.3463e-156, -1.4357e-157],\n",
            "        [ 2.2822e-141, -2.4581e-142],\n",
            "        [ 1.5273e-100, -1.5964e-101],\n",
            "        [ 1.0711e-227, -1.1568e-228],\n",
            "        [  6.6342e+02,  -6.6218e+01],\n",
            "        [  3.4868e-49,  -3.6105e-50],\n",
            "        [  8.8979e-79,  -9.3004e-80],\n",
            "        [ 3.8451e-258, -4.1522e-259],\n",
            "        [  5.7369e-46,  -5.8998e-47],\n",
            "        [ 9.1118e-255, -9.8395e-256],\n",
            "        [ 1.1921e-159, -1.2713e-160],\n",
            "        [ 1.4443e-223, -1.5598e-224]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 9.9967e-01],\n",
            "        [8.7914e-258],\n",
            "        [5.9889e-239],\n",
            "        [8.1558e-153],\n",
            "        [3.1553e-157],\n",
            "        [6.7921e-149],\n",
            "        [3.1414e-130],\n",
            "        [ 2.0537e-99],\n",
            "        [7.5829e-195],\n",
            "        [ 1.0000e+00],\n",
            "        [4.6520e-243],\n",
            "        [3.1693e-158],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.2861e-215]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.3670e+03,  -1.2073e+02],\n",
            "        [ 3.7036e-255, -3.9994e-256],\n",
            "        [ 2.5230e-236, -2.7245e-237],\n",
            "        [ 3.6178e-150, -3.8583e-151],\n",
            "        [ 1.3997e-154, -1.4927e-155],\n",
            "        [ 3.0129e-146, -3.2132e-147],\n",
            "        [ 1.4687e-127, -1.5468e-128],\n",
            "        [  9.7589e-97,  -1.0200e-97],\n",
            "        [ 3.2520e-192, -3.5077e-193],\n",
            "        [  7.8725e+02,  -8.1103e+01],\n",
            "        [ 1.9597e-240, -2.1163e-241],\n",
            "        [ 1.4059e-155, -1.4993e-156],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [  9.3781e+02,  -9.6322e+01],\n",
            "        [  4.8966e+02,  -7.6293e+01],\n",
            "        [ 5.4170e-213, -5.8503e-214]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[3.8957e-162],\n",
            "        [4.8746e-108],\n",
            "        [ 1.0000e+00],\n",
            "        [8.4221e-251],\n",
            "        [1.0442e-222],\n",
            "        [ 1.0000e+00],\n",
            "        [4.5912e-184],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.9180e-12],\n",
            "        [ 1.0000e+00],\n",
            "        [3.4792e-216],\n",
            "        [1.6475e-172],\n",
            "        [ 4.4981e-28],\n",
            "        [3.5412e-209]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.7281e-159, -1.8430e-160],\n",
            "        [ 2.3164e-105, -2.4212e-106],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 3.5480e-248, -3.8313e-249],\n",
            "        [ 4.3981e-220, -4.7499e-221],\n",
            "        [  7.0161e+02,  -7.2315e+01],\n",
            "        [ 1.9689e-181, -2.1238e-182],\n",
            "        [  5.9240e+02,  -1.2184e+02],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [  1.5247e-09,  -1.3367e-10],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [ 1.4655e-213, -1.5827e-214],\n",
            "        [ 7.3081e-170, -7.7939e-171],\n",
            "        [  2.7502e-25,  -2.7493e-26],\n",
            "        [ 1.4916e-206, -1.6109e-207]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 4.8852e-24],\n",
            "        [3.1410e-199],\n",
            "        [2.3985e-154],\n",
            "        [ 9.9846e-01],\n",
            "        [ 2.6065e-23],\n",
            "        [ 9.5275e-91],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.5259e-42],\n",
            "        [7.0628e-251],\n",
            "        [1.3705e-212],\n",
            "        [2.8059e-134],\n",
            "        [ 4.6020e-40],\n",
            "        [1.3716e-218],\n",
            "        [1.6264e-206],\n",
            "        [ 2.1256e-68],\n",
            "        [1.5790e-106]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  2.9869e-21,  -2.9859e-22],\n",
            "        [ 1.3470e-196, -1.4530e-197],\n",
            "        [ 1.0640e-151, -1.1347e-152],\n",
            "        [  1.3751e+03,  -1.2145e+02],\n",
            "        [  1.5936e-20,  -1.5931e-21],\n",
            "        [  4.5274e-88,  -4.7322e-89],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  2.9764e-39,  -3.0404e-40],\n",
            "        [ 2.9754e-248, -3.2130e-249],\n",
            "        [ 5.7727e-210, -6.2345e-211],\n",
            "        [ 1.2776e-131, -1.3690e-132],\n",
            "        [  2.4788e-37,  -2.5321e-38],\n",
            "        [ 5.7774e-216, -6.2396e-217],\n",
            "        [ 6.8504e-204, -7.3983e-205],\n",
            "        [  9.8788e-66,  -1.0505e-66],\n",
            "        [ 7.5034e-104, -7.8428e-105]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.3851e-151],\n",
            "        [1.1695e-246],\n",
            "        [ 1.0000e+00],\n",
            "        [4.0394e-215],\n",
            "        [2.6852e-126],\n",
            "        [ 1.1731e-56],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.3926e-59],\n",
            "        [1.1329e-118],\n",
            "        [1.3836e-114],\n",
            "        [ 9.7407e-01],\n",
            "        [ 2.2234e-27],\n",
            "        [7.7946e-148],\n",
            "        [ 1.7283e-77],\n",
            "        [ 8.9995e-42],\n",
            "        [8.0017e-212]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 6.1442e-149, -6.5525e-150],\n",
            "        [ 4.9268e-244, -5.3204e-245],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 1.7014e-212, -1.8375e-213],\n",
            "        [ 1.2554e-123, -1.3222e-124],\n",
            "        [  5.5229e-54,  -5.8370e-55],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [  1.1264e-56,  -1.1905e-57],\n",
            "        [ 5.2968e-116, -5.5784e-117],\n",
            "        [ 6.5747e-112, -6.8721e-113],\n",
            "        [  1.3415e+03,  -1.1848e+02],\n",
            "        [  1.3594e-24,  -1.3589e-25],\n",
            "        [ 3.5210e-145, -3.7923e-146],\n",
            "        [  8.2129e-75,  -8.5844e-76],\n",
            "        [  4.8475e-39,  -4.9516e-40],\n",
            "        [ 3.3704e-209, -3.6399e-210]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[8.9560e-250],\n",
            "        [1.8341e-131],\n",
            "        [4.5060e-114],\n",
            "        [7.8183e-103],\n",
            "        [ 1.0000e+00],\n",
            "        [7.1746e-198],\n",
            "        [1.1607e-215],\n",
            "        [6.5557e-204],\n",
            "        [5.0403e-176],\n",
            "        [4.2511e-230],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.4015e-44],\n",
            "        [ 8.7319e-91],\n",
            "        [8.5409e-124],\n",
            "        [1.8019e-164],\n",
            "        [3.7125e-227]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.7729e-247, -4.0743e-248],\n",
            "        [ 8.5752e-129, -9.0311e-130],\n",
            "        [ 2.1412e-111, -2.2381e-112],\n",
            "        [ 3.7152e-100, -3.8833e-101],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 3.0769e-195, -3.3189e-196],\n",
            "        [ 4.8888e-213, -5.2798e-214],\n",
            "        [ 2.8114e-201, -3.0325e-202],\n",
            "        [ 2.2359e-173, -2.3845e-174],\n",
            "        [ 1.7906e-227, -1.9338e-228],\n",
            "        [  5.7836e+02,  -1.2097e+02],\n",
            "        [  1.2593e-41,  -1.2951e-42],\n",
            "        [  4.1494e-88,  -4.3370e-89],\n",
            "        [ 3.9931e-121, -4.2054e-122],\n",
            "        [ 7.9930e-162, -8.5242e-163],\n",
            "        [ 1.5637e-224, -1.6888e-225]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.1512e-90],\n",
            "        [3.0331e-232],\n",
            "        [2.8819e-250],\n",
            "        [3.3494e-136],\n",
            "        [4.5298e-214],\n",
            "        [5.8565e-253],\n",
            "        [1.8518e-105],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [3.8744e-178],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 7.9654e-20],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4298e-233],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.4706e-88,  -5.7181e-89],\n",
            "        [ 1.2776e-229, -1.3798e-230],\n",
            "        [ 1.2140e-247, -1.3110e-248],\n",
            "        [ 1.5250e-133, -1.6342e-134],\n",
            "        [ 1.9080e-211, -2.0606e-212],\n",
            "        [ 2.4672e-250, -2.6642e-251],\n",
            "        [ 8.7998e-103, -9.1979e-104],\n",
            "        [  5.7836e+02,  -1.2097e+02],\n",
            "        [  5.9025e+02,  -1.1900e+02],\n",
            "        [ 1.7186e-175, -1.8329e-176],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  5.8689e+02,  -1.2101e+02],\n",
            "        [  4.9607e-17,  -5.0060e-18],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [ 6.0224e-231, -6.5041e-232],\n",
            "        [  5.3872e+02,  -5.4285e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 8.8326e-38],\n",
            "        [2.9311e-179],\n",
            "        [ 2.6189e-22],\n",
            "        [1.7492e-225],\n",
            "        [ 6.7550e-91],\n",
            "        [2.8903e-138],\n",
            "        [3.6499e-224],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4250e-240],\n",
            "        [ 2.4023e-57],\n",
            "        [1.6539e-216],\n",
            "        [3.7479e-200],\n",
            "        [ 5.9786e-46],\n",
            "        [1.0042e-122],\n",
            "        [ 4.8718e-37]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.6342e+02,  -6.6218e+01],\n",
            "        [  4.8439e-35,  -4.9256e-36],\n",
            "        [ 1.3002e-176, -1.3866e-177],\n",
            "        [  1.6100e-19,  -1.6276e-20],\n",
            "        [ 7.3678e-223, -7.9571e-224],\n",
            "        [  3.2100e-88,  -3.3552e-89],\n",
            "        [ 1.3160e-135, -1.4102e-136],\n",
            "        [ 1.5374e-221, -1.6603e-222],\n",
            "        [  3.6463e+02,  -3.5452e+01],\n",
            "        [ 6.0030e-238, -6.4825e-239],\n",
            "        [  1.1310e-54,  -1.1953e-55],\n",
            "        [ 6.9663e-214, -7.5235e-215],\n",
            "        [ 1.6073e-197, -1.7337e-198],\n",
            "        [  3.1352e-43,  -3.2242e-44],\n",
            "        [ 4.6951e-120, -4.9447e-121],\n",
            "        [  2.6717e-34,  -2.7168e-35]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.3524e-130],\n",
            "        [1.2280e-247],\n",
            "        [2.2154e-166],\n",
            "        [9.2931e-222],\n",
            "        [1.6798e-166],\n",
            "        [1.4934e-222],\n",
            "        [ 6.5403e-82],\n",
            "        [ 3.1576e-95],\n",
            "        [5.0224e-181],\n",
            "        [2.1020e-254],\n",
            "        [1.0873e-136],\n",
            "        [ 9.2781e-97],\n",
            "        [ 3.1812e-35],\n",
            "        [ 1.0000e+00],\n",
            "        [3.5316e-261],\n",
            "        [ 3.8472e-96]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.0998e-127, -1.1583e-128],\n",
            "        [ 5.1733e-245, -5.5865e-246],\n",
            "        [ 9.8274e-164, -1.0481e-164],\n",
            "        [ 3.9143e-219, -4.2274e-220],\n",
            "        [ 7.4513e-164, -7.9466e-165],\n",
            "        [ 6.2902e-220, -6.7934e-221],\n",
            "        [  3.1079e-79,  -3.2485e-80],\n",
            "        [  1.5005e-92,  -1.5683e-93],\n",
            "        [ 2.2279e-178, -2.3760e-179],\n",
            "        [ 8.8553e-252, -9.5626e-253],\n",
            "        [ 4.9508e-134, -5.3052e-135],\n",
            "        [  4.4089e-94,  -4.6084e-95],\n",
            "        [  1.7446e-32,  -1.7740e-33],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 1.4878e-258, -1.6066e-259],\n",
            "        [  1.8282e-93,  -1.9109e-94]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.9898e-201],\n",
            "        [ 2.2831e-53],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.8552e-92],\n",
            "        [2.0590e-240],\n",
            "        [4.8530e-204],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1765e-242],\n",
            "        [3.9711e-115],\n",
            "        [ 1.0000e+00],\n",
            "        [ 9.9979e-01],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.9690e-107],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 8.5331e-199, -9.2042e-200],\n",
            "        [  1.0749e-50,  -1.1360e-51],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [  2.3072e-89,  -2.4115e-90],\n",
            "        [ 8.6740e-238, -9.3668e-239],\n",
            "        [ 2.0812e-201, -2.2449e-202],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [ 4.9564e-240, -5.3523e-241],\n",
            "        [ 1.8871e-112, -1.9724e-113],\n",
            "        [  5.4963e+02,  -9.1911e+01],\n",
            "        [  1.3672e+03,  -1.2075e+02],\n",
            "        [  4.1606e+02,  -4.4058e+01],\n",
            "        [  5.7529e+02,  -1.1797e+02],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [ 1.4109e-104, -1.4747e-105],\n",
            "        [  5.5109e+02,  -9.3525e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[6.4981e-110],\n",
            "        [1.2140e-111],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.9521e-73],\n",
            "        [3.3930e-236],\n",
            "        [6.7842e-141],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.7734e-02],\n",
            "        [ 1.2144e-57],\n",
            "        [ 1.0000e+00],\n",
            "        [ 8.9853e-91],\n",
            "        [ 2.8088e-30],\n",
            "        [1.1155e-235],\n",
            "        [ 1.2296e-20],\n",
            "        [ 5.4611e-50],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.0879e-107, -3.2275e-108],\n",
            "        [ 5.7689e-109, -6.0299e-110],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [  1.4029e-70,  -1.4663e-71],\n",
            "        [ 1.4291e-233, -1.5435e-234],\n",
            "        [ 3.0890e-138, -3.3100e-139],\n",
            "        [  3.8605e+02,  -3.9216e+01],\n",
            "        [  3.3731e+01,  -2.9608e+00],\n",
            "        [  5.7173e-55,  -6.0425e-56],\n",
            "        [  5.8686e+02,  -1.2100e+02],\n",
            "        [  4.2698e-88,  -4.4629e-89],\n",
            "        [  1.5404e-27,  -1.5663e-28],\n",
            "        [ 4.6987e-233, -5.0745e-234],\n",
            "        [  7.6576e-18,  -7.7276e-19],\n",
            "        [  2.8638e-47,  -2.9451e-48],\n",
            "        [  5.4963e+02,  -9.1911e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.4908e-67],\n",
            "        [5.4820e-247],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.9912e-21],\n",
            "        [ 3.0561e-70],\n",
            "        [ 1.7415e-33],\n",
            "        [ 1.0000e+00],\n",
            "        [9.7864e-112],\n",
            "        [ 1.0000e+00],\n",
            "        [2.2318e-117],\n",
            "        [1.6050e-212],\n",
            "        [ 3.2593e-40],\n",
            "        [2.8360e-195],\n",
            "        [7.5858e-111],\n",
            "        [ 1.0000e+00],\n",
            "        [5.4920e-246]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  7.0188e-65,  -7.4180e-66],\n",
            "        [ 2.3094e-244, -2.4939e-245],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [  2.4857e-18,  -2.5084e-19],\n",
            "        [  1.4203e-67,  -1.5104e-68],\n",
            "        [  9.5504e-31,  -9.7115e-32],\n",
            "        [  5.9025e+02,  -1.1900e+02],\n",
            "        [ 4.6505e-109, -4.8608e-110],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 1.0605e-114, -1.1085e-115],\n",
            "        [ 6.7602e-210, -7.3010e-211],\n",
            "        [  1.7556e-37,  -1.7933e-38],\n",
            "        [ 1.2162e-192, -1.3119e-193],\n",
            "        [ 3.6047e-108, -3.7678e-109],\n",
            "        [  3.6973e+02,  -3.6254e+01],\n",
            "        [ 2.3136e-243, -2.4984e-244]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 8.1339e-74],\n",
            "        [3.9043e-105],\n",
            "        [ 2.1056e-93],\n",
            "        [2.8102e-133],\n",
            "        [2.8155e-201],\n",
            "        [5.2331e-154],\n",
            "        [2.4908e-218],\n",
            "        [9.2106e-109],\n",
            "        [ 5.0113e-62],\n",
            "        [3.5140e-199],\n",
            "        [4.0042e-188],\n",
            "        [2.6725e-235],\n",
            "        [1.1716e-101],\n",
            "        [1.3780e-137],\n",
            "        [8.9980e-157],\n",
            "        [ 1.3762e-96]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  3.8652e-71,  -4.0400e-72],\n",
            "        [ 1.8553e-102, -1.9392e-103],\n",
            "        [  1.0006e-90,  -1.0458e-91],\n",
            "        [ 1.2795e-130, -1.3711e-131],\n",
            "        [ 1.2075e-198, -1.3024e-199],\n",
            "        [ 2.3214e-151, -2.4756e-152],\n",
            "        [ 1.0491e-215, -1.1331e-216],\n",
            "        [ 4.3769e-106, -4.5749e-107],\n",
            "        [  2.3593e-59,  -2.4935e-60],\n",
            "        [ 1.5070e-196, -1.6255e-197],\n",
            "        [ 1.7172e-185, -1.8523e-186],\n",
            "        [ 1.1257e-232, -1.2157e-233],\n",
            "        [  5.5675e-99, -5.8194e-100],\n",
            "        [ 6.2744e-135, -6.7235e-136],\n",
            "        [ 3.9914e-154, -4.2567e-155],\n",
            "        [  6.5396e-94,  -6.8354e-95]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.5691e-246],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.4233e-91],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0479e-25],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1283e-213],\n",
            "        [7.6872e-229],\n",
            "        [1.0239e-165],\n",
            "        [4.5443e-119],\n",
            "        [5.8316e-124],\n",
            "        [5.5135e-148],\n",
            "        [1.9941e-143],\n",
            "        [ 5.8126e-58],\n",
            "        [2.6890e-206],\n",
            "        [1.6330e-214]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 6.6100e-244, -7.1380e-245],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [  6.7637e-89,  -7.0697e-90],\n",
            "        [  5.8689e+02,  -1.2101e+02],\n",
            "        [  6.4068e-23,  -6.4048e-24],\n",
            "        [  5.5109e+02,  -9.3525e+01],\n",
            "        [ 4.7525e-211, -5.1327e-212],\n",
            "        [ 3.2379e-226, -3.4969e-227],\n",
            "        [ 4.5419e-163, -4.8438e-164],\n",
            "        [ 2.1246e-116, -2.2376e-117],\n",
            "        [ 2.7264e-121, -2.8714e-122],\n",
            "        [ 2.4906e-145, -2.6825e-146],\n",
            "        [ 9.0793e-141, -9.7292e-142],\n",
            "        [  2.7366e-55,  -2.8922e-56],\n",
            "        [ 1.1326e-203, -1.2232e-204],\n",
            "        [ 6.8784e-212, -7.4287e-213]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.1838e-40],\n",
            "        [3.0890e-237],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9842e-200],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.2644e-157],\n",
            "        [6.3181e-147],\n",
            "        [ 1.0000e+00],\n",
            "        [3.6630e-117],\n",
            "        [3.0140e-197],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.8574e-57],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.0686e-152]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.3764e-38,  -6.5134e-39],\n",
            "        [ 1.3013e-234, -1.4053e-235],\n",
            "        [  1.2818e+03,  -1.3027e+02],\n",
            "        [ 8.5095e-198, -9.1788e-199],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  3.7238e+02,  -3.6803e+01],\n",
            "        [ 1.0045e-154, -1.0712e-155],\n",
            "        [ 2.8540e-144, -3.0740e-145],\n",
            "        [  5.7529e+02,  -1.1797e+02],\n",
            "        [ 1.7406e-114, -1.8194e-115],\n",
            "        [ 1.2925e-194, -1.3942e-195],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [  1.8161e-54,  -1.9193e-55],\n",
            "        [  7.3452e+02,  -7.6257e+01],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [ 9.1763e-150, -9.7862e-151]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.0293e-191],\n",
            "        [ 1.0000e+00],\n",
            "        [3.1236e-141],\n",
            "        [ 2.0487e-59],\n",
            "        [2.3352e-119],\n",
            "        [ 9.2906e-63],\n",
            "        [1.2744e-163],\n",
            "        [ 1.5147e-69],\n",
            "        [ 8.7578e-50],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.4421e-236],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [5.7136e-242],\n",
            "        [ 2.8156e-98]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.7280e-188, -1.8639e-189],\n",
            "        [  4.4460e+02,  -4.7974e+01],\n",
            "        [ 1.4222e-138, -1.5240e-139],\n",
            "        [  9.6453e-57,  -1.0194e-57],\n",
            "        [ 1.0918e-116, -1.1498e-117],\n",
            "        [  4.3740e-60,  -4.6228e-61],\n",
            "        [ 5.6532e-161, -6.0289e-162],\n",
            "        [  7.0395e-67,  -7.4859e-68],\n",
            "        [  4.5925e-47,  -4.7229e-48],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [  5.1483e+02,  -5.0428e+01],\n",
            "        [ 1.0286e-233, -1.1109e-234],\n",
            "        [  5.3872e+02,  -5.4285e+01],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [ 2.4070e-239, -2.5992e-240],\n",
            "        [  1.3380e-95,  -1.3985e-96]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.7110e-81],\n",
            "        [ 1.7573e-11],\n",
            "        [7.3566e-237],\n",
            "        [ 1.0225e-15],\n",
            "        [2.3216e-251],\n",
            "        [7.1959e-140],\n",
            "        [1.9903e-158],\n",
            "        [ 1.0000e+00],\n",
            "        [2.2074e-254],\n",
            "        [2.7664e-193],\n",
            "        [2.4775e-202],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.0212e-01],\n",
            "        [2.6265e-148]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  3.9506e+02,  -3.9294e+01],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [  2.2386e-78,  -2.3399e-79],\n",
            "        [  1.4575e-08,  -1.2746e-09],\n",
            "        [ 3.0991e-234, -3.3466e-235],\n",
            "        [  7.2433e-13,  -6.4028e-14],\n",
            "        [ 9.7802e-249, -1.0561e-249],\n",
            "        [ 3.2764e-137, -3.5109e-138],\n",
            "        [ 8.8286e-156, -9.4155e-157],\n",
            "        [  6.0837e+02,  -1.1248e+02],\n",
            "        [ 9.2990e-252, -1.0042e-252],\n",
            "        [ 1.1864e-190, -1.2797e-191],\n",
            "        [ 1.0625e-199, -1.1460e-200],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [  6.1070e+02,  -5.3605e+01],\n",
            "        [ 1.1864e-145, -1.2779e-146]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.5890e-210],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.4995e-97],\n",
            "        [1.0791e-152],\n",
            "        [3.3072e-173],\n",
            "        [2.6737e-179],\n",
            "        [9.2794e-177],\n",
            "        [ 1.0000e+00],\n",
            "        [1.7806e-152],\n",
            "        [ 4.9843e-29],\n",
            "        [ 3.5514e-98],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.9338e-95],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.0763e-24]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 6.6930e-208, -7.2283e-209],\n",
            "        [  8.4802e+02,  -8.7843e+01],\n",
            "        [  1.0261e+03,  -1.0555e+02],\n",
            "        [  2.1381e-94,  -2.2349e-95],\n",
            "        [ 4.7868e-150, -5.1050e-151],\n",
            "        [ 1.4671e-170, -1.5646e-171],\n",
            "        [ 1.1860e-176, -1.2649e-177],\n",
            "        [ 4.1163e-174, -4.3899e-175],\n",
            "        [  4.9249e+02,  -7.6992e+01],\n",
            "        [ 7.8987e-150, -8.4237e-151],\n",
            "        [  2.7334e-26,  -2.7796e-27],\n",
            "        [  1.6876e-95,  -1.7639e-96],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [  9.1895e-93,  -9.6051e-94],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  3.7151e-21,  -3.7139e-22]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.2866e-130],\n",
            "        [ 4.5175e-80],\n",
            "        [ 7.7697e-83],\n",
            "        [ 1.1061e-65],\n",
            "        [ 1.3544e-59],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 7.6672e-03],\n",
            "        [ 3.5745e-84],\n",
            "        [ 5.3766e-30],\n",
            "        [7.4925e-254],\n",
            "        [5.6676e-213],\n",
            "        [7.9243e-104],\n",
            "        [ 1.0000e+00],\n",
            "        [3.7102e-206],\n",
            "        [1.9241e-215]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 6.0154e-128, -6.3353e-129],\n",
            "        [  2.1467e-77,  -2.2438e-78],\n",
            "        [  3.6921e-80,  -3.8592e-81],\n",
            "        [  5.2076e-63,  -5.5038e-64],\n",
            "        [  6.3763e-57,  -6.7390e-58],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  9.3251e+00,  -8.1853e-01],\n",
            "        [  1.6986e-81,  -1.7754e-82],\n",
            "        [  2.9486e-27,  -2.9983e-28],\n",
            "        [ 3.1564e-251, -3.4085e-252],\n",
            "        [ 2.3872e-210, -2.5782e-211],\n",
            "        [ 3.7656e-101, -3.9359e-102],\n",
            "        [  5.3872e+02,  -5.4285e+01],\n",
            "        [ 1.5628e-203, -1.6878e-204],\n",
            "        [ 8.1046e-213, -8.7529e-214]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 9.4943e-49],\n",
            "        [4.8452e-142],\n",
            "        [7.9278e-199],\n",
            "        [2.7691e-126],\n",
            "        [1.0864e-217],\n",
            "        [1.3910e-239],\n",
            "        [1.5282e-127],\n",
            "        [1.9095e-198],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.2826e-94],\n",
            "        [ 1.0000e+00],\n",
            "        [2.5855e-245],\n",
            "        [ 1.1877e-90],\n",
            "        [4.2474e-158],\n",
            "        [ 1.3507e-33]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  3.5124e+02,  -3.1585e+01],\n",
            "        [  4.9787e-46,  -5.1201e-47],\n",
            "        [ 2.2061e-139, -2.3640e-140],\n",
            "        [ 3.3999e-196, -3.6673e-197],\n",
            "        [ 1.2946e-123, -1.3635e-124],\n",
            "        [ 4.5761e-215, -4.9422e-216],\n",
            "        [ 5.8599e-237, -6.3279e-238],\n",
            "        [ 7.1448e-125, -7.5247e-126],\n",
            "        [ 8.1889e-196, -8.8329e-197],\n",
            "        [  3.6463e+02,  -3.5452e+01],\n",
            "        [  2.0351e-91,  -2.1271e-92],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [ 1.0892e-242, -1.1762e-243],\n",
            "        [  5.6438e-88,  -5.8991e-89],\n",
            "        [ 1.8841e-155, -2.0093e-156],\n",
            "        [  7.4073e-31,  -7.5323e-32]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.1436e-118],\n",
            "        [7.8319e-257],\n",
            "        [2.6641e-104],\n",
            "        [ 3.7697e-36],\n",
            "        [ 9.9912e-01],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.9787e-76],\n",
            "        [ 1.0000e+00],\n",
            "        [1.6986e-199],\n",
            "        [ 6.7063e-37],\n",
            "        [3.9627e-208],\n",
            "        [2.6087e-162],\n",
            "        [4.1639e-201],\n",
            "        [2.0133e-128],\n",
            "        [1.1953e-170],\n",
            "        [ 8.9775e-87]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.0187e-115, -1.0647e-116],\n",
            "        [ 3.2993e-254, -3.5629e-255],\n",
            "        [ 1.2660e-101, -1.3232e-102],\n",
            "        [  2.0673e-33,  -2.1022e-34],\n",
            "        [  1.3760e+03,  -1.2153e+02],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [  1.8907e-73,  -1.9762e-74],\n",
            "        [  4.7015e+02,  -6.5526e+01],\n",
            "        [ 7.2844e-197, -7.8573e-198],\n",
            "        [  3.6778e-34,  -3.7398e-35],\n",
            "        [ 1.6691e-205, -1.8026e-206],\n",
            "        [ 1.1572e-159, -1.2341e-160],\n",
            "        [ 1.7857e-198, -1.9261e-199],\n",
            "        [ 9.4125e-126, -9.9130e-127],\n",
            "        [ 5.3021e-168, -5.6545e-169],\n",
            "        [  4.2661e-84,  -4.4590e-85]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 3.4376e-70],\n",
            "        [ 1.5268e-78],\n",
            "        [ 2.1156e-48],\n",
            "        [ 1.0000e+00],\n",
            "        [2.2285e-159],\n",
            "        [ 2.0444e-72],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1976e-147],\n",
            "        [ 1.0000e+00],\n",
            "        [6.3229e-253],\n",
            "        [ 8.6117e-54],\n",
            "        [1.0089e-189],\n",
            "        [3.6185e-202],\n",
            "        [9.1435e-222],\n",
            "        [9.7585e-248],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.5977e-67,  -1.6990e-68],\n",
            "        [  7.2555e-76,  -7.5837e-77],\n",
            "        [  1.1094e-45,  -1.1409e-46],\n",
            "        [  6.4954e+02,  -1.0551e+02],\n",
            "        [ 9.8853e-157, -1.0542e-157],\n",
            "        [  9.7147e-70,  -1.0154e-70],\n",
            "        [  8.2980e+02,  -8.5925e+01],\n",
            "        [ 5.4098e-145, -5.8267e-146],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [ 2.6636e-250, -2.8764e-251],\n",
            "        [  4.0544e-51,  -4.2850e-52],\n",
            "        [ 4.3267e-187, -4.6670e-188],\n",
            "        [ 1.5518e-199, -1.6739e-200],\n",
            "        [ 3.8513e-219, -4.1594e-220],\n",
            "        [ 4.1110e-245, -4.4393e-246],\n",
            "        [  5.8722e+02,  -1.2032e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 4.5611e-73],\n",
            "        [2.1890e-249],\n",
            "        [1.9270e-104],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.1158e-86],\n",
            "        [ 1.4347e-76],\n",
            "        [2.2306e-210],\n",
            "        [8.7812e-197],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.4040e-51],\n",
            "        [3.2686e-125],\n",
            "        [ 3.2646e-44],\n",
            "        [ 1.0000e+00],\n",
            "        [7.3679e-130],\n",
            "        [2.5623e-252]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  2.1674e-70,  -2.2655e-71],\n",
            "        [ 9.2218e-247, -9.9583e-248],\n",
            "        [ 9.1569e-102, -9.5711e-103],\n",
            "        [  3.4418e+02,  -2.7783e+01],\n",
            "        [  1.4806e-83,  -1.5476e-84],\n",
            "        [  6.8178e-74,  -7.1262e-75],\n",
            "        [ 9.3954e-208, -1.0147e-208],\n",
            "        [ 3.7658e-194, -4.0620e-195],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [  8.7320e+02,  -8.9490e+01],\n",
            "        [  7.0796e-49,  -7.3307e-50],\n",
            "        [ 1.5282e-122, -1.6094e-123],\n",
            "        [  1.7119e-41,  -1.7605e-42],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 3.4447e-127, -3.6278e-128],\n",
            "        [ 1.0794e-249, -1.1656e-250]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [1.0917e-231],\n",
            "        [9.9487e-249],\n",
            "        [ 2.9732e-91],\n",
            "        [8.2292e-210],\n",
            "        [8.1420e-202],\n",
            "        [2.0395e-114],\n",
            "        [ 6.3823e-27],\n",
            "        [6.5026e-157],\n",
            "        [ 1.0000e+00],\n",
            "        [2.1329e-100],\n",
            "        [ 1.0000e+00],\n",
            "        [3.1969e-147],\n",
            "        [ 1.0000e+00],\n",
            "        [5.0917e-119],\n",
            "        [8.3737e-214]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.0423e+02,  -4.9161e+01],\n",
            "        [ 4.5982e-229, -4.9660e-230],\n",
            "        [ 4.1911e-246, -4.5259e-247],\n",
            "        [  1.4129e-88,  -1.4768e-89],\n",
            "        [ 3.4662e-207, -3.7435e-208],\n",
            "        [ 3.4917e-199, -3.7664e-200],\n",
            "        [ 9.6917e-112, -1.0130e-112],\n",
            "        [  3.9022e-24,  -3.9009e-25],\n",
            "        [ 2.8845e-154, -3.0763e-155],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  1.0136e-97,  -1.0594e-98],\n",
            "        [  4.2878e+02,  -3.7466e+01],\n",
            "        [ 1.4441e-144, -1.5554e-145],\n",
            "        [  4.3071e+02,  -4.5970e+01],\n",
            "        [ 2.3805e-116, -2.5071e-117],\n",
            "        [ 3.5271e-211, -3.8092e-212]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[5.6362e-230],\n",
            "        [ 1.0000e+00],\n",
            "        [3.3234e-122],\n",
            "        [ 1.0000e+00],\n",
            "        [1.7304e-198],\n",
            "        [ 2.9637e-75],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9014e-183],\n",
            "        [2.7662e-195],\n",
            "        [2.6225e-221],\n",
            "        [2.2730e-243],\n",
            "        [ 1.0000e+00],\n",
            "        [4.2652e-242],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4345e-217],\n",
            "        [5.4836e-150]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.3740e-227, -2.5639e-228],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 1.5538e-119, -1.6364e-120],\n",
            "        [  8.4802e+02,  -8.7843e+01],\n",
            "        [ 7.4210e-196, -8.0046e-197],\n",
            "        [  1.4084e-72,  -1.4721e-73],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [ 8.1542e-181, -8.7955e-182],\n",
            "        [ 1.1863e-192, -1.2796e-193],\n",
            "        [ 1.1046e-218, -1.1930e-219],\n",
            "        [ 9.5755e-241, -1.0340e-241],\n",
            "        [  1.2038e+03,  -1.0669e+02],\n",
            "        [ 1.7968e-239, -1.9403e-240],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 6.0424e-215, -6.5257e-216],\n",
            "        [ 2.4325e-147, -2.5942e-148]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 9.5979e-32],\n",
            "        [4.2453e-215],\n",
            "        [ 1.0000e+00],\n",
            "        [9.5227e-251],\n",
            "        [ 6.4605e-65],\n",
            "        [2.7468e-118],\n",
            "        [2.3819e-111],\n",
            "        [2.7563e-240],\n",
            "        [1.3550e-176],\n",
            "        [2.6123e-244],\n",
            "        [ 1.8952e-98],\n",
            "        [ 1.0000e+00],\n",
            "        [1.0827e-120],\n",
            "        [ 3.8097e-32],\n",
            "        [ 4.7826e-68],\n",
            "        [8.8558e-174]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.2636e-29,  -5.3524e-30],\n",
            "        [ 1.7882e-212, -1.9312e-213],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [ 4.0116e-248, -4.3320e-249],\n",
            "        [  3.0416e-62,  -3.2146e-63],\n",
            "        [ 1.3053e-115, -1.3643e-116],\n",
            "        [ 1.1319e-108, -1.1831e-109],\n",
            "        [ 1.1612e-237, -1.2539e-238],\n",
            "        [ 6.0105e-174, -6.4101e-175],\n",
            "        [ 1.1005e-241, -1.1884e-242],\n",
            "        [  9.0059e-96,  -9.4133e-97],\n",
            "        [  5.4963e+02,  -9.1911e+01],\n",
            "        [ 5.0620e-118, -5.3312e-119],\n",
            "        [  2.0893e-29,  -2.1245e-30],\n",
            "        [  2.2227e-65,  -2.3637e-66],\n",
            "        [ 3.9284e-171, -4.1895e-172]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [4.8648e-194],\n",
            "        [1.0179e-234],\n",
            "        [4.6451e-231],\n",
            "        [ 1.2324e-64],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.8339e-39],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0211e-92],\n",
            "        [1.0802e-117],\n",
            "        [ 2.0664e-69],\n",
            "        [ 4.0765e-45],\n",
            "        [1.1515e-214],\n",
            "        [4.7038e-218],\n",
            "        [ 2.8853e-20]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.7836e+02,  -1.2097e+02],\n",
            "        [ 2.0863e-191, -2.2504e-192],\n",
            "        [ 4.2874e-232, -4.6304e-233],\n",
            "        [ 1.9566e-228, -2.1131e-229],\n",
            "        [  5.8021e-62,  -6.1320e-63],\n",
            "        [  5.6697e+02,  -5.8016e+01],\n",
            "        [  9.8781e-37,  -1.0090e-37],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  4.8525e-90,  -5.0720e-91],\n",
            "        [ 5.1329e-115, -5.3651e-116],\n",
            "        [  9.6036e-67,  -1.0213e-67],\n",
            "        [  2.1377e-42,  -2.1984e-43],\n",
            "        [ 4.8503e-212, -5.2382e-213],\n",
            "        [ 1.9813e-215, -2.1398e-216],\n",
            "        [  1.7969e-17,  -1.8133e-18]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.1506e-227],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.8432e-72],\n",
            "        [6.3558e-128],\n",
            "        [ 1.5521e-45],\n",
            "        [9.6722e-160],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.3275e-36],\n",
            "        [ 1.2058e-13],\n",
            "        [6.2280e-205],\n",
            "        [ 2.8043e-87],\n",
            "        [1.4199e-104],\n",
            "        [ 1.0000e+00],\n",
            "        [ 7.7169e-58]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 4.8464e-225, -5.2341e-226],\n",
            "        [  4.9320e+02,  -4.7357e+01],\n",
            "        [  2.7767e-69,  -2.9023e-70],\n",
            "        [ 2.9715e-125, -3.1295e-126],\n",
            "        [  8.1390e-43,  -8.3701e-44],\n",
            "        [ 4.2905e-157, -4.5757e-158],\n",
            "        [  6.6342e+02,  -6.6218e+01],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [  6.6342e+02,  -6.6218e+01],\n",
            "        [  1.8248e-33,  -1.8556e-34],\n",
            "        [  9.1070e-11,  -8.0122e-12],\n",
            "        [ 2.6747e-202, -2.8847e-203],\n",
            "        [  1.3326e-84,  -1.3929e-85],\n",
            "        [ 6.7472e-102, -7.0524e-103],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [  3.6331e-55,  -3.8398e-56]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 3.1412e-39],\n",
            "        [ 7.4903e-37],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.7545e-225],\n",
            "        [3.1029e-192],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1323e-148],\n",
            "        [3.2503e-256],\n",
            "        [1.5652e-116],\n",
            "        [ 1.0000e+00],\n",
            "        [4.3689e-152],\n",
            "        [ 2.2184e-29],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.0099e-247]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.6920e-36,  -1.7283e-37],\n",
            "        [  4.1077e-34,  -4.1771e-35],\n",
            "        [  3.9795e+02,  -4.1608e+01],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 7.3899e-223, -7.9810e-224],\n",
            "        [ 1.3307e-189, -1.4353e-190],\n",
            "        [  6.6342e+02,  -6.6218e+01],\n",
            "        [ 5.0228e-146, -5.3567e-147],\n",
            "        [ 1.3693e-253, -1.4786e-254],\n",
            "        [ 7.4380e-114, -7.7745e-115],\n",
            "        [  1.2731e+03,  -1.1284e+02],\n",
            "        [ 1.9380e-149, -2.0668e-150],\n",
            "        [  1.2166e-26,  -1.2371e-27],\n",
            "        [  4.1606e+02,  -4.4058e+01],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [ 4.2545e-245, -4.5943e-246]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[3.5326e-251],\n",
            "        [ 2.6288e-50],\n",
            "        [2.8876e-144],\n",
            "        [ 6.4151e-73],\n",
            "        [3.2873e-232],\n",
            "        [ 1.0000e+00],\n",
            "        [2.0996e-139],\n",
            "        [6.3037e-255],\n",
            "        [5.8698e-139],\n",
            "        [4.6734e-259],\n",
            "        [ 9.8430e-96],\n",
            "        [2.7723e-250],\n",
            "        [2.9566e-139],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.4882e-248, -1.6071e-249],\n",
            "        [  1.3785e-47,  -1.4177e-48],\n",
            "        [ 1.3044e-141, -1.4049e-142],\n",
            "        [  3.0485e-70,  -3.1863e-71],\n",
            "        [ 1.3846e-229, -1.4954e-230],\n",
            "        [  4.1092e+02,  -4.3286e+01],\n",
            "        [ 9.5597e-137, -1.0244e-137],\n",
            "        [ 2.6556e-252, -2.8677e-253],\n",
            "        [ 2.6726e-136, -2.8639e-137],\n",
            "        [ 1.9688e-256, -2.1260e-257],\n",
            "        [  4.6773e-93,  -4.8889e-94],\n",
            "        [ 1.1679e-247, -1.2612e-248],\n",
            "        [ 1.3462e-136, -1.4426e-137],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  6.4954e+02,  -1.0551e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 9.2523e-61],\n",
            "        [ 5.9002e-70],\n",
            "        [9.2284e-242],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.8633e-24],\n",
            "        [1.1673e-255],\n",
            "        [4.9778e-169],\n",
            "        [ 1.0000e+00],\n",
            "        [ 7.7601e-47],\n",
            "        [ 5.0385e-24],\n",
            "        [ 1.0196e-63],\n",
            "        [ 4.3607e-83],\n",
            "        [3.0383e-201],\n",
            "        [6.8215e-233]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.5111e+02,  -9.3532e+01],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [  4.3560e-58,  -4.6037e-59],\n",
            "        [  2.7421e-67,  -2.9160e-68],\n",
            "        [ 3.8877e-239, -4.1982e-240],\n",
            "        [  6.6342e+02,  -6.6218e+01],\n",
            "        [  3.5849e-21,  -3.5837e-22],\n",
            "        [ 4.9173e-253, -5.3101e-254],\n",
            "        [ 2.2081e-166, -2.3549e-167],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  4.0693e-44,  -4.1849e-45],\n",
            "        [  3.0806e-21,  -3.0796e-22],\n",
            "        [  4.8003e-61,  -5.0734e-62],\n",
            "        [  2.0722e-80,  -2.1659e-81],\n",
            "        [ 1.3030e-198, -1.4055e-199],\n",
            "        [ 2.8733e-230, -3.1031e-231]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.9678e-173],\n",
            "        [ 2.1021e-88],\n",
            "        [ 1.0000e+00],\n",
            "        [2.6897e-232],\n",
            "        [ 5.0918e-65],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9382e-217],\n",
            "        [ 2.4372e-38],\n",
            "        [ 8.8421e-43],\n",
            "        [2.5222e-151],\n",
            "        [2.9253e-219],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.8540e-26],\n",
            "        [1.1122e-180],\n",
            "        [3.5559e-152],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.2037e-170, -2.3501e-171],\n",
            "        [  9.9892e-86,  -1.0441e-86],\n",
            "        [  6.4871e+02,  -1.0633e+02],\n",
            "        [ 1.1329e-229, -1.2235e-230],\n",
            "        [  2.3972e-62,  -2.5336e-63],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [ 8.1638e-215, -8.8168e-216],\n",
            "        [  1.3366e-35,  -1.3591e-36],\n",
            "        [  4.6554e-40,  -4.7789e-41],\n",
            "        [ 1.1188e-148, -1.1932e-149],\n",
            "        [ 1.2321e-216, -1.3307e-217],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [  4.1906e-23,  -4.1892e-24],\n",
            "        [ 4.9335e-178, -5.2615e-179],\n",
            "        [ 1.5773e-149, -1.6822e-150],\n",
            "        [  3.8605e+02,  -3.9216e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.8255e-260],\n",
            "        [ 2.6186e-07],\n",
            "        [1.4190e-252],\n",
            "        [3.4649e-148],\n",
            "        [7.7150e-150],\n",
            "        [1.4427e-244],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.2970e-141],\n",
            "        [8.5984e-112],\n",
            "        [ 5.4430e-81],\n",
            "        [3.4433e-141],\n",
            "        [8.3484e-180],\n",
            "        [1.3083e-100],\n",
            "        [ 1.0000e+00],\n",
            "        [9.0642e-209]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.1903e-257, -1.2854e-258],\n",
            "        [  2.3259e-04,  -2.0395e-05],\n",
            "        [ 5.9779e-250, -6.4554e-251],\n",
            "        [ 1.5652e-145, -1.6858e-146],\n",
            "        [ 3.4223e-147, -3.6498e-148],\n",
            "        [ 6.0775e-242, -6.5629e-243],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [  6.4871e+02,  -1.0633e+02],\n",
            "        [ 1.0459e-138, -1.1207e-139],\n",
            "        [ 4.0860e-109, -4.2708e-110],\n",
            "        [  2.5865e-78,  -2.7035e-79],\n",
            "        [ 1.5678e-138, -1.6800e-139],\n",
            "        [ 3.7033e-177, -3.9494e-178],\n",
            "        [  6.2171e-98,  -6.4983e-99],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 3.8179e-206, -4.1233e-207]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1768e-122],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [8.7530e-191],\n",
            "        [ 4.4194e-93],\n",
            "        [5.8289e-216],\n",
            "        [5.8371e-231],\n",
            "        [ 9.8777e-34],\n",
            "        [3.9933e-192],\n",
            "        [ 2.6296e-34],\n",
            "        [ 5.8305e-72],\n",
            "        [2.8339e-165],\n",
            "        [ 1.0000e+00],\n",
            "        [2.9111e-229]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.8686e+02,  -1.2100e+02],\n",
            "        [  5.7529e+02,  -1.1797e+02],\n",
            "        [ 5.5019e-120, -5.7944e-121],\n",
            "        [  3.8375e+02,  -3.8766e+01],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 3.7538e-188, -4.0490e-189],\n",
            "        [  2.1001e-90,  -2.1951e-91],\n",
            "        [ 2.4552e-213, -2.6516e-214],\n",
            "        [ 2.4586e-228, -2.6553e-229],\n",
            "        [  5.4170e-31,  -5.5084e-32],\n",
            "        [ 1.7125e-189, -1.8472e-190],\n",
            "        [  1.4421e-31,  -1.4664e-32],\n",
            "        [  2.7706e-69,  -2.8960e-70],\n",
            "        [ 1.2571e-162, -1.3406e-163],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [ 1.2262e-226, -1.3242e-227]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[7.3884e-230],\n",
            "        [3.6210e-142],\n",
            "        [1.1687e-233],\n",
            "        [ 1.0000e+00],\n",
            "        [4.7644e-126],\n",
            "        [1.9297e-178],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [4.4235e-261],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.7887e-36],\n",
            "        [ 3.1661e-82],\n",
            "        [2.4386e-247],\n",
            "        [6.0848e-180],\n",
            "        [ 9.1391e-17],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.1121e-227, -3.3610e-228],\n",
            "        [ 1.6487e-139, -1.7667e-140],\n",
            "        [ 4.9226e-231, -5.3164e-232],\n",
            "        [  4.4460e+02,  -4.7974e+01],\n",
            "        [ 2.2275e-123, -2.3459e-124],\n",
            "        [ 8.5598e-176, -9.1287e-177],\n",
            "        [  8.4802e+02,  -8.7843e+01],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 1.8635e-258, -2.0123e-259],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [  9.8092e-34,  -9.9747e-35],\n",
            "        [  1.5045e-79,  -1.5726e-80],\n",
            "        [ 1.0273e-244, -1.1094e-245],\n",
            "        [ 2.6992e-177, -2.8786e-178],\n",
            "        [  5.8699e-14,  -5.9114e-15],\n",
            "        [  8.0770e+02,  -8.3486e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 3.7512e-49],\n",
            "        [3.0057e-245],\n",
            "        [1.1369e-219],\n",
            "        [1.8636e-156],\n",
            "        [1.6503e-141],\n",
            "        [1.5777e-103],\n",
            "        [ 5.1922e-97],\n",
            "        [ 3.8881e-85],\n",
            "        [ 2.6098e-31],\n",
            "        [2.1205e-101],\n",
            "        [4.6492e-214],\n",
            "        [ 8.0251e-08],\n",
            "        [ 1.2760e-38],\n",
            "        [2.5196e-168],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.9671e-46,  -2.0229e-47],\n",
            "        [ 1.2662e-242, -1.3673e-243],\n",
            "        [ 4.7887e-217, -5.1717e-218],\n",
            "        [ 8.2667e-154, -8.8162e-155],\n",
            "        [ 7.5141e-139, -8.0519e-140],\n",
            "        [ 7.4970e-101, -7.8361e-102],\n",
            "        [  2.4673e-94,  -2.5789e-95],\n",
            "        [  1.8476e-82,  -1.9312e-83],\n",
            "        [  1.4312e-28,  -1.4554e-29],\n",
            "        [  1.0076e-98,  -1.0532e-99],\n",
            "        [ 1.9583e-211, -2.1149e-212],\n",
            "        [  7.2970e-05,  -6.3886e-06],\n",
            "        [  6.8731e-36,  -7.0208e-37],\n",
            "        [ 1.1177e-165, -1.1920e-166],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [  5.7495e+02,  -1.1654e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[5.2770e-127],\n",
            "        [ 6.6397e-16],\n",
            "        [ 6.1022e-98],\n",
            "        [6.8448e-257],\n",
            "        [7.3241e-202],\n",
            "        [1.0899e-145],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.8333e-56],\n",
            "        [ 7.4743e-88],\n",
            "        [ 1.0000e+00],\n",
            "        [1.6704e-200],\n",
            "        [1.4685e-181],\n",
            "        [1.9943e-152],\n",
            "        [1.4663e-198],\n",
            "        [9.4651e-221],\n",
            "        [ 6.9427e-77]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.4671e-124, -2.5983e-125],\n",
            "        [  4.7037e-13,  -4.1579e-14],\n",
            "        [  2.8998e-95,  -3.0309e-96],\n",
            "        [ 2.8835e-254, -3.1138e-255],\n",
            "        [ 3.1409e-199, -3.3880e-200],\n",
            "        [ 4.9234e-143, -5.3028e-144],\n",
            "        [  5.2885e+02,  -5.2672e+01],\n",
            "        [  1.3339e-53,  -1.4098e-54],\n",
            "        [  3.5518e-85,  -3.7124e-86],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 7.1635e-198, -7.7269e-199],\n",
            "        [ 6.5144e-179, -6.9474e-180],\n",
            "        [ 8.8466e-150, -9.4346e-151],\n",
            "        [ 6.2881e-196, -6.7826e-197],\n",
            "        [ 3.9867e-218, -4.3056e-219],\n",
            "        [  3.2991e-74,  -3.4484e-75]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.9282e-98],\n",
            "        [1.4887e-176],\n",
            "        [4.7216e-208],\n",
            "        [1.3329e-241],\n",
            "        [ 1.0000e+00],\n",
            "        [4.2554e-207],\n",
            "        [2.8597e-160],\n",
            "        [4.0856e-170],\n",
            "        [1.1376e-160],\n",
            "        [2.5650e-244],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.7714e-19],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.3520e-86],\n",
            "        [ 9.4917e-08],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  9.1625e-96,  -9.5770e-97],\n",
            "        [ 6.6037e-174, -7.0426e-175],\n",
            "        [ 1.9888e-205, -2.1479e-206],\n",
            "        [ 5.6153e-239, -6.0638e-240],\n",
            "        [  5.8689e+02,  -1.2101e+02],\n",
            "        [ 1.7924e-204, -1.9358e-205],\n",
            "        [ 1.2685e-157, -1.3529e-158],\n",
            "        [ 1.8123e-167, -1.9328e-168],\n",
            "        [ 5.0464e-158, -5.3818e-159],\n",
            "        [ 1.0806e-241, -1.1669e-242],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  1.7348e-16,  -1.7495e-17],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [  2.0681e-83,  -2.1616e-84],\n",
            "        [  8.4991e-05,  -7.4498e-06],\n",
            "        [  5.8722e+02,  -1.2032e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 7.0378e-04],\n",
            "        [ 1.0000e+00],\n",
            "        [4.9140e-151],\n",
            "        [ 1.1253e-83],\n",
            "        [1.2529e-257],\n",
            "        [8.2742e-122],\n",
            "        [ 1.7533e-78],\n",
            "        [1.3234e-113],\n",
            "        [7.6395e-142],\n",
            "        [ 1.0000e+00],\n",
            "        [1.0619e-207],\n",
            "        [ 1.2446e-87],\n",
            "        [3.1333e-225],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.1923e-48],\n",
            "        [1.5269e-249]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  8.5596e-01,  -7.5134e-02],\n",
            "        [  3.7601e+02,  -3.7538e+01],\n",
            "        [ 2.1798e-148, -2.3247e-149],\n",
            "        [  5.3473e-81,  -5.5892e-82],\n",
            "        [ 5.2781e-255, -5.6997e-256],\n",
            "        [ 3.8684e-119, -4.0741e-120],\n",
            "        [  8.3317e-76,  -8.7086e-77],\n",
            "        [ 6.2886e-111, -6.5730e-112],\n",
            "        [ 3.4784e-139, -3.7273e-140],\n",
            "        [  5.5111e+02,  -9.3532e+01],\n",
            "        [ 4.4729e-205, -4.8307e-206],\n",
            "        [  5.9142e-85,  -6.1818e-86],\n",
            "        [ 1.3198e-222, -1.4253e-223],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  1.6740e-45,  -1.7215e-46],\n",
            "        [ 6.4324e-247, -6.9462e-248]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.5764e-258],\n",
            "        [ 4.0330e-14],\n",
            "        [ 1.0000e+00],\n",
            "        [4.7169e-163],\n",
            "        [1.6866e-183],\n",
            "        [ 1.0000e+00],\n",
            "        [1.0538e-204],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 9.7426e-01],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4461e-208],\n",
            "        [1.9712e-181],\n",
            "        [2.8661e-235]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 6.6409e-256, -7.1714e-257],\n",
            "        [  3.0461e-11,  -2.6799e-12],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [ 2.0924e-160, -2.2315e-161],\n",
            "        [ 7.2332e-181, -7.8020e-182],\n",
            "        [  3.4418e+02,  -2.7783e+01],\n",
            "        [ 4.5191e-202, -4.8745e-203],\n",
            "        [  5.5792e+02,  -9.8510e+01],\n",
            "        [  5.7012e+02,  -1.1699e+02],\n",
            "        [  3.8954e+02,  -4.0072e+01],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [  1.3417e+03,  -1.1850e+02],\n",
            "        [  5.3872e+02,  -5.4285e+01],\n",
            "        [ 6.0912e-206, -6.5785e-207],\n",
            "        [ 8.7442e-179, -9.3254e-180],\n",
            "        [ 1.2072e-232, -1.3038e-233]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[3.8851e-216],\n",
            "        [2.9024e-142],\n",
            "        [ 9.4693e-19],\n",
            "        [4.2774e-220],\n",
            "        [ 8.0443e-71],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.1384e-21],\n",
            "        [1.1401e-188],\n",
            "        [ 1.0000e+00],\n",
            "        [1.8500e-208],\n",
            "        [ 1.0000e+00],\n",
            "        [1.6247e-156],\n",
            "        [3.5327e-261],\n",
            "        [ 6.3009e-28],\n",
            "        [ 8.0779e-27]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.6365e-213, -1.7674e-214],\n",
            "        [ 1.3215e-139, -1.4161e-140],\n",
            "        [  5.9276e-16,  -5.9779e-17],\n",
            "        [ 1.8017e-217, -1.9458e-218],\n",
            "        [  3.7386e-68,  -3.9757e-69],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  2.5773e-18,  -2.6008e-19],\n",
            "        [ 4.8892e-186, -5.2737e-187],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [ 7.7923e-206, -8.4156e-207],\n",
            "        [  4.2789e+02,  -3.7351e+01],\n",
            "        [ 7.2072e-154, -7.6863e-155],\n",
            "        [ 1.4882e-258, -1.6071e-259],\n",
            "        [  3.8524e-25,  -3.8511e-26],\n",
            "        [  4.9389e-24,  -4.9373e-25]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.0162e-177],\n",
            "        [ 1.0000e+00],\n",
            "        [2.8256e-171],\n",
            "        [9.0082e-143],\n",
            "        [2.6973e-200],\n",
            "        [6.1332e-223],\n",
            "        [ 5.7727e-95],\n",
            "        [ 1.2086e-50],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.5600e-37],\n",
            "        [1.9722e-260],\n",
            "        [1.7828e-166],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9163e-107],\n",
            "        [3.3720e-223],\n",
            "        [1.9495e-213]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 4.5080e-175, -4.8076e-176],\n",
            "        [  5.4963e+02,  -9.1911e+01],\n",
            "        [ 1.2534e-168, -1.3367e-169],\n",
            "        [ 4.1016e-140, -4.3951e-141],\n",
            "        [ 1.1567e-197, -1.2477e-198],\n",
            "        [ 2.5833e-220, -2.7900e-221],\n",
            "        [  2.7432e-92,  -2.8672e-93],\n",
            "        [  6.3378e-48,  -6.5178e-49],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [  1.4039e-34,  -1.4276e-35],\n",
            "        [ 8.3083e-258, -8.9719e-259],\n",
            "        [ 7.9082e-164, -8.4338e-165],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [ 9.1063e-105, -9.5182e-106],\n",
            "        [ 1.4203e-220, -1.5339e-221],\n",
            "        [ 8.2113e-211, -8.8681e-212]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.2341e-252],\n",
            "        [ 8.4921e-70],\n",
            "        [ 3.5277e-91],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.3321e-24],\n",
            "        [1.4765e-171],\n",
            "        [ 2.7284e-61],\n",
            "        [1.0136e-108],\n",
            "        [ 1.1745e-13],\n",
            "        [4.6079e-192],\n",
            "        [1.7685e-118],\n",
            "        [1.1221e-197],\n",
            "        [ 1.0000e+00],\n",
            "        [2.0087e-141],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.7837e-249, -1.9262e-250],\n",
            "        [  3.9467e-67,  -4.1970e-68],\n",
            "        [  1.6763e-88,  -1.7522e-89],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [  8.1447e-22,  -8.1420e-23],\n",
            "        [ 6.5496e-169, -6.9850e-170],\n",
            "        [  1.2845e-58,  -1.3576e-59],\n",
            "        [ 4.8168e-106, -5.0347e-107],\n",
            "        [  8.8707e-11,  -7.8042e-12],\n",
            "        [ 1.9761e-189, -2.1315e-190],\n",
            "        [ 8.4040e-116, -8.7841e-117],\n",
            "        [ 4.8122e-195, -5.1907e-196],\n",
            "        [  5.5109e+02,  -9.3525e+01],\n",
            "        [ 9.1461e-139, -9.8007e-140],\n",
            "        [  3.5124e+02,  -3.1585e+01],\n",
            "        [  5.7495e+02,  -1.1654e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.1916e-84],\n",
            "        [ 7.5322e-94],\n",
            "        [ 1.0000e+00],\n",
            "        [1.8604e-247],\n",
            "        [6.2112e-134],\n",
            "        [ 4.1562e-84],\n",
            "        [ 9.9027e-01],\n",
            "        [ 1.0000e+00],\n",
            "        [8.0628e-207],\n",
            "        [ 1.0000e+00],\n",
            "        [2.7933e-219],\n",
            "        [2.6177e-103],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.1723e-04],\n",
            "        [ 1.0000e+00],\n",
            "        [8.2944e-195]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.6626e-82,  -5.9187e-83],\n",
            "        [  3.5793e-91,  -3.7412e-92],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [ 7.8375e-245, -8.4634e-246],\n",
            "        [ 2.8281e-131, -3.0305e-132],\n",
            "        [  1.9750e-81,  -2.0644e-82],\n",
            "        [  1.3638e+03,  -1.2045e+02],\n",
            "        [  8.2980e+02,  -8.5925e+01],\n",
            "        [ 3.3961e-204, -3.6678e-205],\n",
            "        [  6.4867e+02,  -1.0630e+02],\n",
            "        [ 1.1766e-216, -1.2707e-217],\n",
            "        [ 1.2439e-100, -1.3002e-101],\n",
            "        [  4.8966e+02,  -7.6293e+01],\n",
            "        [  1.3056e-01,  -1.1446e-02],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [ 3.5571e-192, -3.8369e-193]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 5.8407e-84],\n",
            "        [ 5.6504e-35],\n",
            "        [9.1793e-242],\n",
            "        [ 4.1941e-47],\n",
            "        [3.6889e-234],\n",
            "        [2.9990e-143],\n",
            "        [ 2.9791e-65],\n",
            "        [ 5.6847e-05],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4881e-163],\n",
            "        [ 1.0000e+00],\n",
            "        [1.2673e-127],\n",
            "        [ 4.3727e-12],\n",
            "        [ 5.4424e-95],\n",
            "        [ 3.4738e-31]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.8734e+02,  -7.4476e+01],\n",
            "        [  2.7755e-81,  -2.9010e-82],\n",
            "        [  3.0987e-32,  -3.1510e-33],\n",
            "        [ 3.8670e-239, -4.1758e-240],\n",
            "        [  2.1994e-44,  -2.2618e-45],\n",
            "        [ 1.5538e-231, -1.6781e-232],\n",
            "        [ 1.3655e-140, -1.4633e-141],\n",
            "        [  1.4025e-62,  -1.4823e-63],\n",
            "        [  6.1500e-02,  -5.3911e-03],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [ 6.6011e-161, -7.0398e-162],\n",
            "        [  5.7617e+02,  -1.1569e+02],\n",
            "        [ 5.9249e-125, -6.2399e-126],\n",
            "        [  3.4762e-09,  -3.0476e-10],\n",
            "        [  2.5862e-92,  -2.7032e-93],\n",
            "        [  1.9051e-28,  -1.9372e-29]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [5.3238e-104],\n",
            "        [3.8484e-230],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [2.5551e-130],\n",
            "        [2.2349e-175],\n",
            "        [2.9816e-251],\n",
            "        [ 5.2546e-29],\n",
            "        [ 1.4845e-40],\n",
            "        [ 1.0000e+00],\n",
            "        [4.9316e-150],\n",
            "        [ 1.6443e-85],\n",
            "        [1.6351e-105],\n",
            "        [1.5572e-200],\n",
            "        [2.7138e-120]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  3.6463e+02,  -3.5452e+01],\n",
            "        [ 2.5298e-101, -2.6443e-102],\n",
            "        [ 1.6210e-227, -1.7506e-228],\n",
            "        [  8.2608e+02,  -9.1654e+01],\n",
            "        [  3.4981e+02,  -3.0207e+01],\n",
            "        [ 1.1946e-127, -1.2581e-128],\n",
            "        [ 9.9140e-173, -1.0573e-173],\n",
            "        [ 1.2560e-248, -1.3564e-249],\n",
            "        [  2.8817e-26,  -2.9303e-27],\n",
            "        [  7.9958e-38,  -8.1676e-39],\n",
            "        [  8.4802e+02,  -8.7843e+01],\n",
            "        [ 2.1876e-147, -2.3330e-148],\n",
            "        [  7.8135e-83,  -8.1670e-84],\n",
            "        [ 7.7698e-103, -8.1213e-104],\n",
            "        [ 6.6780e-198, -7.2032e-199],\n",
            "        [ 1.2688e-117, -1.3362e-118]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[3.1766e-209],\n",
            "        [ 2.1504e-55],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.1115e-04],\n",
            "        [ 1.4211e-82],\n",
            "        [2.5540e-171],\n",
            "        [1.6567e-220],\n",
            "        [ 1.0000e+00],\n",
            "        [7.0458e-157],\n",
            "        [1.1081e-251],\n",
            "        [2.6494e-155],\n",
            "        [ 1.0000e+00],\n",
            "        [4.1049e-184],\n",
            "        [3.0229e-182],\n",
            "        [5.4986e-199]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.3380e-206, -1.4450e-207],\n",
            "        [  1.0124e-52,  -1.0700e-53],\n",
            "        [  3.8954e+02,  -4.0072e+01],\n",
            "        [  5.0423e+02,  -4.9161e+01],\n",
            "        [  1.2379e-01,  -1.0852e-02],\n",
            "        [  6.7528e-80,  -7.0583e-81],\n",
            "        [ 1.1329e-168, -1.2082e-169],\n",
            "        [ 6.9781e-218, -7.5363e-219],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [ 3.1254e-154, -3.3332e-155],\n",
            "        [ 4.6682e-249, -5.0411e-250],\n",
            "        [ 1.1752e-152, -1.2534e-153],\n",
            "        [  4.6914e+02,  -6.4745e+01],\n",
            "        [ 1.7604e-181, -1.8988e-182],\n",
            "        [ 1.3407e-179, -1.4293e-180],\n",
            "        [ 2.3581e-196, -2.5435e-197]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.3225e-251],\n",
            "        [4.9076e-231],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.4500e-53],\n",
            "        [4.8494e-220],\n",
            "        [ 1.7506e-73],\n",
            "        [ 1.0000e+00],\n",
            "        [1.1371e-111],\n",
            "        [ 1.0000e+00],\n",
            "        [1.7058e-132],\n",
            "        [3.9626e-177],\n",
            "        [1.5663e-158],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.1439e-97],\n",
            "        [ 1.4833e-58],\n",
            "        [ 2.1373e-38]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 5.5715e-249, -6.0165e-250],\n",
            "        [ 2.0671e-228, -2.2325e-229],\n",
            "        [  5.5109e+02,  -9.3525e+01],\n",
            "        [  6.8266e-51,  -7.2149e-52],\n",
            "        [ 2.0426e-217, -2.2060e-218],\n",
            "        [  8.3189e-71,  -8.6952e-72],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [ 5.4036e-109, -5.6481e-110],\n",
            "        [  4.2789e+02,  -3.7351e+01],\n",
            "        [ 7.9607e-130, -8.4152e-131],\n",
            "        [ 1.7578e-174, -1.8746e-175],\n",
            "        [ 6.9482e-156, -7.4100e-157],\n",
            "        [  5.8722e+02,  -1.2032e+02],\n",
            "        [  1.9692e-94,  -2.0582e-95],\n",
            "        [  6.9832e-56,  -7.3804e-57],\n",
            "        [  1.1721e-35,  -1.1919e-36]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 7.8404e-37],\n",
            "        [1.4916e-239],\n",
            "        [ 1.0000e+00],\n",
            "        [3.7552e-156],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.0435e-65],\n",
            "        [5.4738e-106],\n",
            "        [3.1242e-154],\n",
            "        [1.8479e-117],\n",
            "        [1.3379e-198],\n",
            "        [1.5743e-111],\n",
            "        [ 9.5208e-07],\n",
            "        [9.2746e-147],\n",
            "        [ 4.9501e-94],\n",
            "        [ 1.0000e+00],\n",
            "        [9.6458e-188]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.2998e-34,  -4.3723e-35],\n",
            "        [ 6.2836e-237, -6.7855e-238],\n",
            "        [  6.0837e+02,  -1.1248e+02],\n",
            "        [ 1.6658e-153, -1.7765e-154],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  1.9037e-62,  -2.0120e-63],\n",
            "        [ 2.6011e-103, -2.7188e-104],\n",
            "        [ 1.3859e-151, -1.4780e-152],\n",
            "        [ 8.7811e-115, -9.1783e-116],\n",
            "        [ 5.7375e-196, -6.1888e-197],\n",
            "        [ 7.4809e-109, -7.8193e-110],\n",
            "        [  8.7055e-04,  -7.6293e-05],\n",
            "        [ 4.1895e-144, -4.5124e-145],\n",
            "        [  2.3523e-91,  -2.4587e-92],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [ 4.1366e-185, -4.4619e-186]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[3.8749e-206],\n",
            "        [ 1.8251e-52],\n",
            "        [5.7682e-106],\n",
            "        [ 2.2833e-15],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.6538e-56],\n",
            "        [6.5254e-103],\n",
            "        [3.8494e-156],\n",
            "        [ 1.0000e+00],\n",
            "        [1.8664e-198],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.7888e-71],\n",
            "        [1.6529e-117],\n",
            "        [6.7741e-226],\n",
            "        [1.5497e-172],\n",
            "        [ 8.7098e-81]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.6321e-203, -1.7627e-204],\n",
            "        [  9.2031e-50,  -9.5295e-51],\n",
            "        [ 2.7410e-103, -2.8650e-104],\n",
            "        [  1.6758e-12,  -1.4775e-13],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  7.7859e-54,  -8.2288e-55],\n",
            "        [ 3.1009e-100, -3.2411e-101],\n",
            "        [ 1.7076e-153, -1.8211e-154],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 8.0042e-196, -8.6337e-197],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  2.6904e-68,  -2.8610e-69],\n",
            "        [ 7.8546e-115, -8.2098e-116],\n",
            "        [ 2.8533e-223, -3.0815e-224],\n",
            "        [ 6.8741e-170, -7.3311e-171],\n",
            "        [  4.1389e-78,  -4.3261e-79]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.9641e-43],\n",
            "        [6.1827e-202],\n",
            "        [ 1.1334e-29],\n",
            "        [ 4.6576e-85],\n",
            "        [8.1483e-240],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.6441e-02],\n",
            "        [1.1625e-215],\n",
            "        [ 9.7033e-21],\n",
            "        [3.4962e-144],\n",
            "        [8.8715e-197],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.7906e-70],\n",
            "        [3.0505e-254],\n",
            "        [ 5.3986e-20]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.0300e-40,  -1.0592e-41],\n",
            "        [ 2.6515e-199, -2.8600e-200],\n",
            "        [  6.2159e-27,  -6.3208e-28],\n",
            "        [  2.2133e-82,  -2.3134e-83],\n",
            "        [ 3.4327e-237, -3.7068e-238],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  8.0807e+01,  -7.0930e+00],\n",
            "        [ 4.8964e-213, -5.2881e-214],\n",
            "        [  6.0430e-18,  -6.0982e-19],\n",
            "        [ 1.5793e-141, -1.7010e-142],\n",
            "        [ 3.8046e-194, -4.1038e-195],\n",
            "        [  5.9240e+02,  -1.2184e+02],\n",
            "        [  5.9240e+02,  -1.2184e+02],\n",
            "        [  3.1559e-67,  -3.3561e-68],\n",
            "        [ 1.2851e-251, -1.3877e-252],\n",
            "        [  3.3621e-17,  -3.3928e-18]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [2.4818e-115],\n",
            "        [ 1.0000e+00],\n",
            "        [7.2424e-233],\n",
            "        [ 1.7482e-41],\n",
            "        [2.4269e-212],\n",
            "        [4.5477e-147],\n",
            "        [2.6244e-248],\n",
            "        [ 1.0000e+00],\n",
            "        [1.2495e-121],\n",
            "        [1.4710e-195],\n",
            "        [ 1.0000e+00],\n",
            "        [2.6892e-224],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [8.5636e-173]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.3549e+02,  -5.2263e+01],\n",
            "        [ 1.1793e-112, -1.2327e-113],\n",
            "        [  5.7836e+02,  -1.2097e+02],\n",
            "        [ 3.0505e-230, -3.2946e-231],\n",
            "        [  9.4162e-39,  -9.6185e-40],\n",
            "        [ 1.0222e-209, -1.1040e-210],\n",
            "        [ 2.0543e-144, -2.2126e-145],\n",
            "        [ 1.1056e-245, -1.1939e-246],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [ 5.8416e-119, -6.1522e-120],\n",
            "        [ 6.3085e-193, -6.8047e-194],\n",
            "        [  5.4963e+02,  -9.1911e+01],\n",
            "        [ 1.1327e-221, -1.2233e-222],\n",
            "        [  5.5111e+02,  -9.3532e+01],\n",
            "        [  4.2990e+02,  -3.7604e+01],\n",
            "        [ 3.7987e-170, -4.0512e-171]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.7897e-207],\n",
            "        [ 2.3631e-89],\n",
            "        [ 2.2996e-52],\n",
            "        [ 7.6785e-79],\n",
            "        [ 2.4519e-60],\n",
            "        [ 1.0000e+00],\n",
            "        [7.5191e-213],\n",
            "        [4.0244e-133],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 7.1291e-26],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.8617e-83]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 7.5381e-205, -8.1411e-206],\n",
            "        [  1.1229e-86,  -1.1737e-87],\n",
            "        [  1.1596e-49,  -1.2007e-50],\n",
            "        [  3.6488e-76,  -3.8138e-77],\n",
            "        [  1.1544e-57,  -1.2200e-58],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [ 3.1671e-210, -3.4204e-211],\n",
            "        [ 1.8324e-130, -1.9635e-131],\n",
            "        [  9.9929e+02,  -1.0278e+02],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [  4.3588e-23,  -4.3574e-24],\n",
            "        [  9.1512e+02,  -9.3922e+01],\n",
            "        [  3.7238e+02,  -3.6803e+01],\n",
            "        [  5.0423e+02,  -4.9161e+01],\n",
            "        [  3.4981e+02,  -3.0207e+01],\n",
            "        [  2.7855e-80,  -2.9115e-81]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 9.4822e-09],\n",
            "        [3.2771e-135],\n",
            "        [1.4289e-233],\n",
            "        [ 8.2301e-41],\n",
            "        [1.5670e-124],\n",
            "        [8.3660e-164],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0150e-64],\n",
            "        [4.1265e-194],\n",
            "        [7.9472e-259],\n",
            "        [ 1.0000e+00],\n",
            "        [2.9259e-116],\n",
            "        [9.5441e-143],\n",
            "        [ 3.7371e-19],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  8.1600e-06,  -7.1533e-07],\n",
            "        [ 1.4921e-132, -1.5989e-133],\n",
            "        [ 6.0187e-231, -6.5002e-232],\n",
            "        [  4.4330e-38,  -4.5283e-39],\n",
            "        [ 7.3263e-122, -7.7158e-123],\n",
            "        [ 3.7111e-161, -3.9578e-162],\n",
            "        [  5.8686e+02,  -1.2100e+02],\n",
            "        [  4.7785e-62,  -5.0503e-63],\n",
            "        [ 1.7697e-191, -1.9088e-192],\n",
            "        [ 3.3479e-256, -3.6153e-257],\n",
            "        [  3.6463e+02,  -3.5452e+01],\n",
            "        [ 1.3904e-113, -1.4533e-114],\n",
            "        [ 4.3456e-140, -4.6566e-141],\n",
            "        [  2.3394e-16,  -2.3592e-17],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  8.2608e+02,  -9.1654e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 2.4384e-29],\n",
            "        [ 4.4730e-50],\n",
            "        [1.2853e-241],\n",
            "        [1.6078e-200],\n",
            "        [ 8.3135e-01],\n",
            "        [1.6472e-188],\n",
            "        [1.0996e-179],\n",
            "        [5.8518e-161],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [7.6215e-212],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.3507e-85],\n",
            "        [1.9321e-152],\n",
            "        [ 1.2803e-62],\n",
            "        [4.7066e-195]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.3373e-26,  -1.3598e-27],\n",
            "        [  2.3456e-47,  -2.4122e-48],\n",
            "        [ 5.4146e-239, -5.8470e-240],\n",
            "        [ 6.8950e-198, -7.4373e-199],\n",
            "        [  1.0111e+03,  -8.8753e+01],\n",
            "        [ 7.0641e-186, -7.6197e-187],\n",
            "        [ 4.8776e-177, -5.2018e-178],\n",
            "        [ 2.5958e-158, -2.7683e-159],\n",
            "        [  5.0436e+02,  -4.9180e+01],\n",
            "        [  5.7529e+02,  -1.1797e+02],\n",
            "        [ 3.2102e-209, -3.4670e-210],\n",
            "        [  7.8725e+02,  -8.1103e+01],\n",
            "        [  3.0178e-82,  -3.1544e-83],\n",
            "        [ 8.5708e-150, -9.1405e-151],\n",
            "        [  6.0277e-60,  -6.3705e-61],\n",
            "        [ 2.0184e-192, -2.1772e-193]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.2029e-175],\n",
            "        [ 1.0000e+00],\n",
            "        [3.8552e-236],\n",
            "        [3.4426e-137],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9532e-142],\n",
            "        [4.8299e-132],\n",
            "        [ 1.4905e-58],\n",
            "        [2.0557e-107],\n",
            "        [ 2.6678e-96],\n",
            "        [ 4.5649e-61],\n",
            "        [ 1.0000e+00],\n",
            "        [6.7073e-129],\n",
            "        [3.5294e-166],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 9.7719e-173, -1.0421e-173],\n",
            "        [  5.5234e+02,  -5.6044e+01],\n",
            "        [ 1.6238e-233, -1.7537e-234],\n",
            "        [ 1.5675e-134, -1.6797e-135],\n",
            "        [  5.1483e+02,  -5.0428e+01],\n",
            "        [  3.9506e+02,  -3.9294e+01],\n",
            "        [ 8.8934e-140, -9.5299e-141],\n",
            "        [ 2.2581e-129, -2.3782e-130],\n",
            "        [  7.0171e-56,  -7.4162e-57],\n",
            "        [ 9.7685e-105, -1.0210e-105],\n",
            "        [  1.2677e-93,  -1.3251e-94],\n",
            "        [  2.1492e-58,  -2.2714e-59],\n",
            "        [  5.9025e+02,  -1.1900e+02],\n",
            "        [ 3.1359e-126, -3.3026e-127],\n",
            "        [ 1.5656e-163, -1.6697e-164],\n",
            "        [  7.8725e+02,  -8.1103e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.1676e-139],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.1467e-71],\n",
            "        [ 4.6681e-64],\n",
            "        [1.7603e-175],\n",
            "        [4.1066e-203],\n",
            "        [ 5.9217e-15],\n",
            "        [ 1.0000e+00],\n",
            "        [3.6079e-170],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5696e-182],\n",
            "        [ 1.6965e-71],\n",
            "        [ 1.0000e+00],\n",
            "        [5.0689e-158],\n",
            "        [3.2736e-261],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 5.3162e-137, -5.6967e-138],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  5.4491e-69,  -5.6956e-70],\n",
            "        [  2.1977e-61,  -2.3227e-62],\n",
            "        [ 7.8087e-173, -8.3278e-174],\n",
            "        [ 1.7611e-200, -1.8996e-201],\n",
            "        [  4.4103e-12,  -3.8844e-13],\n",
            "        [  6.4537e+02,  -1.0145e+02],\n",
            "        [ 1.6004e-167, -1.7068e-168],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [ 6.9614e-180, -7.4213e-181],\n",
            "        [  7.8846e-69,  -8.3847e-70],\n",
            "        [  5.3872e+02,  -5.4285e+01],\n",
            "        [ 2.2485e-155, -2.3980e-156],\n",
            "        [ 1.3791e-258, -1.4892e-259],\n",
            "        [  5.1483e+02,  -5.0428e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.9063e-58],\n",
            "        [7.7347e-158],\n",
            "        [ 1.2018e-93],\n",
            "        [1.3059e-172],\n",
            "        [5.4342e-124],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.5524e-54],\n",
            "        [3.8978e-255],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.2420e-60],\n",
            "        [4.7872e-208],\n",
            "        [1.7381e-241],\n",
            "        [3.0317e-149],\n",
            "        [ 2.2248e-36],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  8.9750e-56,  -9.4854e-57],\n",
            "        [ 3.4311e-155, -3.6591e-156],\n",
            "        [  5.7111e-91,  -5.9694e-92],\n",
            "        [ 5.7929e-170, -6.1780e-171],\n",
            "        [ 2.5406e-121, -2.6757e-122],\n",
            "        [  5.7012e+02,  -1.1699e+02],\n",
            "        [  2.1433e-51,  -2.2651e-52],\n",
            "        [ 1.6420e-252, -1.7732e-253],\n",
            "        [  8.9764e+02,  -9.2082e+01],\n",
            "        [  2.9387e-57,  -3.1059e-58],\n",
            "        [ 2.0164e-205, -2.1777e-206],\n",
            "        [ 7.3219e-239, -7.9067e-240],\n",
            "        [ 1.3449e-146, -1.4342e-147],\n",
            "        [  1.2201e-33,  -1.2407e-34],\n",
            "        [  3.6463e+02,  -3.5452e+01],\n",
            "        [  4.9249e+02,  -7.6992e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 5.4574e-12],\n",
            "        [ 1.3740e-01],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.5878e-20],\n",
            "        [ 3.2923e-89],\n",
            "        [ 2.0713e-83],\n",
            "        [1.7649e-257],\n",
            "        [ 1.4150e-19],\n",
            "        [9.5829e-133],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.6723e-69],\n",
            "        [2.0719e-105],\n",
            "        [ 1.0923e-96],\n",
            "        [5.5302e-134],\n",
            "        [ 1.5397e-40],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.4372e-09,  -3.8849e-10],\n",
            "        [  1.6711e+02,  -1.4668e+01],\n",
            "        [  6.9260e+02,  -7.0197e+01],\n",
            "        [  2.8572e-17,  -2.8833e-18],\n",
            "        [  1.5645e-86,  -1.6353e-87],\n",
            "        [  9.8428e-81,  -1.0288e-81],\n",
            "        [ 7.4349e-255, -8.0287e-256],\n",
            "        [  8.8579e-17,  -8.9330e-18],\n",
            "        [ 4.3633e-130, -4.6756e-131],\n",
            "        [  5.8689e+02,  -1.2101e+02],\n",
            "        [  3.1010e-66,  -3.2976e-67],\n",
            "        [ 9.8458e-103, -1.0291e-103],\n",
            "        [  5.1907e-94,  -5.4255e-95],\n",
            "        [ 2.5180e-131, -2.6982e-132],\n",
            "        [  8.2932e-38,  -8.4714e-39],\n",
            "        [  4.8966e+02,  -7.6293e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [1.3461e-245],\n",
            "        [6.5544e-164],\n",
            "        [5.1549e-188],\n",
            "        [ 3.7727e-25],\n",
            "        [5.2180e-132],\n",
            "        [1.3444e-120],\n",
            "        [ 1.0000e+00],\n",
            "        [1.3865e-196],\n",
            "        [ 1.0000e+00],\n",
            "        [6.5029e-152],\n",
            "        [ 1.3119e-45],\n",
            "        [2.0169e-186],\n",
            "        [8.7062e-137],\n",
            "        [7.8256e-164],\n",
            "        [1.1569e-150]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.8966e+02,  -7.6293e+01],\n",
            "        [ 5.6707e-243, -6.1236e-244],\n",
            "        [ 2.9075e-161, -3.1007e-162],\n",
            "        [ 2.2107e-185, -2.3846e-186],\n",
            "        [  2.3067e-22,  -2.3059e-23],\n",
            "        [ 2.4396e-129, -2.5693e-130],\n",
            "        [ 6.2855e-118, -6.6197e-119],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [ 5.9459e-194, -6.4135e-195],\n",
            "        [  5.8686e+02,  -1.2100e+02],\n",
            "        [ 2.8846e-149, -3.0764e-150],\n",
            "        [  6.8794e-43,  -7.0748e-44],\n",
            "        [ 8.6494e-184, -9.3297e-185],\n",
            "        [ 3.9641e-134, -4.2478e-135],\n",
            "        [ 3.4714e-161, -3.7021e-162],\n",
            "        [ 5.1320e-148, -5.4731e-149]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[7.9108e-239],\n",
            "        [9.3210e-176],\n",
            "        [ 2.3794e-36],\n",
            "        [7.7570e-234],\n",
            "        [ 4.4818e-84],\n",
            "        [ 1.0000e+00],\n",
            "        [2.7602e-100],\n",
            "        [1.1757e-145],\n",
            "        [ 2.8180e-73],\n",
            "        [ 8.7481e-92],\n",
            "        [3.3591e-130],\n",
            "        [2.1498e-181],\n",
            "        [ 1.0000e+00],\n",
            "        [3.8189e-198],\n",
            "        [3.2267e-170],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.3326e-236, -3.5987e-237],\n",
            "        [ 4.1347e-173, -4.4095e-174],\n",
            "        [  1.3049e-33,  -1.3269e-34],\n",
            "        [ 3.2673e-231, -3.5287e-232],\n",
            "        [  2.1297e-81,  -2.2261e-82],\n",
            "        [  5.7056e+02,  -1.1739e+02],\n",
            "        [  1.3117e-97,  -1.3710e-98],\n",
            "        [ 5.3109e-143, -5.7202e-144],\n",
            "        [  1.3391e-70,  -1.3997e-71],\n",
            "        [  4.1571e-89,  -4.3451e-90],\n",
            "        [ 1.5705e-127, -1.6540e-128],\n",
            "        [ 9.5363e-179, -1.0170e-179],\n",
            "        [  4.8966e+02,  -7.6293e+01],\n",
            "        [ 1.6378e-195, -1.7666e-196],\n",
            "        [ 1.4313e-167, -1.5265e-168],\n",
            "        [  5.9240e+02,  -1.2184e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[6.1993e-128],\n",
            "        [3.4793e-179],\n",
            "        [ 4.2182e-03],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [3.6542e-250],\n",
            "        [4.9870e-245],\n",
            "        [1.5696e-225],\n",
            "        [3.9761e-224],\n",
            "        [7.1867e-182],\n",
            "        [1.3605e-182],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.3759e-94],\n",
            "        [9.1568e-227],\n",
            "        [ 9.3512e-63],\n",
            "        [2.2790e-236]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.8984e-125, -3.0525e-126],\n",
            "        [ 1.5434e-176, -1.6460e-177],\n",
            "        [  5.1304e+00,  -4.5033e-01],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  3.8605e+02,  -3.9216e+01],\n",
            "        [ 1.5394e-247, -1.6624e-248],\n",
            "        [ 2.1009e-242, -2.2687e-243],\n",
            "        [ 6.6114e-223, -7.1402e-224],\n",
            "        [ 1.6748e-221, -1.8087e-222],\n",
            "        [ 3.1873e-179, -3.3979e-180],\n",
            "        [ 6.0337e-180, -6.4323e-181],\n",
            "        [  6.6342e+02,  -6.6218e+01],\n",
            "        [  6.5382e-92,  -6.8339e-93],\n",
            "        [ 3.8569e-224, -4.1654e-225],\n",
            "        [  4.4025e-60,  -4.6529e-61],\n",
            "        [ 9.5995e-234, -1.0367e-234]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.7372e-248],\n",
            "        [ 4.6773e-88],\n",
            "        [1.5785e-131],\n",
            "        [2.7902e-220],\n",
            "        [3.3132e-235],\n",
            "        [ 5.0314e-02],\n",
            "        [2.4598e-138],\n",
            "        [ 6.1683e-93],\n",
            "        [ 1.0000e+00],\n",
            "        [2.0266e-202],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.7911e-86],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.2398e-45]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  3.5124e+02,  -3.1585e+01],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [ 7.3182e-246, -7.9028e-247],\n",
            "        [  2.2226e-85,  -2.3232e-86],\n",
            "        [ 7.3802e-129, -7.7726e-130],\n",
            "        [ 1.1753e-217, -1.2693e-218],\n",
            "        [ 1.3956e-232, -1.5072e-233],\n",
            "        [  6.1194e+01,  -5.3714e+00],\n",
            "        [ 1.1200e-135, -1.2002e-136],\n",
            "        [  2.9312e-90,  -3.0637e-91],\n",
            "        [  1.2021e+03,  -1.0612e+02],\n",
            "        [ 8.6911e-200, -9.3746e-201],\n",
            "        [  4.9459e+02,  -4.7635e+01],\n",
            "        [  1.8015e-83,  -1.8830e-84],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [  1.6989e-42,  -1.7472e-43]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.5929e-177],\n",
            "        [1.1583e-256],\n",
            "        [ 1.0000e+00],\n",
            "        [ 7.1418e-80],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.1292e-76],\n",
            "        [ 1.8624e-95],\n",
            "        [4.6033e-215],\n",
            "        [ 3.0187e-91],\n",
            "        [ 5.5755e-02],\n",
            "        [1.5044e-226],\n",
            "        [ 5.0848e-01],\n",
            "        [ 6.2281e-52],\n",
            "        [ 2.8444e-86],\n",
            "        [ 8.6855e-93]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 7.0660e-175, -7.5357e-176],\n",
            "        [ 4.8797e-254, -5.2695e-255],\n",
            "        [  8.2608e+02,  -9.1654e+01],\n",
            "        [  3.3938e-77,  -3.5473e-78],\n",
            "        [  3.6463e+02,  -3.5452e+01],\n",
            "        [  4.3549e+02,  -5.2263e+01],\n",
            "        [  2.4374e-73,  -2.5476e-74],\n",
            "        [  8.8503e-93,  -9.2506e-94],\n",
            "        [ 1.9389e-212, -2.0940e-213],\n",
            "        [  1.4345e-88,  -1.4994e-89],\n",
            "        [  6.7811e+01,  -5.9523e+00],\n",
            "        [ 6.3365e-224, -6.8434e-225],\n",
            "        [  6.1844e+02,  -5.4284e+01],\n",
            "        [  3.1405e-49,  -3.2519e-50],\n",
            "        [  1.3517e-83,  -1.4128e-84],\n",
            "        [  4.1273e-90,  -4.3140e-91]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[6.3540e-237],\n",
            "        [1.0456e-110],\n",
            "        [1.8916e-153],\n",
            "        [ 1.8806e-20],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5547e-119],\n",
            "        [1.0599e-143],\n",
            "        [9.5280e-144],\n",
            "        [1.0246e-187],\n",
            "        [ 8.4607e-67],\n",
            "        [ 1.0000e+00],\n",
            "        [ 8.8288e-02],\n",
            "        [ 1.0000e+00],\n",
            "        [9.1796e-197],\n",
            "        [4.9919e-184],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.6768e-234, -2.8905e-235],\n",
            "        [ 4.9688e-108, -5.1935e-109],\n",
            "        [ 8.3909e-151, -8.9486e-152],\n",
            "        [  1.1712e-17,  -1.1819e-18],\n",
            "        [  4.9249e+02,  -7.6992e+01],\n",
            "        [ 7.2686e-117, -7.6550e-118],\n",
            "        [ 4.8258e-141, -5.1712e-142],\n",
            "        [ 4.3383e-141, -4.6488e-142],\n",
            "        [ 4.3941e-185, -4.7397e-186],\n",
            "        [  3.9833e-64,  -4.2098e-65],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [  1.0738e+02,  -9.4254e+00],\n",
            "        [  5.5106e+02,  -9.3448e+01],\n",
            "        [ 3.9367e-194, -4.2463e-195],\n",
            "        [ 2.1408e-181, -2.3092e-182],\n",
            "        [  5.5109e+02,  -9.3525e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[6.6728e-116],\n",
            "        [2.4246e-224],\n",
            "        [ 1.9585e-37],\n",
            "        [2.1412e-207],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 8.8029e-19],\n",
            "        [ 1.0000e+00],\n",
            "        [1.6900e-206],\n",
            "        [ 5.6667e-35],\n",
            "        [ 3.2899e-01],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.3806e-07],\n",
            "        [2.9853e-196],\n",
            "        [3.1688e-228],\n",
            "        [6.5497e-176]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.1709e-113, -3.3143e-114],\n",
            "        [ 1.0212e-221, -1.1029e-222],\n",
            "        [  1.0741e-34,  -1.0922e-35],\n",
            "        [ 9.0189e-205, -9.7403e-206],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [  5.5105e-16,  -5.5572e-17],\n",
            "        [  5.7529e+02,  -1.1797e+02],\n",
            "        [ 7.1182e-204, -7.6876e-205],\n",
            "        [  3.1077e-32,  -3.1601e-33],\n",
            "        [  4.0013e+02,  -3.5122e+01],\n",
            "        [  5.5234e+02,  -5.6044e+01],\n",
            "        [  4.0055e-04,  -3.5103e-05],\n",
            "        [ 1.2802e-193, -1.3809e-194],\n",
            "        [ 1.3347e-225, -1.4415e-226],\n",
            "        [ 2.9054e-173, -3.0985e-174]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.2275e-198],\n",
            "        [2.1503e-158],\n",
            "        [ 2.2902e-83],\n",
            "        [ 1.0571e-92],\n",
            "        [ 1.2353e-23],\n",
            "        [ 6.5236e-45],\n",
            "        [ 1.7523e-38],\n",
            "        [ 2.0201e-62],\n",
            "        [1.2080e-179],\n",
            "        [1.0413e-240],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.9964e-36],\n",
            "        [1.5021e-189],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.8130e-195, -1.9556e-196],\n",
            "        [ 9.5384e-156, -1.0172e-156],\n",
            "        [  1.0883e-80,  -1.1375e-81],\n",
            "        [  5.0234e-90,  -5.2507e-91],\n",
            "        [  7.5527e-21,  -7.5502e-22],\n",
            "        [  3.4209e-42,  -3.5181e-43],\n",
            "        [  9.6100e-36,  -9.7721e-37],\n",
            "        [  9.5108e-60,  -1.0052e-60],\n",
            "        [ 5.3584e-177, -5.7146e-178],\n",
            "        [ 4.3867e-238, -4.7371e-239],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [  3.8369e-33,  -3.9016e-34],\n",
            "        [ 6.4416e-187, -6.9482e-188],\n",
            "        [  5.1483e+02,  -5.0428e+01],\n",
            "        [  8.2608e+02,  -9.1654e+01],\n",
            "        [  4.8966e+02,  -7.6293e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 8.6293e-38],\n",
            "        [ 1.0000e+00],\n",
            "        [4.1329e-215],\n",
            "        [2.2638e-164],\n",
            "        [8.3048e-194],\n",
            "        [2.0922e-201],\n",
            "        [4.7140e-250],\n",
            "        [3.5594e-125],\n",
            "        [3.1620e-224],\n",
            "        [1.0887e-180],\n",
            "        [ 1.0000e+00],\n",
            "        [2.4911e-228],\n",
            "        [1.1079e-122],\n",
            "        [ 1.9113e-95],\n",
            "        [3.7361e-210],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.7324e-35,  -4.8122e-36],\n",
            "        [  9.1512e+02,  -9.3922e+01],\n",
            "        [ 1.7408e-212, -1.8800e-213],\n",
            "        [ 1.0042e-161, -1.0709e-162],\n",
            "        [ 3.5615e-191, -3.8416e-192],\n",
            "        [ 8.9724e-199, -9.6781e-200],\n",
            "        [ 1.9859e-247, -2.1445e-248],\n",
            "        [ 1.6641e-122, -1.7526e-123],\n",
            "        [ 1.3318e-221, -1.4384e-222],\n",
            "        [ 4.8294e-178, -5.1504e-179],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [ 1.0493e-225, -1.1332e-226],\n",
            "        [ 5.1797e-120, -5.4551e-121],\n",
            "        [  9.0826e-93,  -9.4934e-94],\n",
            "        [ 1.5737e-207, -1.6995e-208],\n",
            "        [  5.7056e+02,  -1.1739e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.2953e-206],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.9230e-99],\n",
            "        [ 1.1619e-36],\n",
            "        [ 1.0000e+00],\n",
            "        [7.4223e-145],\n",
            "        [ 1.0000e+00],\n",
            "        [5.1624e-163],\n",
            "        [ 1.3343e-25],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.1596e-64],\n",
            "        [5.4687e-222],\n",
            "        [2.6880e-162],\n",
            "        [5.1957e-243],\n",
            "        [1.6598e-194]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 9.6678e-204, -1.0441e-204],\n",
            "        [  4.6914e+02,  -6.4745e+01],\n",
            "        [  9.1380e-97,  -9.5513e-98],\n",
            "        [  6.3719e-34,  -6.4794e-35],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [ 3.3528e-142, -3.6112e-143],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [ 2.2900e-160, -2.4422e-161],\n",
            "        [  8.1578e-23,  -8.1552e-24],\n",
            "        [  5.9025e+02,  -1.1900e+02],\n",
            "        [  5.8068e+02,  -1.1914e+02],\n",
            "        [  1.4876e-61,  -1.5722e-62],\n",
            "        [ 2.3035e-219, -2.4877e-220],\n",
            "        [ 1.1924e-159, -1.2716e-160],\n",
            "        [ 2.1888e-240, -2.3636e-241],\n",
            "        [ 7.1182e-192, -7.6780e-193]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 2.1444e-51],\n",
            "        [ 2.8786e-78],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.1314e-33],\n",
            "        [3.6606e-201],\n",
            "        [1.1124e-189],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.6797e-36],\n",
            "        [4.3921e-213],\n",
            "        [1.0016e-208],\n",
            "        [ 4.4771e-07],\n",
            "        [7.4473e-249],\n",
            "        [3.8369e-173]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.0813e-48,  -1.1197e-49],\n",
            "        [  1.3679e-75,  -1.4298e-76],\n",
            "        [  5.7529e+02,  -1.1797e+02],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  3.7238e+02,  -3.6803e+01],\n",
            "        [  1.7173e-30,  -1.7463e-31],\n",
            "        [ 1.5699e-198, -1.6933e-199],\n",
            "        [ 4.7707e-187, -5.1459e-188],\n",
            "        [  3.9506e+02,  -3.9294e+01],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  2.0180e-33,  -2.0520e-34],\n",
            "        [ 1.8500e-210, -1.9980e-211],\n",
            "        [ 4.2187e-206, -4.5562e-207],\n",
            "        [  4.0937e-04,  -3.5876e-05],\n",
            "        [ 3.1373e-246, -3.3879e-247],\n",
            "        [ 1.7020e-170, -1.8152e-171]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [8.3839e-218],\n",
            "        [3.8586e-104],\n",
            "        [ 1.0334e-95],\n",
            "        [6.0337e-203],\n",
            "        [ 1.0000e+00],\n",
            "        [9.3231e-158],\n",
            "        [2.8273e-195],\n",
            "        [4.6764e-171],\n",
            "        [3.5992e-115],\n",
            "        [5.3254e-206],\n",
            "        [5.1850e-134],\n",
            "        [ 2.6683e-64],\n",
            "        [2.8756e-129],\n",
            "        [ 3.8770e-53],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.8068e+02,  -1.1914e+02],\n",
            "        [ 3.5314e-215, -3.8138e-216],\n",
            "        [ 1.8336e-101, -1.9166e-102],\n",
            "        [  4.9105e-93,  -5.1326e-94],\n",
            "        [ 2.5876e-200, -2.7911e-201],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [ 4.1357e-155, -4.4106e-156],\n",
            "        [ 1.2125e-192, -1.3078e-193],\n",
            "        [ 2.0744e-168, -2.2123e-169],\n",
            "        [ 1.7103e-112, -1.7877e-113],\n",
            "        [ 2.2871e-203, -2.4666e-204],\n",
            "        [ 2.3608e-131, -2.5298e-132],\n",
            "        [  1.2562e-61,  -1.3277e-62],\n",
            "        [ 1.3444e-126, -1.4159e-127],\n",
            "        [  1.8253e-50,  -1.9291e-51],\n",
            "        [  5.9278e+02,  -1.2135e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.3600e-103],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4030e-135],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [5.2341e-174],\n",
            "        [1.3303e-140],\n",
            "        [4.5939e-120],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.0767e-21],\n",
            "        [3.5308e-123],\n",
            "        [3.8366e-190],\n",
            "        [4.3186e-247],\n",
            "        [ 9.1247e-20],\n",
            "        [3.7368e-158]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.1215e-100, -1.1722e-101],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [  5.9025e+02,  -1.1900e+02],\n",
            "        [ 6.3882e-133, -6.8455e-134],\n",
            "        [  4.9249e+02,  -7.6992e+01],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [ 2.3218e-171, -2.4762e-172],\n",
            "        [ 6.0570e-138, -6.4906e-139],\n",
            "        [ 2.1478e-117, -2.2620e-118],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [  1.2832e-18,  -1.2963e-19],\n",
            "        [ 1.6508e-120, -1.7385e-121],\n",
            "        [ 1.6453e-187, -1.7747e-188],\n",
            "        [ 1.8193e-244, -1.9646e-245],\n",
            "        [  5.6827e-17,  -5.7346e-18],\n",
            "        [ 1.6576e-155, -1.7678e-156]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [2.3146e-172],\n",
            "        [ 4.7510e-11],\n",
            "        [5.5803e-128],\n",
            "        [1.7504e-181],\n",
            "        [5.7310e-210],\n",
            "        [ 1.4739e-08],\n",
            "        [ 1.0000e+00],\n",
            "        [3.4527e-132],\n",
            "        [ 1.0280e-23],\n",
            "        [4.9316e-178],\n",
            "        [ 9.3308e-42],\n",
            "        [4.7490e-107],\n",
            "        [4.7684e-192],\n",
            "        [1.9827e-242],\n",
            "        [7.6454e-172]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  8.4802e+02,  -8.7843e+01],\n",
            "        [ 1.0268e-169, -1.0950e-170],\n",
            "        [  3.9406e-08,  -3.4462e-09],\n",
            "        [ 2.6090e-125, -2.7477e-126],\n",
            "        [ 7.7645e-179, -8.2805e-180],\n",
            "        [ 2.4139e-207, -2.6070e-208],\n",
            "        [  1.3056e-05,  -1.1438e-06],\n",
            "        [  5.5109e+02,  -9.3525e+01],\n",
            "        [ 1.6142e-129, -1.7001e-130],\n",
            "        [  6.2850e-21,  -6.2830e-22],\n",
            "        [ 2.1876e-175, -2.3330e-176],\n",
            "        [  5.0259e-39,  -5.1339e-40],\n",
            "        [ 2.2567e-104, -2.3588e-105],\n",
            "        [ 2.0449e-189, -2.2058e-190],\n",
            "        [ 8.3524e-240, -9.0195e-241],\n",
            "        [ 3.3914e-169, -3.6169e-170]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.3450e-211],\n",
            "        [1.0912e-183],\n",
            "        [1.5871e-220],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.1825e-77],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.5300e-64],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.7754e-90],\n",
            "        [4.3944e-247],\n",
            "        [ 9.3907e-93],\n",
            "        [ 7.6797e-65]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  3.7401e+02,  -3.7159e+01],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [  5.1483e+02,  -5.0428e+01],\n",
            "        [ 5.6652e-209, -6.1184e-210],\n",
            "        [ 4.6796e-181, -5.0476e-182],\n",
            "        [ 6.6851e-218, -7.2198e-219],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  5.7012e+02,  -1.1699e+02],\n",
            "        [  2.4627e-74,  -2.5741e-75],\n",
            "        [  3.4981e+02,  -3.0207e+01],\n",
            "        [  1.1911e-61,  -1.2589e-62],\n",
            "        [  3.6463e+02,  -3.5452e+01],\n",
            "        [  1.7940e-87,  -1.8752e-88],\n",
            "        [ 1.8512e-244, -1.9991e-245],\n",
            "        [  4.4624e-90,  -4.6643e-91],\n",
            "        [  3.6156e-62,  -3.8212e-63]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.7107e-250],\n",
            "        [1.1921e-218],\n",
            "        [ 4.1692e-95],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5466e-252],\n",
            "        [1.6854e-221],\n",
            "        [4.6963e-233],\n",
            "        [3.2754e-163],\n",
            "        [ 1.0000e+00],\n",
            "        [3.6934e-125],\n",
            "        [ 1.2546e-76],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.4213e-61],\n",
            "        [ 1.3823e-55],\n",
            "        [2.3760e-123],\n",
            "        [1.1119e-127]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.1420e-247, -1.2332e-248],\n",
            "        [ 5.0211e-216, -5.4228e-217],\n",
            "        [  1.9812e-92,  -2.0708e-93],\n",
            "        [  5.3872e+02,  -5.4285e+01],\n",
            "        [ 6.5153e-250, -7.0357e-251],\n",
            "        [ 7.0991e-219, -7.6670e-220],\n",
            "        [ 1.9781e-230, -2.1363e-231],\n",
            "        [ 1.4529e-160, -1.5495e-161],\n",
            "        [  4.4460e+02,  -4.7974e+01],\n",
            "        [ 1.7268e-122, -1.8186e-123],\n",
            "        [  5.9619e-74,  -6.2315e-75],\n",
            "        [  8.2980e+02,  -8.5925e+01],\n",
            "        [  1.6108e-58,  -1.7024e-59],\n",
            "        [  6.5078e-53,  -6.8779e-54],\n",
            "        [ 1.1108e-120, -1.1699e-121],\n",
            "        [ 5.1986e-125, -5.4750e-126]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [2.4315e-240],\n",
            "        [8.3381e-125],\n",
            "        [ 1.4242e-92],\n",
            "        [3.3235e-170],\n",
            "        [3.2082e-250],\n",
            "        [5.5942e-243],\n",
            "        [1.2084e-152],\n",
            "        [2.5276e-102],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 4.0984e-61],\n",
            "        [5.8535e-230],\n",
            "        [2.2466e-235],\n",
            "        [2.2263e-235],\n",
            "        [1.7752e-204]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.0837e+02,  -1.1248e+02],\n",
            "        [ 1.0243e-237, -1.1061e-238],\n",
            "        [ 3.8983e-122, -4.1056e-123],\n",
            "        [  6.7677e-90,  -7.0738e-91],\n",
            "        [ 1.4743e-167, -1.5723e-168],\n",
            "        [ 1.3515e-247, -1.4595e-248],\n",
            "        [ 2.3567e-240, -2.5449e-241],\n",
            "        [ 5.3603e-150, -5.7166e-151],\n",
            "        [  1.2011e-99, -1.2555e-100],\n",
            "        [  4.3071e+02,  -4.5970e+01],\n",
            "        [  4.6881e+02,  -4.2792e+01],\n",
            "        [  1.9295e-58,  -2.0392e-59],\n",
            "        [ 2.4655e-227, -2.6627e-228],\n",
            "        [ 9.4629e-233, -1.0220e-233],\n",
            "        [ 9.3771e-233, -1.0127e-233],\n",
            "        [ 7.6129e-202, -8.2117e-203]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[6.8274e-229],\n",
            "        [4.1025e-260],\n",
            "        [ 2.8121e-46],\n",
            "        [1.8283e-171],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.6481e-189],\n",
            "        [1.1312e-115],\n",
            "        [ 1.0000e+00],\n",
            "        [1.5592e-217],\n",
            "        [ 4.8453e-58],\n",
            "        [2.0365e-236],\n",
            "        [ 9.9137e-66],\n",
            "        [1.4553e-211],\n",
            "        [6.4536e-155],\n",
            "        [7.1032e-187]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.8758e-226, -3.1058e-227],\n",
            "        [ 1.7283e-257, -1.8663e-258],\n",
            "        [  1.4746e-43,  -1.5165e-44],\n",
            "        [ 8.1102e-169, -8.6493e-170],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [  3.9506e+02,  -3.9294e+01],\n",
            "        [ 7.0681e-187, -7.6240e-188],\n",
            "        [ 5.3754e-113, -5.6185e-114],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [ 6.5673e-215, -7.0926e-216],\n",
            "        [  2.2811e-55,  -2.4109e-56],\n",
            "        [ 8.5778e-234, -9.2639e-235],\n",
            "        [  4.6674e-63,  -4.9328e-64],\n",
            "        [ 6.1299e-209, -6.6202e-210],\n",
            "        [ 2.8628e-152, -3.0531e-153],\n",
            "        [ 3.0462e-184, -3.2858e-185]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.1645e-223],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.4559e-78],\n",
            "        [ 3.4871e-91],\n",
            "        [8.3589e-137],\n",
            "        [1.1346e-230],\n",
            "        [ 1.0000e+00],\n",
            "        [8.1789e-119],\n",
            "        [ 1.0000e+00],\n",
            "        [1.8195e-177],\n",
            "        [2.3334e-223],\n",
            "        [1.3117e-169],\n",
            "        [3.4035e-231],\n",
            "        [2.0501e-164],\n",
            "        [7.6735e-171],\n",
            "        [ 1.2426e-44]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 4.9050e-221, -5.2973e-222],\n",
            "        [  7.6426e+02,  -8.3233e+01],\n",
            "        [  1.1670e-75,  -1.2198e-76],\n",
            "        [  1.6571e-88,  -1.7320e-89],\n",
            "        [ 3.8060e-134, -4.0783e-135],\n",
            "        [ 4.7789e-228, -5.1612e-229],\n",
            "        [  4.9320e+02,  -4.7357e+01],\n",
            "        [ 3.8239e-116, -4.0272e-117],\n",
            "        [  6.4537e+02,  -1.0145e+02],\n",
            "        [ 8.0712e-175, -8.6076e-176],\n",
            "        [ 9.8285e-221, -1.0615e-221],\n",
            "        [ 5.8188e-167, -6.2055e-168],\n",
            "        [ 1.4336e-228, -1.5483e-229],\n",
            "        [ 9.0942e-162, -9.6987e-163],\n",
            "        [ 3.4039e-168, -3.6301e-169],\n",
            "        [  6.5161e-42,  -6.7012e-43]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [1.0301e-200],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [3.7781e-148],\n",
            "        [ 1.9381e-01],\n",
            "        [2.9316e-246],\n",
            "        [5.0809e-129],\n",
            "        [ 9.6877e-01],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.4917e-59],\n",
            "        [3.3150e-104],\n",
            "        [ 2.1535e-78],\n",
            "        [3.6750e-198],\n",
            "        [5.4696e-128],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.6342e+02,  -6.6218e+01],\n",
            "        [ 4.4176e-198, -4.7650e-199],\n",
            "        [  5.4963e+02,  -9.1911e+01],\n",
            "        [  5.9278e+02,  -1.2135e+02],\n",
            "        [ 1.7067e-145, -1.8382e-146],\n",
            "        [  2.3572e+02,  -2.0691e+01],\n",
            "        [ 1.2350e-243, -1.3337e-244],\n",
            "        [ 2.3755e-126, -2.5018e-127],\n",
            "        [  1.2829e+03,  -1.1305e+02],\n",
            "        [  5.9025e+02,  -1.1900e+02],\n",
            "        [  1.6439e-56,  -1.7374e-57],\n",
            "        [ 1.5753e-101, -1.6465e-102],\n",
            "        [  1.0233e-75,  -1.0696e-76],\n",
            "        [ 1.5760e-195, -1.7000e-196],\n",
            "        [ 2.5572e-125, -2.6931e-126],\n",
            "        [  3.6463e+02,  -3.5452e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [4.3756e-206],\n",
            "        [2.1962e-106],\n",
            "        [ 2.2524e-32],\n",
            "        [9.9307e-168],\n",
            "        [1.7885e-162],\n",
            "        [9.4104e-178],\n",
            "        [ 4.3592e-67],\n",
            "        [ 3.0892e-72],\n",
            "        [7.2901e-107],\n",
            "        [1.2874e-221],\n",
            "        [1.0497e-140],\n",
            "        [ 4.0636e-99],\n",
            "        [2.6737e-223],\n",
            "        [ 1.0000e+00],\n",
            "        [5.6776e-203]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.9151e+02,  -1.2118e+02],\n",
            "        [ 1.8430e-203, -1.9904e-204],\n",
            "        [ 1.0436e-103, -1.0908e-104],\n",
            "        [  1.2352e-29,  -1.2561e-30],\n",
            "        [ 4.4052e-165, -4.6980e-166],\n",
            "        [ 7.9338e-160, -8.4612e-161],\n",
            "        [ 4.1744e-175, -4.4519e-176],\n",
            "        [  2.0523e-64,  -2.1690e-65],\n",
            "        [  1.4680e-69,  -1.5344e-70],\n",
            "        [ 3.4642e-104, -3.6209e-105],\n",
            "        [ 5.4226e-219, -5.8563e-220],\n",
            "        [ 4.7795e-138, -5.1216e-139],\n",
            "        [  1.9310e-96,  -2.0183e-97],\n",
            "        [ 1.1262e-220, -1.2163e-221],\n",
            "        [  1.1409e+03,  -1.1591e+02],\n",
            "        [ 2.4348e-200, -2.6263e-201]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[5.9695e-242],\n",
            "        [9.3204e-103],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.9473e-90],\n",
            "        [ 1.0000e+00],\n",
            "        [1.3808e-121],\n",
            "        [ 1.0000e+00],\n",
            "        [2.7671e-176],\n",
            "        [ 9.4817e-01],\n",
            "        [2.0350e-199],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.4679e-28],\n",
            "        [ 1.0000e+00],\n",
            "        [5.7668e-128],\n",
            "        [5.3448e-127],\n",
            "        [ 3.2524e-62]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.5148e-239, -2.7156e-240],\n",
            "        [ 4.4290e-100, -4.6294e-101],\n",
            "        [  9.0583e+02,  -9.2948e+01],\n",
            "        [  9.2534e-88,  -9.6720e-89],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [ 6.4554e-119, -6.7987e-120],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [ 1.2274e-173, -1.3090e-174],\n",
            "        [  1.1532e+03,  -1.0122e+02],\n",
            "        [ 8.7270e-197, -9.4134e-198],\n",
            "        [  4.8734e+02,  -7.4476e+01],\n",
            "        [  1.9380e-25,  -1.9713e-26],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [ 2.6962e-125, -2.8395e-126],\n",
            "        [ 2.4989e-124, -2.6317e-125],\n",
            "        [  1.5312e-59,  -1.6183e-60]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.7729e-106],\n",
            "        [ 4.2599e-70],\n",
            "        [1.7583e-175],\n",
            "        [ 3.0810e-56],\n",
            "        [1.5087e-163],\n",
            "        [4.0943e-102],\n",
            "        [7.7504e-109],\n",
            "        [ 1.0758e-23],\n",
            "        [2.2505e-166],\n",
            "        [1.8707e-233],\n",
            "        [7.5964e-170],\n",
            "        [6.1168e-117],\n",
            "        [5.4723e-212],\n",
            "        [ 8.8212e-47],\n",
            "        [3.3906e-251],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.3177e-103, -1.3773e-104],\n",
            "        [  1.9798e-67,  -2.1054e-68],\n",
            "        [ 7.7996e-173, -8.3180e-174],\n",
            "        [  1.4505e-53,  -1.5330e-54],\n",
            "        [ 6.6925e-161, -7.1374e-162],\n",
            "        [  1.9456e-99, -2.0336e-100],\n",
            "        [ 3.6830e-106, -3.8496e-107],\n",
            "        [  6.5774e-21,  -6.5752e-22],\n",
            "        [ 9.9830e-164, -1.0647e-164],\n",
            "        [ 7.8793e-231, -8.5096e-232],\n",
            "        [ 3.3697e-167, -3.5937e-168],\n",
            "        [ 2.9067e-114, -3.0381e-115],\n",
            "        [ 2.3050e-209, -2.4894e-210],\n",
            "        [  4.6258e-44,  -4.7571e-45],\n",
            "        [ 1.4283e-248, -1.5424e-249],\n",
            "        [  4.8734e+02,  -7.4476e+01]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.4479e-95],\n",
            "        [7.4080e-209],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.8495e-28],\n",
            "        [9.8630e-260],\n",
            "        [ 1.0118e-35],\n",
            "        [ 1.0915e-89],\n",
            "        [3.5348e-225],\n",
            "        [7.3639e-112],\n",
            "        [ 4.5080e-16],\n",
            "        [3.6239e-161],\n",
            "        [3.3767e-152],\n",
            "        [3.9417e-156],\n",
            "        [5.6238e-261],\n",
            "        [2.1110e-128],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  6.8801e-93,  -7.1914e-94],\n",
            "        [ 3.1203e-206, -3.3699e-207],\n",
            "        [  5.3872e+02,  -5.4285e+01],\n",
            "        [  2.1513e-25,  -2.1883e-26],\n",
            "        [ 4.1550e-257, -4.4869e-258],\n",
            "        [  5.5489e-33,  -5.6425e-34],\n",
            "        [  5.1867e-87,  -5.4213e-88],\n",
            "        [ 1.4889e-222, -1.6080e-223],\n",
            "        [ 3.4993e-109, -3.6576e-110],\n",
            "        [  2.8954e-13,  -2.9159e-14],\n",
            "        [ 1.6076e-158, -1.7144e-159],\n",
            "        [ 1.4979e-149, -1.5974e-150],\n",
            "        [ 1.7485e-153, -1.8647e-154],\n",
            "        [ 2.3692e-258, -2.5584e-259],\n",
            "        [ 9.8697e-126, -1.0394e-126],\n",
            "        [  1.2731e+03,  -1.1284e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[2.8016e-181],\n",
            "        [ 3.6315e-18],\n",
            "        [3.0839e-119],\n",
            "        [7.8533e-235],\n",
            "        [8.0179e-222],\n",
            "        [1.7221e-115],\n",
            "        [ 3.6811e-24],\n",
            "        [ 4.4846e-22],\n",
            "        [ 1.3272e-38],\n",
            "        [ 1.8102e-54],\n",
            "        [7.4933e-146],\n",
            "        [ 5.4950e-43],\n",
            "        [ 2.7488e-78],\n",
            "        [ 1.0000e+00],\n",
            "        [7.9658e-224],\n",
            "        [6.7359e-128]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.2428e-178, -1.3254e-179],\n",
            "        [  2.3147e-15,  -2.3327e-16],\n",
            "        [ 1.4418e-116, -1.5185e-117],\n",
            "        [ 3.3078e-232, -3.5724e-233],\n",
            "        [ 3.3772e-219, -3.6473e-220],\n",
            "        [ 8.1836e-113, -8.5538e-114],\n",
            "        [  2.2507e-21,  -2.2499e-22],\n",
            "        [  2.7709e-19,  -2.7993e-20],\n",
            "        [  7.1490e-36,  -7.3026e-37],\n",
            "        [  8.5226e-52,  -9.0073e-53],\n",
            "        [ 3.3849e-143, -3.6458e-144],\n",
            "        [  2.8931e-40,  -2.9698e-41],\n",
            "        [  1.3062e-75,  -1.3653e-76],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 3.3552e-221, -3.6236e-222],\n",
            "        [ 3.1492e-125, -3.3167e-126]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.5007e-216],\n",
            "        [3.0160e-247],\n",
            "        [9.6481e-156],\n",
            "        [2.4007e-225],\n",
            "        [ 1.0000e+00],\n",
            "        [2.1768e-237],\n",
            "        [1.1115e-212],\n",
            "        [1.9867e-139],\n",
            "        [1.2396e-141],\n",
            "        [8.0537e-171],\n",
            "        [1.1214e-240],\n",
            "        [ 1.0179e-08],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4111e-135],\n",
            "        [1.3254e-202]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.8957e-213, -2.0474e-214],\n",
            "        [ 1.2706e-244, -1.3720e-245],\n",
            "        [ 4.2798e-153, -4.5643e-154],\n",
            "        [ 1.0112e-222, -1.0921e-223],\n",
            "        [  4.3639e+02,  -5.5017e+01],\n",
            "        [ 9.1700e-235, -9.9025e-236],\n",
            "        [ 4.6817e-210, -5.0561e-211],\n",
            "        [ 9.0460e-137, -9.6934e-138],\n",
            "        [ 5.6442e-139, -6.0481e-140],\n",
            "        [ 3.5726e-168, -3.8100e-169],\n",
            "        [ 4.7242e-238, -5.1015e-239],\n",
            "        [  8.7598e-06,  -7.6792e-07],\n",
            "        [  4.4460e+02,  -4.7974e+01],\n",
            "        [  5.9151e+02,  -1.2118e+02],\n",
            "        [ 6.4252e-133, -6.8851e-134],\n",
            "        [ 5.6839e-200, -6.1310e-201]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 2.8923e-35],\n",
            "        [ 2.1181e-61],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [9.0123e-218],\n",
            "        [ 2.1100e-48],\n",
            "        [9.9370e-168],\n",
            "        [1.8967e-253],\n",
            "        [3.7115e-123],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.3562e-64],\n",
            "        [1.9818e-239],\n",
            "        [5.5000e-231],\n",
            "        [ 6.8006e-94],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.1415e-60]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.5862e-32,  -1.6129e-33],\n",
            "        [  9.9721e-59,  -1.0539e-59],\n",
            "        [  5.1483e+02,  -5.0428e+01],\n",
            "        [  6.0837e+02,  -1.1248e+02],\n",
            "        [ 3.7960e-215, -4.0997e-216],\n",
            "        [  1.1064e-45,  -1.1379e-46],\n",
            "        [ 4.4080e-165, -4.7009e-166],\n",
            "        [ 7.9903e-251, -8.6285e-252],\n",
            "        [ 1.7353e-120, -1.8275e-121],\n",
            "        [  6.4871e+02,  -1.0633e+02],\n",
            "        [  6.3848e-62,  -6.7480e-63],\n",
            "        [ 8.3487e-237, -9.0155e-238],\n",
            "        [ 2.3166e-228, -2.5020e-229],\n",
            "        [  3.2316e-91,  -3.3778e-92],\n",
            "        [  3.7601e+02,  -3.7538e+01],\n",
            "        [  2.8914e-57,  -3.0559e-58]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 2.4716e-95],\n",
            "        [2.9986e-179],\n",
            "        [ 8.1978e-56],\n",
            "        [1.0800e-187],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [1.4488e-108],\n",
            "        [1.3172e-207],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.8580e-39],\n",
            "        [5.1018e-223],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.3691e-04],\n",
            "        [5.7838e-143],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.1745e-92,  -1.2276e-93],\n",
            "        [ 1.3302e-176, -1.4186e-177],\n",
            "        [  3.8595e-53,  -4.0790e-54],\n",
            "        [ 4.6318e-185, -4.9961e-186],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  4.1092e+02,  -4.3286e+01],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [ 6.8845e-106, -7.1959e-107],\n",
            "        [ 5.5480e-205, -5.9918e-206],\n",
            "        [  9.1512e+02,  -9.3922e+01],\n",
            "        [  3.1553e-36,  -3.2231e-37],\n",
            "        [ 2.1489e-220, -2.3208e-221],\n",
            "        [  4.9410e+02,  -7.8683e+01],\n",
            "        [  4.0976e-01,  -3.5968e-02],\n",
            "        [ 2.6335e-140, -2.8220e-141],\n",
            "        [  5.9240e+02,  -1.2184e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.6068e-134],\n",
            "        [ 1.6903e-83],\n",
            "        [1.6286e-137],\n",
            "        [2.4248e-190],\n",
            "        [ 1.0000e+00],\n",
            "        [1.3559e-227],\n",
            "        [7.3714e-229],\n",
            "        [8.2472e-207],\n",
            "        [ 1.0176e-18],\n",
            "        [1.6518e-106],\n",
            "        [1.0408e-255],\n",
            "        [2.7828e-197],\n",
            "        [7.5761e-254],\n",
            "        [5.6850e-249],\n",
            "        [ 1.0000e+00],\n",
            "        [2.8903e-184]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 7.3160e-132, -7.8396e-133],\n",
            "        [  8.0321e-81,  -8.3954e-82],\n",
            "        [ 7.4151e-135, -7.9458e-136],\n",
            "        [ 1.0399e-187, -1.1217e-188],\n",
            "        [  4.6914e+02,  -6.4745e+01],\n",
            "        [ 5.7110e-225, -6.1679e-226],\n",
            "        [ 3.1049e-226, -3.3532e-227],\n",
            "        [ 3.4738e-204, -3.7516e-205],\n",
            "        [  6.3702e-16,  -6.4242e-17],\n",
            "        [ 7.8495e-104, -8.2045e-105],\n",
            "        [ 4.3844e-253, -4.7346e-254],\n",
            "        [ 1.1934e-194, -1.2873e-195],\n",
            "        [ 3.1916e-251, -3.4465e-252],\n",
            "        [ 2.3949e-246, -2.5862e-247],\n",
            "        [  4.8732e+02,  -7.4469e+01],\n",
            "        [ 1.2395e-181, -1.3370e-182]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 2.6259e-85],\n",
            "        [1.3372e-226],\n",
            "        [2.5482e-172],\n",
            "        [ 4.2173e-62],\n",
            "        [2.8981e-221],\n",
            "        [ 1.0000e+00],\n",
            "        [5.4331e-196],\n",
            "        [3.8905e-173],\n",
            "        [ 1.0000e+00],\n",
            "        [3.0826e-145],\n",
            "        [ 2.8749e-58],\n",
            "        [ 2.7788e-66],\n",
            "        [5.0215e-194],\n",
            "        [5.7435e-218],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.0723e-28]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.2478e-82,  -1.3043e-83],\n",
            "        [ 5.6322e-224, -6.0827e-225],\n",
            "        [ 1.1304e-169, -1.2055e-170],\n",
            "        [  1.9855e-59,  -2.0984e-60],\n",
            "        [ 1.2207e-218, -1.3183e-219],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [ 2.3300e-193, -2.5133e-194],\n",
            "        [ 1.7258e-170, -1.8405e-171],\n",
            "        [  3.8605e+02,  -3.9216e+01],\n",
            "        [ 1.3925e-142, -1.4998e-143],\n",
            "        [  1.3535e-55,  -1.4305e-56],\n",
            "        [  1.3082e-63,  -1.3826e-64],\n",
            "        [ 2.1535e-191, -2.3229e-192],\n",
            "        [ 2.4192e-215, -2.6127e-216],\n",
            "        [  5.8686e+02,  -1.2100e+02],\n",
            "        [  1.7170e-25,  -1.7465e-26]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.2435e-111],\n",
            "        [ 4.3156e-31],\n",
            "        [ 1.0000e+00],\n",
            "        [1.0819e-241],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.7456e-73],\n",
            "        [5.7067e-102],\n",
            "        [4.5861e-107],\n",
            "        [ 6.8398e-86],\n",
            "        [ 4.6814e-36],\n",
            "        [1.6001e-152],\n",
            "        [1.4897e-108],\n",
            "        [ 2.0106e-44],\n",
            "        [ 4.1219e-18],\n",
            "        [ 1.4803e-40]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 5.9092e-109, -6.1765e-110],\n",
            "        [  2.3667e-28,  -2.4066e-29],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [ 4.5579e-239, -4.9219e-240],\n",
            "        [  5.7678e+02,  -1.1955e+02],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [  8.2949e-71,  -8.6701e-72],\n",
            "        [  2.7118e-99, -2.8345e-100],\n",
            "        [ 2.1793e-104, -2.2779e-105],\n",
            "        [  3.2503e-83,  -3.3973e-84],\n",
            "        [  2.5673e-33,  -2.6106e-34],\n",
            "        [ 7.0977e-150, -7.5695e-151],\n",
            "        [ 7.0789e-106, -7.3991e-107],\n",
            "        [  1.0544e-41,  -1.0843e-42],\n",
            "        [  2.6274e-15,  -2.6478e-16],\n",
            "        [  7.9732e-38,  -8.1445e-39]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.8708e-248],\n",
            "        [7.2685e-170],\n",
            "        [ 1.7278e-49],\n",
            "        [ 1.8994e-99],\n",
            "        [ 1.3852e-83],\n",
            "        [1.7286e-173],\n",
            "        [ 1.0000e+00],\n",
            "        [4.5449e-161],\n",
            "        [ 1.0000e+00],\n",
            "        [ 5.4150e-01],\n",
            "        [9.5609e-115],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.7166e-53],\n",
            "        [2.2688e-134],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 7.8811e-246, -8.5106e-247],\n",
            "        [ 3.2242e-167, -3.4385e-168],\n",
            "        [  9.0605e-47,  -9.3178e-48],\n",
            "        [  9.0261e-97,  -9.4344e-98],\n",
            "        [  6.5824e-81,  -6.8801e-82],\n",
            "        [ 7.6678e-171, -8.1775e-172],\n",
            "        [  7.0161e+02,  -7.2315e+01],\n",
            "        [ 2.0161e-158, -2.1501e-159],\n",
            "        [  5.4963e+02,  -9.1911e+01],\n",
            "        [  6.5860e+02,  -5.7810e+01],\n",
            "        [ 4.5433e-112, -4.7488e-113],\n",
            "        [  4.4646e+02,  -4.0025e+01],\n",
            "        [  5.8479e+02,  -1.2238e+02],\n",
            "        [  1.2790e-50,  -1.3517e-51],\n",
            "        [ 1.0330e-131, -1.1070e-132],\n",
            "        [  5.9240e+02,  -1.2184e+02]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[9.3883e-238],\n",
            "        [ 5.9846e-52],\n",
            "        [ 1.4862e-10],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.9042e-79],\n",
            "        [7.9024e-118],\n",
            "        [ 6.1426e-23],\n",
            "        [9.2547e-251],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [4.7323e-168],\n",
            "        [2.8231e-198],\n",
            "        [ 5.2121e-69],\n",
            "        [ 7.9456e-52]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 3.9550e-235, -4.2709e-236],\n",
            "        [  3.0177e-49,  -3.1247e-50],\n",
            "        [  1.2559e-07,  -1.0991e-08],\n",
            "        [  3.4418e+02,  -2.7783e+01],\n",
            "        [  1.8553e-76,  -1.9392e-77],\n",
            "        [ 3.7552e-115, -3.9251e-116],\n",
            "        [  3.7557e-20,  -3.7544e-21],\n",
            "        [ 3.8987e-248, -4.2101e-249],\n",
            "        [  7.8845e+02,  -8.6636e+01],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [  5.5110e+02,  -9.3529e+01],\n",
            "        [  3.6456e+02,  -3.5477e+01],\n",
            "        [ 2.0992e-165, -2.2388e-166],\n",
            "        [ 1.2107e-195, -1.3059e-196],\n",
            "        [  2.4223e-66,  -2.5760e-67],\n",
            "        [  4.0065e-49,  -4.1486e-50]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[4.3121e-235],\n",
            "        [1.0404e-131],\n",
            "        [8.6126e-193],\n",
            "        [ 1.0000e+00],\n",
            "        [4.2697e-125],\n",
            "        [5.6286e-184],\n",
            "        [6.9731e-168],\n",
            "        [7.4146e-194],\n",
            "        [ 1.0000e+00],\n",
            "        [2.0291e-108],\n",
            "        [4.9404e-125],\n",
            "        [3.6401e-223],\n",
            "        [ 3.0370e-88],\n",
            "        [ 6.5463e-32],\n",
            "        [ 4.9828e-52],\n",
            "        [2.8471e-180]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 1.8163e-232, -1.9616e-233],\n",
            "        [ 4.8640e-129, -5.1226e-130],\n",
            "        [ 3.6936e-190, -3.9841e-191],\n",
            "        [  3.5571e+02,  -3.2528e+01],\n",
            "        [ 1.9962e-122, -2.1024e-123],\n",
            "        [ 2.4138e-181, -2.6037e-182],\n",
            "        [ 3.0932e-165, -3.2988e-166],\n",
            "        [ 3.1798e-191, -3.4299e-192],\n",
            "        [  3.8605e+02,  -3.9216e+01],\n",
            "        [ 9.6422e-106, -1.0078e-106],\n",
            "        [ 2.3098e-122, -2.4326e-123],\n",
            "        [ 1.5332e-220, -1.6559e-221],\n",
            "        [  1.4432e-85,  -1.5084e-86],\n",
            "        [  3.5900e-29,  -3.6506e-30],\n",
            "        [  2.5126e-49,  -2.6017e-50],\n",
            "        [ 1.2630e-177, -1.3469e-178]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.9734e-15],\n",
            "        [1.0224e-217],\n",
            "        [ 7.5469e-94],\n",
            "        [8.8319e-235],\n",
            "        [2.5966e-124],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.7197e-89],\n",
            "        [ 1.0000e+00],\n",
            "        [2.8380e-238],\n",
            "        [ 1.0000e+00],\n",
            "        [5.2753e-208],\n",
            "        [ 3.5149e-93]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  4.9249e+02,  -7.6992e+01],\n",
            "        [  9.9929e+02,  -1.0278e+02],\n",
            "        [  8.0770e+02,  -8.3486e+01],\n",
            "        [  5.0423e+02,  -4.9161e+01],\n",
            "        [  2.1822e-12,  -1.9241e-13],\n",
            "        [ 4.3063e-215, -4.6507e-216],\n",
            "        [  3.5862e-91,  -3.7485e-92],\n",
            "        [ 3.7200e-232, -4.0176e-233],\n",
            "        [ 1.2140e-121, -1.2785e-122],\n",
            "        [  8.0956e+02,  -8.9309e+01],\n",
            "        [  8.1721e-87,  -8.5418e-88],\n",
            "        [  6.0837e+02,  -1.1248e+02],\n",
            "        [ 1.1956e-235, -1.2910e-236],\n",
            "        [  8.2980e+02,  -8.5925e+01],\n",
            "        [ 2.2220e-205, -2.3997e-206],\n",
            "        [  1.6703e-90,  -1.7458e-91]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "toReturn:  tensor([[0.0000e+00, 0.0000e+00, 4.7996e-10,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         4.9249e+02],\n",
            "        [2.1132e-17, 4.8732e+02, 6.3858e-27,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         9.9929e+02],\n",
            "        [0.0000e+00, 2.8971e-38, 5.8068e+02,  ..., 1.2559e-07, 0.0000e+00,\n",
            "         8.0770e+02],\n",
            "        ...,\n",
            "        [6.9527e+02, 3.7401e+02, 0.0000e+00,  ..., 0.0000e+00, 3.5900e-29,\n",
            "         8.2980e+02],\n",
            "        [0.0000e+00, 3.0156e-42, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [3.6463e+02, 0.0000e+00, 4.3549e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]])\n",
            "result:  tensor([[1.0000e+00],\n",
            "        [1.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [8.7514e-18],\n",
            "        [0.0000e+00],\n",
            "        [1.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [3.1176e-23],\n",
            "        [0.0000e+00],\n",
            "        [1.2755e-26],\n",
            "        [1.0816e-29],\n",
            "        [1.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.2237e-64],\n",
            "        [2.1956e-211],\n",
            "        [ 8.7514e-18],\n",
            "        [3.2099e-216],\n",
            "        [ 1.0000e+00],\n",
            "        [1.2368e-134],\n",
            "        [4.8419e-134],\n",
            "        [ 3.1176e-23],\n",
            "        [9.8646e-168],\n",
            "        [ 1.2755e-26],\n",
            "        [ 1.0816e-29],\n",
            "        [ 1.0000e+00],\n",
            "        [2.1228e-159],\n",
            "        [9.5382e-126]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  3.2796e+02,  -3.6737e+01],\n",
            "        [  5.1240e+02,  -1.0122e+02],\n",
            "        [  5.7872e-62,  -6.1034e-63],\n",
            "        [ 9.2481e-209, -9.9878e-210],\n",
            "        [  5.6537e-15,  -5.6307e-16],\n",
            "        [ 1.3520e-213, -1.4602e-214],\n",
            "        [  5.2486e+02,  -6.2105e+01],\n",
            "        [ 5.7383e-132, -6.1237e-133],\n",
            "        [ 2.2465e-131, -2.3973e-132],\n",
            "        [  1.9381e-20,  -1.9337e-21],\n",
            "        [ 4.4102e-165, -4.6771e-166],\n",
            "        [  7.8890e-24,  -7.8764e-25],\n",
            "        [  6.4908e-27,  -6.4886e-28],\n",
            "        [  5.4122e+02,  -1.1671e+02],\n",
            "        [ 9.7309e-157, -1.0181e-157],\n",
            "        [ 4.4254e-123, -4.7227e-124]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "toReturn:  tensor([[3.2796e+02],\n",
            "        [5.1240e+02],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [5.6537e-15],\n",
            "        [0.0000e+00],\n",
            "        [5.2486e+02],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [1.9381e-20],\n",
            "        [0.0000e+00],\n",
            "        [7.8890e-24],\n",
            "        [6.4908e-27],\n",
            "        [5.4122e+02],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00]])\n",
            "result:  tensor([[0.0000e+00, 1.9932e-06],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 5.1266e-04],\n",
            "        [0.0000e+00, 0.0000e+00]], grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.1186e-90],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.1009e-83],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [3.0456e-216],\n",
            "        [ 1.0000e+00],\n",
            "        [ 9.6392e-80],\n",
            "        [ 2.9620e-95],\n",
            "        [9.7848e-136],\n",
            "        [ 1.0000e+00],\n",
            "        [4.5394e-147],\n",
            "        [ 1.0000e+00],\n",
            "        [ 6.9431e-48],\n",
            "        [ 6.4598e-90],\n",
            "        [3.5284e-151]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  5.2577e-88,  -5.5755e-89],\n",
            "        [  3.1401e+02,  -3.2521e+01],\n",
            "        [  9.8912e-81,  -1.0454e-81],\n",
            "        [  5.2158e+02,  -6.1544e+01],\n",
            "        [  5.4122e+02,  -1.1671e+02],\n",
            "        [ 1.2828e-213, -1.3855e-214],\n",
            "        [  5.2486e+02,  -6.2105e+01],\n",
            "        [  4.5381e-77,  -4.7963e-78],\n",
            "        [  1.3743e-92,  -1.4666e-93],\n",
            "        [ 4.5398e-133, -4.8448e-134],\n",
            "        [  5.1424e+02,  -9.2635e+01],\n",
            "        [ 2.0333e-144, -2.1656e-145],\n",
            "        [  3.0572e+02,  -2.6910e+01],\n",
            "        [  3.8077e-45,  -3.8719e-46],\n",
            "        [  3.0363e-87,  -3.2199e-88],\n",
            "        [ 1.5805e-148, -1.6833e-149]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[ 1.9932e-06],\n",
            "        [4.3842e-124],\n",
            "        [3.4049e-151],\n",
            "        [1.6262e-184],\n",
            "        [ 1.0000e+00],\n",
            "        [1.2223e-124],\n",
            "        [ 3.0808e-73],\n",
            "        [ 1.0000e+00],\n",
            "        [ 3.0388e-71],\n",
            "        [1.2433e-134],\n",
            "        [ 1.0000e+00],\n",
            "        [5.6247e-137],\n",
            "        [ 1.0000e+00],\n",
            "        [2.5334e-185],\n",
            "        [ 5.1266e-04],\n",
            "        [3.0949e-183]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[  1.6547e-03,  -1.6559e-04],\n",
            "        [ 2.0341e-121, -2.1708e-122],\n",
            "        [ 1.5252e-148, -1.6243e-149],\n",
            "        [ 7.2704e-182, -7.7103e-183],\n",
            "        [  3.8552e+02,  -5.6989e+01],\n",
            "        [ 5.6711e-122, -6.0520e-123],\n",
            "        [  1.4504e-70,  -1.5329e-71],\n",
            "        [  5.5800e+02,  -6.6909e+01],\n",
            "        [  1.4307e-68,  -1.5120e-69],\n",
            "        [ 5.7687e-132, -6.1562e-133],\n",
            "        [  5.4071e+02,  -1.1709e+02],\n",
            "        [ 2.6097e-134, -2.7850e-135],\n",
            "        [  6.8056e+02,  -6.9037e+01],\n",
            "        [ 1.1326e-182, -1.2012e-183],\n",
            "        [  5.2814e-01,  -5.2944e-02],\n",
            "        [ 1.3837e-180, -1.4674e-181]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "toReturn:  tensor([[0.0000e+00, 1.6547e-03],\n",
            "        [3.1401e+02, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [5.2158e+02, 0.0000e+00],\n",
            "        [5.4122e+02, 3.8552e+02],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [5.2486e+02, 0.0000e+00],\n",
            "        [0.0000e+00, 5.5800e+02],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [5.1424e+02, 5.4071e+02],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [3.0572e+02, 6.8056e+02],\n",
            "        [4.2039e-45, 0.0000e+00],\n",
            "        [0.0000e+00, 5.2814e-01],\n",
            "        [0.0000e+00, 0.0000e+00]])\n",
            "result:  tensor([[0.0000e+00, 0.0000e+00, 1.2850e-11, 0.0000e+00],\n",
            "        [9.9280e-01, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.3858e-31, 0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 1.5744e-22, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00]],\n",
            "       grad_fn=<BernoulliSampleFunctionBackward>)\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[5.8501e-175],\n",
            "        [ 9.9280e-01],\n",
            "        [6.1146e-221],\n",
            "        [5.9413e-184],\n",
            "        [5.9787e-194],\n",
            "        [2.9774e-214],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.8091e-82],\n",
            "        [ 7.9982e-51],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [ 2.8963e-73],\n",
            "        [2.1565e-102],\n",
            "        [ 1.6378e-57],\n",
            "        [6.7530e-205],\n",
            "        [ 3.0678e-61]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n",
            "delta:  tensor([[ 2.6154e-172, -2.7737e-173],\n",
            "        [  1.0289e+03,  -1.0329e+02],\n",
            "        [ 2.5755e-218, -2.7815e-219],\n",
            "        [ 2.6562e-181, -2.8170e-182],\n",
            "        [ 2.6516e-191, -2.8268e-192],\n",
            "        [ 1.2541e-211, -1.3544e-212],\n",
            "        [  4.4688e+02,  -8.0728e+01],\n",
            "        [  8.5171e-80,  -9.0015e-81],\n",
            "        [  4.2111e-48,  -4.3228e-49],\n",
            "        [  5.1241e+02,  -1.0122e+02],\n",
            "        [  7.1507e+02,  -7.2897e+01],\n",
            "        [  1.3636e-70,  -1.4411e-71],\n",
            "        [  1.0005e-99, -1.0677e-100],\n",
            "        [  8.2930e-55,  -8.5706e-56],\n",
            "        [ 2.8960e-202, -3.1238e-203],\n",
            "        [  1.5534e-58,  -1.6054e-59]], dtype=torch.float64)\n",
            "torch.Size([16, 2])\n",
            "linear 4: 128  :  1\n",
            "grad_output i :  torch.Size([16, 1])\n",
            "tensor([[1.6214e-142],\n",
            "        [ 1.0973e-91],\n",
            "        [3.2034e-126],\n",
            "        [ 2.2145e-50],\n",
            "        [3.1560e-173],\n",
            "        [ 1.0000e+00],\n",
            "        [1.3695e-197],\n",
            "        [3.7878e-154],\n",
            "        [ 1.0000e+00],\n",
            "        [1.9910e-217],\n",
            "        [ 1.0000e+00],\n",
            "        [ 1.0000e+00],\n",
            "        [6.8379e-182],\n",
            "        [ 1.0000e+00],\n",
            "        [2.0604e-131],\n",
            "        [ 1.0000e+00]], dtype=torch.float64)\n",
            "l4 w:  torch.Size([1, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:266: UserWarning: Error detected in BernoulliSampleFunctionBackward. Traceback of forward call that caused the error:\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-105-158ce2e3dc89>\", line 44, in <cell line: 44>\n",
            "    train_dbn(dataloader, dbn_model, num_epochs=1000, learning_rate=0.001, device=device)\n",
            "  File \"<ipython-input-105-158ce2e3dc89>\", line 25, in train_dbn\n",
            "    loss, output = dbn_model(x.to(device).float())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"<ipython-input-104-704ba5d98df3>\", line 160, in forward\n",
            "    energy_pos_samples = self.positive_phase(1, N, v_prob)\n",
            "  File \"<ipython-input-104-704ba5d98df3>\", line 189, in positive_phase\n",
            "    energy_pos, v, h = self.coupling(v, h, True)\n",
            "  File \"<ipython-input-104-704ba5d98df3>\", line 263, in coupling\n",
            "    v, h = self.mh_step(v, h, fix_v)\n",
            "  File \"<ipython-input-104-704ba5d98df3>\", line 437, in mh_step\n",
            "    h_[i] = self.bernoulli_sample(torch.sigmoid(h_[i]))\n",
            "  File \"<ipython-input-104-704ba5d98df3>\", line 312, in bernoulli_sample\n",
            "    return BernoulliSampleFunction.apply(probabilities)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 553, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:113.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-158ce2e3dc89>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#state_dict = torch.load(\"dbn_modelv2_deepConv.pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#dbn_model.load_state_dict(state_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain_dbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-105-158ce2e3dc89>\u001b[0m in \u001b[0;36mtrain_dbn\u001b[0;34m(dataloader, dbn_model, num_epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" validation loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\" time: {elapsed_time:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    287\u001b[0m             )\n\u001b[1;32m    288\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-704ba5d98df3>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mlinear1_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Derivative of ReLU w.r.t. input x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear1_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delta: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;31m# See full discussion on the problems with returning `Union` here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[0;31m# https://github.com/microsoft/pyright/issues/4213\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import math\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "def train_dbn(dataloader, dbn_model, num_epochs, learning_rate, device):\n",
        "    dbn_model.to(device)  # Ensure model is on the correct device\n",
        "    dbn_model.train()\n",
        "    optimizer = Adam(dbn_model.parameters(), lr=learning_rate)\n",
        "    scheduler = LambdaLR(optimizer,\n",
        "                         lr_lambda=lambda t: 1 / math.sqrt(1 + 0.001))\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss=0\n",
        "        total_val=0\n",
        "        i=0\n",
        "        start_time = time.time()\n",
        "        for step, (x, x_e) in enumerate(dataloader):\n",
        "            i+=1\n",
        "            #optimizer.zero_grad()\n",
        "\n",
        "            loss, output = dbn_model(x.to(device).float())\n",
        "            total_loss+=loss.mean().item()\n",
        "            loss2=F.cross_entropy(output, x_e.to(device))\n",
        "            loss = loss.mean() + 0.1*loss2\n",
        "\n",
        "            total_val+=loss2.item()\n",
        "            end_time = time.time()\n",
        "            elapsed_time = end_time - start_time\n",
        "            print(\"data \",step, \" loss: \",loss,\" validation loss: \",loss2, f\" time: {elapsed_time:.4f}\")\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        print(f\"Epoch {epoch} avg loss: {total_loss/i:.4f} avg val loss: {total_val/i:.4f} time: {elapsed_time:.4f}\")\n",
        "\n",
        "dbn_model = DBM(num_features, [4,2,1],model2).to(device)\n",
        "#state_dict = torch.load(\"dbn_modelv2_deepConv.pt\")\n",
        "#dbn_model.load_state_dict(state_dict)\n",
        "train_dbn(dataloader, dbn_model, num_epochs=1000, learning_rate=0.001, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for name, param in dbn_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.grad.data)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_grad_distribution(model):\n",
        "    all_grads = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            all_grads.append(param.grad.data.cpu().flatten())  # Flatten for easier histogramming\n",
        "\n",
        "    plt.hist(all_grads, bins=50)\n",
        "    plt.xlabel(\"Gradient Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Distribution of Gradients in Model\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_grad_distribution(dbn_model)  # Call after .backward()\n",
        "\n"
      ],
      "metadata": {
        "id": "3OGxld1JJQCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p3E7iXRspPJ",
        "outputId": "615ee4ae-6e4e-49e6-88ad-7925deffd8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.2.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchviz)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchviz)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchviz)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchviz)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchviz)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchviz)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->torchviz)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchviz)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4132 sha256=7ae673b903160ac9877e9390feda1df03c365c9d9892b766ce409cd955757953\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Bernoulli, Independent\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "L = 3\n",
        "nh = 10\n",
        "nv = 5\n",
        "\n",
        "v = torch.rand(batch_size, nv, requires_grad=True, dtype=torch.float64)\n",
        "h = [torch.randn(batch_size, nh, requires_grad=True, dtype=torch.float64) for _ in range(L)]\n",
        "\n",
        "\n",
        "weight = nn.ParameterList([nn.Parameter(torch.randn(nh, nv, requires_grad=True, dtype=torch.float64))])\n",
        "weight.extend([nn.Parameter(torch.randn(nh, nh, requires_grad=True, dtype=torch.float64)) for _ in range(L-1)])\n",
        "bias = nn.ParameterList([nn.Parameter(torch.randn(nv, requires_grad=True, dtype=torch.float64))])\n",
        "bias.extend([nn.Parameter(torch.randn(nh, requires_grad=True, dtype=torch.float64)) for _ in range(L)])\n",
        "def energy1(v, h):\n",
        "        energy = - torch.sum(v * bias[0].unsqueeze(0), 1)\n",
        "\n",
        "        for i in range(L):\n",
        "            logits = F.linear(v if i==0 else h[i-1],\n",
        "                              weight[i], bias[i+1])\n",
        "\n",
        "            energy -= torch.sum(h[i] * logits, 1)\n",
        "\n",
        "        return energy\n",
        "\n",
        "def mh_step1(v, h, fix_v=False,\n",
        "                rand_v=None, rand_h=None, rand_u=None):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "\n",
        "        if fix_v:\n",
        "            v_ = v\n",
        "        else:\n",
        "            if rand_v is None:\n",
        "                v_ = torch.empty_like(v).bernoulli_()\n",
        "            else:\n",
        "                v_ = (rand_v < 0.5).float()\n",
        "\n",
        "        if rand_h is None:\n",
        "            h_ = [torch.empty_like(h[i]).bernoulli_() for i in range(L)]\n",
        "        else:\n",
        "            h_ = [(rand_h[i] < 0.5).float() for i in range(L)]\n",
        "\n",
        "        log_ratio = energy1(v, h) - energy1(v_, h_)\n",
        "\n",
        "        if rand_u is None:\n",
        "            accepted = log_ratio.exp().clamp(0, 1).bernoulli().bool()\n",
        "        else:\n",
        "            accepted = rand_u < log_ratio.exp()\n",
        "\n",
        "        if not fix_v:\n",
        "            v = torch.where(accepted.unsqueeze(1), v_, v)\n",
        "        h = [torch.where(accepted.unsqueeze(1), h_[i], h[i]) for i in range(L)]\n",
        "\n",
        "        return v, h\n",
        "\n",
        "\n",
        "result1 = mh_step1(v,h)\n",
        "\n",
        "\n",
        "class ComparatorNetwork(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            nn.Linear(2, hidden_dim),  # Input dimension changed to 2\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1)  # Output remains the same\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.layers(x))\n",
        "\n",
        "class BernoulliApproximator(nn.Module):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(2, hidden_dim)\n",
        "    self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.linear4 = nn.Linear(hidden_dim, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.x=None\n",
        "    self.out1 = None\n",
        "    self.out2 = None\n",
        "    self.out3 = None\n",
        "    self.out4 = None\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.x=x\n",
        "    out = self.relu(self.linear1(x))\n",
        "    self.out1 = out\n",
        "    out = self.relu(self.linear2(out))\n",
        "    self.out2 = out\n",
        "    out = self.relu(self.linear3(out))\n",
        "    self.out3 = out\n",
        "    out = torch.sigmoid(self.linear4(out))\n",
        "    self.out4 = out\n",
        "    return out\n",
        "\n",
        "model = torch.load('bernoullimodel8.pth')\n",
        "\n",
        "model2 = torch.load('greater_than2.pth')\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.data = param.data.double()  # Convert to float64\n",
        "\n",
        "for param in model2.parameters():\n",
        "    param.data = param.data.double()\n",
        "\n",
        "\n",
        "\n",
        "def energy(v, h):\n",
        "        energy = - torch.sum(v * bias[0].unsqueeze(0), 1)\n",
        "        for i in range(L):\n",
        "            logits = F.linear(v if i==0 else h[i-1],\n",
        "                              weight[i], bias[i+1])\n",
        "            energy = energy - torch.sum(h[i] * logits, 1)\n",
        "        return energy\n",
        "\n",
        "def greaterThan(a,b):\n",
        "      if len(a.shape)>1:\n",
        "        result = torch.zeros_like(a)\n",
        "        for i in range(a.shape[1]):\n",
        "          result[:,i] = model2(torch.concat((a[:,i].unsqueeze(1),b[:,i].unsqueeze(1)),dim=1)).squeeze()\n",
        "        return result\n",
        "      else:\n",
        "        return model2(torch.concat((a.unsqueeze(1),b.unsqueeze(1)),dim=1)).squeeze()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"model test: \",model(torch.tensor([0.3,19]).double()))\n",
        "print(\"model test: \",model(torch.tensor([0.3,4]).double()))\n",
        "print(\"model test: \",model(torch.tensor([0.9,18]).double()))\n",
        "print(\"model test: \",model(torch.tensor([0.9,10]).double()))\n",
        "class BernoulliSampleFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, probabilities, model):\n",
        "        result = torch.zeros_like(probabilities)\n",
        "        out4 = []\n",
        "        out3 = []\n",
        "        out2 = []\n",
        "        out1 = []\n",
        "        for i in range(probabilities.shape[1]):\n",
        "          randomNumber =  (torch.randint(0,20,(probabilities.shape[0],1))).double()\n",
        "         # print(\"rn: \",randomNumber)\n",
        "        #  print(\"rn: \",randomNumber.shape)\n",
        "       #   print(\"probabilities[:,i]: \",probabilities[:,i])\n",
        "          input = torch.concat((probabilities[:,i].unsqueeze(1),randomNumber),dim=1)\n",
        "          result[:,i] = model(input).squeeze().double()\n",
        "       #   print(\"result i : \",result[:,i])\n",
        "          out4.append(model.out4)\n",
        "          out3.append(model.out3)\n",
        "          out2.append(model.out2)\n",
        "          out1.append(model.out1)\n",
        "        out1 = torch.stack(out1, dim=0)\n",
        "        out2 = torch.stack(out2, dim=0)\n",
        "        out3 = torch.stack(out3, dim=0)\n",
        "        out4 = torch.stack(out4, dim=0)\n",
        "        ctx.save_for_backward(result,out4,out3,out2,out1) # Store for backward pass\n",
        "      #  print(\"result: \", result)\n",
        "        return result.squeeze()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      result, out4, out3, out2, out1= ctx.saved_tensors\n",
        "   #   print(\"result: \",result)\n",
        "      toReturn = torch.zeros_like(result)\n",
        "      for i in range(result.shape[1]):\n",
        "    #    print(\"linear 4:\" ,model.linear4.in_features, \" : \",model.linear4.out_features)\n",
        "        linear4_copy = nn.Linear(model.linear4.in_features, model.linear4.out_features).to(device)\n",
        "        linear4_copy.weight.data.copy_(model.linear4.weight.data.double())\n",
        "        linear4_copy.bias.data.copy_(model.linear4.bias.data.double())\n",
        "       # print(\"grad_output i : \",grad_output[:,i])\n",
        "   #     print(out4[i,:,:])\n",
        "         #print(\"grad_output: \",grad_output[:,i].shape)\n",
        "      #  print(\"out4: \",out4[i,:,:])\n",
        "        delta = (grad_output[:,i].unsqueeze(1) * (out4[i,:,:])).double()  # Sigmoid derivative\n",
        "     #   print(\"delta: \",delta.shape)\n",
        "    #    print(\"delta initial: \",delta)\n",
        "  #      print(\"l4 w: \",linear4_copy.weight.shape)\n",
        "        delta = torch.mm(delta,linear4_copy.weight.double())\n",
        "     #   print(\"delta 4: \",delta)\n",
        "     #   print(delta.shape)\n",
        "\n",
        "        linear3_copy = nn.Linear(model.linear3.in_features, model.linear3.out_features).to(device)\n",
        "        linear3_copy.weight.data.copy_(model.linear3.weight.data.double())\n",
        "        linear3_copy.bias.data.copy_(model.linear3.bias.data.double())\n",
        "        delta = delta * torch.where(out3[i,:,:] > 0, 1, 0)  # Derivative of ReLU\n",
        "        delta = torch.mm(delta, linear3_copy.weight.double())\n",
        "    #    print(\"delta3: \",delta)\n",
        "       # print(delta.shape)\n",
        "\n",
        "        linear2_copy = nn.Linear(model.linear2.in_features, model.linear2.out_features).to(device)\n",
        "        linear2_copy.weight.data.copy_(model.linear2.weight.data.double())\n",
        "        linear2_copy.bias.data.copy_(model.linear2.bias.data.double())\n",
        "        delta = delta * torch.where(out2[i,:,:] > 0, 1, 0)  # Derivative of ReLU\n",
        "        delta = torch.mm(delta, linear2_copy.weight.double())\n",
        "      #  print(\"delta2: \",delta)\n",
        "     #   print(delta.shape)\n",
        "\n",
        "        # Backpropagate through first layer (ReLU)\n",
        "        linear1_copy = nn.Linear(model.linear1.in_features, model.linear1.out_features).to(device)\n",
        "        linear1_copy.weight.data.copy_(model.linear1.weight.data.double())\n",
        "        linear1_copy.bias.data.copy_(model.linear1.bias.data.double())\n",
        "        delta = delta * torch.where(out1[i,:,:] > 0, 1, 0)  # Derivative of ReLU w.r.t. input x\n",
        "        delta = torch.mm(delta, linear1_copy.weight.double())\n",
        "      #  print(\"delta final: \",delta)\n",
        "      #  print(delta.shape)\n",
        "        toReturn[:,i] = delta[:,0]\n",
        "   #   print(\"toReturn: \",toReturn)\n",
        "      return toReturn*1000, None\n",
        "\n",
        "def bernoulli_sample(probabilities):\n",
        "      #print(\"probs: \",probabilities)\n",
        "      result = BernoulliSampleFunction.apply(probabilities, model)\n",
        "    #  print(\"result: \",result)\n",
        "      return torch.tensor(result)\n",
        "\n",
        "#test = torch.autograd.gradcheck(energy, (v,h[0],h[1],h[2]),create_graph=True)\n",
        "#print(\"AUTOGRAD-1: \",test)\n",
        "#test = torch.autograd.gradcheck(greaterThan, (h[0],h[1]),create_graph=True)\n",
        "#print(\"AUTOGRAD-2: \",test)\n",
        "#test = torch.autograd.gradcheck(bernoulli_sample, (v))\n",
        "#print(\"AUTOGRAD-3: \",test)\n",
        "from torchviz import make_dot\n",
        "\n",
        "\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "class MHStepFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, v, fix_v, rand_v, rand_h, rand_u, *h):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        L = len(h)\n",
        "\n",
        "        if fix_v:\n",
        "            v_ = v\n",
        "        else:\n",
        "            if rand_v is None:\n",
        "                input = torch.full_like(v, 0.5, requires_grad=True)\n",
        "                v_ = bernoulli_sample(input)  # Replace with your implementation\n",
        "            else:\n",
        "                v_ = greaterThan(torch.full_like(rand_v, 0.5, requires_grad=True), rand_v)\n",
        "\n",
        "        if rand_h is None:\n",
        "            h_ = [torch.full_like(h[i], 0.5, requires_grad=True) for i in range(L)]\n",
        "            for i in range(L):\n",
        "                h_[i] = bernoulli_sample(h_[i])\n",
        "        else:\n",
        "            h_ = [torch.ones_like(h[i], requires_grad=True) for i in range(L)]\n",
        "            for i in range(L):\n",
        "                h_[i] = greaterThan(torch.full_like(rand_h[i], 0.5, requires_grad=True), rand_h[i])\n",
        "\n",
        "        log_ratio = energy(v, h) - energy(v_, h_)\n",
        "\n",
        "        if rand_u is None:\n",
        "            accepted = log_ratio.exp().clamp(0, 1).bernoulli().bool()\n",
        "        else:\n",
        "            accepted = rand_u < log_ratio.exp()\n",
        "\n",
        "        if not fix_v:\n",
        "            v = torch.where(accepted.unsqueeze(1), v_, v)\n",
        "        h = [torch.where(accepted.unsqueeze(1), h_[i], h[i]) for i in range(L)]\n",
        "\n",
        "        # For backward, we need accepted and a mask indicating non-updated values\n",
        "        ctx.save_for_backward(accepted)\n",
        "        ctx.mark_non_differentiable(accepted)\n",
        "        return v, *h\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_v, *grad_h):\n",
        "        # Load the mask indicating non-updated values\n",
        "        accepted = ctx.saved_tensors[0]\n",
        "        grad_h = list(grad_h)\n",
        "        # Zero out gradients where accepted is True (or not_accepted is False)\n",
        "        grad_v = torch.where(accepted.unsqueeze(1),0,grad_v)\n",
        "        for i in range(len(grad_h)):\n",
        "            grad_h[i] = torch.where(accepted.unsqueeze(1),0,grad_h[i])\n",
        "\n",
        "        print(\"v: \",grad_v)\n",
        "        [print(h) for h in grad_h]\n",
        "        return (grad_v, None, None, None, None, *grad_h,)  # Gradients for other inputs are None\n",
        "\n",
        "\n",
        "def mh_step2(v, *h, fix_v=False, rand_v=None, rand_h=None, rand_u=None):\n",
        "      return MHStepFunction.apply(v, fix_v, rand_v, rand_h, rand_u,*h)\n",
        "\n",
        "result2 = MHStepFunction.apply(v,None,None,None,None,h[0],h[1],h[2])\n",
        "y_hat = result2[1]\n",
        "# Generate the graph\n",
        "graph = make_dot(y_hat,show_attrs=True, show_saved=True)\n",
        "\n",
        "# Render and save the graph (adjust the filename if needed)\n",
        "graph.render(\"h_mh_step2_graph2\", format=\"png\")\n",
        "\n",
        "test = torch.autograd.gradcheck(mh_step2, (v,h[0],h[1],h[2]))\n",
        "\n",
        "\n",
        "#test = torch.autograd.gradcheck(mh_step2, (v,h[0],h[1],h[2]))\n",
        "#print(\"AUTOGRAD1: \",test)\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def plot_histograms_and_stats(results, title):\n",
        "    if len(results)==3:\n",
        "      _,v,h = results\n",
        "    else:\n",
        "      v, *h = results\n",
        "\n",
        "    # Flatten all the tensors to get a single tensor for easier handling\n",
        "    all_tensors = v\n",
        "    for h1 in h:\n",
        "      for h2 in h1:\n",
        "        all_tensors = torch.cat((all_tensors.flatten(),h2.flatten()),dim=0)\n",
        "    all_tensors = all_tensors.flatten().detach()\n",
        "\n",
        "    # Calculate mean and standard deviation\n",
        "    mean = torch.mean(all_tensors).item()\n",
        "    std = torch.std(all_tensors).item()\n",
        "\n",
        "    # Creating histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(all_tensors.numpy(), bins=50, alpha=0.75, color='blue')\n",
        "    plt.title(f'Histogram of all values in {title}\\nMean: {mean:.4f}, Std: {std:.4f}')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "# Assuming result1 and result2 have been generated correctly by the provided code snippet\n",
        "mean1, std1 = plot_histograms_and_stats(result1, 'result1')\n",
        "mean2, std2 = plot_histograms_and_stats(result2, 'result2')\n",
        "\n",
        "print(f\"Result1 - Mean: {mean1:.4f}, Std: {std1:.4f}\")\n",
        "print(f\"Result2 - Mean: {mean2:.4f}, Std: {std2:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mh_step2(v, *h, fix_v=False, rand_v=None, rand_h=None, rand_u=None):\n",
        "      return MHStepFunction.apply(v, fix_v, rand_v, rand_h, rand_u,*h)\n",
        "\n",
        "\n",
        "def gibbs_step1(v, h, fix_v=False,\n",
        "                   rand_v=None, rand_h=None, rand_u=None, rand_z=None, T=1):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "\n",
        "        v_, h_ = (v, h)\n",
        "\n",
        "        if rand_u is None:\n",
        "            rand_u = torch.rand(N, device=device)\n",
        "\n",
        "        even = rand_u < 0.5\n",
        "        odd = even.logical_not()\n",
        "\n",
        "        if even.sum() > 0:\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h_[0][even],\n",
        "                                  weight[0].t(), bias[0])\n",
        "\n",
        "                if T == 0:\n",
        "                    v_[even] = (logits >= 0).float()\n",
        "                else:\n",
        "                    logits = logits/ T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v_[even] = Independent(Bernoulli(logits=logits), 1).sample()\n",
        "                    else:\n",
        "                        v_[even] = (rand_v[even] < logits.sigmoid()).float()\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h_[i-1][even],\n",
        "                                  weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h_[i+1][even],\n",
        "                                       weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i][even] = (logits >= 0).float()\n",
        "                else:\n",
        "                    logits = logits/T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i][even] = Independent(Bernoulli(logits=logits), 1).sample()\n",
        "                    else:\n",
        "                        h_[i][even] = (rand_h[i][even] < logits.sigmoid()).float()\n",
        "\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v_[even] if i==0 else h_[i-1][even],\n",
        "                                  weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits += F.linear(h_[i+1][even],\n",
        "                                       weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i][even] = (logits >= 0).float()\n",
        "                else:\n",
        "                    logits /= T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i][even] = Independent(Bernoulli(logits=logits), 1).sample()\n",
        "                    else:\n",
        "                        h_[i][even] = (rand_h[i][even] < logits.sigmoid()).float()\n",
        "\n",
        "        if odd.sum() > 0:\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v_[odd] if i==0 else h_[i-1][odd],\n",
        "                                  weight[i],bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits += F.linear(h_[i+1][odd],\n",
        "                                       weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i][odd] = (logits >= 0).float()\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i][odd] = Independent(Bernoulli(logits=logits), 1).sample()\n",
        "                    else:\n",
        "                        h_[i][odd] = (rand_h[i][odd] < logits.sigmoid()).float()\n",
        "\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h_[0][odd],\n",
        "                                  weight[0].t(), bias[0])\n",
        "\n",
        "                if T == 0:\n",
        "                    v_[odd] = (logits >= 0).float()\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v_[odd] = Independent(Bernoulli(logits=logits), 1).sample()\n",
        "                    else:\n",
        "                        v_[odd] = (rand_v[odd] < logits.sigmoid()).float()\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h_[i-1][odd],\n",
        "                                  weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits += F.linear(h_[i+1][odd],\n",
        "                                       weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h_[i][odd] = (logits >= 0).float()\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h_[i][odd] = Independent(Bernoulli(logits=logits), 1).sample()\n",
        "                    else:\n",
        "                        h_[i][odd] = (rand_h[i][odd] < logits.sigmoid()).float()\n",
        "\n",
        "        return v_, h_\n",
        "\n",
        "\n",
        "def bernoulli_sample(probabilities):\n",
        "      result = BernoulliSampleFunction.apply(probabilities, model)\n",
        "      return torch.tensor(result)\n",
        "\n",
        "\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "class GibbsStepFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, v,fix_v, rand_v, rand_h, rand_u, rand_z, T=1, L=L, *all_params):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        h = list(h)\n",
        "        h = all_params[:L]  # h is a list of tensors\n",
        "        weight = all_params[L:2*L]  # weight is a list of tensors (from ParameterList)\n",
        "        bias = all_params[2*L:]\n",
        "        if rand_u is None:\n",
        "            rand_u = torch.rand(N, device=device)\n",
        "\n",
        "        even = rand_u < 0.5\n",
        "        odd = even.logical_not()\n",
        "        if even.sum() > 0:\n",
        "          #  print(\"TEST\",)\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][even],\n",
        "                                  weight[0].t(), bias[0])\n",
        "            #    print(\"v_1: \",v_.grad)\n",
        "                if T == 0:\n",
        "                    v = torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                 #   print(\"v_1: \",v_.grad)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v =  torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                      #  print(\"v_2: \",v.grad)\n",
        "                    else:\n",
        "                        v = torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),greaterThan(logits.sigmoid(),rand_v[even]))\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "              #  print(\"TEST2\")\n",
        "                logits = F.linear(h[i-1][even], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] =  torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits.sigmoid(),rand_h[i][even]))\n",
        "\n",
        "            for i in range(0, len(h), 2):\n",
        "               # print(\"TEST3\")\n",
        "                logits = F.linear(v[even] if i==0 else h[i-1][even],\n",
        "                                  weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits.sigmoid(),rand_h[i][even]))\n",
        "\n",
        "        if odd.sum() > 0:\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v[odd] if i==0 else h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] =  torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits.sigmoid(),rand_h[i][odd]))\n",
        "\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][odd], weight[0].t(), bias[0])\n",
        "\n",
        "                if T == 0:\n",
        "                    v =  torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),greaterThan(logits.sigmoid(),rand_v[odd]))\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), greaterThan(logits.sigmoid(),rand_h[i][odd]))\n",
        "        ctx.save_for_backward(even, odd, L, *all_params)\n",
        "        return v, *h\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_v, *grad_h):\n",
        "        even, odd, L, *all_params = ctx.saved_tensors\n",
        "        even_v\n",
        "\n",
        "\n",
        "\n",
        "def mh_step2(v, *h, fix_v=False, rand_v=None, rand_h=None, rand_u=None, rand_z=None, T=1):\n",
        "      return MHStepFunction.apply(v, fix_v, rand_v, rand_h, rand_u,rand_z,T,*h)\n",
        "\n",
        "\n",
        "def gibbs_step2(v, *h, fix_v=False,\n",
        "                   rand_v=None, rand_h=None, rand_u=None, rand_z=None, T=1):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        h = list(h)\n",
        "        if rand_u is None:\n",
        "            rand_u = torch.rand(N, device=device)\n",
        "\n",
        "        even = rand_u < 0.5\n",
        "        odd = even.logical_not()\n",
        "        if even.sum() > 0:\n",
        "          #  print(\"TEST\",)\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][even],\n",
        "                                  weight[0].t(), bias[0])\n",
        "            #    print(\"v_1: \",v_.grad)\n",
        "                if T == 0:\n",
        "                    v = torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                 #   print(\"v_1: \",v_.grad)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v =  torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                      #  print(\"v_2: \",v.grad)\n",
        "                    else:\n",
        "                        v = torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),greaterThan(logits.sigmoid(),rand_v[even]))\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "              #  print(\"TEST2\")\n",
        "                logits = F.linear(h[i-1][even], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] =  torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits.sigmoid(),rand_h[i][even]))\n",
        "\n",
        "            for i in range(0, len(h), 2):\n",
        "               # print(\"TEST3\")\n",
        "                logits = F.linear(v[even] if i==0 else h[i-1][even],\n",
        "                                  weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits.sigmoid(),rand_h[i][even]))\n",
        "\n",
        "        if odd.sum() > 0:\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v[odd] if i==0 else h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] =  torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),greaterThan(logits.sigmoid(),rand_h[i][odd]))\n",
        "\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][odd], weight[0].t(), bias[0])\n",
        "\n",
        "                if T == 0:\n",
        "                    v =  torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_v is None:\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),greaterThan(logits.sigmoid(),rand_v[odd]))\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "\n",
        "                if T == 0:\n",
        "                    h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), greaterThan(logits,torch.full_like(logits,-0.05)))\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "\n",
        "                    if rand_h is None:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), bernoulli_sample(torch.sigmoid(logits)))\n",
        "                    else:\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), greaterThan(logits.sigmoid(),rand_h[i][odd]))\n",
        "        return v, *h\n",
        "\n",
        "result4 = gibbs_step2(v,h[0],h[1],h[2])\n",
        "\n",
        "y_hat = result4[0]\n",
        "# Generate the graph\n",
        "params_dict = {}\n",
        "for i, param in enumerate(weight.parameters()):\n",
        "    params_dict['weight_' + str(i)] = param\n",
        "for i, param in enumerate(bias.parameters()):\n",
        "    params_dict['bias_' + str(i)] = param\n",
        "\n",
        "graph = make_dot(y_hat, params=params_dict, show_attrs=True, show_saved=True)\n",
        "# Render and save the graph (adjust the filename if needed)\n",
        "graph.render(\"gibbs_step2_graph\", format=\"png\")\n",
        "\n",
        "\n",
        "test = torch.autograd.gradcheck(gibbs_step2, (v,h[0],h[1],h[2]))\n",
        "print(\"AUTOGRAD2: \",test)\n",
        "\n",
        "#mean3, std3 = plot_histograms_and_stats(result3, 'result3')\n",
        "mean4, std4 = plot_histograms_and_stats(result4, 'result4')\n",
        "\n",
        "#print(f\"Result3 - Mean: {mean3:.4f}, Std: {std3:.4f}\")\n",
        "print(f\"Result4 - Mean: {mean4:.4f}, Std: {std4:.4f}\")\n",
        "\n",
        "def coupling1(v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        _v, _h = (v, h)\n",
        "\n",
        "        v, h = mh_step1(v, h, fix_v)\n",
        "        energy = energy1(v, h)\n",
        "\n",
        "        converged = torch.ones(N, dtype=torch.bool, device=device) if fix_v \\\n",
        "                    else torch.all(v == _v, 1)\n",
        "        for i in range(L):\n",
        "            converged = converged.logical_and(torch.all(h[i] == _h[i], 1))\n",
        "\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(L)]\n",
        "            M = _v.size(0)\n",
        "\n",
        "            rand_v = None if fix_v else torch.rand_like(_v)\n",
        "            rand_h = [torch.rand_like(_h[i]) for i in range(L)]\n",
        "            rand_u = torch.rand(M, device=device)\n",
        "\n",
        "            v_, h_ = mh_step1(_v, _h, fix_v, rand_v, rand_h, rand_u)\n",
        "            energy[not_converged] += energy1(v_, h_) - energy1(_v, _h)\n",
        "\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = torch.all(v_ == _v, 1)\n",
        "                v[not_converged] = v_\n",
        "\n",
        "            for i in range(L):\n",
        "                converged_ = converged_.logical_and(torch.all(h_[i] == _h[i], 1))\n",
        "                h[i][not_converged] = h_[i]\n",
        "\n",
        "            converged[not_converged] = converged_\n",
        "\n",
        "        return energy, v, h\n",
        "\n",
        "result5 = coupling1(v,h)\n",
        "\n",
        "def equals(a, b):\n",
        "      similarity_scores = abs(a-b)\n",
        "      return torch.all(similarity_scores < 0.4, dim=1)\n",
        "\n",
        "def coupling2(v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        v, h = mh_step2(v, h, fix_v)\n",
        "        energy = energy1(v, h)\n",
        "        if fix_v:\n",
        "          converged = torch.ones(N, dtype=torch.bool, device=device)\n",
        "        else:\n",
        "          converged = equals(v, _v)\n",
        "        for i in range(L):\n",
        "            converged = converged.logical_and(equals(h[i], _h[i]))\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(L)]\n",
        "            M = _v.size(0)\n",
        "            rand_v = None if fix_v else torch.rand_like(_v)\n",
        "            rand_h = [torch.rand_like(_h[i]) for i in range(L)]\n",
        "            rand_u = torch.rand(M, device=device)\n",
        "            v_, h_ = mh_step2(_v, _h, fix_v, rand_v, rand_h, rand_u)\n",
        "            aaa = energy(v_, h_)\n",
        "            bbb = energy(_v, _h)\n",
        "            energy[not_converged] = energy[not_converged] + (aaa - bbb)\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = equals(v_, _v)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(L):\n",
        "                converged_ = converged_.logical_and(equals(h_[i], _h[i]))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "        return energy, v, *h\n",
        "\n",
        "result6 = coupling2(v,h[0],h[1],h[2])\n",
        "\n",
        "test = torch.autograd.gradcheck(coupling2, (v,h[0],h[1],h[2]))\n",
        "print(\"AUTOGRAD3: \",test)\n",
        "\n",
        "mean5, std5 = plot_histograms_and_stats(result5, 'result5')\n",
        "mean6, std6 = plot_histograms_and_stats(result6, 'result6')\n",
        "\n",
        "print(f\"Result5 - Mean: {mean5:.4f}, Std: {std5:.4f}\")\n",
        "print(f\"Result6 - Mean: {mean6:.4f}, Std: {std6:.4f}\")\n",
        "\n",
        "def local_search1(v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device= v.device\n",
        "\n",
        "        rand_u = torch.rand(N, device=device)\n",
        "        _v, _h = (v, h)\n",
        "        v, h = gibbs_step1(v, h, fix_v, rand_u=rand_u, T=0)\n",
        "\n",
        "        converged = torch.ones(N, dtype=torch.bool, device=device) if fix_v \\\n",
        "                    else torch.all(v == _v, 1)\n",
        "        for i in range(L):\n",
        "            converged = converged.logical_and(torch.all(h[i] == _h[i], 1))\n",
        "\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(L)]\n",
        "            M = _v.size(0)\n",
        "\n",
        "            v_, h_ = gibbs_step1(_v, _h, fix_v,\n",
        "                                     rand_u=rand_u[not_converged], T=0)\n",
        "\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = torch.all(v_ == _v, 1)\n",
        "                v[not_converged] = v_\n",
        "\n",
        "            for i in range(L):\n",
        "                converged_ = converged_.logical_and(torch.all(h_[i] == _h[i], 1))\n",
        "                h[i][not_converged] = h_[i]\n",
        "\n",
        "            converged[not_converged] = converged_\n",
        "\n",
        "        return v, h\n",
        "\n",
        "result7 = local_search1(v,h)\n",
        "\n",
        "def local_search2(v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device= v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        rand_u = torch.rand(N, device=device)\n",
        "        v, h = gibbs_step2(v, h, fix_v, rand_u=rand_u, T=0)\n",
        "        converged = torch.ones(N, dtype=torch.bool, device=device) if fix_v \\\n",
        "                    else equals(v, _v)\n",
        "        for i in range(L):\n",
        "            converged = converged.logical_and(equals(h[i], _h[i]))\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(L)]\n",
        "            M = _v.size(0)\n",
        "            v_, h_ = gibbs_step2(_v, _h, fix_v,\n",
        "                                     rand_u=rand_u[not_converged], T=0)\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = equals(v_, _v)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(L):\n",
        "                converged_ = converged_.logical_and(equals(h_[i], _h[i]))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "\n",
        "        return v, *h\n",
        "\n",
        "result8 = local_search2(v,h)\n",
        "\n",
        "test = torch.autograd.gradcheck(local_search2, (v,h[0],h[1],h[2]))\n",
        "print(\"AUTOGRAD4: \",test)\n",
        "mean7, std7 = plot_histograms_and_stats(result7, 'result7')\n",
        "mean8, std8 = plot_histograms_and_stats(result8, 'result8')\n",
        "\n",
        "print(f\"Result7 - Mean: {mean7:.4f}, Std: {std7:.4f}\")\n",
        "print(f\"Result8 - Mean: {mean8:.4f}, Std: {std8:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eSg8Anh8U0xy",
        "outputId": "0288d69a-3332-4142-956f-0ca43a99c832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model test:  tensor([1.2562e-142], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
            "model test:  tensor([1.], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
            "model test:  tensor([6.3669e-35], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
            "model test:  tensor([1.], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-29aca694f520>:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(result)\n",
            "<ipython-input-27-29aca694f520>:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "v:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "GradcheckError",
          "evalue": "Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 0.0000e+00,  0.0000e+00, -5.0000e+05,  ..., -3.4879e+05,\n         -4.2973e+05, -8.4041e+03],\n        [-5.0000e+05,  8.1936e-39, -5.0000e+05,  ..., -1.5121e+05,\n          4.2973e+05,  8.4041e+03],\n        [-5.0000e+05, -2.6432e+05,  5.0000e+05,  ...,  3.4879e+05,\n         -7.0270e+04, -4.9160e+05],\n        ...,\n        [ 0.0000e+00,  5.0000e+05,  5.0000e+05,  ...,  1.5121e+05,\n         -4.2973e+05, -8.4041e+03],\n        [ 0.0000e+00,  5.0000e+05,  7.5957e-63,  ...,  3.4879e+05,\n          4.2973e+05, -4.9160e+05],\n        [ 5.0000e+05,  5.0000e+05, -5.0000e+05,  ...,  1.5121e+05,\n         -4.2973e+05,  4.9160e+05]], dtype=torch.float64)\nanalytical:tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGradcheckError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-29aca694f520>\u001b[0m in \u001b[0;36m<cell line: 312>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h_mh_step2_graph2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmh_step2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_gradcheck_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[0m_fast_gradcheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfast_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_slow_gradcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     )\n\u001b[0;32m-> 2099\u001b[0;31m     _gradcheck_real_imag(\n\u001b[0m\u001b[1;32m   2100\u001b[0m         \u001b[0mgradcheck_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_gradcheck_real_imag\u001b[0;34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[0m\n\u001b[1;32m   1485\u001b[0m             )\n\u001b[1;32m   1486\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m             gradcheck_fn(\n\u001b[0m\u001b[1;32m   1488\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m                 \u001b[0mfunc_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_slow_gradcheck\u001b[0;34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag, masked)\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalytical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_allclose_with_type_promotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m                     raise GradcheckError(\n\u001b[0m\u001b[1;32m   1629\u001b[0m                         \u001b[0m_get_notallclose_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                     )\n",
            "\u001b[0;31mGradcheckError\u001b[0m: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 0.0000e+00,  0.0000e+00, -5.0000e+05,  ..., -3.4879e+05,\n         -4.2973e+05, -8.4041e+03],\n        [-5.0000e+05,  8.1936e-39, -5.0000e+05,  ..., -1.5121e+05,\n          4.2973e+05,  8.4041e+03],\n        [-5.0000e+05, -2.6432e+05,  5.0000e+05,  ...,  3.4879e+05,\n         -7.0270e+04, -4.9160e+05],\n        ...,\n        [ 0.0000e+00,  5.0000e+05,  5.0000e+05,  ...,  1.5121e+05,\n         -4.2973e+05, -8.4041e+03],\n        [ 0.0000e+00,  5.0000e+05,  7.5957e-63,  ...,  3.4879e+05,\n          4.2973e+05, -4.9160e+05],\n        [ 5.0000e+05,  5.0000e+05, -5.0000e+05,  ...,  1.5121e+05,\n         -4.2973e+05,  4.9160e+05]], dtype=torch.float64)\nanalytical:tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "def generate_data(x):\n",
        "    num_configurations = 20\n",
        "\n",
        "    # Generate the continuous number sequence\n",
        "    configurations = np.arange(num_configurations)\n",
        "\n",
        "    # Threshold based on x\n",
        "    threshold = int(x * num_configurations)\n",
        "    y_values = (configurations < threshold).astype(int)\n",
        "\n",
        "    # Combine input x, configurations, and output y\n",
        "    data = np.concatenate((np.tile(x, (num_configurations, 1)),\n",
        "                           configurations[:, np.newaxis],  # Reshape for concatenation\n",
        "                           y_values[:, np.newaxis]), axis=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "x = 0.08\n",
        "data = generate_data(x)\n",
        "print(data)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "class BernoulliApproximator(nn.Module):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(2, hidden_dim)\n",
        "    self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.linear4 = nn.Linear(hidden_dim, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.x=None\n",
        "    self.out1 = None\n",
        "    self.out2 = None\n",
        "    self.out3 = None\n",
        "    self.out4 = None\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.x=x\n",
        "    out = self.relu(self.linear1(x))\n",
        "    self.out1 = out\n",
        "    out = self.relu(self.linear2(out))\n",
        "    self.out2 = out\n",
        "    out = self.relu(self.linear3(out))\n",
        "    self.out3 = out\n",
        "    out = torch.sigmoid(self.linear4(out))\n",
        "    self.out4 = out\n",
        "    return out\n",
        "\n",
        "probs = torch.rand(10000, 1)\n",
        "data_list = []\n",
        "for p in probs.flatten():  # Iterate over probabilities\n",
        "    data_list.append(generate_data(p.item()))  # Convert to float for compatibility\n",
        "\n",
        "probs = torch.rand(5000, 1)*0.1\n",
        "for p in probs.flatten():  # Iterate over probabilities\n",
        "    data_list.append(generate_data(p.item()))  # Convert to float for compatibility\n",
        "\n",
        "probs = 0.9 * torch.rand(5000, 1)*0.1\n",
        "for p in probs.flatten():  # Iterate over probabilities\n",
        "    data_list.append(generate_data(p.item()))  # Convert to float for compatibility\n",
        "\n",
        "data = np.vstack(data_list)  # Combine the data from all probabilities\n",
        "np.random.shuffle(data)\n",
        "# Create X and Y\n",
        "X = torch.tensor(data[:, :2], dtype=torch.float32)  # Input (x and binary variables)\n",
        "Y = torch.tensor(data[:, 2], dtype=torch.float32)  # Output (y)\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "model = BernoulliApproximator(hidden_dim=64)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "for epoch in range(500000):\n",
        "  total_loss = 0\n",
        "  optimizer.zero_grad()\n",
        "  #  print(X[i])\n",
        "  result = model(X)\n",
        "   # print(result)\n",
        "   # print(Y[i])\n",
        "  loss = nn.BCELoss()(result.squeeze(),Y)\n",
        "  total_loss+=loss\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print('avg_loss: ',total_loss/len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-X-Vcyzh0O3c",
        "outputId": "c266d209-f5bb-4588-fa18-73dc4661374c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "avg_loss:  tensor(9.7755e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7747e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7740e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7733e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7726e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7719e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7711e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7704e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7697e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7690e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7676e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7668e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7654e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7647e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7625e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7618e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7611e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7604e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7597e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7590e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7582e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7575e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7568e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7561e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7554e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7546e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7539e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7510e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7496e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7489e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7481e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7474e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7467e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7460e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7445e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7438e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7431e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7424e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7409e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7402e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7395e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7380e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7373e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7366e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7359e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7351e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7344e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7337e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7329e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7322e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7315e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7308e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7300e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7293e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7286e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7279e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7271e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7264e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7257e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7249e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7242e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7235e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7228e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7213e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7206e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7198e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7191e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7184e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7176e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7169e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7162e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7155e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7133e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7125e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7118e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7111e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7103e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7096e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7089e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7081e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7074e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7067e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7060e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7052e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7045e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7037e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7030e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7023e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7015e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7008e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7001e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6994e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6986e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6979e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6972e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6965e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6959e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6954e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6949e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6947e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6949e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7020e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7101e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7252e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7531e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8048e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0077e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0404e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1025e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2189e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4470e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8869e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8174e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.7579e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3127e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9415e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.6075e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3262e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.3285e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.1935e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.9250e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8412e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.6987e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3539e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6994e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.9683e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3446e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5996e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2073e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2292e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1940e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2200e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6370e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.9040e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4677e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.9205e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3065e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2546e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.5150e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.7354e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9727e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5920e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.5993e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7007e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4706e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5172e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6178e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9745e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0041e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6656e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4176e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1406e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0997e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8125e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9732e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4515e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8204e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1930e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0659e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5406e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3626e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8691e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2224e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3691e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0710e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0291e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2497e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1591e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8447e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1032e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1714e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0230e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0076e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1149e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0666e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8353e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0407e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0728e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0033e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0444e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0257e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8342e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0077e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0273e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9508e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8579e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0107e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0055e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8350e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9184e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0039e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8268e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9392e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9478e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8359e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8479e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9203e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8750e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8178e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8602e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8841e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8336e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8201e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8571e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8160e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8244e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8449e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8276e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8107e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8308e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8143e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8095e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8207e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8189e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8073e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8085e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8150e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8102e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8092e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8042e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8010e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8037e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8039e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7986e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8004e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7995e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7966e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7971e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7937e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7935e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7937e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7923e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7908e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7907e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7905e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7892e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7882e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7879e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7874e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7863e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7855e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7851e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7845e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7836e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7828e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7823e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7817e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7808e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7801e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7788e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7780e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7773e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7767e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7760e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7752e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7745e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7739e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7732e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7725e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7718e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7712e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7705e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7697e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7690e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7676e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7669e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7655e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7648e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7619e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7612e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7605e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7597e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7589e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7581e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7574e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7559e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7543e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7536e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7529e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7516e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7510e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7497e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7490e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7483e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7477e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7457e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7451e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7444e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7438e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7431e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7424e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7418e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7398e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7391e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7385e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7378e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7372e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7365e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7358e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7352e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7345e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7339e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7332e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7326e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7312e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7306e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7299e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7292e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7286e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7279e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7273e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7266e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7259e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7253e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7246e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7240e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7233e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7226e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7213e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7206e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7200e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7193e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7186e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7173e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7166e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7160e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7146e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7133e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7126e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7120e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7113e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7106e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7093e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7086e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7080e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7073e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7066e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7060e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7046e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7033e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7026e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7020e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7013e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7006e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6993e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6986e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6979e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6973e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6966e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6959e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6952e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6946e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6939e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6932e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6925e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6919e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6912e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6905e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6899e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6892e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6885e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6878e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6872e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6865e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6858e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6851e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6845e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6838e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6831e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6824e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6818e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6811e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6804e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6790e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6784e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6777e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6770e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6763e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6750e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6743e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6736e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6729e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6723e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6716e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6702e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6696e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6689e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6682e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6675e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6668e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6662e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6655e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6648e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6641e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6634e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6621e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6614e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6607e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6600e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6593e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6587e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6580e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6573e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6559e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6552e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6546e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6539e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6511e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6505e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6498e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6491e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6484e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6477e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6463e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6456e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6450e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6443e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6422e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6415e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6408e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6402e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6395e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6388e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6374e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6367e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6360e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6353e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6346e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6333e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6326e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6312e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6305e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6291e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6284e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6277e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6270e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6263e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6256e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6250e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6236e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6229e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6222e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6215e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6208e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6201e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6194e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6187e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6173e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6166e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6152e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6145e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6138e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6131e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6125e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6118e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6111e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6104e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6097e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6083e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6076e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6069e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6062e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6055e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6048e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6034e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6027e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6020e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6013e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6006e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5992e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5985e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5971e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5964e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5950e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5943e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5936e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5928e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5921e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5914e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5907e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5900e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5893e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5886e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5879e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5872e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5865e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5858e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5851e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5844e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5836e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5822e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5814e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5807e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5800e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5793e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5786e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5779e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5772e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5764e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5750e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5743e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5736e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5729e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5722e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5708e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5701e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5694e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5686e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5679e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5672e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5665e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5658e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5651e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5644e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5637e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5630e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5622e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5615e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5608e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5601e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5594e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5587e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5580e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5573e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5559e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5544e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5537e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5530e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5516e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5501e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5494e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5487e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5480e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5473e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5460e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5447e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5438e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5439e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5451e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5528e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5814e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6164e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6814e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8037e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0032e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0468e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1290e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2900e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6006e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2459e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5742e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.6203e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3527e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2422e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6364e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.2596e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3288e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.9863e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9351e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2216e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3855e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5929e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.1625e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1602e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.0456e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2160e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.5059e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6056e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4264e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.6483e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.6416e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3705e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2313e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.0176e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.7072e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2479e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0140e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6899e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5205e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9206e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7974e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0352e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.5823e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6042e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7222e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6616e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0500e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3655e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7501e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4476e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6552e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2037e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7589e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2985e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4209e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1040e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7804e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2007e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2557e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0446e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7760e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1272e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1553e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0118e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7574e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0762e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0875e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9318e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7252e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0386e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0459e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8316e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6943e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0130e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0181e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7729e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6687e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9502e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0003e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7375e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6507e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8308e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8809e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7128e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6390e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7500e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7989e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6950e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6322e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6974e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7410e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6808e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6290e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6632e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7003e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6686e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6279e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6422e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6275e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6295e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6473e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6268e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6222e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6349e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6379e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6254e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6182e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6246e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6294e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6230e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6158e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6176e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6198e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6129e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6157e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6158e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6121e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6098e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6109e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6117e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6098e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6074e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6077e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6071e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6052e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6015e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6010e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6009e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6002e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5991e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5982e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5974e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5966e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5950e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5946e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5940e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5932e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5924e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5918e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5913e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5898e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5892e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5886e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5880e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5873e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5866e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5859e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5840e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5833e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5827e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5820e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5814e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5807e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5801e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5794e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5788e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5781e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5775e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5762e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5755e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5749e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5742e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5736e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5729e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5723e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5716e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5703e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5696e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5690e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5677e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5670e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5664e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5657e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5651e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5644e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5637e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5631e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5624e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5618e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5611e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5605e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5598e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5591e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5585e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5578e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5572e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5565e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5558e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5552e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5545e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5539e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5519e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5512e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5506e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5486e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5480e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5473e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5460e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5446e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5440e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5433e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5427e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5420e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5413e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5407e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5400e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5394e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5380e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5374e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5367e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5360e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5354e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5334e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5327e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5320e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5307e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5300e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5294e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5287e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5280e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5274e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5267e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5260e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5254e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5247e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5240e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5234e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5227e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5214e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5207e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5200e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5194e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5187e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5174e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5167e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5160e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5154e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5134e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5127e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5120e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5113e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5107e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5093e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5086e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5080e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5073e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5066e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5060e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5046e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5039e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5033e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5026e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5019e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5013e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5006e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4992e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4985e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4979e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4972e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4965e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4958e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4952e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4945e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4938e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4931e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4925e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4918e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4911e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4897e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4891e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4884e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4877e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4870e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4863e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4857e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4850e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4843e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4836e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4823e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4809e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4802e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4789e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4782e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4775e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4761e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4755e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4748e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4741e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4727e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4720e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4713e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4707e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4700e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4693e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4686e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4679e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4672e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4665e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4658e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4651e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4644e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4637e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4630e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4623e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4616e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4609e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4602e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4595e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4588e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4581e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4574e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4568e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4561e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4554e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4547e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4540e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4533e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4526e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4519e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4513e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4506e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4492e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4485e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4478e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4471e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4457e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4450e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4444e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4437e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4416e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4409e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4402e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4395e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4388e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4374e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4367e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4361e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4354e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4333e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4326e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4312e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4305e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4291e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4284e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4277e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4271e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4264e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4257e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4251e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4240e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4236e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4235e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4237e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4265e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4303e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4376e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4751e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5184e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5970e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7385e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9983e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0470e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1356e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2990e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6177e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2304e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5402e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.2973e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2976e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6090e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.8567e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4731e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7363e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7261e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6668e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.2932e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5919e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1455e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0001e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1186e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8205e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2758e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2505e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.0557e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6299e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.4189e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8876e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7335e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0811e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7988e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5788e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4634e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.6179e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.8991e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4003e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2759e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.9740e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8235e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3594e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.4115e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8357e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0473e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2891e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6563e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6585e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.5166e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4065e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6665e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9922e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.1393e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8667e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6396e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8919e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0051e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4037e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6783e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0157e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2481e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5058e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0199e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1444e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3700e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0202e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0756e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2653e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0180e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0298e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1849e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0144e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0001e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1237e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0100e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8123e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0775e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0053e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7003e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0427e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0003e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0168e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9514e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6109e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9776e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8991e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6027e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6054e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7444e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7984e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6124e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7533e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6196e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6379e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7132e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6248e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6129e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6789e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6271e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5990e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6260e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5926e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6278e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6221e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6109e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6162e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5902e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5988e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6092e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5908e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6018e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5905e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5857e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5948e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5896e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5828e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5888e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5878e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5811e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5839e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5852e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5799e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5801e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5823e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5787e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5773e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5792e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5774e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5752e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5763e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5735e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5736e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5737e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5719e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5714e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5716e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5704e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5694e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5694e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5687e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5676e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5673e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5669e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5659e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5653e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5650e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5642e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5635e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5631e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5625e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5612e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5607e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5600e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5594e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5589e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5582e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5571e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5565e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5558e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5553e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5547e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5535e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5529e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5517e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5511e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5505e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5488e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5482e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5458e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5452e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5446e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5440e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5434e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5428e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5422e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5416e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5404e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5399e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5392e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5375e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5369e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5363e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5357e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5351e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5345e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5339e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5333e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5327e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5321e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5315e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5309e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5303e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5297e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5291e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5285e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5280e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5273e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5268e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5261e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5255e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5250e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5237e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5231e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5226e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5214e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5207e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5201e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5195e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5190e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5184e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5177e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5172e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5165e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5141e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5135e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5129e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5123e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5117e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5111e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5105e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5099e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5093e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5087e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5081e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5075e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5069e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5063e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5057e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5051e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5045e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5039e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5033e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5027e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5021e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5014e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5009e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5002e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4996e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4990e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4984e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4972e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4966e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4960e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4954e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4948e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4942e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4936e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4923e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4917e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4911e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4905e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4899e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4893e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4887e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4881e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4875e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4868e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4862e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4856e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4850e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4844e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4838e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4832e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4826e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4820e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4814e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4807e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4801e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4789e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4783e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4777e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4771e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4764e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4758e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4752e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4746e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4740e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4728e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4721e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4703e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4697e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4691e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4685e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4678e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4672e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4666e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4660e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4654e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4648e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4641e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4635e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4629e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4623e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4611e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4604e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4598e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4592e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4586e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4579e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4573e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4567e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4561e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4555e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4549e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4542e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4536e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4530e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4524e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4511e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4505e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4486e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4480e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4474e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4468e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4462e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4455e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4449e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4443e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4437e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4424e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4418e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4412e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4399e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4393e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4380e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4374e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4368e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4362e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4355e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4349e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4343e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4337e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4330e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4324e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4318e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4312e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4305e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4299e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4293e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4286e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4280e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4274e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4267e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4261e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4255e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4249e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4242e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4236e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4230e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4223e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4217e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4211e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4205e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4198e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4192e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4186e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4179e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4173e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4167e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4160e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4154e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4148e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4141e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4135e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4129e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4122e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4116e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4110e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4103e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4097e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4091e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4084e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4078e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4072e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4059e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4046e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4034e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4027e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4021e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4014e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4008e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4002e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3995e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3989e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3983e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3976e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3970e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3963e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3951e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3944e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3938e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3932e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3925e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3919e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3912e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3900e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3893e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3887e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3880e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3874e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3868e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3861e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3855e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3848e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3842e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3836e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3823e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3803e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3790e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3784e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3778e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3771e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3765e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3758e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3752e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3745e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3739e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3732e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3726e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3720e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3713e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3707e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3700e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3694e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3687e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3681e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3674e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3668e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3655e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3648e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3642e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3635e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3629e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3622e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3616e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3609e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3603e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3596e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3590e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3583e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3577e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3571e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3558e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3544e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3538e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3531e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3512e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3505e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3492e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3486e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3479e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3473e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3460e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3447e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3440e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3433e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3427e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3420e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3414e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3407e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3401e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3394e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3388e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3375e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3368e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3361e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3355e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3348e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3342e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3335e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3328e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3322e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3315e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3309e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3302e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3296e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3289e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3282e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3276e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3269e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3263e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3256e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3250e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3236e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3230e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3223e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3217e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3210e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3203e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3197e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3190e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3183e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3177e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3170e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3164e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3157e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3150e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3144e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3137e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3130e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3124e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3117e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3110e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3104e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3097e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3084e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3077e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3071e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3064e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3057e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3051e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3044e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3037e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3031e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3024e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3017e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3011e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3004e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2991e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2984e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2977e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2971e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2964e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2950e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2944e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2937e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2930e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2924e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2917e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2897e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2890e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2884e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2877e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2871e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2865e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2858e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2842e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2839e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2837e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2837e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2842e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2875e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2913e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3088e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3271e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3577e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4086e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4943e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6377e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8833e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0299e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1026e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2278e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4550e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8593e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6531e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.1814e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.4681e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4374e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2151e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.3351e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.6530e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0544e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.3041e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9518e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1396e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.1611e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4581e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.9079e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0643e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.1744e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0928e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.4722e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9431e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7552e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.5709e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.3487e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.7919e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7330e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.0640e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.4020e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6897e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5800e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9448e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2154e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3054e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0045e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4319e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3347e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9386e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0219e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1979e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8414e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6186e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0104e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0824e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5056e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4047e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0223e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3085e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2487e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8667e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1739e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1494e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7092e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6522e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0900e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0805e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6392e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5118e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0324e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0360e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5951e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0045e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3850e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7082e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8321e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5351e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3663e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5528e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6758e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5096e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4558e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5651e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4834e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3663e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4845e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4571e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3719e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3699e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4288e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4311e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3909e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4069e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3762e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3520e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3672e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3855e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3731e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3536e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3682e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3671e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3552e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3594e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3517e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3514e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3492e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3415e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3446e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3386e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3393e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3408e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3395e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3367e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3357e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3365e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3365e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3349e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3331e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3328e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3331e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3325e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3310e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3300e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3296e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3288e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3277e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3270e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3267e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3263e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3254e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3239e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3236e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3229e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3221e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3214e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3209e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3204e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3198e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3190e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3183e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3178e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3172e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3166e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3141e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3135e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3128e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3122e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3116e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3110e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3103e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3097e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3085e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3079e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3072e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3066e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3060e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3047e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3022e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3016e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3010e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3004e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2991e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2985e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2979e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2973e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2966e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2960e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2954e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2948e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2941e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2935e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2923e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2916e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2898e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2891e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2885e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2879e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2873e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2866e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2860e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2854e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2841e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2835e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2822e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2803e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2791e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2785e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2778e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2772e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2766e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2759e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2753e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2747e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2741e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2728e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2722e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2703e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2696e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2690e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2684e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2677e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2671e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2665e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2658e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2652e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2646e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2639e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2621e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2614e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2608e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2602e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2595e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2589e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2583e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2563e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2557e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2544e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2538e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2519e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2513e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2506e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2500e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2487e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2481e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2474e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2468e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2461e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2455e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2449e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2410e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2404e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2397e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2391e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2385e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2378e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2372e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2365e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2359e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2353e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2346e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2333e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2327e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2320e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2308e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2301e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2295e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2288e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2282e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2275e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2269e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2262e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2256e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2249e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2237e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2230e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2224e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2217e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2211e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2204e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2198e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2191e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2178e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2172e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2165e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2152e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2146e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2133e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2126e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2120e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2113e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2107e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2094e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2087e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2081e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2074e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2068e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2061e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2055e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2048e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2022e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2015e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2008e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2001e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1995e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1988e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1981e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1975e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1968e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1955e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1949e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1942e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1935e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1922e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1916e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1909e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1903e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1896e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1890e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1883e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1876e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1870e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1863e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1857e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1850e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1844e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1837e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1831e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1825e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1818e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1812e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1806e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1800e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1790e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1786e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1784e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1784e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1787e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1796e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1813e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1843e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1896e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1984e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2130e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2370e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2770e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4535e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6379e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9526e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0483e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1410e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3002e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5905e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.1103e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1487e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.1796e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6642e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8955e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.2273e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1476e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1267e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.7459e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.0344e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2113e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.9369e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.5618e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.3289e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8548e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5885e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7523e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7079e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9321e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.9968e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1840e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.4848e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0018e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.1676e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.4877e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.4006e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4178e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.3864e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.3703e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.5661e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0027e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1116e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5280e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4605e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2341e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.7144e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3577e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0072e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4698e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2785e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5277e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3763e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5719e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7450e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0919e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0324e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4990e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3472e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4184e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1290e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3509e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0838e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4013e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1579e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1731e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6189e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7958e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1201e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0447e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2994e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0050e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0615e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6982e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0060e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0044e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3762e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9014e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5172e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7101e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5400e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3290e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4657e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4224e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2898e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3311e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4138e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3495e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3309e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3671e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3091e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2791e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2882e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3071e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2778e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2789e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2982e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2723e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2766e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2881e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2804e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2690e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2735e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2799e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2664e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2701e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2641e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2666e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2645e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2634e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2641e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2613e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2594e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2603e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2606e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2585e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2574e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2574e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2559e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2547e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2547e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2546e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2534e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2521e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2500e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2496e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2485e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2471e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2467e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2461e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2447e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2443e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2418e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2413e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2406e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2400e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2394e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2388e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2382e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2376e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2370e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2365e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2358e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2352e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2346e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2334e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2328e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2322e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2316e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2310e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2305e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2293e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2287e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2281e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2275e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2269e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2263e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2257e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2251e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2239e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2233e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2227e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2221e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2215e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2209e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2203e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2197e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2191e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2179e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2173e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2167e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2161e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2155e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2149e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2143e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2137e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2131e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2125e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2119e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2113e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2107e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2101e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2095e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2089e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2083e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2077e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2071e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2059e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2047e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2029e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2023e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2017e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2011e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2005e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1993e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1987e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1980e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1975e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1968e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1956e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1950e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1944e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1938e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1932e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1926e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1920e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1914e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1908e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1902e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1896e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1890e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1883e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1877e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1871e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1865e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1859e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1841e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1835e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1823e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1817e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1804e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1798e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1792e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1786e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1780e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1774e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1761e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1755e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1749e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1743e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1737e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1731e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1725e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1719e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1712e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1706e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1700e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1694e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1688e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1682e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1676e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1670e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1663e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1657e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1651e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1645e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1639e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1620e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1614e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1608e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1602e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1596e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1590e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1583e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1577e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1571e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1565e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1559e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1552e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1546e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1540e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1534e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1528e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1522e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1515e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1497e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1491e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1484e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1478e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1472e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1460e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1447e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1441e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1435e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1428e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1422e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1416e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1410e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1404e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1397e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1391e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1385e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1379e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1372e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1366e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1360e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1354e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1341e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1335e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1329e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1322e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1316e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1310e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1303e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1297e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1291e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1285e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1279e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1272e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1266e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1260e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1253e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1247e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1240e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1234e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1228e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1221e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1215e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1209e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1202e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1196e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1189e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1183e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1176e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1170e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1163e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1157e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1151e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1144e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1138e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1132e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1125e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1119e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1113e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1107e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1094e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1088e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1081e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1075e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1069e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1062e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1056e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1050e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1043e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1037e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1031e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1024e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1018e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1012e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1005e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0993e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0986e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0980e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0973e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0967e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0961e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0954e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0948e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0942e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0935e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0923e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0916e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0897e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0891e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0884e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0878e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0872e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0865e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0859e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0846e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0840e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0833e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0827e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0821e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0814e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0808e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0801e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0789e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0782e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0776e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0769e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0763e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0750e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0744e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0737e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0731e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0725e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0718e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0712e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0705e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0699e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0693e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0686e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0680e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0674e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0667e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0655e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0650e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0644e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0639e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0635e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0631e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0654e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0680e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0726e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0804e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0933e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1148e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1502e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2093e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3074e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4735e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7521e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0233e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1052e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2507e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5050e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9834e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8714e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.7231e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.5065e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7668e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.4245e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.8676e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0692e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5215e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3157e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0202e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.7928e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8777e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.4517e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.9469e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9516e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4259e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.7522e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.2966e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7700e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1152e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2460e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.7891e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1036e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.4836e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0345e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.1596e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.1552e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6811e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.5049e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.9183e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.0099e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0400e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.7314e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.4563e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0275e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0716e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1292e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4591e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1999e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4628e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7887e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2886e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8021e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8612e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7143e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3152e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7244e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0992e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0389e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4927e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1940e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3219e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2616e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2204e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2761e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0838e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1875e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6506e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7537e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1201e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0030e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0449e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0208e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8178e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0149e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3481e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4087e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9213e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4958e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2269e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6392e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5659e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2091e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3995e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5376e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2665e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2528e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4428e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3240e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1994e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3318e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2455e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2013e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2711e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1933e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2256e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2491e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1974e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2301e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2138e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1884e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2072e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2144e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1913e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2059e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1961e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1845e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1939e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1963e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1848e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1915e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1864e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1806e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1858e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1800e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1793e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1824e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1800e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1766e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1781e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1787e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1747e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1759e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1748e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1727e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1729e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1731e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1705e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1707e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1702e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1688e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1684e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1674e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1665e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1662e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1658e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1649e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1642e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1639e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1625e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1620e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1616e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1609e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1602e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1597e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1592e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1585e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1579e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1574e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1569e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1562e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1556e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1545e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1539e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1534e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1528e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1522e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1516e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1511e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1505e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1488e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1482e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1465e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1459e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1448e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1424e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1419e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1413e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1407e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1401e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1396e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1390e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1384e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1378e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1373e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1367e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1361e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1355e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1349e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1344e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1338e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1332e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1326e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1321e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1315e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1309e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1303e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1297e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1291e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1286e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1280e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1274e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1268e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1262e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1257e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1251e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1239e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1233e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1227e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1222e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1216e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1210e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1204e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1198e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1193e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1187e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1181e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1175e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1169e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1163e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1158e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1152e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1146e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1134e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1128e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1122e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1116e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1111e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1105e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1099e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1093e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1087e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1081e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1075e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1064e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1058e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1052e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1046e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1034e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1022e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1017e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1011e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1005e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0993e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0987e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0981e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0975e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0969e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0963e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0958e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0952e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0946e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0940e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0934e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0928e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0922e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0916e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0898e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0893e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0887e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0881e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0875e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0869e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0863e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0857e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0851e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0845e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0839e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0833e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0827e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0821e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0815e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0809e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0803e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0791e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0785e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0779e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0773e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0761e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0756e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0749e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0743e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0738e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0732e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0726e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0720e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0714e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0708e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0702e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0695e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0690e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0678e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0672e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0666e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0660e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0653e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0648e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0641e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0636e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0630e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0623e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0618e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0611e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0605e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0599e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0593e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0587e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0581e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0575e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0569e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0563e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0557e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0545e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0539e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0533e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0527e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0521e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0515e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0497e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0491e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0485e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0478e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0472e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0460e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0454e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0448e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0424e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0418e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0412e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0399e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0393e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0375e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0369e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0363e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0357e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0351e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0344e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0338e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0332e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0326e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0320e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0308e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0302e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0296e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0289e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0283e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0277e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0271e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0265e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0259e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0253e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0246e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0240e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0234e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0228e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0222e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0216e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0209e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0203e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0197e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0191e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0178e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0172e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0166e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0134e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0128e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0122e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0115e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0109e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0103e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0096e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0084e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0078e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0071e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0059e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0047e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0034e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0022e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0016e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0009e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0003e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9991e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9985e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9972e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9966e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9960e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9953e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9947e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9941e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9935e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9922e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9916e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9897e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9891e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9885e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9879e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9872e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9866e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9860e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9841e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9835e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9822e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9803e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9791e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9785e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9778e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9772e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9766e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9759e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9753e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9747e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9741e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9728e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9722e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9703e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9696e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9690e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9684e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9678e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9671e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9665e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9659e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9652e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9646e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9621e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9614e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9608e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9602e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9595e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9589e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9583e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9557e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9544e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9538e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9519e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9513e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9506e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9500e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9487e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9481e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9474e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9468e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9462e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9455e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9449e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9443e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9399e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9393e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9382e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9377e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9373e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9370e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9369e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9371e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9378e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9392e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9418e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9668e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9879e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0230e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0809e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1783e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3410e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6186e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0088e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0910e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2328e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4904e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9536e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8720e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.6754e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6203e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7054e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.8806e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1286e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.4935e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.7698e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5497e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3873e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6930e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2337e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2036e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5982e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.1824e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7973e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7087e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5702e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8612e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2092e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1310e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.4360e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5994e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.0866e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.7358e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2456e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6901e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.5011e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.6235e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2087e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0295e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.1529e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.6942e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0718e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2723e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1148e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5203e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0490e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2551e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0710e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9055e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2909e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9272e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3806e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1259e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4164e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5494e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0136e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0131e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3818e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1971e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0769e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1024e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2269e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.9200e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3086e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1110e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0760e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1490e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7302e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0654e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7025e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0849e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0007e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2018e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2300e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7774e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5132e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0620e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3330e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2202e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0746e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3416e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3468e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0909e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1151e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2851e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1963e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0535e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1365e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2123e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1084e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0533e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0605e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1167e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1005e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0643e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0958e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0712e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0439e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0629e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0767e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0543e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0422e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0582e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0619e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0449e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0524e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0512e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0395e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0395e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0360e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0373e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0414e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0382e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0334e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0348e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0369e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0341e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0310e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0321e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0331e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0308e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0288e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0294e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0280e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0265e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0268e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0268e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0254e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0241e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0229e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0218e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0215e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0205e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0197e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0194e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0190e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0182e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0175e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0171e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0166e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0152e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0142e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0136e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0130e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0124e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0119e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0113e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0107e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0101e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0096e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0084e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0078e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0073e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0067e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0061e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0055e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0050e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0044e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0039e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0033e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0027e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0021e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0016e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0010e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0004e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9998e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9993e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9987e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9981e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9976e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9970e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9964e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9958e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9953e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9947e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9941e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9935e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9930e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9924e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9918e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9912e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9907e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9901e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9895e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9889e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9884e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9878e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9872e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9866e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9861e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9855e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9849e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9843e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9837e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9832e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9826e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9820e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9815e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9809e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9803e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9797e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9791e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9786e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9780e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9774e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9762e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9751e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9745e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9739e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9733e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9728e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9722e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9716e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9710e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9704e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9699e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9693e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9687e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9681e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9675e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9670e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9664e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9658e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9652e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9646e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9634e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9629e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9623e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9611e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9605e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9600e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9593e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9588e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9582e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9558e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9553e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9547e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9535e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9529e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9512e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9506e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9500e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9494e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9488e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9482e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9465e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9459e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9447e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9441e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9435e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9400e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9394e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9388e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9382e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9376e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9370e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9364e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9358e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9352e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9341e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9335e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9329e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9323e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9317e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9311e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9305e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9299e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9293e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9287e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9281e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9275e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9269e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9263e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9257e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9251e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9240e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9233e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9227e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9222e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9216e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9210e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9204e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9197e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9192e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9173e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9167e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9161e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9155e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9149e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9143e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9137e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9130e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9124e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9118e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9112e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9106e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9094e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9088e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9082e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9076e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9064e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9058e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9052e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9046e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9034e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9022e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9016e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9010e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9004e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8998e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8992e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8986e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8980e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8974e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8968e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8956e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8950e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8944e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8937e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8931e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8925e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8919e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8913e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8907e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8901e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8895e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8889e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8883e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8877e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8871e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8865e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8859e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8847e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8841e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8835e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8823e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8804e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8798e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8792e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8786e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8780e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8774e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8762e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8756e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8749e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8743e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8737e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8731e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8725e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8719e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8713e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8707e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8701e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8695e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8688e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8682e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8676e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8670e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8664e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8658e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8652e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8646e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8621e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8615e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8609e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8603e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8597e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8591e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8584e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8578e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8572e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8560e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8554e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8547e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8535e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8529e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8517e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8510e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8504e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8498e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8492e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8486e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8480e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8474e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8467e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8461e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8455e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8449e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8443e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8424e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8418e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8412e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8399e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8393e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8375e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8368e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8362e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8357e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8351e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8346e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8341e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8336e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8333e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8332e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8333e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8339e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8353e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8378e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8424e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8502e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8636e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8862e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9892e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1003e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2898e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6203e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0191e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1211e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3010e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6369e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2576e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5387e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.1479e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2221e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4504e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.4621e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4804e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5717e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7220e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.5276e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.0759e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.2557e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.4532e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.6451e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.9898e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.1660e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.9701e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0675e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8413e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1135e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4023e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4028e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2776e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9342e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.8573e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0572e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.5151e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4412e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.0408e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.4452e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0837e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.4056e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.1696e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1477e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.7370e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.4269e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4519e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7665e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5462e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6143e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2617e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.7678e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6395e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0246e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.1664e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5842e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2993e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7321e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4904e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0217e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4322e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3872e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0348e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2312e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2897e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1382e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0987e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2046e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2591e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0130e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1323e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5956e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0729e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4217e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0249e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4504e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8705e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4465e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0216e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5790e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4152e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9968e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3622e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0011e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2077e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0176e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1040e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2320e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0349e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0406e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1682e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0057e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1114e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0522e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9901e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0649e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0494e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9861e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0297e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0407e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9881e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0055e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0283e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9916e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9940e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9824e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0017e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9941e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9790e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9908e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9919e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9782e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9826e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9879e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9782e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9771e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9831e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9779e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9738e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9783e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9720e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9741e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9748e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9708e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9723e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9699e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9696e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9685e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9666e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9670e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9668e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9651e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9647e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9649e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9637e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9628e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9629e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9622e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9611e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9609e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9606e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9596e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9590e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9588e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9580e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9573e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9557e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9552e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9548e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9535e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9531e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9518e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9513e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9508e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9502e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9497e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9492e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9486e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9480e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9475e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9458e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9447e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9431e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9425e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9420e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9414e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9409e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9403e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9398e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9392e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9376e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9370e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9364e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9359e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9353e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9348e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9342e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9337e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9331e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9326e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9320e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9315e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9309e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9304e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9292e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9287e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9281e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9276e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9270e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9265e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9259e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9254e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9248e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9237e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9231e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9226e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9215e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9209e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9204e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9198e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9192e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9187e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9181e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9176e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9170e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9165e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9148e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9142e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9137e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9131e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9125e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9120e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9114e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9109e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9103e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9097e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9092e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9086e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9081e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9075e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9069e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9064e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9058e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9047e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9036e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9030e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9024e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9019e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9013e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9007e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9002e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8996e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8990e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8985e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8979e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8974e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8968e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8951e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8945e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8940e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8934e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8923e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8917e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8911e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8900e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8895e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8889e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8883e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8877e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8872e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8866e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8860e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8855e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8849e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8843e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8837e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8832e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8826e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8821e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8815e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8809e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8803e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8798e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8792e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8786e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8781e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8775e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8769e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8764e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8758e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8752e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8746e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8741e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8735e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8729e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8724e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8718e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8712e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8706e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8700e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8695e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8689e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8678e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8672e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8666e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8660e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8655e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8649e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8643e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8637e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8632e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8626e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8620e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8614e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8608e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8603e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8597e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8591e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8586e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8580e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8574e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8568e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8562e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8557e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8545e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8539e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8533e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8528e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8522e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8516e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8510e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8504e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8487e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8481e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8475e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8458e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8452e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8446e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8441e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8435e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8406e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8400e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8394e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8388e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8382e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8376e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8371e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8365e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8359e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8353e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8342e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8335e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8330e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8324e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8318e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8312e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8306e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8300e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8295e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8289e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8283e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8277e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8271e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8265e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8259e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8253e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8248e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8242e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8236e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8230e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8224e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8218e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8212e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8206e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8200e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8195e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8189e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8183e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8177e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8171e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8165e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8142e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8136e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8130e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8124e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8118e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8112e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8106e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8100e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8094e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8088e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8082e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8076e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8059e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8047e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8029e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8023e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8017e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8011e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8005e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7993e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7987e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7981e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7975e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7969e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7963e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7952e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7945e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7940e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7934e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7927e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7922e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7916e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7898e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7891e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7886e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7880e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7874e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7867e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7862e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7856e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7850e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7844e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7838e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7831e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7825e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7820e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7813e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7807e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7801e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7789e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7783e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7777e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7771e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7765e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7759e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7753e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7746e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7740e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7728e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7722e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7703e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7697e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7691e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7685e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7679e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7673e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7667e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7655e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7648e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7642e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7636e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7630e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7624e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7618e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7612e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7606e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7600e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7594e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7588e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7582e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7557e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7552e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7545e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7539e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7533e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7527e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7521e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7515e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7497e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7491e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7484e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7478e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7472e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7466e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7460e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7454e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7448e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7399e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7393e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7380e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7374e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7368e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7362e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7356e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7350e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7344e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7338e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7331e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7325e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7313e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7307e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7301e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7295e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7288e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7282e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7276e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7270e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7264e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7258e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7251e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7245e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7239e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7233e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7227e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7214e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7208e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7202e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7196e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7190e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7183e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7177e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7171e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7165e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7146e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7140e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7134e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7128e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7122e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7115e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7109e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7103e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7097e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7084e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7078e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7072e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7059e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7047e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7034e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7022e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7016e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7009e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7003e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6991e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6985e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6979e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6973e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6968e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6963e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6959e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6956e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6957e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6976e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7005e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7060e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7163e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7352e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7693e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8312e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1504e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5332e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0243e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1593e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4156e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.9290e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.9710e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.3161e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0604e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4651e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.7879e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.9149e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.1718e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5600e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7960e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0144e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8425e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.3451e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0071e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3194e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.1063e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5422e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4832e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5840e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2344e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7298e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.6141e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8329e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0284e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.0287e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.0029e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3240e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8482e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.2971e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2642e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8295e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8752e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.3063e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0734e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8289e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8561e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4031e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3634e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4408e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7475e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7977e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0119e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0556e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5886e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3364e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9117e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1290e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3661e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0663e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9263e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1362e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1806e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3484e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2650e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0984e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0372e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8900e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4969e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0365e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5194e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8354e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.5347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8223e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0791e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8980e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.3987e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8925e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2922e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1298e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8328e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9724e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9713e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8236e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9615e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0338e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8878e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8279e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9354e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9522e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8467e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8320e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9061e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8973e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8274e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8321e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8793e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8627e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8292e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8580e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8412e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8139e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8247e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8416e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8279e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8111e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8197e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8297e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8193e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8088e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8149e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8208e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8134e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8106e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8141e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8043e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8068e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8055e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8021e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8049e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8025e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8000e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8006e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8014e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7997e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7983e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7972e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7956e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7953e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7955e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7947e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7934e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7929e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7923e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7913e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7904e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7899e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7890e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7884e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7880e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7876e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7868e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7862e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7857e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7852e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7846e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7840e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7834e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7829e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7824e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7817e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7812e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7807e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7801e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7790e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7784e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7779e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7773e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7767e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7762e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7756e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7751e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7745e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7739e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7728e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7723e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7717e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7711e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7706e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7701e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7695e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7689e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7684e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7678e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7673e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7667e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7656e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7650e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7644e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7639e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7628e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7622e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7617e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7611e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7605e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7600e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7594e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7588e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7583e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7577e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7572e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7560e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7555e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7549e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7544e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7538e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7527e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7521e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7515e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7510e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7504e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7498e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7493e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7487e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7481e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7459e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7448e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7442e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7436e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7430e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7425e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7419e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7413e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7408e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7402e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7396e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7391e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7385e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7379e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7373e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7367e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7362e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7356e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7350e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7344e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7338e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7332e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7326e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7320e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7307e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7300e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7293e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7287e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7282e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7276e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7270e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7264e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7259e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7253e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7247e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7241e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7235e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7230e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7224e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7218e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7213e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7207e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7201e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7196e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7190e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7184e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7178e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7173e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7167e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7161e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7156e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7150e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7144e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7138e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7133e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7127e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7121e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7116e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7110e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7104e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7099e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7093e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7087e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7081e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7075e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7064e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7058e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7053e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7047e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7041e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7035e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7030e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7024e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7018e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7012e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7007e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7001e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6995e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6989e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6984e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6978e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6972e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6967e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6961e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6955e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6949e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6943e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6938e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6932e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6926e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6920e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6914e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6909e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6903e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6897e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6891e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6885e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6880e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6874e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6868e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6862e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6856e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6851e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6845e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6839e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6833e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6828e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6822e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6804e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6799e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6793e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6787e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6781e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6775e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6769e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6763e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6758e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6752e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6746e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6740e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6734e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6729e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6723e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6717e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6711e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6705e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6699e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6694e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6688e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6682e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6676e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6670e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6664e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6658e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6653e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6647e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6641e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6635e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6629e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6623e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6618e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6612e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6606e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6600e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6594e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6588e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6582e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6570e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6559e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6553e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6547e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6535e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6529e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6523e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6517e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6511e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6506e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6500e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6494e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6488e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6482e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6476e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6470e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6458e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6452e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6446e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6441e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6435e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6429e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6411e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6405e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6399e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6393e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6375e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6369e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6363e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6357e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6351e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6345e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6339e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6333e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6327e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6321e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6315e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6309e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6303e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6297e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6291e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6285e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6279e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6273e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6267e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6261e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6255e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6249e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6243e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6237e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6231e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6225e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6219e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6213e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6207e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6201e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6195e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6189e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6183e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6177e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6172e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6165e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6147e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6142e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6135e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6130e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6123e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6117e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6112e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6105e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6099e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6094e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6088e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6082e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6076e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6061e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6058e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6058e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6063e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6077e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6111e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6592e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7131e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8188e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0285e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4426e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0280e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1958e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5468e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2800e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.9758e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.9111e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8424e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.7773e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.2922e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6812e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.0714e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7575e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5891e-07, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.4875e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3038e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.3429e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.6589e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4790e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.5277e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.8847e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0015e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7754e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8949e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8054e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.8380e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4686e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1073e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0095e-08, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0512e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(6.3469e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2786e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.7681e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.6654e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(7.4783e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.1757e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2557e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(5.7009e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.2168e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.5592e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(4.2800e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0659e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2179e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(3.2516e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.8557e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0534e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.5365e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6495e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7125e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(2.0420e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4730e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2934e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.6977e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.3297e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0718e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.4578e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2184e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9494e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.2889e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1340e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8787e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.1695e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0712e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8383e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0844e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0245e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8161e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(1.0236e-09, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.8963e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8034e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.7999e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.6364e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7983e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4874e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.4410e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7982e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.2920e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8015e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1057e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.1766e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8060e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9947e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0866e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8109e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(9.0155e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8149e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8659e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9590e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8173e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.9139e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8093e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8783e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8172e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7959e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8503e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8148e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7883e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8287e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8112e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7842e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8120e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8066e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7823e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7996e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.8015e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7815e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7905e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7962e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7810e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7840e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7910e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7805e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7860e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7796e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7765e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7783e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7743e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7777e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7767e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7728e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7745e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7747e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7718e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7726e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7702e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7696e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7704e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7689e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7678e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7683e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7675e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7662e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7663e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7659e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7647e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7645e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7643e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7633e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7628e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7626e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7618e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7612e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7609e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7603e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7596e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7592e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7588e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7581e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7576e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7572e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7566e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7561e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7556e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7551e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7545e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7541e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7536e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7530e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7525e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7520e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7515e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7509e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7505e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7500e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7494e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7489e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7484e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7479e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7474e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7469e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7464e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7458e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7453e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7448e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7443e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7438e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7433e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7428e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7417e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7412e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7407e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7402e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7397e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7392e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7387e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7381e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7376e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7371e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7366e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7361e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7356e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7351e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7345e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7340e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7335e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7330e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7325e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7309e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7304e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7299e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7294e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7288e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7283e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7278e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7273e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7268e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7263e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7257e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7252e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7247e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7242e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7237e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7232e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7226e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7221e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7216e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7211e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7205e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7200e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7195e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7190e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7185e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7180e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7174e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7169e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7164e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7159e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7153e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7148e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7143e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7138e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7132e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7127e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7122e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7117e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7112e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7106e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7101e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7096e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7090e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7085e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7080e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7075e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7070e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7065e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7059e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7054e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7049e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7044e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7038e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7033e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7028e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7023e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7017e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7012e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7007e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.7001e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6996e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6991e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6986e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6980e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6975e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6970e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6965e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6959e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6954e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6949e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6943e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6938e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6933e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6928e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6922e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6917e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6911e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6906e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6901e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6896e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6890e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6885e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6880e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6875e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6869e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6864e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6859e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6853e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6848e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6843e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6837e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6832e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6827e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6821e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6816e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6811e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6805e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6800e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6795e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6789e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6784e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6779e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6774e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6768e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6763e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6757e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6752e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6747e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6741e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6736e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6731e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6725e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6720e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6715e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6709e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6704e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6699e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6693e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6688e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6682e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6677e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6672e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6666e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6661e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6656e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6650e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6645e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6640e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6634e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6629e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6623e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6618e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6613e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6607e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6602e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6596e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6591e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6586e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6580e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6575e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6569e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6564e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6559e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6553e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6548e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6542e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6537e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6532e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6526e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6521e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6515e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6510e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6505e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6499e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6494e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6488e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6483e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6477e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6472e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6467e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6461e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6456e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6450e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6445e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6439e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6434e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6428e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6423e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6418e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6412e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6407e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6401e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6396e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6390e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6385e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6380e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6374e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6369e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6363e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6358e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6352e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6347e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6341e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6336e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6330e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6325e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6319e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6314e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6308e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6303e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6297e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6292e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6286e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6281e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6275e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6270e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6264e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6259e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6253e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6248e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6242e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6237e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6231e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6226e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6220e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6215e-10, grad_fn=<DivBackward0>)\n",
            "avg_loss:  tensor(8.6209e-10, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-c4ab83be12fd>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0mtotal_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg_loss: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(torch.tensor([0.3,])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0EmvJhua3K_",
        "outputId": "14a82d4f-02b7-44e3-b5fc-f7d5501b999c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,'bernoullimodel8.pth')"
      ],
      "metadata": {
        "id": "7MBV46DK6irg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0diz5OSz-9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13005c9b-643f-4cf0-9db2-49c58d27a43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "95000 : avg_loss:  tensor(1.2065e-11, grad_fn=<DivBackward0>)\n",
            "95001 : avg_loss:  tensor(1.2065e-11, grad_fn=<DivBackward0>)\n",
            "95002 : avg_loss:  tensor(1.2065e-11, grad_fn=<DivBackward0>)\n",
            "95003 : avg_loss:  tensor(1.2065e-11, grad_fn=<DivBackward0>)\n",
            "95004 : avg_loss:  tensor(1.2065e-11, grad_fn=<DivBackward0>)\n",
            "95005 : avg_loss:  tensor(1.2065e-11, grad_fn=<DivBackward0>)\n",
            "95006 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95007 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95008 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95009 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95010 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95011 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95012 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95013 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95014 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95015 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95016 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95017 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95018 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95019 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95020 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95021 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95022 : avg_loss:  tensor(1.2064e-11, grad_fn=<DivBackward0>)\n",
            "95023 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95024 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95025 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95026 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95027 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95028 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95029 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95030 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95031 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95032 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95033 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95034 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95035 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95036 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95037 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95038 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95039 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95040 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95041 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95042 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95043 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95044 : avg_loss:  tensor(1.2063e-11, grad_fn=<DivBackward0>)\n",
            "95045 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95046 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95047 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95048 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95049 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95050 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95051 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95052 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95053 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95054 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95055 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95056 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95057 : avg_loss:  tensor(1.2062e-11, grad_fn=<DivBackward0>)\n",
            "95058 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95059 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95060 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95061 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95062 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95063 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95064 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95065 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95066 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95067 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95068 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95069 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95070 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95071 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95072 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95073 : avg_loss:  tensor(1.2061e-11, grad_fn=<DivBackward0>)\n",
            "95074 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95075 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95076 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95077 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95078 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95079 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95080 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95081 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95082 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95083 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95084 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95085 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95086 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95087 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95088 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95089 : avg_loss:  tensor(1.2060e-11, grad_fn=<DivBackward0>)\n",
            "95090 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95091 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95092 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95093 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95094 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95095 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95096 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95097 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95098 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95099 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95100 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95101 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95102 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95103 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95104 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95105 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95106 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95107 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95108 : avg_loss:  tensor(1.2059e-11, grad_fn=<DivBackward0>)\n",
            "95109 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95110 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95111 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95112 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95113 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95114 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95115 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95116 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95117 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95118 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95119 : avg_loss:  tensor(1.2058e-11, grad_fn=<DivBackward0>)\n",
            "95120 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95121 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95122 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95123 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95124 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95125 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95126 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95127 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95128 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95129 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95130 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95131 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95132 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95133 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95134 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95135 : avg_loss:  tensor(1.2057e-11, grad_fn=<DivBackward0>)\n",
            "95136 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95137 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95138 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95139 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95140 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95141 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95142 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95143 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95144 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95145 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95146 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95147 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95148 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95149 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95150 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95151 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95152 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95153 : avg_loss:  tensor(1.2056e-11, grad_fn=<DivBackward0>)\n",
            "95154 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95155 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95156 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95157 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95158 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95159 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95160 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95161 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95162 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95163 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95164 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95165 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95166 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95167 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95168 : avg_loss:  tensor(1.2055e-11, grad_fn=<DivBackward0>)\n",
            "95169 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95170 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95171 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95172 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95173 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95174 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95175 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95176 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95177 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95178 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95179 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95180 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95181 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95182 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95183 : avg_loss:  tensor(1.2054e-11, grad_fn=<DivBackward0>)\n",
            "95184 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95185 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95186 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95187 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95188 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95189 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95190 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95191 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95192 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95193 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95194 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95195 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95196 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95197 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95198 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95199 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95200 : avg_loss:  tensor(1.2053e-11, grad_fn=<DivBackward0>)\n",
            "95201 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95202 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95203 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95204 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95205 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95206 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95207 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95208 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95209 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95210 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95211 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95212 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95213 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95214 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95215 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95216 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95217 : avg_loss:  tensor(1.2052e-11, grad_fn=<DivBackward0>)\n",
            "95218 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95219 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95220 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95221 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95222 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95223 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95224 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95225 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95226 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95227 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95228 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95229 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95230 : avg_loss:  tensor(1.2051e-11, grad_fn=<DivBackward0>)\n",
            "95231 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95232 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95233 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95234 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95235 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95236 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95237 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95238 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95239 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95240 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95241 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95242 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95243 : avg_loss:  tensor(1.2050e-11, grad_fn=<DivBackward0>)\n",
            "95244 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95245 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95246 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95247 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95248 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95249 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95250 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95251 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95252 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95253 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95254 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95255 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95256 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95257 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95258 : avg_loss:  tensor(1.2049e-11, grad_fn=<DivBackward0>)\n",
            "95259 : avg_loss:  tensor(1.2048e-11, grad_fn=<DivBackward0>)\n",
            "95260 : avg_loss:  tensor(1.2048e-11, grad_fn=<DivBackward0>)\n",
            "95261 : avg_loss:  tensor(1.2048e-11, grad_fn=<DivBackward0>)\n",
            "95262 : avg_loss:  tensor(1.2048e-11, grad_fn=<DivBackward0>)\n",
            "95263 : avg_loss:  tensor(1.2048e-11, grad_fn=<DivBackward0>)\n",
            "95264 : avg_loss:  tensor(1.2048e-11, grad_fn=<DivBackward0>)\n",
            "95265 : avg_loss:  tensor(1.2048e-11, grad_fn=<DivBackward0>)\n",
            "95266 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95267 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95268 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95269 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95270 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95271 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95272 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95273 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95274 : avg_loss:  tensor(1.2046e-11, grad_fn=<DivBackward0>)\n",
            "95275 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95276 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95277 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95278 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95279 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95280 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95281 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95282 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95283 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95284 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95285 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95286 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95287 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95288 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95289 : avg_loss:  tensor(1.2045e-11, grad_fn=<DivBackward0>)\n",
            "95290 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95291 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95292 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95293 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95294 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95295 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95296 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95297 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95298 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95299 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95300 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95301 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95302 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95303 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95304 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95305 : avg_loss:  tensor(1.2044e-11, grad_fn=<DivBackward0>)\n",
            "95306 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95307 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95308 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95309 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95310 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95311 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95312 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95313 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95314 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95315 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95316 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95317 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95318 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95319 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95320 : avg_loss:  tensor(1.2043e-11, grad_fn=<DivBackward0>)\n",
            "95321 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95322 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95323 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95324 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95325 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95326 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95327 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95328 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95329 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95330 : avg_loss:  tensor(1.2042e-11, grad_fn=<DivBackward0>)\n",
            "95331 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95332 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95333 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95334 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95335 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95336 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95337 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95338 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95339 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95340 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95341 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95342 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95343 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95344 : avg_loss:  tensor(1.2041e-11, grad_fn=<DivBackward0>)\n",
            "95345 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95346 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95347 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95348 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95349 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95350 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95351 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95352 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95353 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95354 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95355 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95356 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95357 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95358 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95359 : avg_loss:  tensor(1.2040e-11, grad_fn=<DivBackward0>)\n",
            "95360 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95361 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95362 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95363 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95364 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95365 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95366 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95367 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95368 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95369 : avg_loss:  tensor(1.2039e-11, grad_fn=<DivBackward0>)\n",
            "95370 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95371 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95372 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95373 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95374 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95375 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95376 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95377 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95378 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95379 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95380 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95381 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95382 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95383 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95384 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95385 : avg_loss:  tensor(1.2038e-11, grad_fn=<DivBackward0>)\n",
            "95386 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95387 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95388 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95389 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95390 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95391 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95392 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95393 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95394 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95395 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95396 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95397 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95398 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95399 : avg_loss:  tensor(1.2037e-11, grad_fn=<DivBackward0>)\n",
            "95400 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95401 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95402 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95403 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95404 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95405 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95406 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95407 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95408 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95409 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95410 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95411 : avg_loss:  tensor(1.2036e-11, grad_fn=<DivBackward0>)\n",
            "95412 : avg_loss:  tensor(1.2035e-11, grad_fn=<DivBackward0>)\n",
            "95413 : avg_loss:  tensor(1.2035e-11, grad_fn=<DivBackward0>)\n",
            "95414 : avg_loss:  tensor(1.2035e-11, grad_fn=<DivBackward0>)\n",
            "95415 : avg_loss:  tensor(1.2035e-11, grad_fn=<DivBackward0>)\n",
            "95416 : avg_loss:  tensor(1.2035e-11, grad_fn=<DivBackward0>)\n",
            "95417 : avg_loss:  tensor(1.2035e-11, grad_fn=<DivBackward0>)\n",
            "95418 : avg_loss:  tensor(1.2035e-11, grad_fn=<DivBackward0>)\n",
            "95419 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95420 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95421 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95422 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95423 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95424 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95425 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95426 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95427 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95428 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95429 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95430 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95431 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95432 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95433 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95434 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95435 : avg_loss:  tensor(1.2034e-11, grad_fn=<DivBackward0>)\n",
            "95436 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95437 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95438 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95439 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95440 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95441 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95442 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95443 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95444 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95445 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95446 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95447 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95448 : avg_loss:  tensor(1.2033e-11, grad_fn=<DivBackward0>)\n",
            "95449 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95450 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95451 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95452 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95453 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95454 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95455 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95456 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95457 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95458 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95459 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95460 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95461 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95462 : avg_loss:  tensor(1.2032e-11, grad_fn=<DivBackward0>)\n",
            "95463 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95464 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95465 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95466 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95467 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95468 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95469 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95470 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95471 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95472 : avg_loss:  tensor(1.2031e-11, grad_fn=<DivBackward0>)\n",
            "95473 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95474 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95475 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95476 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95477 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95478 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95479 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95480 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95481 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95482 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95483 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95484 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95485 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95486 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95487 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95488 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95489 : avg_loss:  tensor(1.2030e-11, grad_fn=<DivBackward0>)\n",
            "95490 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95491 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95492 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95493 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95494 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95495 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95496 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95497 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95498 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95499 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95500 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95501 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95502 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95503 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95504 : avg_loss:  tensor(1.2029e-11, grad_fn=<DivBackward0>)\n",
            "95505 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95506 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95507 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95508 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95509 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95510 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95511 : avg_loss:  tensor(1.2028e-11, grad_fn=<DivBackward0>)\n",
            "95512 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95513 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95514 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95515 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95516 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95517 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95518 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95519 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95520 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95521 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95522 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95523 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95524 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95525 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95526 : avg_loss:  tensor(1.2027e-11, grad_fn=<DivBackward0>)\n",
            "95527 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95528 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95529 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95530 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95531 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95532 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95533 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95534 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95535 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95536 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95537 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95538 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95539 : avg_loss:  tensor(1.2026e-11, grad_fn=<DivBackward0>)\n",
            "95540 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95541 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95542 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95543 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95544 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95545 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95546 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95547 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95548 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95549 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95550 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95551 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95552 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95553 : avg_loss:  tensor(1.2025e-11, grad_fn=<DivBackward0>)\n",
            "95554 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95555 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95556 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95557 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95558 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95559 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95560 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95561 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95562 : avg_loss:  tensor(1.2024e-11, grad_fn=<DivBackward0>)\n",
            "95563 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95564 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95565 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95566 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95567 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95568 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95569 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95570 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95571 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95572 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95573 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95574 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95575 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95576 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95577 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95578 : avg_loss:  tensor(1.2023e-11, grad_fn=<DivBackward0>)\n",
            "95579 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95580 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95581 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95582 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95583 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95584 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95585 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95586 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95587 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95588 : avg_loss:  tensor(1.2022e-11, grad_fn=<DivBackward0>)\n",
            "95589 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95590 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95591 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95592 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95593 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95594 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95595 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95596 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95597 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95598 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95599 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95600 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95601 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95602 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95603 : avg_loss:  tensor(1.2021e-11, grad_fn=<DivBackward0>)\n",
            "95604 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95605 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95606 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95607 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95608 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95609 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95610 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95611 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95612 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95613 : avg_loss:  tensor(1.2020e-11, grad_fn=<DivBackward0>)\n",
            "95614 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95615 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95616 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95617 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95618 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95619 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95620 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95621 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95622 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95623 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95624 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95625 : avg_loss:  tensor(1.2019e-11, grad_fn=<DivBackward0>)\n",
            "95626 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95627 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95628 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95629 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95630 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95631 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95632 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95633 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95634 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95635 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95636 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95637 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95638 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95639 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95640 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95641 : avg_loss:  tensor(1.2018e-11, grad_fn=<DivBackward0>)\n",
            "95642 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95643 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95644 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95645 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95646 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95647 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95648 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95649 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95650 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95651 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95652 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95653 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95654 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95655 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95656 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95657 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95658 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95659 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95660 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95661 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95662 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95663 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95664 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95665 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95666 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95667 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95668 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95669 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95670 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95671 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95672 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95673 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95674 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95675 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95676 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95677 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95678 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95679 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95680 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95681 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95682 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95683 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95684 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95685 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95686 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95687 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95688 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95689 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95690 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95691 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95692 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95693 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95694 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95695 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95696 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95697 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95698 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95699 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95700 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95701 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95702 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95703 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95704 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95705 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95706 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95707 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95708 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95709 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95710 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95711 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95712 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95713 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95714 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95715 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95716 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95717 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95718 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95719 : avg_loss:  tensor(1.2017e-11, grad_fn=<DivBackward0>)\n",
            "95720 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95721 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95722 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95723 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95724 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95725 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95726 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95727 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95728 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95729 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95730 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95731 : avg_loss:  tensor(1.2016e-11, grad_fn=<DivBackward0>)\n",
            "95732 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95733 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95734 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95735 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95736 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95737 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95738 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95739 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95740 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95741 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95742 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95743 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95744 : avg_loss:  tensor(1.2015e-11, grad_fn=<DivBackward0>)\n",
            "95745 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95746 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95747 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95748 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95749 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95750 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95751 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95752 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95753 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95754 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95755 : avg_loss:  tensor(1.2014e-11, grad_fn=<DivBackward0>)\n",
            "95756 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95757 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95758 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95759 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95760 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95761 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95762 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95763 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95764 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95765 : avg_loss:  tensor(1.2013e-11, grad_fn=<DivBackward0>)\n",
            "95766 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95767 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95768 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95769 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95770 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95771 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95772 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95773 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95774 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95775 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95776 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95777 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95778 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95779 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95780 : avg_loss:  tensor(1.2012e-11, grad_fn=<DivBackward0>)\n",
            "95781 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95782 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95783 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95784 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95785 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95786 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95787 : avg_loss:  tensor(1.2011e-11, grad_fn=<DivBackward0>)\n",
            "95788 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95789 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95790 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95791 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95792 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95793 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95794 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95795 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95796 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95797 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95798 : avg_loss:  tensor(1.2010e-11, grad_fn=<DivBackward0>)\n",
            "95799 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95800 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95801 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95802 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95803 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95804 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95805 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95806 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95807 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95808 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95809 : avg_loss:  tensor(1.2009e-11, grad_fn=<DivBackward0>)\n",
            "95810 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95811 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95812 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95813 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95814 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95815 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95816 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95817 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95818 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95819 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95820 : avg_loss:  tensor(1.2008e-11, grad_fn=<DivBackward0>)\n",
            "95821 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95822 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95823 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95824 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95825 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95826 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95827 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95828 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95829 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95830 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95831 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95832 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95833 : avg_loss:  tensor(1.2007e-11, grad_fn=<DivBackward0>)\n",
            "95834 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95835 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95836 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95837 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95838 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95839 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95840 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95841 : avg_loss:  tensor(1.2006e-11, grad_fn=<DivBackward0>)\n",
            "95842 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95843 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95844 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95845 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95846 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95847 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95848 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95849 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95850 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95851 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95852 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95853 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95854 : avg_loss:  tensor(1.2005e-11, grad_fn=<DivBackward0>)\n",
            "95855 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95856 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95857 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95858 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95859 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95860 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95861 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95862 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95863 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95864 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95865 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95866 : avg_loss:  tensor(1.2004e-11, grad_fn=<DivBackward0>)\n",
            "95867 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95868 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95869 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95870 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95871 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95872 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95873 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95874 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95875 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95876 : avg_loss:  tensor(1.2003e-11, grad_fn=<DivBackward0>)\n",
            "95877 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95878 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95879 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95880 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95881 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95882 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95883 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95884 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95885 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95886 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95887 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95888 : avg_loss:  tensor(1.2002e-11, grad_fn=<DivBackward0>)\n",
            "95889 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95890 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95891 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95892 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95893 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95894 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95895 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95896 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95897 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95898 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95899 : avg_loss:  tensor(1.2001e-11, grad_fn=<DivBackward0>)\n",
            "95900 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95901 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95902 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95903 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95904 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95905 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95906 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95907 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95908 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95909 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95910 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95911 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95912 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95913 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95914 : avg_loss:  tensor(1.2000e-11, grad_fn=<DivBackward0>)\n",
            "95915 : avg_loss:  tensor(1.1999e-11, grad_fn=<DivBackward0>)\n",
            "95916 : avg_loss:  tensor(1.1999e-11, grad_fn=<DivBackward0>)\n",
            "95917 : avg_loss:  tensor(1.1999e-11, grad_fn=<DivBackward0>)\n",
            "95918 : avg_loss:  tensor(1.1999e-11, grad_fn=<DivBackward0>)\n",
            "95919 : avg_loss:  tensor(1.1999e-11, grad_fn=<DivBackward0>)\n",
            "95920 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95921 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95922 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95923 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95924 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95925 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95926 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95927 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95928 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95929 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95930 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95931 : avg_loss:  tensor(1.1998e-11, grad_fn=<DivBackward0>)\n",
            "95932 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95933 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95934 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95935 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95936 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95937 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95938 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95939 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95940 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95941 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95942 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95943 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95944 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95945 : avg_loss:  tensor(1.1997e-11, grad_fn=<DivBackward0>)\n",
            "95946 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95947 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95948 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95949 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95950 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95951 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95952 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95953 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95954 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95955 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95956 : avg_loss:  tensor(1.1996e-11, grad_fn=<DivBackward0>)\n",
            "95957 : avg_loss:  tensor(1.1995e-11, grad_fn=<DivBackward0>)\n",
            "95958 : avg_loss:  tensor(1.1995e-11, grad_fn=<DivBackward0>)\n",
            "95959 : avg_loss:  tensor(1.1995e-11, grad_fn=<DivBackward0>)\n",
            "95960 : avg_loss:  tensor(1.1995e-11, grad_fn=<DivBackward0>)\n",
            "95961 : avg_loss:  tensor(1.1995e-11, grad_fn=<DivBackward0>)\n",
            "95962 : avg_loss:  tensor(1.1995e-11, grad_fn=<DivBackward0>)\n",
            "95963 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95964 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95965 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95966 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95967 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95968 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95969 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95970 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95971 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95972 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95973 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95974 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95975 : avg_loss:  tensor(1.1994e-11, grad_fn=<DivBackward0>)\n",
            "95976 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95977 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95978 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95979 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95980 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95981 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95982 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95983 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95984 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95985 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95986 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95987 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95988 : avg_loss:  tensor(1.1993e-11, grad_fn=<DivBackward0>)\n",
            "95989 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95990 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95991 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95992 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95993 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95994 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95995 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95996 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95997 : avg_loss:  tensor(1.1992e-11, grad_fn=<DivBackward0>)\n",
            "95998 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "95999 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "96000 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "96001 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "96002 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "96003 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "96004 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "96005 : avg_loss:  tensor(1.1991e-11, grad_fn=<DivBackward0>)\n",
            "96006 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96007 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96008 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96009 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96010 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96011 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96012 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96013 : avg_loss:  tensor(1.1990e-11, grad_fn=<DivBackward0>)\n",
            "96014 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96015 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96016 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96017 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96018 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96019 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96020 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96021 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96022 : avg_loss:  tensor(1.1989e-11, grad_fn=<DivBackward0>)\n",
            "96023 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96024 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96025 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96026 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96027 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96028 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96029 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96030 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96031 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96032 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96033 : avg_loss:  tensor(1.1988e-11, grad_fn=<DivBackward0>)\n",
            "96034 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96035 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96036 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96037 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96038 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96039 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96040 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96041 : avg_loss:  tensor(1.1987e-11, grad_fn=<DivBackward0>)\n",
            "96042 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96043 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96044 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96045 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96046 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96047 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96048 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96049 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96050 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96051 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96052 : avg_loss:  tensor(1.1986e-11, grad_fn=<DivBackward0>)\n",
            "96053 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96054 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96055 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96056 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96057 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96058 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96059 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96060 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96061 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96062 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96063 : avg_loss:  tensor(1.1985e-11, grad_fn=<DivBackward0>)\n",
            "96064 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96065 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96066 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96067 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96068 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96069 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96070 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96071 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96072 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96073 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96074 : avg_loss:  tensor(1.1984e-11, grad_fn=<DivBackward0>)\n",
            "96075 : avg_loss:  tensor(1.1983e-11, grad_fn=<DivBackward0>)\n",
            "96076 : avg_loss:  tensor(1.1983e-11, grad_fn=<DivBackward0>)\n",
            "96077 : avg_loss:  tensor(1.1983e-11, grad_fn=<DivBackward0>)\n",
            "96078 : avg_loss:  tensor(1.1983e-11, grad_fn=<DivBackward0>)\n",
            "96079 : avg_loss:  tensor(1.1983e-11, grad_fn=<DivBackward0>)\n",
            "96080 : avg_loss:  tensor(1.1983e-11, grad_fn=<DivBackward0>)\n",
            "96081 : avg_loss:  tensor(1.1983e-11, grad_fn=<DivBackward0>)\n",
            "96082 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96083 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96084 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96085 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96086 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96087 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96088 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96089 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96090 : avg_loss:  tensor(1.1982e-11, grad_fn=<DivBackward0>)\n",
            "96091 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96092 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96093 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96094 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96095 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96096 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96097 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96098 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96099 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96100 : avg_loss:  tensor(1.1981e-11, grad_fn=<DivBackward0>)\n",
            "96101 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96102 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96103 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96104 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96105 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96106 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96107 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96108 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96109 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96110 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96111 : avg_loss:  tensor(1.1980e-11, grad_fn=<DivBackward0>)\n",
            "96112 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96113 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96114 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96115 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96116 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96117 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96118 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96119 : avg_loss:  tensor(1.1979e-11, grad_fn=<DivBackward0>)\n",
            "96120 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96121 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96122 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96123 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96124 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96125 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96126 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96127 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96128 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96129 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96130 : avg_loss:  tensor(1.1978e-11, grad_fn=<DivBackward0>)\n",
            "96131 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96132 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96133 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96134 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96135 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96136 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96137 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96138 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96139 : avg_loss:  tensor(1.1977e-11, grad_fn=<DivBackward0>)\n",
            "96140 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96141 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96142 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96143 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96144 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96145 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96146 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96147 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96148 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96149 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96150 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96151 : avg_loss:  tensor(1.1976e-11, grad_fn=<DivBackward0>)\n",
            "96152 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96153 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96154 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96155 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96156 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96157 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96158 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96159 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96160 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96161 : avg_loss:  tensor(1.1975e-11, grad_fn=<DivBackward0>)\n",
            "96162 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96163 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96164 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96165 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96166 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96167 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96168 : avg_loss:  tensor(1.1974e-11, grad_fn=<DivBackward0>)\n",
            "96169 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96170 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96171 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96172 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96173 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96174 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96175 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96176 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96177 : avg_loss:  tensor(1.1973e-11, grad_fn=<DivBackward0>)\n",
            "96178 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96179 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96180 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96181 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96182 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96183 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96184 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96185 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96186 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96187 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96188 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96189 : avg_loss:  tensor(1.1972e-11, grad_fn=<DivBackward0>)\n",
            "96190 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96191 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96192 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96193 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96194 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96195 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96196 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96197 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96198 : avg_loss:  tensor(1.1971e-11, grad_fn=<DivBackward0>)\n",
            "96199 : avg_loss:  tensor(1.1970e-11, grad_fn=<DivBackward0>)\n",
            "96200 : avg_loss:  tensor(1.1970e-11, grad_fn=<DivBackward0>)\n",
            "96201 : avg_loss:  tensor(1.1970e-11, grad_fn=<DivBackward0>)\n",
            "96202 : avg_loss:  tensor(1.1970e-11, grad_fn=<DivBackward0>)\n",
            "96203 : avg_loss:  tensor(1.1970e-11, grad_fn=<DivBackward0>)\n",
            "96204 : avg_loss:  tensor(1.1970e-11, grad_fn=<DivBackward0>)\n",
            "96205 : avg_loss:  tensor(1.1970e-11, grad_fn=<DivBackward0>)\n",
            "96206 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96207 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96208 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96209 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96210 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96211 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96212 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96213 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96214 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96215 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96216 : avg_loss:  tensor(1.1969e-11, grad_fn=<DivBackward0>)\n",
            "96217 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96218 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96219 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96220 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96221 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96222 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96223 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96224 : avg_loss:  tensor(1.1968e-11, grad_fn=<DivBackward0>)\n",
            "96225 : avg_loss:  tensor(1.1967e-11, grad_fn=<DivBackward0>)\n",
            "96226 : avg_loss:  tensor(1.1967e-11, grad_fn=<DivBackward0>)\n",
            "96227 : avg_loss:  tensor(1.1967e-11, grad_fn=<DivBackward0>)\n",
            "96228 : avg_loss:  tensor(1.1967e-11, grad_fn=<DivBackward0>)\n",
            "96229 : avg_loss:  tensor(1.1967e-11, grad_fn=<DivBackward0>)\n",
            "96230 : avg_loss:  tensor(1.1967e-11, grad_fn=<DivBackward0>)\n",
            "96231 : avg_loss:  tensor(1.1967e-11, grad_fn=<DivBackward0>)\n",
            "96232 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96233 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96234 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96235 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96236 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96237 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96238 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96239 : avg_loss:  tensor(1.1966e-11, grad_fn=<DivBackward0>)\n",
            "96240 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96241 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96242 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96243 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96244 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96245 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96246 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96247 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96248 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96249 : avg_loss:  tensor(1.1965e-11, grad_fn=<DivBackward0>)\n",
            "96250 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96251 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96252 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96253 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96254 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96255 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96256 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96257 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96258 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96259 : avg_loss:  tensor(1.1964e-11, grad_fn=<DivBackward0>)\n",
            "96260 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96261 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96262 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96263 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96264 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96265 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96266 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96267 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96268 : avg_loss:  tensor(1.1963e-11, grad_fn=<DivBackward0>)\n",
            "96269 : avg_loss:  tensor(1.1962e-11, grad_fn=<DivBackward0>)\n",
            "96270 : avg_loss:  tensor(1.1962e-11, grad_fn=<DivBackward0>)\n",
            "96271 : avg_loss:  tensor(1.1962e-11, grad_fn=<DivBackward0>)\n",
            "96272 : avg_loss:  tensor(1.1962e-11, grad_fn=<DivBackward0>)\n",
            "96273 : avg_loss:  tensor(1.1962e-11, grad_fn=<DivBackward0>)\n",
            "96274 : avg_loss:  tensor(1.1962e-11, grad_fn=<DivBackward0>)\n",
            "96275 : avg_loss:  tensor(1.1962e-11, grad_fn=<DivBackward0>)\n",
            "96276 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96277 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96278 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96279 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96280 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96281 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96282 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96283 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96284 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96285 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96286 : avg_loss:  tensor(1.1961e-11, grad_fn=<DivBackward0>)\n",
            "96287 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96288 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96289 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96290 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96291 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96292 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96293 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96294 : avg_loss:  tensor(1.1960e-11, grad_fn=<DivBackward0>)\n",
            "96295 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96296 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96297 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96298 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96299 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96300 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96301 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96302 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96303 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96304 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96305 : avg_loss:  tensor(1.1959e-11, grad_fn=<DivBackward0>)\n",
            "96306 : avg_loss:  tensor(1.1958e-11, grad_fn=<DivBackward0>)\n",
            "96307 : avg_loss:  tensor(1.1958e-11, grad_fn=<DivBackward0>)\n",
            "96308 : avg_loss:  tensor(1.1958e-11, grad_fn=<DivBackward0>)\n",
            "96309 : avg_loss:  tensor(1.1958e-11, grad_fn=<DivBackward0>)\n",
            "96310 : avg_loss:  tensor(1.1958e-11, grad_fn=<DivBackward0>)\n",
            "96311 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96312 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96313 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96314 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96315 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96316 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96317 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96318 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96319 : avg_loss:  tensor(1.1957e-11, grad_fn=<DivBackward0>)\n",
            "96320 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96321 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96322 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96323 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96324 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96325 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96326 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96327 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96328 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96329 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96330 : avg_loss:  tensor(1.1956e-11, grad_fn=<DivBackward0>)\n",
            "96331 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96332 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96333 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96334 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96335 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96336 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96337 : avg_loss:  tensor(1.1955e-11, grad_fn=<DivBackward0>)\n",
            "96338 : avg_loss:  tensor(1.1954e-11, grad_fn=<DivBackward0>)\n",
            "96339 : avg_loss:  tensor(1.1954e-11, grad_fn=<DivBackward0>)\n",
            "96340 : avg_loss:  tensor(1.1954e-11, grad_fn=<DivBackward0>)\n",
            "96341 : avg_loss:  tensor(1.1954e-11, grad_fn=<DivBackward0>)\n",
            "96342 : avg_loss:  tensor(1.1954e-11, grad_fn=<DivBackward0>)\n",
            "96343 : avg_loss:  tensor(1.1954e-11, grad_fn=<DivBackward0>)\n",
            "96344 : avg_loss:  tensor(1.1954e-11, grad_fn=<DivBackward0>)\n",
            "96345 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96346 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96347 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96348 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96349 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96350 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96351 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96352 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96353 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96354 : avg_loss:  tensor(1.1953e-11, grad_fn=<DivBackward0>)\n",
            "96355 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96356 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96357 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96358 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96359 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96360 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96361 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96362 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96363 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96364 : avg_loss:  tensor(1.1952e-11, grad_fn=<DivBackward0>)\n",
            "96365 : avg_loss:  tensor(1.1951e-11, grad_fn=<DivBackward0>)\n",
            "96366 : avg_loss:  tensor(1.1951e-11, grad_fn=<DivBackward0>)\n",
            "96367 : avg_loss:  tensor(1.1951e-11, grad_fn=<DivBackward0>)\n",
            "96368 : avg_loss:  tensor(1.1951e-11, grad_fn=<DivBackward0>)\n",
            "96369 : avg_loss:  tensor(1.1951e-11, grad_fn=<DivBackward0>)\n",
            "96370 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96371 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96372 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96373 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96374 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96375 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96376 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96377 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96378 : avg_loss:  tensor(1.1950e-11, grad_fn=<DivBackward0>)\n",
            "96379 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96380 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96381 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96382 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96383 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96384 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96385 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96386 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96387 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96388 : avg_loss:  tensor(1.1949e-11, grad_fn=<DivBackward0>)\n",
            "96389 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96390 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96391 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96392 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96393 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96394 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96395 : avg_loss:  tensor(1.1948e-11, grad_fn=<DivBackward0>)\n",
            "96396 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96397 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96398 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96399 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96400 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96401 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96402 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96403 : avg_loss:  tensor(1.1947e-11, grad_fn=<DivBackward0>)\n",
            "96404 : avg_loss:  tensor(1.1946e-11, grad_fn=<DivBackward0>)\n",
            "96405 : avg_loss:  tensor(1.1946e-11, grad_fn=<DivBackward0>)\n",
            "96406 : avg_loss:  tensor(1.1946e-11, grad_fn=<DivBackward0>)\n",
            "96407 : avg_loss:  tensor(1.1946e-11, grad_fn=<DivBackward0>)\n",
            "96408 : avg_loss:  tensor(1.1946e-11, grad_fn=<DivBackward0>)\n",
            "96409 : avg_loss:  tensor(1.1946e-11, grad_fn=<DivBackward0>)\n",
            "96410 : avg_loss:  tensor(1.1946e-11, grad_fn=<DivBackward0>)\n",
            "96411 : avg_loss:  tensor(1.1945e-11, grad_fn=<DivBackward0>)\n",
            "96412 : avg_loss:  tensor(1.1945e-11, grad_fn=<DivBackward0>)\n",
            "96413 : avg_loss:  tensor(1.1945e-11, grad_fn=<DivBackward0>)\n",
            "96414 : avg_loss:  tensor(1.1945e-11, grad_fn=<DivBackward0>)\n",
            "96415 : avg_loss:  tensor(1.1945e-11, grad_fn=<DivBackward0>)\n",
            "96416 : avg_loss:  tensor(1.1945e-11, grad_fn=<DivBackward0>)\n",
            "96417 : avg_loss:  tensor(1.1945e-11, grad_fn=<DivBackward0>)\n",
            "96418 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96419 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96420 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96421 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96422 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96423 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96424 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96425 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96426 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96427 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96428 : avg_loss:  tensor(1.1944e-11, grad_fn=<DivBackward0>)\n",
            "96429 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96430 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96431 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96432 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96433 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96434 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96435 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96436 : avg_loss:  tensor(1.1943e-11, grad_fn=<DivBackward0>)\n",
            "96437 : avg_loss:  tensor(1.1942e-11, grad_fn=<DivBackward0>)\n",
            "96438 : avg_loss:  tensor(1.1942e-11, grad_fn=<DivBackward0>)\n",
            "96439 : avg_loss:  tensor(1.1942e-11, grad_fn=<DivBackward0>)\n",
            "96440 : avg_loss:  tensor(1.1942e-11, grad_fn=<DivBackward0>)\n",
            "96441 : avg_loss:  tensor(1.1942e-11, grad_fn=<DivBackward0>)\n",
            "96442 : avg_loss:  tensor(1.1942e-11, grad_fn=<DivBackward0>)\n",
            "96443 : avg_loss:  tensor(1.1942e-11, grad_fn=<DivBackward0>)\n",
            "96444 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96445 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96446 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96447 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96448 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96449 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96450 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96451 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96452 : avg_loss:  tensor(1.1941e-11, grad_fn=<DivBackward0>)\n",
            "96453 : avg_loss:  tensor(1.1940e-11, grad_fn=<DivBackward0>)\n",
            "96454 : avg_loss:  tensor(1.1940e-11, grad_fn=<DivBackward0>)\n",
            "96455 : avg_loss:  tensor(1.1940e-11, grad_fn=<DivBackward0>)\n",
            "96456 : avg_loss:  tensor(1.1940e-11, grad_fn=<DivBackward0>)\n",
            "96457 : avg_loss:  tensor(1.1940e-11, grad_fn=<DivBackward0>)\n",
            "96458 : avg_loss:  tensor(1.1940e-11, grad_fn=<DivBackward0>)\n",
            "96459 : avg_loss:  tensor(1.1940e-11, grad_fn=<DivBackward0>)\n",
            "96460 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96461 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96462 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96463 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96464 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96465 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96466 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96467 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96468 : avg_loss:  tensor(1.1939e-11, grad_fn=<DivBackward0>)\n",
            "96469 : avg_loss:  tensor(1.1938e-11, grad_fn=<DivBackward0>)\n",
            "96470 : avg_loss:  tensor(1.1938e-11, grad_fn=<DivBackward0>)\n",
            "96471 : avg_loss:  tensor(1.1938e-11, grad_fn=<DivBackward0>)\n",
            "96472 : avg_loss:  tensor(1.1938e-11, grad_fn=<DivBackward0>)\n",
            "96473 : avg_loss:  tensor(1.1938e-11, grad_fn=<DivBackward0>)\n",
            "96474 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96475 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96476 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96477 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96478 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96479 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96480 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96481 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96482 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96483 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96484 : avg_loss:  tensor(1.1937e-11, grad_fn=<DivBackward0>)\n",
            "96485 : avg_loss:  tensor(1.1936e-11, grad_fn=<DivBackward0>)\n",
            "96486 : avg_loss:  tensor(1.1936e-11, grad_fn=<DivBackward0>)\n",
            "96487 : avg_loss:  tensor(1.1936e-11, grad_fn=<DivBackward0>)\n",
            "96488 : avg_loss:  tensor(1.1936e-11, grad_fn=<DivBackward0>)\n",
            "96489 : avg_loss:  tensor(1.1936e-11, grad_fn=<DivBackward0>)\n",
            "96490 : avg_loss:  tensor(1.1936e-11, grad_fn=<DivBackward0>)\n",
            "96491 : avg_loss:  tensor(1.1936e-11, grad_fn=<DivBackward0>)\n",
            "96492 : avg_loss:  tensor(1.1935e-11, grad_fn=<DivBackward0>)\n",
            "96493 : avg_loss:  tensor(1.1935e-11, grad_fn=<DivBackward0>)\n",
            "96494 : avg_loss:  tensor(1.1935e-11, grad_fn=<DivBackward0>)\n",
            "96495 : avg_loss:  tensor(1.1935e-11, grad_fn=<DivBackward0>)\n",
            "96496 : avg_loss:  tensor(1.1935e-11, grad_fn=<DivBackward0>)\n",
            "96497 : avg_loss:  tensor(1.1935e-11, grad_fn=<DivBackward0>)\n",
            "96498 : avg_loss:  tensor(1.1935e-11, grad_fn=<DivBackward0>)\n",
            "96499 : avg_loss:  tensor(1.1934e-11, grad_fn=<DivBackward0>)\n",
            "96500 : avg_loss:  tensor(1.1934e-11, grad_fn=<DivBackward0>)\n",
            "96501 : avg_loss:  tensor(1.1934e-11, grad_fn=<DivBackward0>)\n",
            "96502 : avg_loss:  tensor(1.1934e-11, grad_fn=<DivBackward0>)\n",
            "96503 : avg_loss:  tensor(1.1934e-11, grad_fn=<DivBackward0>)\n",
            "96504 : avg_loss:  tensor(1.1934e-11, grad_fn=<DivBackward0>)\n",
            "96505 : avg_loss:  tensor(1.1934e-11, grad_fn=<DivBackward0>)\n",
            "96506 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96507 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96508 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96509 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96510 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96511 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96512 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96513 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96514 : avg_loss:  tensor(1.1933e-11, grad_fn=<DivBackward0>)\n",
            "96515 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96516 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96517 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96518 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96519 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96520 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96521 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96522 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96523 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96524 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96525 : avg_loss:  tensor(1.1932e-11, grad_fn=<DivBackward0>)\n",
            "96526 : avg_loss:  tensor(1.1931e-11, grad_fn=<DivBackward0>)\n",
            "96527 : avg_loss:  tensor(1.1931e-11, grad_fn=<DivBackward0>)\n",
            "96528 : avg_loss:  tensor(1.1931e-11, grad_fn=<DivBackward0>)\n",
            "96529 : avg_loss:  tensor(1.1931e-11, grad_fn=<DivBackward0>)\n",
            "96530 : avg_loss:  tensor(1.1931e-11, grad_fn=<DivBackward0>)\n",
            "96531 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96532 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96533 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96534 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96535 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96536 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96537 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96538 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96539 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96540 : avg_loss:  tensor(1.1930e-11, grad_fn=<DivBackward0>)\n",
            "96541 : avg_loss:  tensor(1.1929e-11, grad_fn=<DivBackward0>)\n",
            "96542 : avg_loss:  tensor(1.1929e-11, grad_fn=<DivBackward0>)\n",
            "96543 : avg_loss:  tensor(1.1929e-11, grad_fn=<DivBackward0>)\n",
            "96544 : avg_loss:  tensor(1.1929e-11, grad_fn=<DivBackward0>)\n",
            "96545 : avg_loss:  tensor(1.1929e-11, grad_fn=<DivBackward0>)\n",
            "96546 : avg_loss:  tensor(1.1929e-11, grad_fn=<DivBackward0>)\n",
            "96547 : avg_loss:  tensor(1.1929e-11, grad_fn=<DivBackward0>)\n",
            "96548 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96549 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96550 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96551 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96552 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96553 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96554 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96555 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96556 : avg_loss:  tensor(1.1928e-11, grad_fn=<DivBackward0>)\n",
            "96557 : avg_loss:  tensor(1.1927e-11, grad_fn=<DivBackward0>)\n",
            "96558 : avg_loss:  tensor(1.1927e-11, grad_fn=<DivBackward0>)\n",
            "96559 : avg_loss:  tensor(1.1927e-11, grad_fn=<DivBackward0>)\n",
            "96560 : avg_loss:  tensor(1.1927e-11, grad_fn=<DivBackward0>)\n",
            "96561 : avg_loss:  tensor(1.1927e-11, grad_fn=<DivBackward0>)\n",
            "96562 : avg_loss:  tensor(1.1927e-11, grad_fn=<DivBackward0>)\n",
            "96563 : avg_loss:  tensor(1.1927e-11, grad_fn=<DivBackward0>)\n",
            "96564 : avg_loss:  tensor(1.1926e-11, grad_fn=<DivBackward0>)\n",
            "96565 : avg_loss:  tensor(1.1926e-11, grad_fn=<DivBackward0>)\n",
            "96566 : avg_loss:  tensor(1.1926e-11, grad_fn=<DivBackward0>)\n",
            "96567 : avg_loss:  tensor(1.1926e-11, grad_fn=<DivBackward0>)\n",
            "96568 : avg_loss:  tensor(1.1926e-11, grad_fn=<DivBackward0>)\n",
            "96569 : avg_loss:  tensor(1.1926e-11, grad_fn=<DivBackward0>)\n",
            "96570 : avg_loss:  tensor(1.1926e-11, grad_fn=<DivBackward0>)\n",
            "96571 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96572 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96573 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96574 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96575 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96576 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96577 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96578 : avg_loss:  tensor(1.1925e-11, grad_fn=<DivBackward0>)\n",
            "96579 : avg_loss:  tensor(1.1924e-11, grad_fn=<DivBackward0>)\n",
            "96580 : avg_loss:  tensor(1.1924e-11, grad_fn=<DivBackward0>)\n",
            "96581 : avg_loss:  tensor(1.1924e-11, grad_fn=<DivBackward0>)\n",
            "96582 : avg_loss:  tensor(1.1924e-11, grad_fn=<DivBackward0>)\n",
            "96583 : avg_loss:  tensor(1.1924e-11, grad_fn=<DivBackward0>)\n",
            "96584 : avg_loss:  tensor(1.1924e-11, grad_fn=<DivBackward0>)\n",
            "96585 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96586 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96587 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96588 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96589 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96590 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96591 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96592 : avg_loss:  tensor(1.1923e-11, grad_fn=<DivBackward0>)\n",
            "96593 : avg_loss:  tensor(1.1922e-11, grad_fn=<DivBackward0>)\n",
            "96594 : avg_loss:  tensor(1.1922e-11, grad_fn=<DivBackward0>)\n",
            "96595 : avg_loss:  tensor(1.1922e-11, grad_fn=<DivBackward0>)\n",
            "96596 : avg_loss:  tensor(1.1922e-11, grad_fn=<DivBackward0>)\n",
            "96597 : avg_loss:  tensor(1.1922e-11, grad_fn=<DivBackward0>)\n",
            "96598 : avg_loss:  tensor(1.1922e-11, grad_fn=<DivBackward0>)\n",
            "96599 : avg_loss:  tensor(1.1922e-11, grad_fn=<DivBackward0>)\n",
            "96600 : avg_loss:  tensor(1.1921e-11, grad_fn=<DivBackward0>)\n",
            "96601 : avg_loss:  tensor(1.1921e-11, grad_fn=<DivBackward0>)\n",
            "96602 : avg_loss:  tensor(1.1921e-11, grad_fn=<DivBackward0>)\n",
            "96603 : avg_loss:  tensor(1.1921e-11, grad_fn=<DivBackward0>)\n",
            "96604 : avg_loss:  tensor(1.1921e-11, grad_fn=<DivBackward0>)\n",
            "96605 : avg_loss:  tensor(1.1921e-11, grad_fn=<DivBackward0>)\n",
            "96606 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96607 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96608 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96609 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96610 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96611 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96612 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96613 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96614 : avg_loss:  tensor(1.1920e-11, grad_fn=<DivBackward0>)\n",
            "96615 : avg_loss:  tensor(1.1919e-11, grad_fn=<DivBackward0>)\n",
            "96616 : avg_loss:  tensor(1.1919e-11, grad_fn=<DivBackward0>)\n",
            "96617 : avg_loss:  tensor(1.1919e-11, grad_fn=<DivBackward0>)\n",
            "96618 : avg_loss:  tensor(1.1919e-11, grad_fn=<DivBackward0>)\n",
            "96619 : avg_loss:  tensor(1.1919e-11, grad_fn=<DivBackward0>)\n",
            "96620 : avg_loss:  tensor(1.1919e-11, grad_fn=<DivBackward0>)\n",
            "96621 : avg_loss:  tensor(1.1919e-11, grad_fn=<DivBackward0>)\n",
            "96622 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96623 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96624 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96625 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96626 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96627 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96628 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96629 : avg_loss:  tensor(1.1918e-11, grad_fn=<DivBackward0>)\n",
            "96630 : avg_loss:  tensor(1.1917e-11, grad_fn=<DivBackward0>)\n",
            "96631 : avg_loss:  tensor(1.1917e-11, grad_fn=<DivBackward0>)\n",
            "96632 : avg_loss:  tensor(1.1917e-11, grad_fn=<DivBackward0>)\n",
            "96633 : avg_loss:  tensor(1.1917e-11, grad_fn=<DivBackward0>)\n",
            "96634 : avg_loss:  tensor(1.1917e-11, grad_fn=<DivBackward0>)\n",
            "96635 : avg_loss:  tensor(1.1917e-11, grad_fn=<DivBackward0>)\n",
            "96636 : avg_loss:  tensor(1.1917e-11, grad_fn=<DivBackward0>)\n",
            "96637 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96638 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96639 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96640 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96641 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96642 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96643 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96644 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96645 : avg_loss:  tensor(1.1916e-11, grad_fn=<DivBackward0>)\n",
            "96646 : avg_loss:  tensor(1.1915e-11, grad_fn=<DivBackward0>)\n",
            "96647 : avg_loss:  tensor(1.1915e-11, grad_fn=<DivBackward0>)\n",
            "96648 : avg_loss:  tensor(1.1915e-11, grad_fn=<DivBackward0>)\n",
            "96649 : avg_loss:  tensor(1.1915e-11, grad_fn=<DivBackward0>)\n",
            "96650 : avg_loss:  tensor(1.1915e-11, grad_fn=<DivBackward0>)\n",
            "96651 : avg_loss:  tensor(1.1915e-11, grad_fn=<DivBackward0>)\n",
            "96652 : avg_loss:  tensor(1.1915e-11, grad_fn=<DivBackward0>)\n",
            "96653 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96654 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96655 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96656 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96657 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96658 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96659 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96660 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96661 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96662 : avg_loss:  tensor(1.1914e-11, grad_fn=<DivBackward0>)\n",
            "96663 : avg_loss:  tensor(1.1913e-11, grad_fn=<DivBackward0>)\n",
            "96664 : avg_loss:  tensor(1.1913e-11, grad_fn=<DivBackward0>)\n",
            "96665 : avg_loss:  tensor(1.1913e-11, grad_fn=<DivBackward0>)\n",
            "96666 : avg_loss:  tensor(1.1913e-11, grad_fn=<DivBackward0>)\n",
            "96667 : avg_loss:  tensor(1.1913e-11, grad_fn=<DivBackward0>)\n",
            "96668 : avg_loss:  tensor(1.1913e-11, grad_fn=<DivBackward0>)\n",
            "96669 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96670 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96671 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96672 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96673 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96674 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96675 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96676 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96677 : avg_loss:  tensor(1.1912e-11, grad_fn=<DivBackward0>)\n",
            "96678 : avg_loss:  tensor(1.1911e-11, grad_fn=<DivBackward0>)\n",
            "96679 : avg_loss:  tensor(1.1910e-11, grad_fn=<DivBackward0>)\n",
            "96680 : avg_loss:  tensor(1.1909e-11, grad_fn=<DivBackward0>)\n",
            "96681 : avg_loss:  tensor(1.1909e-11, grad_fn=<DivBackward0>)\n",
            "96682 : avg_loss:  tensor(1.1909e-11, grad_fn=<DivBackward0>)\n",
            "96683 : avg_loss:  tensor(1.1909e-11, grad_fn=<DivBackward0>)\n",
            "96684 : avg_loss:  tensor(1.1909e-11, grad_fn=<DivBackward0>)\n",
            "96685 : avg_loss:  tensor(1.1909e-11, grad_fn=<DivBackward0>)\n",
            "96686 : avg_loss:  tensor(1.1908e-11, grad_fn=<DivBackward0>)\n",
            "96687 : avg_loss:  tensor(1.1908e-11, grad_fn=<DivBackward0>)\n",
            "96688 : avg_loss:  tensor(1.1908e-11, grad_fn=<DivBackward0>)\n",
            "96689 : avg_loss:  tensor(1.1908e-11, grad_fn=<DivBackward0>)\n",
            "96690 : avg_loss:  tensor(1.1908e-11, grad_fn=<DivBackward0>)\n",
            "96691 : avg_loss:  tensor(1.1908e-11, grad_fn=<DivBackward0>)\n",
            "96692 : avg_loss:  tensor(1.1907e-11, grad_fn=<DivBackward0>)\n",
            "96693 : avg_loss:  tensor(1.1907e-11, grad_fn=<DivBackward0>)\n",
            "96694 : avg_loss:  tensor(1.1907e-11, grad_fn=<DivBackward0>)\n",
            "96695 : avg_loss:  tensor(1.1907e-11, grad_fn=<DivBackward0>)\n",
            "96696 : avg_loss:  tensor(1.1907e-11, grad_fn=<DivBackward0>)\n",
            "96697 : avg_loss:  tensor(1.1907e-11, grad_fn=<DivBackward0>)\n",
            "96698 : avg_loss:  tensor(1.1907e-11, grad_fn=<DivBackward0>)\n",
            "96699 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96700 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96701 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96702 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96703 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96704 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96705 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96706 : avg_loss:  tensor(1.1905e-11, grad_fn=<DivBackward0>)\n",
            "96707 : avg_loss:  tensor(1.1906e-11, grad_fn=<DivBackward0>)\n",
            "96708 : avg_loss:  tensor(1.1905e-11, grad_fn=<DivBackward0>)\n",
            "96709 : avg_loss:  tensor(1.1905e-11, grad_fn=<DivBackward0>)\n",
            "96710 : avg_loss:  tensor(1.1905e-11, grad_fn=<DivBackward0>)\n",
            "96711 : avg_loss:  tensor(1.1905e-11, grad_fn=<DivBackward0>)\n",
            "96712 : avg_loss:  tensor(1.1905e-11, grad_fn=<DivBackward0>)\n",
            "96713 : avg_loss:  tensor(1.1905e-11, grad_fn=<DivBackward0>)\n",
            "96714 : avg_loss:  tensor(1.1904e-11, grad_fn=<DivBackward0>)\n",
            "96715 : avg_loss:  tensor(1.1904e-11, grad_fn=<DivBackward0>)\n",
            "96716 : avg_loss:  tensor(1.1904e-11, grad_fn=<DivBackward0>)\n",
            "96717 : avg_loss:  tensor(1.1904e-11, grad_fn=<DivBackward0>)\n",
            "96718 : avg_loss:  tensor(1.1904e-11, grad_fn=<DivBackward0>)\n",
            "96719 : avg_loss:  tensor(1.1904e-11, grad_fn=<DivBackward0>)\n",
            "96720 : avg_loss:  tensor(1.1904e-11, grad_fn=<DivBackward0>)\n",
            "96721 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96722 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96723 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96724 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96725 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96726 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96727 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96728 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96729 : avg_loss:  tensor(1.1903e-11, grad_fn=<DivBackward0>)\n",
            "96730 : avg_loss:  tensor(1.1902e-11, grad_fn=<DivBackward0>)\n",
            "96731 : avg_loss:  tensor(1.1902e-11, grad_fn=<DivBackward0>)\n",
            "96732 : avg_loss:  tensor(1.1902e-11, grad_fn=<DivBackward0>)\n",
            "96733 : avg_loss:  tensor(1.1902e-11, grad_fn=<DivBackward0>)\n",
            "96734 : avg_loss:  tensor(1.1902e-11, grad_fn=<DivBackward0>)\n",
            "96735 : avg_loss:  tensor(1.1902e-11, grad_fn=<DivBackward0>)\n",
            "96736 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96737 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96738 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96739 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96740 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96741 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96742 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96743 : avg_loss:  tensor(1.1901e-11, grad_fn=<DivBackward0>)\n",
            "96744 : avg_loss:  tensor(1.1900e-11, grad_fn=<DivBackward0>)\n",
            "96745 : avg_loss:  tensor(1.1900e-11, grad_fn=<DivBackward0>)\n",
            "96746 : avg_loss:  tensor(1.1900e-11, grad_fn=<DivBackward0>)\n",
            "96747 : avg_loss:  tensor(1.1900e-11, grad_fn=<DivBackward0>)\n",
            "96748 : avg_loss:  tensor(1.1900e-11, grad_fn=<DivBackward0>)\n",
            "96749 : avg_loss:  tensor(1.1900e-11, grad_fn=<DivBackward0>)\n",
            "96750 : avg_loss:  tensor(1.1900e-11, grad_fn=<DivBackward0>)\n",
            "96751 : avg_loss:  tensor(1.1899e-11, grad_fn=<DivBackward0>)\n",
            "96752 : avg_loss:  tensor(1.1899e-11, grad_fn=<DivBackward0>)\n",
            "96753 : avg_loss:  tensor(1.1899e-11, grad_fn=<DivBackward0>)\n",
            "96754 : avg_loss:  tensor(1.1899e-11, grad_fn=<DivBackward0>)\n",
            "96755 : avg_loss:  tensor(1.1899e-11, grad_fn=<DivBackward0>)\n",
            "96756 : avg_loss:  tensor(1.1899e-11, grad_fn=<DivBackward0>)\n",
            "96757 : avg_loss:  tensor(1.1899e-11, grad_fn=<DivBackward0>)\n",
            "96758 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96759 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96760 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96761 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96762 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96763 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96764 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96765 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96766 : avg_loss:  tensor(1.1898e-11, grad_fn=<DivBackward0>)\n",
            "96767 : avg_loss:  tensor(1.1897e-11, grad_fn=<DivBackward0>)\n",
            "96768 : avg_loss:  tensor(1.1897e-11, grad_fn=<DivBackward0>)\n",
            "96769 : avg_loss:  tensor(1.1897e-11, grad_fn=<DivBackward0>)\n",
            "96770 : avg_loss:  tensor(1.1897e-11, grad_fn=<DivBackward0>)\n",
            "96771 : avg_loss:  tensor(1.1897e-11, grad_fn=<DivBackward0>)\n",
            "96772 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96773 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96774 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96775 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96776 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96777 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96778 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96779 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96780 : avg_loss:  tensor(1.1896e-11, grad_fn=<DivBackward0>)\n",
            "96781 : avg_loss:  tensor(1.1895e-11, grad_fn=<DivBackward0>)\n",
            "96782 : avg_loss:  tensor(1.1895e-11, grad_fn=<DivBackward0>)\n",
            "96783 : avg_loss:  tensor(1.1895e-11, grad_fn=<DivBackward0>)\n",
            "96784 : avg_loss:  tensor(1.1895e-11, grad_fn=<DivBackward0>)\n",
            "96785 : avg_loss:  tensor(1.1895e-11, grad_fn=<DivBackward0>)\n",
            "96786 : avg_loss:  tensor(1.1895e-11, grad_fn=<DivBackward0>)\n",
            "96787 : avg_loss:  tensor(1.1895e-11, grad_fn=<DivBackward0>)\n",
            "96788 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96789 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96790 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96791 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96792 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96793 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96794 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96795 : avg_loss:  tensor(1.1894e-11, grad_fn=<DivBackward0>)\n",
            "96796 : avg_loss:  tensor(1.1893e-11, grad_fn=<DivBackward0>)\n",
            "96797 : avg_loss:  tensor(1.1893e-11, grad_fn=<DivBackward0>)\n",
            "96798 : avg_loss:  tensor(1.1893e-11, grad_fn=<DivBackward0>)\n",
            "96799 : avg_loss:  tensor(1.1893e-11, grad_fn=<DivBackward0>)\n",
            "96800 : avg_loss:  tensor(1.1892e-11, grad_fn=<DivBackward0>)\n",
            "96801 : avg_loss:  tensor(1.1892e-11, grad_fn=<DivBackward0>)\n",
            "96802 : avg_loss:  tensor(1.1892e-11, grad_fn=<DivBackward0>)\n",
            "96803 : avg_loss:  tensor(1.1892e-11, grad_fn=<DivBackward0>)\n",
            "96804 : avg_loss:  tensor(1.1892e-11, grad_fn=<DivBackward0>)\n",
            "96805 : avg_loss:  tensor(1.1892e-11, grad_fn=<DivBackward0>)\n",
            "96806 : avg_loss:  tensor(1.1892e-11, grad_fn=<DivBackward0>)\n",
            "96807 : avg_loss:  tensor(1.1891e-11, grad_fn=<DivBackward0>)\n",
            "96808 : avg_loss:  tensor(1.1891e-11, grad_fn=<DivBackward0>)\n",
            "96809 : avg_loss:  tensor(1.1891e-11, grad_fn=<DivBackward0>)\n",
            "96810 : avg_loss:  tensor(1.1891e-11, grad_fn=<DivBackward0>)\n",
            "96811 : avg_loss:  tensor(1.1891e-11, grad_fn=<DivBackward0>)\n",
            "96812 : avg_loss:  tensor(1.1891e-11, grad_fn=<DivBackward0>)\n",
            "96813 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96814 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96815 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96816 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96817 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96818 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96819 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96820 : avg_loss:  tensor(1.1889e-11, grad_fn=<DivBackward0>)\n",
            "96821 : avg_loss:  tensor(1.1890e-11, grad_fn=<DivBackward0>)\n",
            "96822 : avg_loss:  tensor(1.1889e-11, grad_fn=<DivBackward0>)\n",
            "96823 : avg_loss:  tensor(1.1889e-11, grad_fn=<DivBackward0>)\n",
            "96824 : avg_loss:  tensor(1.1889e-11, grad_fn=<DivBackward0>)\n",
            "96825 : avg_loss:  tensor(1.1889e-11, grad_fn=<DivBackward0>)\n",
            "96826 : avg_loss:  tensor(1.1889e-11, grad_fn=<DivBackward0>)\n",
            "96827 : avg_loss:  tensor(1.1889e-11, grad_fn=<DivBackward0>)\n",
            "96828 : avg_loss:  tensor(1.1888e-11, grad_fn=<DivBackward0>)\n",
            "96829 : avg_loss:  tensor(1.1888e-11, grad_fn=<DivBackward0>)\n",
            "96830 : avg_loss:  tensor(1.1888e-11, grad_fn=<DivBackward0>)\n",
            "96831 : avg_loss:  tensor(1.1888e-11, grad_fn=<DivBackward0>)\n",
            "96832 : avg_loss:  tensor(1.1888e-11, grad_fn=<DivBackward0>)\n",
            "96833 : avg_loss:  tensor(1.1888e-11, grad_fn=<DivBackward0>)\n",
            "96834 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96835 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96836 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96837 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96838 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96839 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96840 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96841 : avg_loss:  tensor(1.1887e-11, grad_fn=<DivBackward0>)\n",
            "96842 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96843 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96844 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96845 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96846 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96847 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96848 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96849 : avg_loss:  tensor(1.1886e-11, grad_fn=<DivBackward0>)\n",
            "96850 : avg_loss:  tensor(1.1885e-11, grad_fn=<DivBackward0>)\n",
            "96851 : avg_loss:  tensor(1.1885e-11, grad_fn=<DivBackward0>)\n",
            "96852 : avg_loss:  tensor(1.1885e-11, grad_fn=<DivBackward0>)\n",
            "96853 : avg_loss:  tensor(1.1885e-11, grad_fn=<DivBackward0>)\n",
            "96854 : avg_loss:  tensor(1.1885e-11, grad_fn=<DivBackward0>)\n",
            "96855 : avg_loss:  tensor(1.1885e-11, grad_fn=<DivBackward0>)\n",
            "96856 : avg_loss:  tensor(1.1884e-11, grad_fn=<DivBackward0>)\n",
            "96857 : avg_loss:  tensor(1.1884e-11, grad_fn=<DivBackward0>)\n",
            "96858 : avg_loss:  tensor(1.1884e-11, grad_fn=<DivBackward0>)\n",
            "96859 : avg_loss:  tensor(1.1884e-11, grad_fn=<DivBackward0>)\n",
            "96860 : avg_loss:  tensor(1.1884e-11, grad_fn=<DivBackward0>)\n",
            "96861 : avg_loss:  tensor(1.1884e-11, grad_fn=<DivBackward0>)\n",
            "96862 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96863 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96864 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96865 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96866 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96867 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96868 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96869 : avg_loss:  tensor(1.1883e-11, grad_fn=<DivBackward0>)\n",
            "96870 : avg_loss:  tensor(1.1882e-11, grad_fn=<DivBackward0>)\n",
            "96871 : avg_loss:  tensor(1.1882e-11, grad_fn=<DivBackward0>)\n",
            "96872 : avg_loss:  tensor(1.1882e-11, grad_fn=<DivBackward0>)\n",
            "96873 : avg_loss:  tensor(1.1882e-11, grad_fn=<DivBackward0>)\n",
            "96874 : avg_loss:  tensor(1.1882e-11, grad_fn=<DivBackward0>)\n",
            "96875 : avg_loss:  tensor(1.1882e-11, grad_fn=<DivBackward0>)\n",
            "96876 : avg_loss:  tensor(1.1882e-11, grad_fn=<DivBackward0>)\n",
            "96877 : avg_loss:  tensor(1.1881e-11, grad_fn=<DivBackward0>)\n",
            "96878 : avg_loss:  tensor(1.1881e-11, grad_fn=<DivBackward0>)\n",
            "96879 : avg_loss:  tensor(1.1881e-11, grad_fn=<DivBackward0>)\n",
            "96880 : avg_loss:  tensor(1.1881e-11, grad_fn=<DivBackward0>)\n",
            "96881 : avg_loss:  tensor(1.1881e-11, grad_fn=<DivBackward0>)\n",
            "96882 : avg_loss:  tensor(1.1881e-11, grad_fn=<DivBackward0>)\n",
            "96883 : avg_loss:  tensor(1.1880e-11, grad_fn=<DivBackward0>)\n",
            "96884 : avg_loss:  tensor(1.1880e-11, grad_fn=<DivBackward0>)\n",
            "96885 : avg_loss:  tensor(1.1880e-11, grad_fn=<DivBackward0>)\n",
            "96886 : avg_loss:  tensor(1.1880e-11, grad_fn=<DivBackward0>)\n",
            "96887 : avg_loss:  tensor(1.1880e-11, grad_fn=<DivBackward0>)\n",
            "96888 : avg_loss:  tensor(1.1880e-11, grad_fn=<DivBackward0>)\n",
            "96889 : avg_loss:  tensor(1.1880e-11, grad_fn=<DivBackward0>)\n",
            "96890 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96891 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96892 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96893 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96894 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96895 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96896 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96897 : avg_loss:  tensor(1.1879e-11, grad_fn=<DivBackward0>)\n",
            "96898 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96899 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96900 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96901 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96902 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96903 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96904 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96905 : avg_loss:  tensor(1.1878e-11, grad_fn=<DivBackward0>)\n",
            "96906 : avg_loss:  tensor(1.1877e-11, grad_fn=<DivBackward0>)\n",
            "96907 : avg_loss:  tensor(1.1877e-11, grad_fn=<DivBackward0>)\n",
            "96908 : avg_loss:  tensor(1.1877e-11, grad_fn=<DivBackward0>)\n",
            "96909 : avg_loss:  tensor(1.1877e-11, grad_fn=<DivBackward0>)\n",
            "96910 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96911 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96912 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96913 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96914 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96915 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96916 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96917 : avg_loss:  tensor(1.1876e-11, grad_fn=<DivBackward0>)\n",
            "96918 : avg_loss:  tensor(1.1875e-11, grad_fn=<DivBackward0>)\n",
            "96919 : avg_loss:  tensor(1.1875e-11, grad_fn=<DivBackward0>)\n",
            "96920 : avg_loss:  tensor(1.1875e-11, grad_fn=<DivBackward0>)\n",
            "96921 : avg_loss:  tensor(1.1875e-11, grad_fn=<DivBackward0>)\n",
            "96922 : avg_loss:  tensor(1.1875e-11, grad_fn=<DivBackward0>)\n",
            "96923 : avg_loss:  tensor(1.1875e-11, grad_fn=<DivBackward0>)\n",
            "96924 : avg_loss:  tensor(1.1875e-11, grad_fn=<DivBackward0>)\n",
            "96925 : avg_loss:  tensor(1.1874e-11, grad_fn=<DivBackward0>)\n",
            "96926 : avg_loss:  tensor(1.1874e-11, grad_fn=<DivBackward0>)\n",
            "96927 : avg_loss:  tensor(1.1874e-11, grad_fn=<DivBackward0>)\n",
            "96928 : avg_loss:  tensor(1.1874e-11, grad_fn=<DivBackward0>)\n",
            "96929 : avg_loss:  tensor(1.1874e-11, grad_fn=<DivBackward0>)\n",
            "96930 : avg_loss:  tensor(1.1874e-11, grad_fn=<DivBackward0>)\n",
            "96931 : avg_loss:  tensor(1.1874e-11, grad_fn=<DivBackward0>)\n",
            "96932 : avg_loss:  tensor(1.1873e-11, grad_fn=<DivBackward0>)\n",
            "96933 : avg_loss:  tensor(1.1873e-11, grad_fn=<DivBackward0>)\n",
            "96934 : avg_loss:  tensor(1.1873e-11, grad_fn=<DivBackward0>)\n",
            "96935 : avg_loss:  tensor(1.1873e-11, grad_fn=<DivBackward0>)\n",
            "96936 : avg_loss:  tensor(1.1873e-11, grad_fn=<DivBackward0>)\n",
            "96937 : avg_loss:  tensor(1.1873e-11, grad_fn=<DivBackward0>)\n",
            "96938 : avg_loss:  tensor(1.1872e-11, grad_fn=<DivBackward0>)\n",
            "96939 : avg_loss:  tensor(1.1872e-11, grad_fn=<DivBackward0>)\n",
            "96940 : avg_loss:  tensor(1.1872e-11, grad_fn=<DivBackward0>)\n",
            "96941 : avg_loss:  tensor(1.1872e-11, grad_fn=<DivBackward0>)\n",
            "96942 : avg_loss:  tensor(1.1872e-11, grad_fn=<DivBackward0>)\n",
            "96943 : avg_loss:  tensor(1.1872e-11, grad_fn=<DivBackward0>)\n",
            "96944 : avg_loss:  tensor(1.1872e-11, grad_fn=<DivBackward0>)\n",
            "96945 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96946 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96947 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96948 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96949 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96950 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96951 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96952 : avg_loss:  tensor(1.1871e-11, grad_fn=<DivBackward0>)\n",
            "96953 : avg_loss:  tensor(1.1870e-11, grad_fn=<DivBackward0>)\n",
            "96954 : avg_loss:  tensor(1.1870e-11, grad_fn=<DivBackward0>)\n",
            "96955 : avg_loss:  tensor(1.1870e-11, grad_fn=<DivBackward0>)\n",
            "96956 : avg_loss:  tensor(1.1869e-11, grad_fn=<DivBackward0>)\n",
            "96957 : avg_loss:  tensor(1.1869e-11, grad_fn=<DivBackward0>)\n",
            "96958 : avg_loss:  tensor(1.1869e-11, grad_fn=<DivBackward0>)\n",
            "96959 : avg_loss:  tensor(1.1869e-11, grad_fn=<DivBackward0>)\n",
            "96960 : avg_loss:  tensor(1.1869e-11, grad_fn=<DivBackward0>)\n",
            "96961 : avg_loss:  tensor(1.1869e-11, grad_fn=<DivBackward0>)\n",
            "96962 : avg_loss:  tensor(1.1869e-11, grad_fn=<DivBackward0>)\n",
            "96963 : avg_loss:  tensor(1.1868e-11, grad_fn=<DivBackward0>)\n",
            "96964 : avg_loss:  tensor(1.1868e-11, grad_fn=<DivBackward0>)\n",
            "96965 : avg_loss:  tensor(1.1868e-11, grad_fn=<DivBackward0>)\n",
            "96966 : avg_loss:  tensor(1.1868e-11, grad_fn=<DivBackward0>)\n",
            "96967 : avg_loss:  tensor(1.1868e-11, grad_fn=<DivBackward0>)\n",
            "96968 : avg_loss:  tensor(1.1868e-11, grad_fn=<DivBackward0>)\n",
            "96969 : avg_loss:  tensor(1.1867e-11, grad_fn=<DivBackward0>)\n",
            "96970 : avg_loss:  tensor(1.1867e-11, grad_fn=<DivBackward0>)\n",
            "96971 : avg_loss:  tensor(1.1867e-11, grad_fn=<DivBackward0>)\n",
            "96972 : avg_loss:  tensor(1.1867e-11, grad_fn=<DivBackward0>)\n",
            "96973 : avg_loss:  tensor(1.1867e-11, grad_fn=<DivBackward0>)\n",
            "96974 : avg_loss:  tensor(1.1867e-11, grad_fn=<DivBackward0>)\n",
            "96975 : avg_loss:  tensor(1.1867e-11, grad_fn=<DivBackward0>)\n",
            "96976 : avg_loss:  tensor(1.1866e-11, grad_fn=<DivBackward0>)\n",
            "96977 : avg_loss:  tensor(1.1866e-11, grad_fn=<DivBackward0>)\n",
            "96978 : avg_loss:  tensor(1.1866e-11, grad_fn=<DivBackward0>)\n",
            "96979 : avg_loss:  tensor(1.1866e-11, grad_fn=<DivBackward0>)\n",
            "96980 : avg_loss:  tensor(1.1866e-11, grad_fn=<DivBackward0>)\n",
            "96981 : avg_loss:  tensor(1.1866e-11, grad_fn=<DivBackward0>)\n",
            "96982 : avg_loss:  tensor(1.1865e-11, grad_fn=<DivBackward0>)\n",
            "96983 : avg_loss:  tensor(1.1865e-11, grad_fn=<DivBackward0>)\n",
            "96984 : avg_loss:  tensor(1.1865e-11, grad_fn=<DivBackward0>)\n",
            "96985 : avg_loss:  tensor(1.1865e-11, grad_fn=<DivBackward0>)\n",
            "96986 : avg_loss:  tensor(1.1865e-11, grad_fn=<DivBackward0>)\n",
            "96987 : avg_loss:  tensor(1.1865e-11, grad_fn=<DivBackward0>)\n",
            "96988 : avg_loss:  tensor(1.1864e-11, grad_fn=<DivBackward0>)\n",
            "96989 : avg_loss:  tensor(1.1864e-11, grad_fn=<DivBackward0>)\n",
            "96990 : avg_loss:  tensor(1.1864e-11, grad_fn=<DivBackward0>)\n",
            "96991 : avg_loss:  tensor(1.1864e-11, grad_fn=<DivBackward0>)\n",
            "96992 : avg_loss:  tensor(1.1864e-11, grad_fn=<DivBackward0>)\n",
            "96993 : avg_loss:  tensor(1.1864e-11, grad_fn=<DivBackward0>)\n",
            "96994 : avg_loss:  tensor(1.1864e-11, grad_fn=<DivBackward0>)\n",
            "96995 : avg_loss:  tensor(1.1863e-11, grad_fn=<DivBackward0>)\n",
            "96996 : avg_loss:  tensor(1.1863e-11, grad_fn=<DivBackward0>)\n",
            "96997 : avg_loss:  tensor(1.1863e-11, grad_fn=<DivBackward0>)\n",
            "96998 : avg_loss:  tensor(1.1863e-11, grad_fn=<DivBackward0>)\n",
            "96999 : avg_loss:  tensor(1.1863e-11, grad_fn=<DivBackward0>)\n",
            "97000 : avg_loss:  tensor(1.1863e-11, grad_fn=<DivBackward0>)\n",
            "97001 : avg_loss:  tensor(1.1863e-11, grad_fn=<DivBackward0>)\n",
            "97002 : avg_loss:  tensor(1.1862e-11, grad_fn=<DivBackward0>)\n",
            "97003 : avg_loss:  tensor(1.1862e-11, grad_fn=<DivBackward0>)\n",
            "97004 : avg_loss:  tensor(1.1862e-11, grad_fn=<DivBackward0>)\n",
            "97005 : avg_loss:  tensor(1.1862e-11, grad_fn=<DivBackward0>)\n",
            "97006 : avg_loss:  tensor(1.1862e-11, grad_fn=<DivBackward0>)\n",
            "97007 : avg_loss:  tensor(1.1862e-11, grad_fn=<DivBackward0>)\n",
            "97008 : avg_loss:  tensor(1.1862e-11, grad_fn=<DivBackward0>)\n",
            "97009 : avg_loss:  tensor(1.1861e-11, grad_fn=<DivBackward0>)\n",
            "97010 : avg_loss:  tensor(1.1861e-11, grad_fn=<DivBackward0>)\n",
            "97011 : avg_loss:  tensor(1.1861e-11, grad_fn=<DivBackward0>)\n",
            "97012 : avg_loss:  tensor(1.1861e-11, grad_fn=<DivBackward0>)\n",
            "97013 : avg_loss:  tensor(1.1860e-11, grad_fn=<DivBackward0>)\n",
            "97014 : avg_loss:  tensor(1.1860e-11, grad_fn=<DivBackward0>)\n",
            "97015 : avg_loss:  tensor(1.1860e-11, grad_fn=<DivBackward0>)\n",
            "97016 : avg_loss:  tensor(1.1860e-11, grad_fn=<DivBackward0>)\n",
            "97017 : avg_loss:  tensor(1.1860e-11, grad_fn=<DivBackward0>)\n",
            "97018 : avg_loss:  tensor(1.1860e-11, grad_fn=<DivBackward0>)\n",
            "97019 : avg_loss:  tensor(1.1860e-11, grad_fn=<DivBackward0>)\n",
            "97020 : avg_loss:  tensor(1.1859e-11, grad_fn=<DivBackward0>)\n",
            "97021 : avg_loss:  tensor(1.1859e-11, grad_fn=<DivBackward0>)\n",
            "97022 : avg_loss:  tensor(1.1859e-11, grad_fn=<DivBackward0>)\n",
            "97023 : avg_loss:  tensor(1.1859e-11, grad_fn=<DivBackward0>)\n",
            "97024 : avg_loss:  tensor(1.1859e-11, grad_fn=<DivBackward0>)\n",
            "97025 : avg_loss:  tensor(1.1859e-11, grad_fn=<DivBackward0>)\n",
            "97026 : avg_loss:  tensor(1.1858e-11, grad_fn=<DivBackward0>)\n",
            "97027 : avg_loss:  tensor(1.1858e-11, grad_fn=<DivBackward0>)\n",
            "97028 : avg_loss:  tensor(1.1858e-11, grad_fn=<DivBackward0>)\n",
            "97029 : avg_loss:  tensor(1.1858e-11, grad_fn=<DivBackward0>)\n",
            "97030 : avg_loss:  tensor(1.1858e-11, grad_fn=<DivBackward0>)\n",
            "97031 : avg_loss:  tensor(1.1858e-11, grad_fn=<DivBackward0>)\n",
            "97032 : avg_loss:  tensor(1.1858e-11, grad_fn=<DivBackward0>)\n",
            "97033 : avg_loss:  tensor(1.1857e-11, grad_fn=<DivBackward0>)\n",
            "97034 : avg_loss:  tensor(1.1857e-11, grad_fn=<DivBackward0>)\n",
            "97035 : avg_loss:  tensor(1.1857e-11, grad_fn=<DivBackward0>)\n",
            "97036 : avg_loss:  tensor(1.1857e-11, grad_fn=<DivBackward0>)\n",
            "97037 : avg_loss:  tensor(1.1857e-11, grad_fn=<DivBackward0>)\n",
            "97038 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97039 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97040 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97041 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97042 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97043 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97044 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97045 : avg_loss:  tensor(1.1856e-11, grad_fn=<DivBackward0>)\n",
            "97046 : avg_loss:  tensor(1.1855e-11, grad_fn=<DivBackward0>)\n",
            "97047 : avg_loss:  tensor(1.1855e-11, grad_fn=<DivBackward0>)\n",
            "97048 : avg_loss:  tensor(1.1855e-11, grad_fn=<DivBackward0>)\n",
            "97049 : avg_loss:  tensor(1.1855e-11, grad_fn=<DivBackward0>)\n",
            "97050 : avg_loss:  tensor(1.1855e-11, grad_fn=<DivBackward0>)\n",
            "97051 : avg_loss:  tensor(1.1855e-11, grad_fn=<DivBackward0>)\n",
            "97052 : avg_loss:  tensor(1.1854e-11, grad_fn=<DivBackward0>)\n",
            "97053 : avg_loss:  tensor(1.1854e-11, grad_fn=<DivBackward0>)\n",
            "97054 : avg_loss:  tensor(1.1854e-11, grad_fn=<DivBackward0>)\n",
            "97055 : avg_loss:  tensor(1.1854e-11, grad_fn=<DivBackward0>)\n",
            "97056 : avg_loss:  tensor(1.1854e-11, grad_fn=<DivBackward0>)\n",
            "97057 : avg_loss:  tensor(1.1853e-11, grad_fn=<DivBackward0>)\n",
            "97058 : avg_loss:  tensor(1.1853e-11, grad_fn=<DivBackward0>)\n",
            "97059 : avg_loss:  tensor(1.1853e-11, grad_fn=<DivBackward0>)\n",
            "97060 : avg_loss:  tensor(1.1853e-11, grad_fn=<DivBackward0>)\n",
            "97061 : avg_loss:  tensor(1.1853e-11, grad_fn=<DivBackward0>)\n",
            "97062 : avg_loss:  tensor(1.1853e-11, grad_fn=<DivBackward0>)\n",
            "97063 : avg_loss:  tensor(1.1852e-11, grad_fn=<DivBackward0>)\n",
            "97064 : avg_loss:  tensor(1.1852e-11, grad_fn=<DivBackward0>)\n",
            "97065 : avg_loss:  tensor(1.1852e-11, grad_fn=<DivBackward0>)\n",
            "97066 : avg_loss:  tensor(1.1852e-11, grad_fn=<DivBackward0>)\n",
            "97067 : avg_loss:  tensor(1.1852e-11, grad_fn=<DivBackward0>)\n",
            "97068 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97069 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97070 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97071 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97072 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97073 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97074 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97075 : avg_loss:  tensor(1.1851e-11, grad_fn=<DivBackward0>)\n",
            "97076 : avg_loss:  tensor(1.1850e-11, grad_fn=<DivBackward0>)\n",
            "97077 : avg_loss:  tensor(1.1850e-11, grad_fn=<DivBackward0>)\n",
            "97078 : avg_loss:  tensor(1.1850e-11, grad_fn=<DivBackward0>)\n",
            "97079 : avg_loss:  tensor(1.1850e-11, grad_fn=<DivBackward0>)\n",
            "97080 : avg_loss:  tensor(1.1850e-11, grad_fn=<DivBackward0>)\n",
            "97081 : avg_loss:  tensor(1.1850e-11, grad_fn=<DivBackward0>)\n",
            "97082 : avg_loss:  tensor(1.1849e-11, grad_fn=<DivBackward0>)\n",
            "97083 : avg_loss:  tensor(1.1849e-11, grad_fn=<DivBackward0>)\n",
            "97084 : avg_loss:  tensor(1.1849e-11, grad_fn=<DivBackward0>)\n",
            "97085 : avg_loss:  tensor(1.1849e-11, grad_fn=<DivBackward0>)\n",
            "97086 : avg_loss:  tensor(1.1849e-11, grad_fn=<DivBackward0>)\n",
            "97087 : avg_loss:  tensor(1.1848e-11, grad_fn=<DivBackward0>)\n",
            "97088 : avg_loss:  tensor(1.1848e-11, grad_fn=<DivBackward0>)\n",
            "97089 : avg_loss:  tensor(1.1848e-11, grad_fn=<DivBackward0>)\n",
            "97090 : avg_loss:  tensor(1.1848e-11, grad_fn=<DivBackward0>)\n",
            "97091 : avg_loss:  tensor(1.1848e-11, grad_fn=<DivBackward0>)\n",
            "97092 : avg_loss:  tensor(1.1847e-11, grad_fn=<DivBackward0>)\n",
            "97093 : avg_loss:  tensor(1.1847e-11, grad_fn=<DivBackward0>)\n",
            "97094 : avg_loss:  tensor(1.1847e-11, grad_fn=<DivBackward0>)\n",
            "97095 : avg_loss:  tensor(1.1847e-11, grad_fn=<DivBackward0>)\n",
            "97096 : avg_loss:  tensor(1.1847e-11, grad_fn=<DivBackward0>)\n",
            "97097 : avg_loss:  tensor(1.1847e-11, grad_fn=<DivBackward0>)\n",
            "97098 : avg_loss:  tensor(1.1847e-11, grad_fn=<DivBackward0>)\n",
            "97099 : avg_loss:  tensor(1.1846e-11, grad_fn=<DivBackward0>)\n",
            "97100 : avg_loss:  tensor(1.1846e-11, grad_fn=<DivBackward0>)\n",
            "97101 : avg_loss:  tensor(1.1846e-11, grad_fn=<DivBackward0>)\n",
            "97102 : avg_loss:  tensor(1.1846e-11, grad_fn=<DivBackward0>)\n",
            "97103 : avg_loss:  tensor(1.1846e-11, grad_fn=<DivBackward0>)\n",
            "97104 : avg_loss:  tensor(1.1846e-11, grad_fn=<DivBackward0>)\n",
            "97105 : avg_loss:  tensor(1.1845e-11, grad_fn=<DivBackward0>)\n",
            "97106 : avg_loss:  tensor(1.1845e-11, grad_fn=<DivBackward0>)\n",
            "97107 : avg_loss:  tensor(1.1845e-11, grad_fn=<DivBackward0>)\n",
            "97108 : avg_loss:  tensor(1.1845e-11, grad_fn=<DivBackward0>)\n",
            "97109 : avg_loss:  tensor(1.1845e-11, grad_fn=<DivBackward0>)\n",
            "97110 : avg_loss:  tensor(1.1844e-11, grad_fn=<DivBackward0>)\n",
            "97111 : avg_loss:  tensor(1.1844e-11, grad_fn=<DivBackward0>)\n",
            "97112 : avg_loss:  tensor(1.1844e-11, grad_fn=<DivBackward0>)\n",
            "97113 : avg_loss:  tensor(1.1844e-11, grad_fn=<DivBackward0>)\n",
            "97114 : avg_loss:  tensor(1.1844e-11, grad_fn=<DivBackward0>)\n",
            "97115 : avg_loss:  tensor(1.1844e-11, grad_fn=<DivBackward0>)\n",
            "97116 : avg_loss:  tensor(1.1843e-11, grad_fn=<DivBackward0>)\n",
            "97117 : avg_loss:  tensor(1.1843e-11, grad_fn=<DivBackward0>)\n",
            "97118 : avg_loss:  tensor(1.1843e-11, grad_fn=<DivBackward0>)\n",
            "97119 : avg_loss:  tensor(1.1843e-11, grad_fn=<DivBackward0>)\n",
            "97120 : avg_loss:  tensor(1.1843e-11, grad_fn=<DivBackward0>)\n",
            "97121 : avg_loss:  tensor(1.1843e-11, grad_fn=<DivBackward0>)\n",
            "97122 : avg_loss:  tensor(1.1843e-11, grad_fn=<DivBackward0>)\n",
            "97123 : avg_loss:  tensor(1.1842e-11, grad_fn=<DivBackward0>)\n",
            "97124 : avg_loss:  tensor(1.1842e-11, grad_fn=<DivBackward0>)\n",
            "97125 : avg_loss:  tensor(1.1842e-11, grad_fn=<DivBackward0>)\n",
            "97126 : avg_loss:  tensor(1.1842e-11, grad_fn=<DivBackward0>)\n",
            "97127 : avg_loss:  tensor(1.1842e-11, grad_fn=<DivBackward0>)\n",
            "97128 : avg_loss:  tensor(1.1841e-11, grad_fn=<DivBackward0>)\n",
            "97129 : avg_loss:  tensor(1.1841e-11, grad_fn=<DivBackward0>)\n",
            "97130 : avg_loss:  tensor(1.1841e-11, grad_fn=<DivBackward0>)\n",
            "97131 : avg_loss:  tensor(1.1841e-11, grad_fn=<DivBackward0>)\n",
            "97132 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97133 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97134 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97135 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97136 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97137 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97138 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97139 : avg_loss:  tensor(1.1840e-11, grad_fn=<DivBackward0>)\n",
            "97140 : avg_loss:  tensor(1.1839e-11, grad_fn=<DivBackward0>)\n",
            "97141 : avg_loss:  tensor(1.1839e-11, grad_fn=<DivBackward0>)\n",
            "97142 : avg_loss:  tensor(1.1839e-11, grad_fn=<DivBackward0>)\n",
            "97143 : avg_loss:  tensor(1.1839e-11, grad_fn=<DivBackward0>)\n",
            "97144 : avg_loss:  tensor(1.1839e-11, grad_fn=<DivBackward0>)\n",
            "97145 : avg_loss:  tensor(1.1838e-11, grad_fn=<DivBackward0>)\n",
            "97146 : avg_loss:  tensor(1.1838e-11, grad_fn=<DivBackward0>)\n",
            "97147 : avg_loss:  tensor(1.1838e-11, grad_fn=<DivBackward0>)\n",
            "97148 : avg_loss:  tensor(1.1838e-11, grad_fn=<DivBackward0>)\n",
            "97149 : avg_loss:  tensor(1.1838e-11, grad_fn=<DivBackward0>)\n",
            "97150 : avg_loss:  tensor(1.1838e-11, grad_fn=<DivBackward0>)\n",
            "97151 : avg_loss:  tensor(1.1838e-11, grad_fn=<DivBackward0>)\n",
            "97152 : avg_loss:  tensor(1.1837e-11, grad_fn=<DivBackward0>)\n",
            "97153 : avg_loss:  tensor(1.1837e-11, grad_fn=<DivBackward0>)\n",
            "97154 : avg_loss:  tensor(1.1837e-11, grad_fn=<DivBackward0>)\n",
            "97155 : avg_loss:  tensor(1.1837e-11, grad_fn=<DivBackward0>)\n",
            "97156 : avg_loss:  tensor(1.1836e-11, grad_fn=<DivBackward0>)\n",
            "97157 : avg_loss:  tensor(1.1837e-11, grad_fn=<DivBackward0>)\n",
            "97158 : avg_loss:  tensor(1.1836e-11, grad_fn=<DivBackward0>)\n",
            "97159 : avg_loss:  tensor(1.1836e-11, grad_fn=<DivBackward0>)\n",
            "97160 : avg_loss:  tensor(1.1836e-11, grad_fn=<DivBackward0>)\n",
            "97161 : avg_loss:  tensor(1.1836e-11, grad_fn=<DivBackward0>)\n",
            "97162 : avg_loss:  tensor(1.1836e-11, grad_fn=<DivBackward0>)\n",
            "97163 : avg_loss:  tensor(1.1835e-11, grad_fn=<DivBackward0>)\n",
            "97164 : avg_loss:  tensor(1.1835e-11, grad_fn=<DivBackward0>)\n",
            "97165 : avg_loss:  tensor(1.1835e-11, grad_fn=<DivBackward0>)\n",
            "97166 : avg_loss:  tensor(1.1835e-11, grad_fn=<DivBackward0>)\n",
            "97167 : avg_loss:  tensor(1.1835e-11, grad_fn=<DivBackward0>)\n",
            "97168 : avg_loss:  tensor(1.1835e-11, grad_fn=<DivBackward0>)\n",
            "97169 : avg_loss:  tensor(1.1835e-11, grad_fn=<DivBackward0>)\n",
            "97170 : avg_loss:  tensor(1.1834e-11, grad_fn=<DivBackward0>)\n",
            "97171 : avg_loss:  tensor(1.1834e-11, grad_fn=<DivBackward0>)\n",
            "97172 : avg_loss:  tensor(1.1834e-11, grad_fn=<DivBackward0>)\n",
            "97173 : avg_loss:  tensor(1.1834e-11, grad_fn=<DivBackward0>)\n",
            "97174 : avg_loss:  tensor(1.1834e-11, grad_fn=<DivBackward0>)\n",
            "97175 : avg_loss:  tensor(1.1833e-11, grad_fn=<DivBackward0>)\n",
            "97176 : avg_loss:  tensor(1.1833e-11, grad_fn=<DivBackward0>)\n",
            "97177 : avg_loss:  tensor(1.1833e-11, grad_fn=<DivBackward0>)\n",
            "97178 : avg_loss:  tensor(1.1833e-11, grad_fn=<DivBackward0>)\n",
            "97179 : avg_loss:  tensor(1.1833e-11, grad_fn=<DivBackward0>)\n",
            "97180 : avg_loss:  tensor(1.1832e-11, grad_fn=<DivBackward0>)\n",
            "97181 : avg_loss:  tensor(1.1832e-11, grad_fn=<DivBackward0>)\n",
            "97182 : avg_loss:  tensor(1.1832e-11, grad_fn=<DivBackward0>)\n",
            "97183 : avg_loss:  tensor(1.1832e-11, grad_fn=<DivBackward0>)\n",
            "97184 : avg_loss:  tensor(1.1832e-11, grad_fn=<DivBackward0>)\n",
            "97185 : avg_loss:  tensor(1.1832e-11, grad_fn=<DivBackward0>)\n",
            "97186 : avg_loss:  tensor(1.1832e-11, grad_fn=<DivBackward0>)\n",
            "97187 : avg_loss:  tensor(1.1831e-11, grad_fn=<DivBackward0>)\n",
            "97188 : avg_loss:  tensor(1.1831e-11, grad_fn=<DivBackward0>)\n",
            "97189 : avg_loss:  tensor(1.1831e-11, grad_fn=<DivBackward0>)\n",
            "97190 : avg_loss:  tensor(1.1831e-11, grad_fn=<DivBackward0>)\n",
            "97191 : avg_loss:  tensor(1.1831e-11, grad_fn=<DivBackward0>)\n",
            "97192 : avg_loss:  tensor(1.1831e-11, grad_fn=<DivBackward0>)\n",
            "97193 : avg_loss:  tensor(1.1831e-11, grad_fn=<DivBackward0>)\n",
            "97194 : avg_loss:  tensor(1.1830e-11, grad_fn=<DivBackward0>)\n",
            "97195 : avg_loss:  tensor(1.1830e-11, grad_fn=<DivBackward0>)\n",
            "97196 : avg_loss:  tensor(1.1830e-11, grad_fn=<DivBackward0>)\n",
            "97197 : avg_loss:  tensor(1.1830e-11, grad_fn=<DivBackward0>)\n",
            "97198 : avg_loss:  tensor(1.1829e-11, grad_fn=<DivBackward0>)\n",
            "97199 : avg_loss:  tensor(1.1829e-11, grad_fn=<DivBackward0>)\n",
            "97200 : avg_loss:  tensor(1.1829e-11, grad_fn=<DivBackward0>)\n",
            "97201 : avg_loss:  tensor(1.1829e-11, grad_fn=<DivBackward0>)\n",
            "97202 : avg_loss:  tensor(1.1829e-11, grad_fn=<DivBackward0>)\n",
            "97203 : avg_loss:  tensor(1.1829e-11, grad_fn=<DivBackward0>)\n",
            "97204 : avg_loss:  tensor(1.1828e-11, grad_fn=<DivBackward0>)\n",
            "97205 : avg_loss:  tensor(1.1828e-11, grad_fn=<DivBackward0>)\n",
            "97206 : avg_loss:  tensor(1.1828e-11, grad_fn=<DivBackward0>)\n",
            "97207 : avg_loss:  tensor(1.1828e-11, grad_fn=<DivBackward0>)\n",
            "97208 : avg_loss:  tensor(1.1828e-11, grad_fn=<DivBackward0>)\n",
            "97209 : avg_loss:  tensor(1.1828e-11, grad_fn=<DivBackward0>)\n",
            "97210 : avg_loss:  tensor(1.1828e-11, grad_fn=<DivBackward0>)\n",
            "97211 : avg_loss:  tensor(1.1827e-11, grad_fn=<DivBackward0>)\n",
            "97212 : avg_loss:  tensor(1.1827e-11, grad_fn=<DivBackward0>)\n",
            "97213 : avg_loss:  tensor(1.1827e-11, grad_fn=<DivBackward0>)\n",
            "97214 : avg_loss:  tensor(1.1827e-11, grad_fn=<DivBackward0>)\n",
            "97215 : avg_loss:  tensor(1.1826e-11, grad_fn=<DivBackward0>)\n",
            "97216 : avg_loss:  tensor(1.1826e-11, grad_fn=<DivBackward0>)\n",
            "97217 : avg_loss:  tensor(1.1826e-11, grad_fn=<DivBackward0>)\n",
            "97218 : avg_loss:  tensor(1.1826e-11, grad_fn=<DivBackward0>)\n",
            "97219 : avg_loss:  tensor(1.1826e-11, grad_fn=<DivBackward0>)\n",
            "97220 : avg_loss:  tensor(1.1826e-11, grad_fn=<DivBackward0>)\n",
            "97221 : avg_loss:  tensor(1.1825e-11, grad_fn=<DivBackward0>)\n",
            "97222 : avg_loss:  tensor(1.1825e-11, grad_fn=<DivBackward0>)\n",
            "97223 : avg_loss:  tensor(1.1825e-11, grad_fn=<DivBackward0>)\n",
            "97224 : avg_loss:  tensor(1.1825e-11, grad_fn=<DivBackward0>)\n",
            "97225 : avg_loss:  tensor(1.1825e-11, grad_fn=<DivBackward0>)\n",
            "97226 : avg_loss:  tensor(1.1824e-11, grad_fn=<DivBackward0>)\n",
            "97227 : avg_loss:  tensor(1.1824e-11, grad_fn=<DivBackward0>)\n",
            "97228 : avg_loss:  tensor(1.1824e-11, grad_fn=<DivBackward0>)\n",
            "97229 : avg_loss:  tensor(1.1824e-11, grad_fn=<DivBackward0>)\n",
            "97230 : avg_loss:  tensor(1.1824e-11, grad_fn=<DivBackward0>)\n",
            "97231 : avg_loss:  tensor(1.1824e-11, grad_fn=<DivBackward0>)\n",
            "97232 : avg_loss:  tensor(1.1823e-11, grad_fn=<DivBackward0>)\n",
            "97233 : avg_loss:  tensor(1.1823e-11, grad_fn=<DivBackward0>)\n",
            "97234 : avg_loss:  tensor(1.1823e-11, grad_fn=<DivBackward0>)\n",
            "97235 : avg_loss:  tensor(1.1823e-11, grad_fn=<DivBackward0>)\n",
            "97236 : avg_loss:  tensor(1.1823e-11, grad_fn=<DivBackward0>)\n",
            "97237 : avg_loss:  tensor(1.1823e-11, grad_fn=<DivBackward0>)\n",
            "97238 : avg_loss:  tensor(1.1822e-11, grad_fn=<DivBackward0>)\n",
            "97239 : avg_loss:  tensor(1.1822e-11, grad_fn=<DivBackward0>)\n",
            "97240 : avg_loss:  tensor(1.1822e-11, grad_fn=<DivBackward0>)\n",
            "97241 : avg_loss:  tensor(1.1822e-11, grad_fn=<DivBackward0>)\n",
            "97242 : avg_loss:  tensor(1.1822e-11, grad_fn=<DivBackward0>)\n",
            "97243 : avg_loss:  tensor(1.1821e-11, grad_fn=<DivBackward0>)\n",
            "97244 : avg_loss:  tensor(1.1821e-11, grad_fn=<DivBackward0>)\n",
            "97245 : avg_loss:  tensor(1.1821e-11, grad_fn=<DivBackward0>)\n",
            "97246 : avg_loss:  tensor(1.1821e-11, grad_fn=<DivBackward0>)\n",
            "97247 : avg_loss:  tensor(1.1821e-11, grad_fn=<DivBackward0>)\n",
            "97248 : avg_loss:  tensor(1.1821e-11, grad_fn=<DivBackward0>)\n",
            "97249 : avg_loss:  tensor(1.1820e-11, grad_fn=<DivBackward0>)\n",
            "97250 : avg_loss:  tensor(1.1820e-11, grad_fn=<DivBackward0>)\n",
            "97251 : avg_loss:  tensor(1.1820e-11, grad_fn=<DivBackward0>)\n",
            "97252 : avg_loss:  tensor(1.1820e-11, grad_fn=<DivBackward0>)\n",
            "97253 : avg_loss:  tensor(1.1820e-11, grad_fn=<DivBackward0>)\n",
            "97254 : avg_loss:  tensor(1.1820e-11, grad_fn=<DivBackward0>)\n",
            "97255 : avg_loss:  tensor(1.1819e-11, grad_fn=<DivBackward0>)\n",
            "97256 : avg_loss:  tensor(1.1819e-11, grad_fn=<DivBackward0>)\n",
            "97257 : avg_loss:  tensor(1.1819e-11, grad_fn=<DivBackward0>)\n",
            "97258 : avg_loss:  tensor(1.1819e-11, grad_fn=<DivBackward0>)\n",
            "97259 : avg_loss:  tensor(1.1819e-11, grad_fn=<DivBackward0>)\n",
            "97260 : avg_loss:  tensor(1.1819e-11, grad_fn=<DivBackward0>)\n",
            "97261 : avg_loss:  tensor(1.1818e-11, grad_fn=<DivBackward0>)\n",
            "97262 : avg_loss:  tensor(1.1818e-11, grad_fn=<DivBackward0>)\n",
            "97263 : avg_loss:  tensor(1.1818e-11, grad_fn=<DivBackward0>)\n",
            "97264 : avg_loss:  tensor(1.1818e-11, grad_fn=<DivBackward0>)\n",
            "97265 : avg_loss:  tensor(1.1818e-11, grad_fn=<DivBackward0>)\n",
            "97266 : avg_loss:  tensor(1.1817e-11, grad_fn=<DivBackward0>)\n",
            "97267 : avg_loss:  tensor(1.1817e-11, grad_fn=<DivBackward0>)\n",
            "97268 : avg_loss:  tensor(1.1817e-11, grad_fn=<DivBackward0>)\n",
            "97269 : avg_loss:  tensor(1.1817e-11, grad_fn=<DivBackward0>)\n",
            "97270 : avg_loss:  tensor(1.1817e-11, grad_fn=<DivBackward0>)\n",
            "97271 : avg_loss:  tensor(1.1816e-11, grad_fn=<DivBackward0>)\n",
            "97272 : avg_loss:  tensor(1.1816e-11, grad_fn=<DivBackward0>)\n",
            "97273 : avg_loss:  tensor(1.1816e-11, grad_fn=<DivBackward0>)\n",
            "97274 : avg_loss:  tensor(1.1816e-11, grad_fn=<DivBackward0>)\n",
            "97275 : avg_loss:  tensor(1.1816e-11, grad_fn=<DivBackward0>)\n",
            "97276 : avg_loss:  tensor(1.1816e-11, grad_fn=<DivBackward0>)\n",
            "97277 : avg_loss:  tensor(1.1815e-11, grad_fn=<DivBackward0>)\n",
            "97278 : avg_loss:  tensor(1.1815e-11, grad_fn=<DivBackward0>)\n",
            "97279 : avg_loss:  tensor(1.1815e-11, grad_fn=<DivBackward0>)\n",
            "97280 : avg_loss:  tensor(1.1815e-11, grad_fn=<DivBackward0>)\n",
            "97281 : avg_loss:  tensor(1.1815e-11, grad_fn=<DivBackward0>)\n",
            "97282 : avg_loss:  tensor(1.1815e-11, grad_fn=<DivBackward0>)\n",
            "97283 : avg_loss:  tensor(1.1814e-11, grad_fn=<DivBackward0>)\n",
            "97284 : avg_loss:  tensor(1.1814e-11, grad_fn=<DivBackward0>)\n",
            "97285 : avg_loss:  tensor(1.1814e-11, grad_fn=<DivBackward0>)\n",
            "97286 : avg_loss:  tensor(1.1814e-11, grad_fn=<DivBackward0>)\n",
            "97287 : avg_loss:  tensor(1.1814e-11, grad_fn=<DivBackward0>)\n",
            "97288 : avg_loss:  tensor(1.1814e-11, grad_fn=<DivBackward0>)\n",
            "97289 : avg_loss:  tensor(1.1813e-11, grad_fn=<DivBackward0>)\n",
            "97290 : avg_loss:  tensor(1.1813e-11, grad_fn=<DivBackward0>)\n",
            "97291 : avg_loss:  tensor(1.1813e-11, grad_fn=<DivBackward0>)\n",
            "97292 : avg_loss:  tensor(1.1813e-11, grad_fn=<DivBackward0>)\n",
            "97293 : avg_loss:  tensor(1.1813e-11, grad_fn=<DivBackward0>)\n",
            "97294 : avg_loss:  tensor(1.1812e-11, grad_fn=<DivBackward0>)\n",
            "97295 : avg_loss:  tensor(1.1812e-11, grad_fn=<DivBackward0>)\n",
            "97296 : avg_loss:  tensor(1.1812e-11, grad_fn=<DivBackward0>)\n",
            "97297 : avg_loss:  tensor(1.1812e-11, grad_fn=<DivBackward0>)\n",
            "97298 : avg_loss:  tensor(1.1812e-11, grad_fn=<DivBackward0>)\n",
            "97299 : avg_loss:  tensor(1.1812e-11, grad_fn=<DivBackward0>)\n",
            "97300 : avg_loss:  tensor(1.1811e-11, grad_fn=<DivBackward0>)\n",
            "97301 : avg_loss:  tensor(1.1811e-11, grad_fn=<DivBackward0>)\n",
            "97302 : avg_loss:  tensor(1.1811e-11, grad_fn=<DivBackward0>)\n",
            "97303 : avg_loss:  tensor(1.1811e-11, grad_fn=<DivBackward0>)\n",
            "97304 : avg_loss:  tensor(1.1811e-11, grad_fn=<DivBackward0>)\n",
            "97305 : avg_loss:  tensor(1.1811e-11, grad_fn=<DivBackward0>)\n",
            "97306 : avg_loss:  tensor(1.1810e-11, grad_fn=<DivBackward0>)\n",
            "97307 : avg_loss:  tensor(1.1810e-11, grad_fn=<DivBackward0>)\n",
            "97308 : avg_loss:  tensor(1.1810e-11, grad_fn=<DivBackward0>)\n",
            "97309 : avg_loss:  tensor(1.1810e-11, grad_fn=<DivBackward0>)\n",
            "97310 : avg_loss:  tensor(1.1810e-11, grad_fn=<DivBackward0>)\n",
            "97311 : avg_loss:  tensor(1.1809e-11, grad_fn=<DivBackward0>)\n",
            "97312 : avg_loss:  tensor(1.1809e-11, grad_fn=<DivBackward0>)\n",
            "97313 : avg_loss:  tensor(1.1809e-11, grad_fn=<DivBackward0>)\n",
            "97314 : avg_loss:  tensor(1.1809e-11, grad_fn=<DivBackward0>)\n",
            "97315 : avg_loss:  tensor(1.1809e-11, grad_fn=<DivBackward0>)\n",
            "97316 : avg_loss:  tensor(1.1808e-11, grad_fn=<DivBackward0>)\n",
            "97317 : avg_loss:  tensor(1.1808e-11, grad_fn=<DivBackward0>)\n",
            "97318 : avg_loss:  tensor(1.1808e-11, grad_fn=<DivBackward0>)\n",
            "97319 : avg_loss:  tensor(1.1808e-11, grad_fn=<DivBackward0>)\n",
            "97320 : avg_loss:  tensor(1.1808e-11, grad_fn=<DivBackward0>)\n",
            "97321 : avg_loss:  tensor(1.1808e-11, grad_fn=<DivBackward0>)\n",
            "97322 : avg_loss:  tensor(1.1808e-11, grad_fn=<DivBackward0>)\n",
            "97323 : avg_loss:  tensor(1.1807e-11, grad_fn=<DivBackward0>)\n",
            "97324 : avg_loss:  tensor(1.1807e-11, grad_fn=<DivBackward0>)\n",
            "97325 : avg_loss:  tensor(1.1807e-11, grad_fn=<DivBackward0>)\n",
            "97326 : avg_loss:  tensor(1.1807e-11, grad_fn=<DivBackward0>)\n",
            "97327 : avg_loss:  tensor(1.1807e-11, grad_fn=<DivBackward0>)\n",
            "97328 : avg_loss:  tensor(1.1807e-11, grad_fn=<DivBackward0>)\n",
            "97329 : avg_loss:  tensor(1.1806e-11, grad_fn=<DivBackward0>)\n",
            "97330 : avg_loss:  tensor(1.1806e-11, grad_fn=<DivBackward0>)\n",
            "97331 : avg_loss:  tensor(1.1806e-11, grad_fn=<DivBackward0>)\n",
            "97332 : avg_loss:  tensor(1.1805e-11, grad_fn=<DivBackward0>)\n",
            "97333 : avg_loss:  tensor(1.1805e-11, grad_fn=<DivBackward0>)\n",
            "97334 : avg_loss:  tensor(1.1805e-11, grad_fn=<DivBackward0>)\n",
            "97335 : avg_loss:  tensor(1.1805e-11, grad_fn=<DivBackward0>)\n",
            "97336 : avg_loss:  tensor(1.1804e-11, grad_fn=<DivBackward0>)\n",
            "97337 : avg_loss:  tensor(1.1804e-11, grad_fn=<DivBackward0>)\n",
            "97338 : avg_loss:  tensor(1.1804e-11, grad_fn=<DivBackward0>)\n",
            "97339 : avg_loss:  tensor(1.1804e-11, grad_fn=<DivBackward0>)\n",
            "97340 : avg_loss:  tensor(1.1804e-11, grad_fn=<DivBackward0>)\n",
            "97341 : avg_loss:  tensor(1.1804e-11, grad_fn=<DivBackward0>)\n",
            "97342 : avg_loss:  tensor(1.1803e-11, grad_fn=<DivBackward0>)\n",
            "97343 : avg_loss:  tensor(1.1803e-11, grad_fn=<DivBackward0>)\n",
            "97344 : avg_loss:  tensor(1.1803e-11, grad_fn=<DivBackward0>)\n",
            "97345 : avg_loss:  tensor(1.1803e-11, grad_fn=<DivBackward0>)\n",
            "97346 : avg_loss:  tensor(1.1803e-11, grad_fn=<DivBackward0>)\n",
            "97347 : avg_loss:  tensor(1.1803e-11, grad_fn=<DivBackward0>)\n",
            "97348 : avg_loss:  tensor(1.1802e-11, grad_fn=<DivBackward0>)\n",
            "97349 : avg_loss:  tensor(1.1802e-11, grad_fn=<DivBackward0>)\n",
            "97350 : avg_loss:  tensor(1.1802e-11, grad_fn=<DivBackward0>)\n",
            "97351 : avg_loss:  tensor(1.1802e-11, grad_fn=<DivBackward0>)\n",
            "97352 : avg_loss:  tensor(1.1802e-11, grad_fn=<DivBackward0>)\n",
            "97353 : avg_loss:  tensor(1.1802e-11, grad_fn=<DivBackward0>)\n",
            "97354 : avg_loss:  tensor(1.1802e-11, grad_fn=<DivBackward0>)\n",
            "97355 : avg_loss:  tensor(1.1801e-11, grad_fn=<DivBackward0>)\n",
            "97356 : avg_loss:  tensor(1.1801e-11, grad_fn=<DivBackward0>)\n",
            "97357 : avg_loss:  tensor(1.1801e-11, grad_fn=<DivBackward0>)\n",
            "97358 : avg_loss:  tensor(1.1800e-11, grad_fn=<DivBackward0>)\n",
            "97359 : avg_loss:  tensor(1.1800e-11, grad_fn=<DivBackward0>)\n",
            "97360 : avg_loss:  tensor(1.1800e-11, grad_fn=<DivBackward0>)\n",
            "97361 : avg_loss:  tensor(1.1800e-11, grad_fn=<DivBackward0>)\n",
            "97362 : avg_loss:  tensor(1.1800e-11, grad_fn=<DivBackward0>)\n",
            "97363 : avg_loss:  tensor(1.1800e-11, grad_fn=<DivBackward0>)\n",
            "97364 : avg_loss:  tensor(1.1799e-11, grad_fn=<DivBackward0>)\n",
            "97365 : avg_loss:  tensor(1.1799e-11, grad_fn=<DivBackward0>)\n",
            "97366 : avg_loss:  tensor(1.1799e-11, grad_fn=<DivBackward0>)\n",
            "97367 : avg_loss:  tensor(1.1799e-11, grad_fn=<DivBackward0>)\n",
            "97368 : avg_loss:  tensor(1.1799e-11, grad_fn=<DivBackward0>)\n",
            "97369 : avg_loss:  tensor(1.1799e-11, grad_fn=<DivBackward0>)\n",
            "97370 : avg_loss:  tensor(1.1799e-11, grad_fn=<DivBackward0>)\n",
            "97371 : avg_loss:  tensor(1.1798e-11, grad_fn=<DivBackward0>)\n",
            "97372 : avg_loss:  tensor(1.1798e-11, grad_fn=<DivBackward0>)\n",
            "97373 : avg_loss:  tensor(1.1798e-11, grad_fn=<DivBackward0>)\n",
            "97374 : avg_loss:  tensor(1.1798e-11, grad_fn=<DivBackward0>)\n",
            "97375 : avg_loss:  tensor(1.1797e-11, grad_fn=<DivBackward0>)\n",
            "97376 : avg_loss:  tensor(1.1797e-11, grad_fn=<DivBackward0>)\n",
            "97377 : avg_loss:  tensor(1.1797e-11, grad_fn=<DivBackward0>)\n",
            "97378 : avg_loss:  tensor(1.1797e-11, grad_fn=<DivBackward0>)\n",
            "97379 : avg_loss:  tensor(1.1797e-11, grad_fn=<DivBackward0>)\n",
            "97380 : avg_loss:  tensor(1.1796e-11, grad_fn=<DivBackward0>)\n",
            "97381 : avg_loss:  tensor(1.1796e-11, grad_fn=<DivBackward0>)\n",
            "97382 : avg_loss:  tensor(1.1796e-11, grad_fn=<DivBackward0>)\n",
            "97383 : avg_loss:  tensor(1.1796e-11, grad_fn=<DivBackward0>)\n",
            "97384 : avg_loss:  tensor(1.1796e-11, grad_fn=<DivBackward0>)\n",
            "97385 : avg_loss:  tensor(1.1796e-11, grad_fn=<DivBackward0>)\n",
            "97386 : avg_loss:  tensor(1.1795e-11, grad_fn=<DivBackward0>)\n",
            "97387 : avg_loss:  tensor(1.1795e-11, grad_fn=<DivBackward0>)\n",
            "97388 : avg_loss:  tensor(1.1795e-11, grad_fn=<DivBackward0>)\n",
            "97389 : avg_loss:  tensor(1.1795e-11, grad_fn=<DivBackward0>)\n",
            "97390 : avg_loss:  tensor(1.1795e-11, grad_fn=<DivBackward0>)\n",
            "97391 : avg_loss:  tensor(1.1794e-11, grad_fn=<DivBackward0>)\n",
            "97392 : avg_loss:  tensor(1.1794e-11, grad_fn=<DivBackward0>)\n",
            "97393 : avg_loss:  tensor(1.1794e-11, grad_fn=<DivBackward0>)\n",
            "97394 : avg_loss:  tensor(1.1794e-11, grad_fn=<DivBackward0>)\n",
            "97395 : avg_loss:  tensor(1.1794e-11, grad_fn=<DivBackward0>)\n",
            "97396 : avg_loss:  tensor(1.1794e-11, grad_fn=<DivBackward0>)\n",
            "97397 : avg_loss:  tensor(1.1793e-11, grad_fn=<DivBackward0>)\n",
            "97398 : avg_loss:  tensor(1.1793e-11, grad_fn=<DivBackward0>)\n",
            "97399 : avg_loss:  tensor(1.1793e-11, grad_fn=<DivBackward0>)\n",
            "97400 : avg_loss:  tensor(1.1793e-11, grad_fn=<DivBackward0>)\n",
            "97401 : avg_loss:  tensor(1.1792e-11, grad_fn=<DivBackward0>)\n",
            "97402 : avg_loss:  tensor(1.1792e-11, grad_fn=<DivBackward0>)\n",
            "97403 : avg_loss:  tensor(1.1792e-11, grad_fn=<DivBackward0>)\n",
            "97404 : avg_loss:  tensor(1.1792e-11, grad_fn=<DivBackward0>)\n",
            "97405 : avg_loss:  tensor(1.1792e-11, grad_fn=<DivBackward0>)\n",
            "97406 : avg_loss:  tensor(1.1792e-11, grad_fn=<DivBackward0>)\n",
            "97407 : avg_loss:  tensor(1.1791e-11, grad_fn=<DivBackward0>)\n",
            "97408 : avg_loss:  tensor(1.1791e-11, grad_fn=<DivBackward0>)\n",
            "97409 : avg_loss:  tensor(1.1791e-11, grad_fn=<DivBackward0>)\n",
            "97410 : avg_loss:  tensor(1.1791e-11, grad_fn=<DivBackward0>)\n",
            "97411 : avg_loss:  tensor(1.1791e-11, grad_fn=<DivBackward0>)\n",
            "97412 : avg_loss:  tensor(1.1790e-11, grad_fn=<DivBackward0>)\n",
            "97413 : avg_loss:  tensor(1.1790e-11, grad_fn=<DivBackward0>)\n",
            "97414 : avg_loss:  tensor(1.1790e-11, grad_fn=<DivBackward0>)\n",
            "97415 : avg_loss:  tensor(1.1790e-11, grad_fn=<DivBackward0>)\n",
            "97416 : avg_loss:  tensor(1.1790e-11, grad_fn=<DivBackward0>)\n",
            "97417 : avg_loss:  tensor(1.1790e-11, grad_fn=<DivBackward0>)\n",
            "97418 : avg_loss:  tensor(1.1789e-11, grad_fn=<DivBackward0>)\n",
            "97419 : avg_loss:  tensor(1.1789e-11, grad_fn=<DivBackward0>)\n",
            "97420 : avg_loss:  tensor(1.1789e-11, grad_fn=<DivBackward0>)\n",
            "97421 : avg_loss:  tensor(1.1789e-11, grad_fn=<DivBackward0>)\n",
            "97422 : avg_loss:  tensor(1.1789e-11, grad_fn=<DivBackward0>)\n",
            "97423 : avg_loss:  tensor(1.1788e-11, grad_fn=<DivBackward0>)\n",
            "97424 : avg_loss:  tensor(1.1788e-11, grad_fn=<DivBackward0>)\n",
            "97425 : avg_loss:  tensor(1.1788e-11, grad_fn=<DivBackward0>)\n",
            "97426 : avg_loss:  tensor(1.1788e-11, grad_fn=<DivBackward0>)\n",
            "97427 : avg_loss:  tensor(1.1788e-11, grad_fn=<DivBackward0>)\n",
            "97428 : avg_loss:  tensor(1.1788e-11, grad_fn=<DivBackward0>)\n",
            "97429 : avg_loss:  tensor(1.1787e-11, grad_fn=<DivBackward0>)\n",
            "97430 : avg_loss:  tensor(1.1787e-11, grad_fn=<DivBackward0>)\n",
            "97431 : avg_loss:  tensor(1.1787e-11, grad_fn=<DivBackward0>)\n",
            "97432 : avg_loss:  tensor(1.1787e-11, grad_fn=<DivBackward0>)\n",
            "97433 : avg_loss:  tensor(1.1787e-11, grad_fn=<DivBackward0>)\n",
            "97434 : avg_loss:  tensor(1.1787e-11, grad_fn=<DivBackward0>)\n",
            "97435 : avg_loss:  tensor(1.1786e-11, grad_fn=<DivBackward0>)\n",
            "97436 : avg_loss:  tensor(1.1786e-11, grad_fn=<DivBackward0>)\n",
            "97437 : avg_loss:  tensor(1.1786e-11, grad_fn=<DivBackward0>)\n",
            "97438 : avg_loss:  tensor(1.1786e-11, grad_fn=<DivBackward0>)\n",
            "97439 : avg_loss:  tensor(1.1785e-11, grad_fn=<DivBackward0>)\n",
            "97440 : avg_loss:  tensor(1.1785e-11, grad_fn=<DivBackward0>)\n",
            "97441 : avg_loss:  tensor(1.1785e-11, grad_fn=<DivBackward0>)\n",
            "97442 : avg_loss:  tensor(1.1785e-11, grad_fn=<DivBackward0>)\n",
            "97443 : avg_loss:  tensor(1.1785e-11, grad_fn=<DivBackward0>)\n",
            "97444 : avg_loss:  tensor(1.1784e-11, grad_fn=<DivBackward0>)\n",
            "97445 : avg_loss:  tensor(1.1784e-11, grad_fn=<DivBackward0>)\n",
            "97446 : avg_loss:  tensor(1.1784e-11, grad_fn=<DivBackward0>)\n",
            "97447 : avg_loss:  tensor(1.1784e-11, grad_fn=<DivBackward0>)\n",
            "97448 : avg_loss:  tensor(1.1784e-11, grad_fn=<DivBackward0>)\n",
            "97449 : avg_loss:  tensor(1.1784e-11, grad_fn=<DivBackward0>)\n",
            "97450 : avg_loss:  tensor(1.1784e-11, grad_fn=<DivBackward0>)\n",
            "97451 : avg_loss:  tensor(1.1783e-11, grad_fn=<DivBackward0>)\n",
            "97452 : avg_loss:  tensor(1.1783e-11, grad_fn=<DivBackward0>)\n",
            "97453 : avg_loss:  tensor(1.1783e-11, grad_fn=<DivBackward0>)\n",
            "97454 : avg_loss:  tensor(1.1782e-11, grad_fn=<DivBackward0>)\n",
            "97455 : avg_loss:  tensor(1.1782e-11, grad_fn=<DivBackward0>)\n",
            "97456 : avg_loss:  tensor(1.1782e-11, grad_fn=<DivBackward0>)\n",
            "97457 : avg_loss:  tensor(1.1782e-11, grad_fn=<DivBackward0>)\n",
            "97458 : avg_loss:  tensor(1.1782e-11, grad_fn=<DivBackward0>)\n",
            "97459 : avg_loss:  tensor(1.1781e-11, grad_fn=<DivBackward0>)\n",
            "97460 : avg_loss:  tensor(1.1781e-11, grad_fn=<DivBackward0>)\n",
            "97461 : avg_loss:  tensor(1.1781e-11, grad_fn=<DivBackward0>)\n",
            "97462 : avg_loss:  tensor(1.1781e-11, grad_fn=<DivBackward0>)\n",
            "97463 : avg_loss:  tensor(1.1781e-11, grad_fn=<DivBackward0>)\n",
            "97464 : avg_loss:  tensor(1.1780e-11, grad_fn=<DivBackward0>)\n",
            "97465 : avg_loss:  tensor(1.1780e-11, grad_fn=<DivBackward0>)\n",
            "97466 : avg_loss:  tensor(1.1780e-11, grad_fn=<DivBackward0>)\n",
            "97467 : avg_loss:  tensor(1.1780e-11, grad_fn=<DivBackward0>)\n",
            "97468 : avg_loss:  tensor(1.1780e-11, grad_fn=<DivBackward0>)\n",
            "97469 : avg_loss:  tensor(1.1780e-11, grad_fn=<DivBackward0>)\n",
            "97470 : avg_loss:  tensor(1.1779e-11, grad_fn=<DivBackward0>)\n",
            "97471 : avg_loss:  tensor(1.1779e-11, grad_fn=<DivBackward0>)\n",
            "97472 : avg_loss:  tensor(1.1779e-11, grad_fn=<DivBackward0>)\n",
            "97473 : avg_loss:  tensor(1.1779e-11, grad_fn=<DivBackward0>)\n",
            "97474 : avg_loss:  tensor(1.1778e-11, grad_fn=<DivBackward0>)\n",
            "97475 : avg_loss:  tensor(1.1778e-11, grad_fn=<DivBackward0>)\n",
            "97476 : avg_loss:  tensor(1.1778e-11, grad_fn=<DivBackward0>)\n",
            "97477 : avg_loss:  tensor(1.1778e-11, grad_fn=<DivBackward0>)\n",
            "97478 : avg_loss:  tensor(1.1778e-11, grad_fn=<DivBackward0>)\n",
            "97479 : avg_loss:  tensor(1.1777e-11, grad_fn=<DivBackward0>)\n",
            "97480 : avg_loss:  tensor(1.1777e-11, grad_fn=<DivBackward0>)\n",
            "97481 : avg_loss:  tensor(1.1777e-11, grad_fn=<DivBackward0>)\n",
            "97482 : avg_loss:  tensor(1.1777e-11, grad_fn=<DivBackward0>)\n",
            "97483 : avg_loss:  tensor(1.1777e-11, grad_fn=<DivBackward0>)\n",
            "97484 : avg_loss:  tensor(1.1777e-11, grad_fn=<DivBackward0>)\n",
            "97485 : avg_loss:  tensor(1.1776e-11, grad_fn=<DivBackward0>)\n",
            "97486 : avg_loss:  tensor(1.1776e-11, grad_fn=<DivBackward0>)\n",
            "97487 : avg_loss:  tensor(1.1776e-11, grad_fn=<DivBackward0>)\n",
            "97488 : avg_loss:  tensor(1.1776e-11, grad_fn=<DivBackward0>)\n",
            "97489 : avg_loss:  tensor(1.1775e-11, grad_fn=<DivBackward0>)\n",
            "97490 : avg_loss:  tensor(1.1775e-11, grad_fn=<DivBackward0>)\n",
            "97491 : avg_loss:  tensor(1.1775e-11, grad_fn=<DivBackward0>)\n",
            "97492 : avg_loss:  tensor(1.1775e-11, grad_fn=<DivBackward0>)\n",
            "97493 : avg_loss:  tensor(1.1775e-11, grad_fn=<DivBackward0>)\n",
            "97494 : avg_loss:  tensor(1.1775e-11, grad_fn=<DivBackward0>)\n",
            "97495 : avg_loss:  tensor(1.1774e-11, grad_fn=<DivBackward0>)\n",
            "97496 : avg_loss:  tensor(1.1774e-11, grad_fn=<DivBackward0>)\n",
            "97497 : avg_loss:  tensor(1.1774e-11, grad_fn=<DivBackward0>)\n",
            "97498 : avg_loss:  tensor(1.1774e-11, grad_fn=<DivBackward0>)\n",
            "97499 : avg_loss:  tensor(1.1774e-11, grad_fn=<DivBackward0>)\n",
            "97500 : avg_loss:  tensor(1.1773e-11, grad_fn=<DivBackward0>)\n",
            "97501 : avg_loss:  tensor(1.1773e-11, grad_fn=<DivBackward0>)\n",
            "97502 : avg_loss:  tensor(1.1773e-11, grad_fn=<DivBackward0>)\n",
            "97503 : avg_loss:  tensor(1.1773e-11, grad_fn=<DivBackward0>)\n",
            "97504 : avg_loss:  tensor(1.1772e-11, grad_fn=<DivBackward0>)\n",
            "97505 : avg_loss:  tensor(1.1772e-11, grad_fn=<DivBackward0>)\n",
            "97506 : avg_loss:  tensor(1.1772e-11, grad_fn=<DivBackward0>)\n",
            "97507 : avg_loss:  tensor(1.1772e-11, grad_fn=<DivBackward0>)\n",
            "97508 : avg_loss:  tensor(1.1772e-11, grad_fn=<DivBackward0>)\n",
            "97509 : avg_loss:  tensor(1.1771e-11, grad_fn=<DivBackward0>)\n",
            "97510 : avg_loss:  tensor(1.1771e-11, grad_fn=<DivBackward0>)\n",
            "97511 : avg_loss:  tensor(1.1771e-11, grad_fn=<DivBackward0>)\n",
            "97512 : avg_loss:  tensor(1.1771e-11, grad_fn=<DivBackward0>)\n",
            "97513 : avg_loss:  tensor(1.1771e-11, grad_fn=<DivBackward0>)\n",
            "97514 : avg_loss:  tensor(1.1771e-11, grad_fn=<DivBackward0>)\n",
            "97515 : avg_loss:  tensor(1.1771e-11, grad_fn=<DivBackward0>)\n",
            "97516 : avg_loss:  tensor(1.1770e-11, grad_fn=<DivBackward0>)\n",
            "97517 : avg_loss:  tensor(1.1770e-11, grad_fn=<DivBackward0>)\n",
            "97518 : avg_loss:  tensor(1.1770e-11, grad_fn=<DivBackward0>)\n",
            "97519 : avg_loss:  tensor(1.1769e-11, grad_fn=<DivBackward0>)\n",
            "97520 : avg_loss:  tensor(1.1769e-11, grad_fn=<DivBackward0>)\n",
            "97521 : avg_loss:  tensor(1.1769e-11, grad_fn=<DivBackward0>)\n",
            "97522 : avg_loss:  tensor(1.1769e-11, grad_fn=<DivBackward0>)\n",
            "97523 : avg_loss:  tensor(1.1769e-11, grad_fn=<DivBackward0>)\n",
            "97524 : avg_loss:  tensor(1.1769e-11, grad_fn=<DivBackward0>)\n",
            "97525 : avg_loss:  tensor(1.1768e-11, grad_fn=<DivBackward0>)\n",
            "97526 : avg_loss:  tensor(1.1768e-11, grad_fn=<DivBackward0>)\n",
            "97527 : avg_loss:  tensor(1.1768e-11, grad_fn=<DivBackward0>)\n",
            "97528 : avg_loss:  tensor(1.1768e-11, grad_fn=<DivBackward0>)\n",
            "97529 : avg_loss:  tensor(1.1768e-11, grad_fn=<DivBackward0>)\n",
            "97530 : avg_loss:  tensor(1.1767e-11, grad_fn=<DivBackward0>)\n",
            "97531 : avg_loss:  tensor(1.1767e-11, grad_fn=<DivBackward0>)\n",
            "97532 : avg_loss:  tensor(1.1767e-11, grad_fn=<DivBackward0>)\n",
            "97533 : avg_loss:  tensor(1.1767e-11, grad_fn=<DivBackward0>)\n",
            "97534 : avg_loss:  tensor(1.1767e-11, grad_fn=<DivBackward0>)\n",
            "97535 : avg_loss:  tensor(1.1767e-11, grad_fn=<DivBackward0>)\n",
            "97536 : avg_loss:  tensor(1.1766e-11, grad_fn=<DivBackward0>)\n",
            "97537 : avg_loss:  tensor(1.1766e-11, grad_fn=<DivBackward0>)\n",
            "97538 : avg_loss:  tensor(1.1766e-11, grad_fn=<DivBackward0>)\n",
            "97539 : avg_loss:  tensor(1.1766e-11, grad_fn=<DivBackward0>)\n",
            "97540 : avg_loss:  tensor(1.1765e-11, grad_fn=<DivBackward0>)\n",
            "97541 : avg_loss:  tensor(1.1765e-11, grad_fn=<DivBackward0>)\n",
            "97542 : avg_loss:  tensor(1.1765e-11, grad_fn=<DivBackward0>)\n",
            "97543 : avg_loss:  tensor(1.1765e-11, grad_fn=<DivBackward0>)\n",
            "97544 : avg_loss:  tensor(1.1765e-11, grad_fn=<DivBackward0>)\n",
            "97545 : avg_loss:  tensor(1.1765e-11, grad_fn=<DivBackward0>)\n",
            "97546 : avg_loss:  tensor(1.1764e-11, grad_fn=<DivBackward0>)\n",
            "97547 : avg_loss:  tensor(1.1764e-11, grad_fn=<DivBackward0>)\n",
            "97548 : avg_loss:  tensor(1.1764e-11, grad_fn=<DivBackward0>)\n",
            "97549 : avg_loss:  tensor(1.1764e-11, grad_fn=<DivBackward0>)\n",
            "97550 : avg_loss:  tensor(1.1763e-11, grad_fn=<DivBackward0>)\n",
            "97551 : avg_loss:  tensor(1.1763e-11, grad_fn=<DivBackward0>)\n",
            "97552 : avg_loss:  tensor(1.1763e-11, grad_fn=<DivBackward0>)\n",
            "97553 : avg_loss:  tensor(1.1763e-11, grad_fn=<DivBackward0>)\n",
            "97554 : avg_loss:  tensor(1.1763e-11, grad_fn=<DivBackward0>)\n",
            "97555 : avg_loss:  tensor(1.1762e-11, grad_fn=<DivBackward0>)\n",
            "97556 : avg_loss:  tensor(1.1762e-11, grad_fn=<DivBackward0>)\n",
            "97557 : avg_loss:  tensor(1.1762e-11, grad_fn=<DivBackward0>)\n",
            "97558 : avg_loss:  tensor(1.1762e-11, grad_fn=<DivBackward0>)\n",
            "97559 : avg_loss:  tensor(1.1761e-11, grad_fn=<DivBackward0>)\n",
            "97560 : avg_loss:  tensor(1.1761e-11, grad_fn=<DivBackward0>)\n",
            "97561 : avg_loss:  tensor(1.1761e-11, grad_fn=<DivBackward0>)\n",
            "97562 : avg_loss:  tensor(1.1761e-11, grad_fn=<DivBackward0>)\n",
            "97563 : avg_loss:  tensor(1.1760e-11, grad_fn=<DivBackward0>)\n",
            "97564 : avg_loss:  tensor(1.1760e-11, grad_fn=<DivBackward0>)\n",
            "97565 : avg_loss:  tensor(1.1760e-11, grad_fn=<DivBackward0>)\n",
            "97566 : avg_loss:  tensor(1.1760e-11, grad_fn=<DivBackward0>)\n",
            "97567 : avg_loss:  tensor(1.1760e-11, grad_fn=<DivBackward0>)\n",
            "97568 : avg_loss:  tensor(1.1760e-11, grad_fn=<DivBackward0>)\n",
            "97569 : avg_loss:  tensor(1.1759e-11, grad_fn=<DivBackward0>)\n",
            "97570 : avg_loss:  tensor(1.1759e-11, grad_fn=<DivBackward0>)\n",
            "97571 : avg_loss:  tensor(1.1759e-11, grad_fn=<DivBackward0>)\n",
            "97572 : avg_loss:  tensor(1.1759e-11, grad_fn=<DivBackward0>)\n",
            "97573 : avg_loss:  tensor(1.1759e-11, grad_fn=<DivBackward0>)\n",
            "97574 : avg_loss:  tensor(1.1758e-11, grad_fn=<DivBackward0>)\n",
            "97575 : avg_loss:  tensor(1.1758e-11, grad_fn=<DivBackward0>)\n",
            "97576 : avg_loss:  tensor(1.1758e-11, grad_fn=<DivBackward0>)\n",
            "97577 : avg_loss:  tensor(1.1757e-11, grad_fn=<DivBackward0>)\n",
            "97578 : avg_loss:  tensor(1.1757e-11, grad_fn=<DivBackward0>)\n",
            "97579 : avg_loss:  tensor(1.1757e-11, grad_fn=<DivBackward0>)\n",
            "97580 : avg_loss:  tensor(1.1757e-11, grad_fn=<DivBackward0>)\n",
            "97581 : avg_loss:  tensor(1.1757e-11, grad_fn=<DivBackward0>)\n",
            "97582 : avg_loss:  tensor(1.1757e-11, grad_fn=<DivBackward0>)\n",
            "97583 : avg_loss:  tensor(1.1756e-11, grad_fn=<DivBackward0>)\n",
            "97584 : avg_loss:  tensor(1.1756e-11, grad_fn=<DivBackward0>)\n",
            "97585 : avg_loss:  tensor(1.1756e-11, grad_fn=<DivBackward0>)\n",
            "97586 : avg_loss:  tensor(1.1756e-11, grad_fn=<DivBackward0>)\n",
            "97587 : avg_loss:  tensor(1.1756e-11, grad_fn=<DivBackward0>)\n",
            "97588 : avg_loss:  tensor(1.1755e-11, grad_fn=<DivBackward0>)\n",
            "97589 : avg_loss:  tensor(1.1755e-11, grad_fn=<DivBackward0>)\n",
            "97590 : avg_loss:  tensor(1.1755e-11, grad_fn=<DivBackward0>)\n",
            "97591 : avg_loss:  tensor(1.1755e-11, grad_fn=<DivBackward0>)\n",
            "97592 : avg_loss:  tensor(1.1755e-11, grad_fn=<DivBackward0>)\n",
            "97593 : avg_loss:  tensor(1.1755e-11, grad_fn=<DivBackward0>)\n",
            "97594 : avg_loss:  tensor(1.1754e-11, grad_fn=<DivBackward0>)\n",
            "97595 : avg_loss:  tensor(1.1754e-11, grad_fn=<DivBackward0>)\n",
            "97596 : avg_loss:  tensor(1.1754e-11, grad_fn=<DivBackward0>)\n",
            "97597 : avg_loss:  tensor(1.1754e-11, grad_fn=<DivBackward0>)\n",
            "97598 : avg_loss:  tensor(1.1753e-11, grad_fn=<DivBackward0>)\n",
            "97599 : avg_loss:  tensor(1.1753e-11, grad_fn=<DivBackward0>)\n",
            "97600 : avg_loss:  tensor(1.1753e-11, grad_fn=<DivBackward0>)\n",
            "97601 : avg_loss:  tensor(1.1753e-11, grad_fn=<DivBackward0>)\n",
            "97602 : avg_loss:  tensor(1.1753e-11, grad_fn=<DivBackward0>)\n",
            "97603 : avg_loss:  tensor(1.1752e-11, grad_fn=<DivBackward0>)\n",
            "97604 : avg_loss:  tensor(1.1752e-11, grad_fn=<DivBackward0>)\n",
            "97605 : avg_loss:  tensor(1.1752e-11, grad_fn=<DivBackward0>)\n",
            "97606 : avg_loss:  tensor(1.1752e-11, grad_fn=<DivBackward0>)\n",
            "97607 : avg_loss:  tensor(1.1752e-11, grad_fn=<DivBackward0>)\n",
            "97608 : avg_loss:  tensor(1.1751e-11, grad_fn=<DivBackward0>)\n",
            "97609 : avg_loss:  tensor(1.1751e-11, grad_fn=<DivBackward0>)\n",
            "97610 : avg_loss:  tensor(1.1751e-11, grad_fn=<DivBackward0>)\n",
            "97611 : avg_loss:  tensor(1.1751e-11, grad_fn=<DivBackward0>)\n",
            "97612 : avg_loss:  tensor(1.1751e-11, grad_fn=<DivBackward0>)\n",
            "97613 : avg_loss:  tensor(1.1750e-11, grad_fn=<DivBackward0>)\n",
            "97614 : avg_loss:  tensor(1.1750e-11, grad_fn=<DivBackward0>)\n",
            "97615 : avg_loss:  tensor(1.1750e-11, grad_fn=<DivBackward0>)\n",
            "97616 : avg_loss:  tensor(1.1750e-11, grad_fn=<DivBackward0>)\n",
            "97617 : avg_loss:  tensor(1.1750e-11, grad_fn=<DivBackward0>)\n",
            "97618 : avg_loss:  tensor(1.1749e-11, grad_fn=<DivBackward0>)\n",
            "97619 : avg_loss:  tensor(1.1749e-11, grad_fn=<DivBackward0>)\n",
            "97620 : avg_loss:  tensor(1.1749e-11, grad_fn=<DivBackward0>)\n",
            "97621 : avg_loss:  tensor(1.1749e-11, grad_fn=<DivBackward0>)\n",
            "97622 : avg_loss:  tensor(1.1748e-11, grad_fn=<DivBackward0>)\n",
            "97623 : avg_loss:  tensor(1.1748e-11, grad_fn=<DivBackward0>)\n",
            "97624 : avg_loss:  tensor(1.1748e-11, grad_fn=<DivBackward0>)\n",
            "97625 : avg_loss:  tensor(1.1748e-11, grad_fn=<DivBackward0>)\n",
            "97626 : avg_loss:  tensor(1.1748e-11, grad_fn=<DivBackward0>)\n",
            "97627 : avg_loss:  tensor(1.1748e-11, grad_fn=<DivBackward0>)\n",
            "97628 : avg_loss:  tensor(1.1747e-11, grad_fn=<DivBackward0>)\n",
            "97629 : avg_loss:  tensor(1.1747e-11, grad_fn=<DivBackward0>)\n",
            "97630 : avg_loss:  tensor(1.1747e-11, grad_fn=<DivBackward0>)\n",
            "97631 : avg_loss:  tensor(1.1747e-11, grad_fn=<DivBackward0>)\n",
            "97632 : avg_loss:  tensor(1.1747e-11, grad_fn=<DivBackward0>)\n",
            "97633 : avg_loss:  tensor(1.1746e-11, grad_fn=<DivBackward0>)\n",
            "97634 : avg_loss:  tensor(1.1746e-11, grad_fn=<DivBackward0>)\n",
            "97635 : avg_loss:  tensor(1.1745e-11, grad_fn=<DivBackward0>)\n",
            "97636 : avg_loss:  tensor(1.1745e-11, grad_fn=<DivBackward0>)\n",
            "97637 : avg_loss:  tensor(1.1745e-11, grad_fn=<DivBackward0>)\n",
            "97638 : avg_loss:  tensor(1.1745e-11, grad_fn=<DivBackward0>)\n",
            "97639 : avg_loss:  tensor(1.1745e-11, grad_fn=<DivBackward0>)\n",
            "97640 : avg_loss:  tensor(1.1745e-11, grad_fn=<DivBackward0>)\n",
            "97641 : avg_loss:  tensor(1.1745e-11, grad_fn=<DivBackward0>)\n",
            "97642 : avg_loss:  tensor(1.1744e-11, grad_fn=<DivBackward0>)\n",
            "97643 : avg_loss:  tensor(1.1744e-11, grad_fn=<DivBackward0>)\n",
            "97644 : avg_loss:  tensor(1.1744e-11, grad_fn=<DivBackward0>)\n",
            "97645 : avg_loss:  tensor(1.1744e-11, grad_fn=<DivBackward0>)\n",
            "97646 : avg_loss:  tensor(1.1743e-11, grad_fn=<DivBackward0>)\n",
            "97647 : avg_loss:  tensor(1.1743e-11, grad_fn=<DivBackward0>)\n",
            "97648 : avg_loss:  tensor(1.1743e-11, grad_fn=<DivBackward0>)\n",
            "97649 : avg_loss:  tensor(1.1743e-11, grad_fn=<DivBackward0>)\n",
            "97650 : avg_loss:  tensor(1.1743e-11, grad_fn=<DivBackward0>)\n",
            "97651 : avg_loss:  tensor(1.1742e-11, grad_fn=<DivBackward0>)\n",
            "97652 : avg_loss:  tensor(1.1742e-11, grad_fn=<DivBackward0>)\n",
            "97653 : avg_loss:  tensor(1.1742e-11, grad_fn=<DivBackward0>)\n",
            "97654 : avg_loss:  tensor(1.1742e-11, grad_fn=<DivBackward0>)\n",
            "97655 : avg_loss:  tensor(1.1741e-11, grad_fn=<DivBackward0>)\n",
            "97656 : avg_loss:  tensor(1.1741e-11, grad_fn=<DivBackward0>)\n",
            "97657 : avg_loss:  tensor(1.1741e-11, grad_fn=<DivBackward0>)\n",
            "97658 : avg_loss:  tensor(1.1741e-11, grad_fn=<DivBackward0>)\n",
            "97659 : avg_loss:  tensor(1.1741e-11, grad_fn=<DivBackward0>)\n",
            "97660 : avg_loss:  tensor(1.1741e-11, grad_fn=<DivBackward0>)\n",
            "97661 : avg_loss:  tensor(1.1740e-11, grad_fn=<DivBackward0>)\n",
            "97662 : avg_loss:  tensor(1.1740e-11, grad_fn=<DivBackward0>)\n",
            "97663 : avg_loss:  tensor(1.1740e-11, grad_fn=<DivBackward0>)\n",
            "97664 : avg_loss:  tensor(1.1740e-11, grad_fn=<DivBackward0>)\n",
            "97665 : avg_loss:  tensor(1.1739e-11, grad_fn=<DivBackward0>)\n",
            "97666 : avg_loss:  tensor(1.1739e-11, grad_fn=<DivBackward0>)\n",
            "97667 : avg_loss:  tensor(1.1739e-11, grad_fn=<DivBackward0>)\n",
            "97668 : avg_loss:  tensor(1.1739e-11, grad_fn=<DivBackward0>)\n",
            "97669 : avg_loss:  tensor(1.1739e-11, grad_fn=<DivBackward0>)\n",
            "97670 : avg_loss:  tensor(1.1739e-11, grad_fn=<DivBackward0>)\n",
            "97671 : avg_loss:  tensor(1.1738e-11, grad_fn=<DivBackward0>)\n",
            "97672 : avg_loss:  tensor(1.1738e-11, grad_fn=<DivBackward0>)\n",
            "97673 : avg_loss:  tensor(1.1738e-11, grad_fn=<DivBackward0>)\n",
            "97674 : avg_loss:  tensor(1.1737e-11, grad_fn=<DivBackward0>)\n",
            "97675 : avg_loss:  tensor(1.1737e-11, grad_fn=<DivBackward0>)\n",
            "97676 : avg_loss:  tensor(1.1737e-11, grad_fn=<DivBackward0>)\n",
            "97677 : avg_loss:  tensor(1.1737e-11, grad_fn=<DivBackward0>)\n",
            "97678 : avg_loss:  tensor(1.1737e-11, grad_fn=<DivBackward0>)\n",
            "97679 : avg_loss:  tensor(1.1736e-11, grad_fn=<DivBackward0>)\n",
            "97680 : avg_loss:  tensor(1.1736e-11, grad_fn=<DivBackward0>)\n",
            "97681 : avg_loss:  tensor(1.1736e-11, grad_fn=<DivBackward0>)\n",
            "97682 : avg_loss:  tensor(1.1736e-11, grad_fn=<DivBackward0>)\n",
            "97683 : avg_loss:  tensor(1.1736e-11, grad_fn=<DivBackward0>)\n",
            "97684 : avg_loss:  tensor(1.1735e-11, grad_fn=<DivBackward0>)\n",
            "97685 : avg_loss:  tensor(1.1735e-11, grad_fn=<DivBackward0>)\n",
            "97686 : avg_loss:  tensor(1.1735e-11, grad_fn=<DivBackward0>)\n",
            "97687 : avg_loss:  tensor(1.1735e-11, grad_fn=<DivBackward0>)\n",
            "97688 : avg_loss:  tensor(1.1734e-11, grad_fn=<DivBackward0>)\n",
            "97689 : avg_loss:  tensor(1.1734e-11, grad_fn=<DivBackward0>)\n",
            "97690 : avg_loss:  tensor(1.1734e-11, grad_fn=<DivBackward0>)\n",
            "97691 : avg_loss:  tensor(1.1734e-11, grad_fn=<DivBackward0>)\n",
            "97692 : avg_loss:  tensor(1.1733e-11, grad_fn=<DivBackward0>)\n",
            "97693 : avg_loss:  tensor(1.1733e-11, grad_fn=<DivBackward0>)\n",
            "97694 : avg_loss:  tensor(1.1733e-11, grad_fn=<DivBackward0>)\n",
            "97695 : avg_loss:  tensor(1.1733e-11, grad_fn=<DivBackward0>)\n",
            "97696 : avg_loss:  tensor(1.1733e-11, grad_fn=<DivBackward0>)\n",
            "97697 : avg_loss:  tensor(1.1733e-11, grad_fn=<DivBackward0>)\n",
            "97698 : avg_loss:  tensor(1.1732e-11, grad_fn=<DivBackward0>)\n",
            "97699 : avg_loss:  tensor(1.1732e-11, grad_fn=<DivBackward0>)\n",
            "97700 : avg_loss:  tensor(1.1732e-11, grad_fn=<DivBackward0>)\n",
            "97701 : avg_loss:  tensor(1.1732e-11, grad_fn=<DivBackward0>)\n",
            "97702 : avg_loss:  tensor(1.1732e-11, grad_fn=<DivBackward0>)\n",
            "97703 : avg_loss:  tensor(1.1731e-11, grad_fn=<DivBackward0>)\n",
            "97704 : avg_loss:  tensor(1.1731e-11, grad_fn=<DivBackward0>)\n",
            "97705 : avg_loss:  tensor(1.1731e-11, grad_fn=<DivBackward0>)\n",
            "97706 : avg_loss:  tensor(1.1731e-11, grad_fn=<DivBackward0>)\n",
            "97707 : avg_loss:  tensor(1.1730e-11, grad_fn=<DivBackward0>)\n",
            "97708 : avg_loss:  tensor(1.1730e-11, grad_fn=<DivBackward0>)\n",
            "97709 : avg_loss:  tensor(1.1730e-11, grad_fn=<DivBackward0>)\n",
            "97710 : avg_loss:  tensor(1.1730e-11, grad_fn=<DivBackward0>)\n",
            "97711 : avg_loss:  tensor(1.1730e-11, grad_fn=<DivBackward0>)\n",
            "97712 : avg_loss:  tensor(1.1729e-11, grad_fn=<DivBackward0>)\n",
            "97713 : avg_loss:  tensor(1.1729e-11, grad_fn=<DivBackward0>)\n",
            "97714 : avg_loss:  tensor(1.1729e-11, grad_fn=<DivBackward0>)\n",
            "97715 : avg_loss:  tensor(1.1729e-11, grad_fn=<DivBackward0>)\n",
            "97716 : avg_loss:  tensor(1.1729e-11, grad_fn=<DivBackward0>)\n",
            "97717 : avg_loss:  tensor(1.1729e-11, grad_fn=<DivBackward0>)\n",
            "97718 : avg_loss:  tensor(1.1728e-11, grad_fn=<DivBackward0>)\n",
            "97719 : avg_loss:  tensor(1.1728e-11, grad_fn=<DivBackward0>)\n",
            "97720 : avg_loss:  tensor(1.1728e-11, grad_fn=<DivBackward0>)\n",
            "97721 : avg_loss:  tensor(1.1728e-11, grad_fn=<DivBackward0>)\n",
            "97722 : avg_loss:  tensor(1.1727e-11, grad_fn=<DivBackward0>)\n",
            "97723 : avg_loss:  tensor(1.1727e-11, grad_fn=<DivBackward0>)\n",
            "97724 : avg_loss:  tensor(1.1727e-11, grad_fn=<DivBackward0>)\n",
            "97725 : avg_loss:  tensor(1.1726e-11, grad_fn=<DivBackward0>)\n",
            "97726 : avg_loss:  tensor(1.1726e-11, grad_fn=<DivBackward0>)\n",
            "97727 : avg_loss:  tensor(1.1726e-11, grad_fn=<DivBackward0>)\n",
            "97728 : avg_loss:  tensor(1.1726e-11, grad_fn=<DivBackward0>)\n",
            "97729 : avg_loss:  tensor(1.1725e-11, grad_fn=<DivBackward0>)\n",
            "97730 : avg_loss:  tensor(1.1725e-11, grad_fn=<DivBackward0>)\n",
            "97731 : avg_loss:  tensor(1.1725e-11, grad_fn=<DivBackward0>)\n",
            "97732 : avg_loss:  tensor(1.1725e-11, grad_fn=<DivBackward0>)\n",
            "97733 : avg_loss:  tensor(1.1725e-11, grad_fn=<DivBackward0>)\n",
            "97734 : avg_loss:  tensor(1.1724e-11, grad_fn=<DivBackward0>)\n",
            "97735 : avg_loss:  tensor(1.1724e-11, grad_fn=<DivBackward0>)\n",
            "97736 : avg_loss:  tensor(1.1724e-11, grad_fn=<DivBackward0>)\n",
            "97737 : avg_loss:  tensor(1.1724e-11, grad_fn=<DivBackward0>)\n",
            "97738 : avg_loss:  tensor(1.1724e-11, grad_fn=<DivBackward0>)\n",
            "97739 : avg_loss:  tensor(1.1724e-11, grad_fn=<DivBackward0>)\n",
            "97740 : avg_loss:  tensor(1.1723e-11, grad_fn=<DivBackward0>)\n",
            "97741 : avg_loss:  tensor(1.1723e-11, grad_fn=<DivBackward0>)\n",
            "97742 : avg_loss:  tensor(1.1723e-11, grad_fn=<DivBackward0>)\n",
            "97743 : avg_loss:  tensor(1.1722e-11, grad_fn=<DivBackward0>)\n",
            "97744 : avg_loss:  tensor(1.1722e-11, grad_fn=<DivBackward0>)\n",
            "97745 : avg_loss:  tensor(1.1722e-11, grad_fn=<DivBackward0>)\n",
            "97746 : avg_loss:  tensor(1.1722e-11, grad_fn=<DivBackward0>)\n",
            "97747 : avg_loss:  tensor(1.1722e-11, grad_fn=<DivBackward0>)\n",
            "97748 : avg_loss:  tensor(1.1722e-11, grad_fn=<DivBackward0>)\n",
            "97749 : avg_loss:  tensor(1.1721e-11, grad_fn=<DivBackward0>)\n",
            "97750 : avg_loss:  tensor(1.1721e-11, grad_fn=<DivBackward0>)\n",
            "97751 : avg_loss:  tensor(1.1721e-11, grad_fn=<DivBackward0>)\n",
            "97752 : avg_loss:  tensor(1.1721e-11, grad_fn=<DivBackward0>)\n",
            "97753 : avg_loss:  tensor(1.1721e-11, grad_fn=<DivBackward0>)\n",
            "97754 : avg_loss:  tensor(1.1720e-11, grad_fn=<DivBackward0>)\n",
            "97755 : avg_loss:  tensor(1.1720e-11, grad_fn=<DivBackward0>)\n",
            "97756 : avg_loss:  tensor(1.1720e-11, grad_fn=<DivBackward0>)\n",
            "97757 : avg_loss:  tensor(1.1720e-11, grad_fn=<DivBackward0>)\n",
            "97758 : avg_loss:  tensor(1.1719e-11, grad_fn=<DivBackward0>)\n",
            "97759 : avg_loss:  tensor(1.1719e-11, grad_fn=<DivBackward0>)\n",
            "97760 : avg_loss:  tensor(1.1719e-11, grad_fn=<DivBackward0>)\n",
            "97761 : avg_loss:  tensor(1.1719e-11, grad_fn=<DivBackward0>)\n",
            "97762 : avg_loss:  tensor(1.1718e-11, grad_fn=<DivBackward0>)\n",
            "97763 : avg_loss:  tensor(1.1718e-11, grad_fn=<DivBackward0>)\n",
            "97764 : avg_loss:  tensor(1.1717e-11, grad_fn=<DivBackward0>)\n",
            "97765 : avg_loss:  tensor(1.1717e-11, grad_fn=<DivBackward0>)\n",
            "97766 : avg_loss:  tensor(1.1717e-11, grad_fn=<DivBackward0>)\n",
            "97767 : avg_loss:  tensor(1.1717e-11, grad_fn=<DivBackward0>)\n",
            "97768 : avg_loss:  tensor(1.1717e-11, grad_fn=<DivBackward0>)\n",
            "97769 : avg_loss:  tensor(1.1716e-11, grad_fn=<DivBackward0>)\n",
            "97770 : avg_loss:  tensor(1.1716e-11, grad_fn=<DivBackward0>)\n",
            "97771 : avg_loss:  tensor(1.1716e-11, grad_fn=<DivBackward0>)\n",
            "97772 : avg_loss:  tensor(1.1716e-11, grad_fn=<DivBackward0>)\n",
            "97773 : avg_loss:  tensor(1.1716e-11, grad_fn=<DivBackward0>)\n",
            "97774 : avg_loss:  tensor(1.1716e-11, grad_fn=<DivBackward0>)\n",
            "97775 : avg_loss:  tensor(1.1715e-11, grad_fn=<DivBackward0>)\n",
            "97776 : avg_loss:  tensor(1.1715e-11, grad_fn=<DivBackward0>)\n",
            "97777 : avg_loss:  tensor(1.1715e-11, grad_fn=<DivBackward0>)\n",
            "97778 : avg_loss:  tensor(1.1715e-11, grad_fn=<DivBackward0>)\n",
            "97779 : avg_loss:  tensor(1.1714e-11, grad_fn=<DivBackward0>)\n",
            "97780 : avg_loss:  tensor(1.1714e-11, grad_fn=<DivBackward0>)\n",
            "97781 : avg_loss:  tensor(1.1714e-11, grad_fn=<DivBackward0>)\n",
            "97782 : avg_loss:  tensor(1.1714e-11, grad_fn=<DivBackward0>)\n",
            "97783 : avg_loss:  tensor(1.1713e-11, grad_fn=<DivBackward0>)\n",
            "97784 : avg_loss:  tensor(1.1713e-11, grad_fn=<DivBackward0>)\n",
            "97785 : avg_loss:  tensor(1.1713e-11, grad_fn=<DivBackward0>)\n",
            "97786 : avg_loss:  tensor(1.1713e-11, grad_fn=<DivBackward0>)\n",
            "97787 : avg_loss:  tensor(1.1713e-11, grad_fn=<DivBackward0>)\n",
            "97788 : avg_loss:  tensor(1.1712e-11, grad_fn=<DivBackward0>)\n",
            "97789 : avg_loss:  tensor(1.1712e-11, grad_fn=<DivBackward0>)\n",
            "97790 : avg_loss:  tensor(1.1712e-11, grad_fn=<DivBackward0>)\n",
            "97791 : avg_loss:  tensor(1.1712e-11, grad_fn=<DivBackward0>)\n",
            "97792 : avg_loss:  tensor(1.1712e-11, grad_fn=<DivBackward0>)\n",
            "97793 : avg_loss:  tensor(1.1711e-11, grad_fn=<DivBackward0>)\n",
            "97794 : avg_loss:  tensor(1.1711e-11, grad_fn=<DivBackward0>)\n",
            "97795 : avg_loss:  tensor(1.1711e-11, grad_fn=<DivBackward0>)\n",
            "97796 : avg_loss:  tensor(1.1710e-11, grad_fn=<DivBackward0>)\n",
            "97797 : avg_loss:  tensor(1.1710e-11, grad_fn=<DivBackward0>)\n",
            "97798 : avg_loss:  tensor(1.1710e-11, grad_fn=<DivBackward0>)\n",
            "97799 : avg_loss:  tensor(1.1710e-11, grad_fn=<DivBackward0>)\n",
            "97800 : avg_loss:  tensor(1.1710e-11, grad_fn=<DivBackward0>)\n",
            "97801 : avg_loss:  tensor(1.1709e-11, grad_fn=<DivBackward0>)\n",
            "97802 : avg_loss:  tensor(1.1709e-11, grad_fn=<DivBackward0>)\n",
            "97803 : avg_loss:  tensor(1.1709e-11, grad_fn=<DivBackward0>)\n",
            "97804 : avg_loss:  tensor(1.1709e-11, grad_fn=<DivBackward0>)\n",
            "97805 : avg_loss:  tensor(1.1709e-11, grad_fn=<DivBackward0>)\n",
            "97806 : avg_loss:  tensor(1.1708e-11, grad_fn=<DivBackward0>)\n",
            "97807 : avg_loss:  tensor(1.1708e-11, grad_fn=<DivBackward0>)\n",
            "97808 : avg_loss:  tensor(1.1708e-11, grad_fn=<DivBackward0>)\n",
            "97809 : avg_loss:  tensor(1.1708e-11, grad_fn=<DivBackward0>)\n",
            "97810 : avg_loss:  tensor(1.1707e-11, grad_fn=<DivBackward0>)\n",
            "97811 : avg_loss:  tensor(1.1707e-11, grad_fn=<DivBackward0>)\n",
            "97812 : avg_loss:  tensor(1.1707e-11, grad_fn=<DivBackward0>)\n",
            "97813 : avg_loss:  tensor(1.1707e-11, grad_fn=<DivBackward0>)\n",
            "97814 : avg_loss:  tensor(1.1706e-11, grad_fn=<DivBackward0>)\n",
            "97815 : avg_loss:  tensor(1.1706e-11, grad_fn=<DivBackward0>)\n",
            "97816 : avg_loss:  tensor(1.1706e-11, grad_fn=<DivBackward0>)\n",
            "97817 : avg_loss:  tensor(1.1706e-11, grad_fn=<DivBackward0>)\n",
            "97818 : avg_loss:  tensor(1.1706e-11, grad_fn=<DivBackward0>)\n",
            "97819 : avg_loss:  tensor(1.1705e-11, grad_fn=<DivBackward0>)\n",
            "97820 : avg_loss:  tensor(1.1705e-11, grad_fn=<DivBackward0>)\n",
            "97821 : avg_loss:  tensor(1.1705e-11, grad_fn=<DivBackward0>)\n",
            "97822 : avg_loss:  tensor(1.1705e-11, grad_fn=<DivBackward0>)\n",
            "97823 : avg_loss:  tensor(1.1704e-11, grad_fn=<DivBackward0>)\n",
            "97824 : avg_loss:  tensor(1.1704e-11, grad_fn=<DivBackward0>)\n",
            "97825 : avg_loss:  tensor(1.1704e-11, grad_fn=<DivBackward0>)\n",
            "97826 : avg_loss:  tensor(1.1704e-11, grad_fn=<DivBackward0>)\n",
            "97827 : avg_loss:  tensor(1.1704e-11, grad_fn=<DivBackward0>)\n",
            "97828 : avg_loss:  tensor(1.1703e-11, grad_fn=<DivBackward0>)\n",
            "97829 : avg_loss:  tensor(1.1703e-11, grad_fn=<DivBackward0>)\n",
            "97830 : avg_loss:  tensor(1.1703e-11, grad_fn=<DivBackward0>)\n",
            "97831 : avg_loss:  tensor(1.1702e-11, grad_fn=<DivBackward0>)\n",
            "97832 : avg_loss:  tensor(1.1702e-11, grad_fn=<DivBackward0>)\n",
            "97833 : avg_loss:  tensor(1.1702e-11, grad_fn=<DivBackward0>)\n",
            "97834 : avg_loss:  tensor(1.1702e-11, grad_fn=<DivBackward0>)\n",
            "97835 : avg_loss:  tensor(1.1702e-11, grad_fn=<DivBackward0>)\n",
            "97836 : avg_loss:  tensor(1.1701e-11, grad_fn=<DivBackward0>)\n",
            "97837 : avg_loss:  tensor(1.1701e-11, grad_fn=<DivBackward0>)\n",
            "97838 : avg_loss:  tensor(1.1701e-11, grad_fn=<DivBackward0>)\n",
            "97839 : avg_loss:  tensor(1.1701e-11, grad_fn=<DivBackward0>)\n",
            "97840 : avg_loss:  tensor(1.1701e-11, grad_fn=<DivBackward0>)\n",
            "97841 : avg_loss:  tensor(1.1700e-11, grad_fn=<DivBackward0>)\n",
            "97842 : avg_loss:  tensor(1.1700e-11, grad_fn=<DivBackward0>)\n",
            "97843 : avg_loss:  tensor(1.1700e-11, grad_fn=<DivBackward0>)\n",
            "97844 : avg_loss:  tensor(1.1700e-11, grad_fn=<DivBackward0>)\n",
            "97845 : avg_loss:  tensor(1.1700e-11, grad_fn=<DivBackward0>)\n",
            "97846 : avg_loss:  tensor(1.1699e-11, grad_fn=<DivBackward0>)\n",
            "97847 : avg_loss:  tensor(1.1699e-11, grad_fn=<DivBackward0>)\n",
            "97848 : avg_loss:  tensor(1.1699e-11, grad_fn=<DivBackward0>)\n",
            "97849 : avg_loss:  tensor(1.1698e-11, grad_fn=<DivBackward0>)\n",
            "97850 : avg_loss:  tensor(1.1698e-11, grad_fn=<DivBackward0>)\n",
            "97851 : avg_loss:  tensor(1.1698e-11, grad_fn=<DivBackward0>)\n",
            "97852 : avg_loss:  tensor(1.1698e-11, grad_fn=<DivBackward0>)\n",
            "97853 : avg_loss:  tensor(1.1697e-11, grad_fn=<DivBackward0>)\n",
            "97854 : avg_loss:  tensor(1.1697e-11, grad_fn=<DivBackward0>)\n",
            "97855 : avg_loss:  tensor(1.1697e-11, grad_fn=<DivBackward0>)\n",
            "97856 : avg_loss:  tensor(1.1697e-11, grad_fn=<DivBackward0>)\n",
            "97857 : avg_loss:  tensor(1.1697e-11, grad_fn=<DivBackward0>)\n",
            "97858 : avg_loss:  tensor(1.1696e-11, grad_fn=<DivBackward0>)\n",
            "97859 : avg_loss:  tensor(1.1696e-11, grad_fn=<DivBackward0>)\n",
            "97860 : avg_loss:  tensor(1.1696e-11, grad_fn=<DivBackward0>)\n",
            "97861 : avg_loss:  tensor(1.1695e-11, grad_fn=<DivBackward0>)\n",
            "97862 : avg_loss:  tensor(1.1695e-11, grad_fn=<DivBackward0>)\n",
            "97863 : avg_loss:  tensor(1.1695e-11, grad_fn=<DivBackward0>)\n",
            "97864 : avg_loss:  tensor(1.1695e-11, grad_fn=<DivBackward0>)\n",
            "97865 : avg_loss:  tensor(1.1695e-11, grad_fn=<DivBackward0>)\n",
            "97866 : avg_loss:  tensor(1.1694e-11, grad_fn=<DivBackward0>)\n",
            "97867 : avg_loss:  tensor(1.1694e-11, grad_fn=<DivBackward0>)\n",
            "97868 : avg_loss:  tensor(1.1694e-11, grad_fn=<DivBackward0>)\n",
            "97869 : avg_loss:  tensor(1.1693e-11, grad_fn=<DivBackward0>)\n",
            "97870 : avg_loss:  tensor(1.1693e-11, grad_fn=<DivBackward0>)\n",
            "97871 : avg_loss:  tensor(1.1693e-11, grad_fn=<DivBackward0>)\n",
            "97872 : avg_loss:  tensor(1.1693e-11, grad_fn=<DivBackward0>)\n",
            "97873 : avg_loss:  tensor(1.1693e-11, grad_fn=<DivBackward0>)\n",
            "97874 : avg_loss:  tensor(1.1692e-11, grad_fn=<DivBackward0>)\n",
            "97875 : avg_loss:  tensor(1.1692e-11, grad_fn=<DivBackward0>)\n",
            "97876 : avg_loss:  tensor(1.1692e-11, grad_fn=<DivBackward0>)\n",
            "97877 : avg_loss:  tensor(1.1692e-11, grad_fn=<DivBackward0>)\n",
            "97878 : avg_loss:  tensor(1.1692e-11, grad_fn=<DivBackward0>)\n",
            "97879 : avg_loss:  tensor(1.1692e-11, grad_fn=<DivBackward0>)\n",
            "97880 : avg_loss:  tensor(1.1691e-11, grad_fn=<DivBackward0>)\n",
            "97881 : avg_loss:  tensor(1.1691e-11, grad_fn=<DivBackward0>)\n",
            "97882 : avg_loss:  tensor(1.1691e-11, grad_fn=<DivBackward0>)\n",
            "97883 : avg_loss:  tensor(1.1690e-11, grad_fn=<DivBackward0>)\n",
            "97884 : avg_loss:  tensor(1.1690e-11, grad_fn=<DivBackward0>)\n",
            "97885 : avg_loss:  tensor(1.1690e-11, grad_fn=<DivBackward0>)\n",
            "97886 : avg_loss:  tensor(1.1690e-11, grad_fn=<DivBackward0>)\n",
            "97887 : avg_loss:  tensor(1.1689e-11, grad_fn=<DivBackward0>)\n",
            "97888 : avg_loss:  tensor(1.1689e-11, grad_fn=<DivBackward0>)\n",
            "97889 : avg_loss:  tensor(1.1689e-11, grad_fn=<DivBackward0>)\n",
            "97890 : avg_loss:  tensor(1.1689e-11, grad_fn=<DivBackward0>)\n",
            "97891 : avg_loss:  tensor(1.1689e-11, grad_fn=<DivBackward0>)\n",
            "97892 : avg_loss:  tensor(1.1688e-11, grad_fn=<DivBackward0>)\n",
            "97893 : avg_loss:  tensor(1.1688e-11, grad_fn=<DivBackward0>)\n",
            "97894 : avg_loss:  tensor(1.1688e-11, grad_fn=<DivBackward0>)\n",
            "97895 : avg_loss:  tensor(1.1688e-11, grad_fn=<DivBackward0>)\n",
            "97896 : avg_loss:  tensor(1.1688e-11, grad_fn=<DivBackward0>)\n",
            "97897 : avg_loss:  tensor(1.1687e-11, grad_fn=<DivBackward0>)\n",
            "97898 : avg_loss:  tensor(1.1687e-11, grad_fn=<DivBackward0>)\n",
            "97899 : avg_loss:  tensor(1.1687e-11, grad_fn=<DivBackward0>)\n",
            "97900 : avg_loss:  tensor(1.1686e-11, grad_fn=<DivBackward0>)\n",
            "97901 : avg_loss:  tensor(1.1686e-11, grad_fn=<DivBackward0>)\n",
            "97902 : avg_loss:  tensor(1.1686e-11, grad_fn=<DivBackward0>)\n",
            "97903 : avg_loss:  tensor(1.1686e-11, grad_fn=<DivBackward0>)\n",
            "97904 : avg_loss:  tensor(1.1685e-11, grad_fn=<DivBackward0>)\n",
            "97905 : avg_loss:  tensor(1.1685e-11, grad_fn=<DivBackward0>)\n",
            "97906 : avg_loss:  tensor(1.1685e-11, grad_fn=<DivBackward0>)\n",
            "97907 : avg_loss:  tensor(1.1685e-11, grad_fn=<DivBackward0>)\n",
            "97908 : avg_loss:  tensor(1.1685e-11, grad_fn=<DivBackward0>)\n",
            "97909 : avg_loss:  tensor(1.1684e-11, grad_fn=<DivBackward0>)\n",
            "97910 : avg_loss:  tensor(1.1684e-11, grad_fn=<DivBackward0>)\n",
            "97911 : avg_loss:  tensor(1.1684e-11, grad_fn=<DivBackward0>)\n",
            "97912 : avg_loss:  tensor(1.1684e-11, grad_fn=<DivBackward0>)\n",
            "97913 : avg_loss:  tensor(1.1683e-11, grad_fn=<DivBackward0>)\n",
            "97914 : avg_loss:  tensor(1.1683e-11, grad_fn=<DivBackward0>)\n",
            "97915 : avg_loss:  tensor(1.1683e-11, grad_fn=<DivBackward0>)\n",
            "97916 : avg_loss:  tensor(1.1683e-11, grad_fn=<DivBackward0>)\n",
            "97917 : avg_loss:  tensor(1.1682e-11, grad_fn=<DivBackward0>)\n",
            "97918 : avg_loss:  tensor(1.1682e-11, grad_fn=<DivBackward0>)\n",
            "97919 : avg_loss:  tensor(1.1682e-11, grad_fn=<DivBackward0>)\n",
            "97920 : avg_loss:  tensor(1.1682e-11, grad_fn=<DivBackward0>)\n",
            "97921 : avg_loss:  tensor(1.1681e-11, grad_fn=<DivBackward0>)\n",
            "97922 : avg_loss:  tensor(1.1681e-11, grad_fn=<DivBackward0>)\n",
            "97923 : avg_loss:  tensor(1.1681e-11, grad_fn=<DivBackward0>)\n",
            "97924 : avg_loss:  tensor(1.1681e-11, grad_fn=<DivBackward0>)\n",
            "97925 : avg_loss:  tensor(1.1681e-11, grad_fn=<DivBackward0>)\n",
            "97926 : avg_loss:  tensor(1.1680e-11, grad_fn=<DivBackward0>)\n",
            "97927 : avg_loss:  tensor(1.1680e-11, grad_fn=<DivBackward0>)\n",
            "97928 : avg_loss:  tensor(1.1680e-11, grad_fn=<DivBackward0>)\n",
            "97929 : avg_loss:  tensor(1.1680e-11, grad_fn=<DivBackward0>)\n",
            "97930 : avg_loss:  tensor(1.1679e-11, grad_fn=<DivBackward0>)\n",
            "97931 : avg_loss:  tensor(1.1679e-11, grad_fn=<DivBackward0>)\n",
            "97932 : avg_loss:  tensor(1.1679e-11, grad_fn=<DivBackward0>)\n",
            "97933 : avg_loss:  tensor(1.1678e-11, grad_fn=<DivBackward0>)\n",
            "97934 : avg_loss:  tensor(1.1678e-11, grad_fn=<DivBackward0>)\n",
            "97935 : avg_loss:  tensor(1.1678e-11, grad_fn=<DivBackward0>)\n",
            "97936 : avg_loss:  tensor(1.1678e-11, grad_fn=<DivBackward0>)\n",
            "97937 : avg_loss:  tensor(1.1677e-11, grad_fn=<DivBackward0>)\n",
            "97938 : avg_loss:  tensor(1.1677e-11, grad_fn=<DivBackward0>)\n",
            "97939 : avg_loss:  tensor(1.1677e-11, grad_fn=<DivBackward0>)\n",
            "97940 : avg_loss:  tensor(1.1677e-11, grad_fn=<DivBackward0>)\n",
            "97941 : avg_loss:  tensor(1.1677e-11, grad_fn=<DivBackward0>)\n",
            "97942 : avg_loss:  tensor(1.1676e-11, grad_fn=<DivBackward0>)\n",
            "97943 : avg_loss:  tensor(1.1676e-11, grad_fn=<DivBackward0>)\n",
            "97944 : avg_loss:  tensor(1.1676e-11, grad_fn=<DivBackward0>)\n",
            "97945 : avg_loss:  tensor(1.1676e-11, grad_fn=<DivBackward0>)\n",
            "97946 : avg_loss:  tensor(1.1675e-11, grad_fn=<DivBackward0>)\n",
            "97947 : avg_loss:  tensor(1.1675e-11, grad_fn=<DivBackward0>)\n",
            "97948 : avg_loss:  tensor(1.1675e-11, grad_fn=<DivBackward0>)\n",
            "97949 : avg_loss:  tensor(1.1675e-11, grad_fn=<DivBackward0>)\n",
            "97950 : avg_loss:  tensor(1.1674e-11, grad_fn=<DivBackward0>)\n",
            "97951 : avg_loss:  tensor(1.1674e-11, grad_fn=<DivBackward0>)\n",
            "97952 : avg_loss:  tensor(1.1674e-11, grad_fn=<DivBackward0>)\n",
            "97953 : avg_loss:  tensor(1.1673e-11, grad_fn=<DivBackward0>)\n",
            "97954 : avg_loss:  tensor(1.1673e-11, grad_fn=<DivBackward0>)\n",
            "97955 : avg_loss:  tensor(1.1673e-11, grad_fn=<DivBackward0>)\n",
            "97956 : avg_loss:  tensor(1.1673e-11, grad_fn=<DivBackward0>)\n",
            "97957 : avg_loss:  tensor(1.1672e-11, grad_fn=<DivBackward0>)\n",
            "97958 : avg_loss:  tensor(1.1672e-11, grad_fn=<DivBackward0>)\n",
            "97959 : avg_loss:  tensor(1.1672e-11, grad_fn=<DivBackward0>)\n",
            "97960 : avg_loss:  tensor(1.1672e-11, grad_fn=<DivBackward0>)\n",
            "97961 : avg_loss:  tensor(1.1671e-11, grad_fn=<DivBackward0>)\n",
            "97962 : avg_loss:  tensor(1.1671e-11, grad_fn=<DivBackward0>)\n",
            "97963 : avg_loss:  tensor(1.1671e-11, grad_fn=<DivBackward0>)\n",
            "97964 : avg_loss:  tensor(1.1671e-11, grad_fn=<DivBackward0>)\n",
            "97965 : avg_loss:  tensor(1.1671e-11, grad_fn=<DivBackward0>)\n",
            "97966 : avg_loss:  tensor(1.1670e-11, grad_fn=<DivBackward0>)\n",
            "97967 : avg_loss:  tensor(1.1670e-11, grad_fn=<DivBackward0>)\n",
            "97968 : avg_loss:  tensor(1.1670e-11, grad_fn=<DivBackward0>)\n",
            "97969 : avg_loss:  tensor(1.1669e-11, grad_fn=<DivBackward0>)\n",
            "97970 : avg_loss:  tensor(1.1669e-11, grad_fn=<DivBackward0>)\n",
            "97971 : avg_loss:  tensor(1.1669e-11, grad_fn=<DivBackward0>)\n",
            "97972 : avg_loss:  tensor(1.1669e-11, grad_fn=<DivBackward0>)\n",
            "97973 : avg_loss:  tensor(1.1669e-11, grad_fn=<DivBackward0>)\n",
            "97974 : avg_loss:  tensor(1.1668e-11, grad_fn=<DivBackward0>)\n",
            "97975 : avg_loss:  tensor(1.1668e-11, grad_fn=<DivBackward0>)\n",
            "97976 : avg_loss:  tensor(1.1668e-11, grad_fn=<DivBackward0>)\n",
            "97977 : avg_loss:  tensor(1.1667e-11, grad_fn=<DivBackward0>)\n",
            "97978 : avg_loss:  tensor(1.1667e-11, grad_fn=<DivBackward0>)\n",
            "97979 : avg_loss:  tensor(1.1667e-11, grad_fn=<DivBackward0>)\n",
            "97980 : avg_loss:  tensor(1.1667e-11, grad_fn=<DivBackward0>)\n",
            "97981 : avg_loss:  tensor(1.1667e-11, grad_fn=<DivBackward0>)\n",
            "97982 : avg_loss:  tensor(1.1666e-11, grad_fn=<DivBackward0>)\n",
            "97983 : avg_loss:  tensor(1.1666e-11, grad_fn=<DivBackward0>)\n",
            "97984 : avg_loss:  tensor(1.1666e-11, grad_fn=<DivBackward0>)\n",
            "97985 : avg_loss:  tensor(1.1666e-11, grad_fn=<DivBackward0>)\n",
            "97986 : avg_loss:  tensor(1.1665e-11, grad_fn=<DivBackward0>)\n",
            "97987 : avg_loss:  tensor(1.1665e-11, grad_fn=<DivBackward0>)\n",
            "97988 : avg_loss:  tensor(1.1665e-11, grad_fn=<DivBackward0>)\n",
            "97989 : avg_loss:  tensor(1.1665e-11, grad_fn=<DivBackward0>)\n",
            "97990 : avg_loss:  tensor(1.1664e-11, grad_fn=<DivBackward0>)\n",
            "97991 : avg_loss:  tensor(1.1664e-11, grad_fn=<DivBackward0>)\n",
            "97992 : avg_loss:  tensor(1.1664e-11, grad_fn=<DivBackward0>)\n",
            "97993 : avg_loss:  tensor(1.1664e-11, grad_fn=<DivBackward0>)\n",
            "97994 : avg_loss:  tensor(1.1663e-11, grad_fn=<DivBackward0>)\n",
            "97995 : avg_loss:  tensor(1.1663e-11, grad_fn=<DivBackward0>)\n",
            "97996 : avg_loss:  tensor(1.1663e-11, grad_fn=<DivBackward0>)\n",
            "97997 : avg_loss:  tensor(1.1663e-11, grad_fn=<DivBackward0>)\n",
            "97998 : avg_loss:  tensor(1.1662e-11, grad_fn=<DivBackward0>)\n",
            "97999 : avg_loss:  tensor(1.1662e-11, grad_fn=<DivBackward0>)\n",
            "98000 : avg_loss:  tensor(1.1662e-11, grad_fn=<DivBackward0>)\n",
            "98001 : avg_loss:  tensor(1.1662e-11, grad_fn=<DivBackward0>)\n",
            "98002 : avg_loss:  tensor(1.1661e-11, grad_fn=<DivBackward0>)\n",
            "98003 : avg_loss:  tensor(1.1661e-11, grad_fn=<DivBackward0>)\n",
            "98004 : avg_loss:  tensor(1.1661e-11, grad_fn=<DivBackward0>)\n",
            "98005 : avg_loss:  tensor(1.1661e-11, grad_fn=<DivBackward0>)\n",
            "98006 : avg_loss:  tensor(1.1661e-11, grad_fn=<DivBackward0>)\n",
            "98007 : avg_loss:  tensor(1.1660e-11, grad_fn=<DivBackward0>)\n",
            "98008 : avg_loss:  tensor(1.1660e-11, grad_fn=<DivBackward0>)\n",
            "98009 : avg_loss:  tensor(1.1660e-11, grad_fn=<DivBackward0>)\n",
            "98010 : avg_loss:  tensor(1.1660e-11, grad_fn=<DivBackward0>)\n",
            "98011 : avg_loss:  tensor(1.1659e-11, grad_fn=<DivBackward0>)\n",
            "98012 : avg_loss:  tensor(1.1659e-11, grad_fn=<DivBackward0>)\n",
            "98013 : avg_loss:  tensor(1.1659e-11, grad_fn=<DivBackward0>)\n",
            "98014 : avg_loss:  tensor(1.1659e-11, grad_fn=<DivBackward0>)\n",
            "98015 : avg_loss:  tensor(1.1658e-11, grad_fn=<DivBackward0>)\n",
            "98016 : avg_loss:  tensor(1.1658e-11, grad_fn=<DivBackward0>)\n",
            "98017 : avg_loss:  tensor(1.1658e-11, grad_fn=<DivBackward0>)\n",
            "98018 : avg_loss:  tensor(1.1657e-11, grad_fn=<DivBackward0>)\n",
            "98019 : avg_loss:  tensor(1.1657e-11, grad_fn=<DivBackward0>)\n",
            "98020 : avg_loss:  tensor(1.1657e-11, grad_fn=<DivBackward0>)\n",
            "98021 : avg_loss:  tensor(1.1657e-11, grad_fn=<DivBackward0>)\n",
            "98022 : avg_loss:  tensor(1.1657e-11, grad_fn=<DivBackward0>)\n",
            "98023 : avg_loss:  tensor(1.1656e-11, grad_fn=<DivBackward0>)\n",
            "98024 : avg_loss:  tensor(1.1656e-11, grad_fn=<DivBackward0>)\n",
            "98025 : avg_loss:  tensor(1.1656e-11, grad_fn=<DivBackward0>)\n",
            "98026 : avg_loss:  tensor(1.1656e-11, grad_fn=<DivBackward0>)\n",
            "98027 : avg_loss:  tensor(1.1655e-11, grad_fn=<DivBackward0>)\n",
            "98028 : avg_loss:  tensor(1.1655e-11, grad_fn=<DivBackward0>)\n",
            "98029 : avg_loss:  tensor(1.1655e-11, grad_fn=<DivBackward0>)\n",
            "98030 : avg_loss:  tensor(1.1654e-11, grad_fn=<DivBackward0>)\n",
            "98031 : avg_loss:  tensor(1.1654e-11, grad_fn=<DivBackward0>)\n",
            "98032 : avg_loss:  tensor(1.1654e-11, grad_fn=<DivBackward0>)\n",
            "98033 : avg_loss:  tensor(1.1654e-11, grad_fn=<DivBackward0>)\n",
            "98034 : avg_loss:  tensor(1.1653e-11, grad_fn=<DivBackward0>)\n",
            "98035 : avg_loss:  tensor(1.1653e-11, grad_fn=<DivBackward0>)\n",
            "98036 : avg_loss:  tensor(1.1653e-11, grad_fn=<DivBackward0>)\n",
            "98037 : avg_loss:  tensor(1.1653e-11, grad_fn=<DivBackward0>)\n",
            "98038 : avg_loss:  tensor(1.1653e-11, grad_fn=<DivBackward0>)\n",
            "98039 : avg_loss:  tensor(1.1652e-11, grad_fn=<DivBackward0>)\n",
            "98040 : avg_loss:  tensor(1.1652e-11, grad_fn=<DivBackward0>)\n",
            "98041 : avg_loss:  tensor(1.1652e-11, grad_fn=<DivBackward0>)\n",
            "98042 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98043 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98044 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98045 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98046 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98047 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98048 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98049 : avg_loss:  tensor(1.1649e-11, grad_fn=<DivBackward0>)\n",
            "98050 : avg_loss:  tensor(1.1649e-11, grad_fn=<DivBackward0>)\n",
            "98051 : avg_loss:  tensor(1.1652e-11, grad_fn=<DivBackward0>)\n",
            "98052 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98053 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98054 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98055 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98056 : avg_loss:  tensor(1.1651e-11, grad_fn=<DivBackward0>)\n",
            "98057 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98058 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98059 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98060 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98061 : avg_loss:  tensor(1.1650e-11, grad_fn=<DivBackward0>)\n",
            "98062 : avg_loss:  tensor(1.1649e-11, grad_fn=<DivBackward0>)\n",
            "98063 : avg_loss:  tensor(1.1649e-11, grad_fn=<DivBackward0>)\n",
            "98064 : avg_loss:  tensor(1.1648e-11, grad_fn=<DivBackward0>)\n",
            "98065 : avg_loss:  tensor(1.1648e-11, grad_fn=<DivBackward0>)\n",
            "98066 : avg_loss:  tensor(1.1648e-11, grad_fn=<DivBackward0>)\n",
            "98067 : avg_loss:  tensor(1.1648e-11, grad_fn=<DivBackward0>)\n",
            "98068 : avg_loss:  tensor(1.1647e-11, grad_fn=<DivBackward0>)\n",
            "98069 : avg_loss:  tensor(1.1647e-11, grad_fn=<DivBackward0>)\n",
            "98070 : avg_loss:  tensor(1.1647e-11, grad_fn=<DivBackward0>)\n",
            "98071 : avg_loss:  tensor(1.1647e-11, grad_fn=<DivBackward0>)\n",
            "98072 : avg_loss:  tensor(1.1646e-11, grad_fn=<DivBackward0>)\n",
            "98073 : avg_loss:  tensor(1.1646e-11, grad_fn=<DivBackward0>)\n",
            "98074 : avg_loss:  tensor(1.1646e-11, grad_fn=<DivBackward0>)\n",
            "98075 : avg_loss:  tensor(1.1646e-11, grad_fn=<DivBackward0>)\n",
            "98076 : avg_loss:  tensor(1.1645e-11, grad_fn=<DivBackward0>)\n",
            "98077 : avg_loss:  tensor(1.1645e-11, grad_fn=<DivBackward0>)\n",
            "98078 : avg_loss:  tensor(1.1645e-11, grad_fn=<DivBackward0>)\n",
            "98079 : avg_loss:  tensor(1.1645e-11, grad_fn=<DivBackward0>)\n",
            "98080 : avg_loss:  tensor(1.1644e-11, grad_fn=<DivBackward0>)\n",
            "98081 : avg_loss:  tensor(1.1644e-11, grad_fn=<DivBackward0>)\n",
            "98082 : avg_loss:  tensor(1.1644e-11, grad_fn=<DivBackward0>)\n",
            "98083 : avg_loss:  tensor(1.1644e-11, grad_fn=<DivBackward0>)\n",
            "98084 : avg_loss:  tensor(1.1644e-11, grad_fn=<DivBackward0>)\n",
            "98085 : avg_loss:  tensor(1.1643e-11, grad_fn=<DivBackward0>)\n",
            "98086 : avg_loss:  tensor(1.1643e-11, grad_fn=<DivBackward0>)\n",
            "98087 : avg_loss:  tensor(1.1643e-11, grad_fn=<DivBackward0>)\n",
            "98088 : avg_loss:  tensor(1.1642e-11, grad_fn=<DivBackward0>)\n",
            "98089 : avg_loss:  tensor(1.1642e-11, grad_fn=<DivBackward0>)\n",
            "98090 : avg_loss:  tensor(1.1642e-11, grad_fn=<DivBackward0>)\n",
            "98091 : avg_loss:  tensor(1.1642e-11, grad_fn=<DivBackward0>)\n",
            "98092 : avg_loss:  tensor(1.1641e-11, grad_fn=<DivBackward0>)\n",
            "98093 : avg_loss:  tensor(1.1641e-11, grad_fn=<DivBackward0>)\n",
            "98094 : avg_loss:  tensor(1.1641e-11, grad_fn=<DivBackward0>)\n",
            "98095 : avg_loss:  tensor(1.1641e-11, grad_fn=<DivBackward0>)\n",
            "98096 : avg_loss:  tensor(1.1640e-11, grad_fn=<DivBackward0>)\n",
            "98097 : avg_loss:  tensor(1.1640e-11, grad_fn=<DivBackward0>)\n",
            "98098 : avg_loss:  tensor(1.1640e-11, grad_fn=<DivBackward0>)\n",
            "98099 : avg_loss:  tensor(1.1640e-11, grad_fn=<DivBackward0>)\n",
            "98100 : avg_loss:  tensor(1.1639e-11, grad_fn=<DivBackward0>)\n",
            "98101 : avg_loss:  tensor(1.1639e-11, grad_fn=<DivBackward0>)\n",
            "98102 : avg_loss:  tensor(1.1639e-11, grad_fn=<DivBackward0>)\n",
            "98103 : avg_loss:  tensor(1.1639e-11, grad_fn=<DivBackward0>)\n",
            "98104 : avg_loss:  tensor(1.1638e-11, grad_fn=<DivBackward0>)\n",
            "98105 : avg_loss:  tensor(1.1638e-11, grad_fn=<DivBackward0>)\n",
            "98106 : avg_loss:  tensor(1.1638e-11, grad_fn=<DivBackward0>)\n",
            "98107 : avg_loss:  tensor(1.1638e-11, grad_fn=<DivBackward0>)\n",
            "98108 : avg_loss:  tensor(1.1637e-11, grad_fn=<DivBackward0>)\n",
            "98109 : avg_loss:  tensor(1.1637e-11, grad_fn=<DivBackward0>)\n",
            "98110 : avg_loss:  tensor(1.1637e-11, grad_fn=<DivBackward0>)\n",
            "98111 : avg_loss:  tensor(1.1636e-11, grad_fn=<DivBackward0>)\n",
            "98112 : avg_loss:  tensor(1.1636e-11, grad_fn=<DivBackward0>)\n",
            "98113 : avg_loss:  tensor(1.1636e-11, grad_fn=<DivBackward0>)\n",
            "98114 : avg_loss:  tensor(1.1636e-11, grad_fn=<DivBackward0>)\n",
            "98115 : avg_loss:  tensor(1.1636e-11, grad_fn=<DivBackward0>)\n",
            "98116 : avg_loss:  tensor(1.1635e-11, grad_fn=<DivBackward0>)\n",
            "98117 : avg_loss:  tensor(1.1635e-11, grad_fn=<DivBackward0>)\n",
            "98118 : avg_loss:  tensor(1.1635e-11, grad_fn=<DivBackward0>)\n",
            "98119 : avg_loss:  tensor(1.1634e-11, grad_fn=<DivBackward0>)\n",
            "98120 : avg_loss:  tensor(1.1634e-11, grad_fn=<DivBackward0>)\n",
            "98121 : avg_loss:  tensor(1.1634e-11, grad_fn=<DivBackward0>)\n",
            "98122 : avg_loss:  tensor(1.1634e-11, grad_fn=<DivBackward0>)\n",
            "98123 : avg_loss:  tensor(1.1634e-11, grad_fn=<DivBackward0>)\n",
            "98124 : avg_loss:  tensor(1.1633e-11, grad_fn=<DivBackward0>)\n",
            "98125 : avg_loss:  tensor(1.1633e-11, grad_fn=<DivBackward0>)\n",
            "98126 : avg_loss:  tensor(1.1633e-11, grad_fn=<DivBackward0>)\n",
            "98127 : avg_loss:  tensor(1.1632e-11, grad_fn=<DivBackward0>)\n",
            "98128 : avg_loss:  tensor(1.1632e-11, grad_fn=<DivBackward0>)\n",
            "98129 : avg_loss:  tensor(1.1632e-11, grad_fn=<DivBackward0>)\n",
            "98130 : avg_loss:  tensor(1.1632e-11, grad_fn=<DivBackward0>)\n",
            "98131 : avg_loss:  tensor(1.1631e-11, grad_fn=<DivBackward0>)\n",
            "98132 : avg_loss:  tensor(1.1631e-11, grad_fn=<DivBackward0>)\n",
            "98133 : avg_loss:  tensor(1.1631e-11, grad_fn=<DivBackward0>)\n",
            "98134 : avg_loss:  tensor(1.1631e-11, grad_fn=<DivBackward0>)\n",
            "98135 : avg_loss:  tensor(1.1630e-11, grad_fn=<DivBackward0>)\n",
            "98136 : avg_loss:  tensor(1.1630e-11, grad_fn=<DivBackward0>)\n",
            "98137 : avg_loss:  tensor(1.1630e-11, grad_fn=<DivBackward0>)\n",
            "98138 : avg_loss:  tensor(1.1630e-11, grad_fn=<DivBackward0>)\n",
            "98139 : avg_loss:  tensor(1.1630e-11, grad_fn=<DivBackward0>)\n",
            "98140 : avg_loss:  tensor(1.1629e-11, grad_fn=<DivBackward0>)\n",
            "98141 : avg_loss:  tensor(1.1629e-11, grad_fn=<DivBackward0>)\n",
            "98142 : avg_loss:  tensor(1.1628e-11, grad_fn=<DivBackward0>)\n",
            "98143 : avg_loss:  tensor(1.1628e-11, grad_fn=<DivBackward0>)\n",
            "98144 : avg_loss:  tensor(1.1628e-11, grad_fn=<DivBackward0>)\n",
            "98145 : avg_loss:  tensor(1.1628e-11, grad_fn=<DivBackward0>)\n",
            "98146 : avg_loss:  tensor(1.1627e-11, grad_fn=<DivBackward0>)\n",
            "98147 : avg_loss:  tensor(1.1627e-11, grad_fn=<DivBackward0>)\n",
            "98148 : avg_loss:  tensor(1.1627e-11, grad_fn=<DivBackward0>)\n",
            "98149 : avg_loss:  tensor(1.1627e-11, grad_fn=<DivBackward0>)\n",
            "98150 : avg_loss:  tensor(1.1626e-11, grad_fn=<DivBackward0>)\n",
            "98151 : avg_loss:  tensor(1.1626e-11, grad_fn=<DivBackward0>)\n",
            "98152 : avg_loss:  tensor(1.1626e-11, grad_fn=<DivBackward0>)\n",
            "98153 : avg_loss:  tensor(1.1625e-11, grad_fn=<DivBackward0>)\n",
            "98154 : avg_loss:  tensor(1.1625e-11, grad_fn=<DivBackward0>)\n",
            "98155 : avg_loss:  tensor(1.1625e-11, grad_fn=<DivBackward0>)\n",
            "98156 : avg_loss:  tensor(1.1625e-11, grad_fn=<DivBackward0>)\n",
            "98157 : avg_loss:  tensor(1.1624e-11, grad_fn=<DivBackward0>)\n",
            "98158 : avg_loss:  tensor(1.1624e-11, grad_fn=<DivBackward0>)\n",
            "98159 : avg_loss:  tensor(1.1624e-11, grad_fn=<DivBackward0>)\n",
            "98160 : avg_loss:  tensor(1.1624e-11, grad_fn=<DivBackward0>)\n",
            "98161 : avg_loss:  tensor(1.1623e-11, grad_fn=<DivBackward0>)\n",
            "98162 : avg_loss:  tensor(1.1623e-11, grad_fn=<DivBackward0>)\n",
            "98163 : avg_loss:  tensor(1.1623e-11, grad_fn=<DivBackward0>)\n",
            "98164 : avg_loss:  tensor(1.1623e-11, grad_fn=<DivBackward0>)\n",
            "98165 : avg_loss:  tensor(1.1622e-11, grad_fn=<DivBackward0>)\n",
            "98166 : avg_loss:  tensor(1.1622e-11, grad_fn=<DivBackward0>)\n",
            "98167 : avg_loss:  tensor(1.1622e-11, grad_fn=<DivBackward0>)\n",
            "98168 : avg_loss:  tensor(1.1622e-11, grad_fn=<DivBackward0>)\n",
            "98169 : avg_loss:  tensor(1.1621e-11, grad_fn=<DivBackward0>)\n",
            "98170 : avg_loss:  tensor(1.1621e-11, grad_fn=<DivBackward0>)\n",
            "98171 : avg_loss:  tensor(1.1621e-11, grad_fn=<DivBackward0>)\n",
            "98172 : avg_loss:  tensor(1.1621e-11, grad_fn=<DivBackward0>)\n",
            "98173 : avg_loss:  tensor(1.1620e-11, grad_fn=<DivBackward0>)\n",
            "98174 : avg_loss:  tensor(1.1620e-11, grad_fn=<DivBackward0>)\n",
            "98175 : avg_loss:  tensor(1.1620e-11, grad_fn=<DivBackward0>)\n",
            "98176 : avg_loss:  tensor(1.1619e-11, grad_fn=<DivBackward0>)\n",
            "98177 : avg_loss:  tensor(1.1619e-11, grad_fn=<DivBackward0>)\n",
            "98178 : avg_loss:  tensor(1.1619e-11, grad_fn=<DivBackward0>)\n",
            "98179 : avg_loss:  tensor(1.1619e-11, grad_fn=<DivBackward0>)\n",
            "98180 : avg_loss:  tensor(1.1619e-11, grad_fn=<DivBackward0>)\n",
            "98181 : avg_loss:  tensor(1.1618e-11, grad_fn=<DivBackward0>)\n",
            "98182 : avg_loss:  tensor(1.1618e-11, grad_fn=<DivBackward0>)\n",
            "98183 : avg_loss:  tensor(1.1618e-11, grad_fn=<DivBackward0>)\n",
            "98184 : avg_loss:  tensor(1.1618e-11, grad_fn=<DivBackward0>)\n",
            "98185 : avg_loss:  tensor(1.1617e-11, grad_fn=<DivBackward0>)\n",
            "98186 : avg_loss:  tensor(1.1617e-11, grad_fn=<DivBackward0>)\n",
            "98187 : avg_loss:  tensor(1.1616e-11, grad_fn=<DivBackward0>)\n",
            "98188 : avg_loss:  tensor(1.1616e-11, grad_fn=<DivBackward0>)\n",
            "98189 : avg_loss:  tensor(1.1616e-11, grad_fn=<DivBackward0>)\n",
            "98190 : avg_loss:  tensor(1.1616e-11, grad_fn=<DivBackward0>)\n",
            "98191 : avg_loss:  tensor(1.1616e-11, grad_fn=<DivBackward0>)\n",
            "98192 : avg_loss:  tensor(1.1615e-11, grad_fn=<DivBackward0>)\n",
            "98193 : avg_loss:  tensor(1.1615e-11, grad_fn=<DivBackward0>)\n",
            "98194 : avg_loss:  tensor(1.1615e-11, grad_fn=<DivBackward0>)\n",
            "98195 : avg_loss:  tensor(1.1615e-11, grad_fn=<DivBackward0>)\n",
            "98196 : avg_loss:  tensor(1.1614e-11, grad_fn=<DivBackward0>)\n",
            "98197 : avg_loss:  tensor(1.1614e-11, grad_fn=<DivBackward0>)\n",
            "98198 : avg_loss:  tensor(1.1614e-11, grad_fn=<DivBackward0>)\n",
            "98199 : avg_loss:  tensor(1.1614e-11, grad_fn=<DivBackward0>)\n",
            "98200 : avg_loss:  tensor(1.1613e-11, grad_fn=<DivBackward0>)\n",
            "98201 : avg_loss:  tensor(1.1613e-11, grad_fn=<DivBackward0>)\n",
            "98202 : avg_loss:  tensor(1.1613e-11, grad_fn=<DivBackward0>)\n",
            "98203 : avg_loss:  tensor(1.1612e-11, grad_fn=<DivBackward0>)\n",
            "98204 : avg_loss:  tensor(1.1612e-11, grad_fn=<DivBackward0>)\n",
            "98205 : avg_loss:  tensor(1.1612e-11, grad_fn=<DivBackward0>)\n",
            "98206 : avg_loss:  tensor(1.1612e-11, grad_fn=<DivBackward0>)\n",
            "98207 : avg_loss:  tensor(1.1611e-11, grad_fn=<DivBackward0>)\n",
            "98208 : avg_loss:  tensor(1.1611e-11, grad_fn=<DivBackward0>)\n",
            "98209 : avg_loss:  tensor(1.1611e-11, grad_fn=<DivBackward0>)\n",
            "98210 : avg_loss:  tensor(1.1610e-11, grad_fn=<DivBackward0>)\n",
            "98211 : avg_loss:  tensor(1.1610e-11, grad_fn=<DivBackward0>)\n",
            "98212 : avg_loss:  tensor(1.1610e-11, grad_fn=<DivBackward0>)\n",
            "98213 : avg_loss:  tensor(1.1610e-11, grad_fn=<DivBackward0>)\n",
            "98214 : avg_loss:  tensor(1.1610e-11, grad_fn=<DivBackward0>)\n",
            "98215 : avg_loss:  tensor(1.1609e-11, grad_fn=<DivBackward0>)\n",
            "98216 : avg_loss:  tensor(1.1609e-11, grad_fn=<DivBackward0>)\n",
            "98217 : avg_loss:  tensor(1.1609e-11, grad_fn=<DivBackward0>)\n",
            "98218 : avg_loss:  tensor(1.1608e-11, grad_fn=<DivBackward0>)\n",
            "98219 : avg_loss:  tensor(1.1608e-11, grad_fn=<DivBackward0>)\n",
            "98220 : avg_loss:  tensor(1.1608e-11, grad_fn=<DivBackward0>)\n",
            "98221 : avg_loss:  tensor(1.1607e-11, grad_fn=<DivBackward0>)\n",
            "98222 : avg_loss:  tensor(1.1607e-11, grad_fn=<DivBackward0>)\n",
            "98223 : avg_loss:  tensor(1.1607e-11, grad_fn=<DivBackward0>)\n",
            "98224 : avg_loss:  tensor(1.1607e-11, grad_fn=<DivBackward0>)\n",
            "98225 : avg_loss:  tensor(1.1607e-11, grad_fn=<DivBackward0>)\n",
            "98226 : avg_loss:  tensor(1.1606e-11, grad_fn=<DivBackward0>)\n",
            "98227 : avg_loss:  tensor(1.1606e-11, grad_fn=<DivBackward0>)\n",
            "98228 : avg_loss:  tensor(1.1606e-11, grad_fn=<DivBackward0>)\n",
            "98229 : avg_loss:  tensor(1.1606e-11, grad_fn=<DivBackward0>)\n",
            "98230 : avg_loss:  tensor(1.1605e-11, grad_fn=<DivBackward0>)\n",
            "98231 : avg_loss:  tensor(1.1604e-11, grad_fn=<DivBackward0>)\n",
            "98232 : avg_loss:  tensor(1.1604e-11, grad_fn=<DivBackward0>)\n",
            "98233 : avg_loss:  tensor(1.1604e-11, grad_fn=<DivBackward0>)\n",
            "98234 : avg_loss:  tensor(1.1604e-11, grad_fn=<DivBackward0>)\n",
            "98235 : avg_loss:  tensor(1.1604e-11, grad_fn=<DivBackward0>)\n",
            "98236 : avg_loss:  tensor(1.1603e-11, grad_fn=<DivBackward0>)\n",
            "98237 : avg_loss:  tensor(1.1603e-11, grad_fn=<DivBackward0>)\n",
            "98238 : avg_loss:  tensor(1.1603e-11, grad_fn=<DivBackward0>)\n",
            "98239 : avg_loss:  tensor(1.1603e-11, grad_fn=<DivBackward0>)\n",
            "98240 : avg_loss:  tensor(1.1602e-11, grad_fn=<DivBackward0>)\n",
            "98241 : avg_loss:  tensor(1.1602e-11, grad_fn=<DivBackward0>)\n",
            "98242 : avg_loss:  tensor(1.1602e-11, grad_fn=<DivBackward0>)\n",
            "98243 : avg_loss:  tensor(1.1601e-11, grad_fn=<DivBackward0>)\n",
            "98244 : avg_loss:  tensor(1.1601e-11, grad_fn=<DivBackward0>)\n",
            "98245 : avg_loss:  tensor(1.1601e-11, grad_fn=<DivBackward0>)\n",
            "98246 : avg_loss:  tensor(1.1600e-11, grad_fn=<DivBackward0>)\n",
            "98247 : avg_loss:  tensor(1.1600e-11, grad_fn=<DivBackward0>)\n",
            "98248 : avg_loss:  tensor(1.1600e-11, grad_fn=<DivBackward0>)\n",
            "98249 : avg_loss:  tensor(1.1600e-11, grad_fn=<DivBackward0>)\n",
            "98250 : avg_loss:  tensor(1.1599e-11, grad_fn=<DivBackward0>)\n",
            "98251 : avg_loss:  tensor(1.1599e-11, grad_fn=<DivBackward0>)\n",
            "98252 : avg_loss:  tensor(1.1599e-11, grad_fn=<DivBackward0>)\n",
            "98253 : avg_loss:  tensor(1.1599e-11, grad_fn=<DivBackward0>)\n",
            "98254 : avg_loss:  tensor(1.1598e-11, grad_fn=<DivBackward0>)\n",
            "98255 : avg_loss:  tensor(1.1598e-11, grad_fn=<DivBackward0>)\n",
            "98256 : avg_loss:  tensor(1.1598e-11, grad_fn=<DivBackward0>)\n",
            "98257 : avg_loss:  tensor(1.1598e-11, grad_fn=<DivBackward0>)\n",
            "98258 : avg_loss:  tensor(1.1597e-11, grad_fn=<DivBackward0>)\n",
            "98259 : avg_loss:  tensor(1.1597e-11, grad_fn=<DivBackward0>)\n",
            "98260 : avg_loss:  tensor(1.1597e-11, grad_fn=<DivBackward0>)\n",
            "98261 : avg_loss:  tensor(1.1596e-11, grad_fn=<DivBackward0>)\n",
            "98262 : avg_loss:  tensor(1.1596e-11, grad_fn=<DivBackward0>)\n",
            "98263 : avg_loss:  tensor(1.1596e-11, grad_fn=<DivBackward0>)\n",
            "98264 : avg_loss:  tensor(1.1596e-11, grad_fn=<DivBackward0>)\n",
            "98265 : avg_loss:  tensor(1.1595e-11, grad_fn=<DivBackward0>)\n",
            "98266 : avg_loss:  tensor(1.1595e-11, grad_fn=<DivBackward0>)\n",
            "98267 : avg_loss:  tensor(1.1595e-11, grad_fn=<DivBackward0>)\n",
            "98268 : avg_loss:  tensor(1.1594e-11, grad_fn=<DivBackward0>)\n",
            "98269 : avg_loss:  tensor(1.1594e-11, grad_fn=<DivBackward0>)\n",
            "98270 : avg_loss:  tensor(1.1594e-11, grad_fn=<DivBackward0>)\n",
            "98271 : avg_loss:  tensor(1.1594e-11, grad_fn=<DivBackward0>)\n",
            "98272 : avg_loss:  tensor(1.1593e-11, grad_fn=<DivBackward0>)\n",
            "98273 : avg_loss:  tensor(1.1593e-11, grad_fn=<DivBackward0>)\n",
            "98274 : avg_loss:  tensor(1.1593e-11, grad_fn=<DivBackward0>)\n",
            "98275 : avg_loss:  tensor(1.1593e-11, grad_fn=<DivBackward0>)\n",
            "98276 : avg_loss:  tensor(1.1592e-11, grad_fn=<DivBackward0>)\n",
            "98277 : avg_loss:  tensor(1.1592e-11, grad_fn=<DivBackward0>)\n",
            "98278 : avg_loss:  tensor(1.1592e-11, grad_fn=<DivBackward0>)\n",
            "98279 : avg_loss:  tensor(1.1591e-11, grad_fn=<DivBackward0>)\n",
            "98280 : avg_loss:  tensor(1.1591e-11, grad_fn=<DivBackward0>)\n",
            "98281 : avg_loss:  tensor(1.1591e-11, grad_fn=<DivBackward0>)\n",
            "98282 : avg_loss:  tensor(1.1591e-11, grad_fn=<DivBackward0>)\n",
            "98283 : avg_loss:  tensor(1.1590e-11, grad_fn=<DivBackward0>)\n",
            "98284 : avg_loss:  tensor(1.1590e-11, grad_fn=<DivBackward0>)\n",
            "98285 : avg_loss:  tensor(1.1590e-11, grad_fn=<DivBackward0>)\n",
            "98286 : avg_loss:  tensor(1.1589e-11, grad_fn=<DivBackward0>)\n",
            "98287 : avg_loss:  tensor(1.1589e-11, grad_fn=<DivBackward0>)\n",
            "98288 : avg_loss:  tensor(1.1589e-11, grad_fn=<DivBackward0>)\n",
            "98289 : avg_loss:  tensor(1.1588e-11, grad_fn=<DivBackward0>)\n",
            "98290 : avg_loss:  tensor(1.1588e-11, grad_fn=<DivBackward0>)\n",
            "98291 : avg_loss:  tensor(1.1588e-11, grad_fn=<DivBackward0>)\n",
            "98292 : avg_loss:  tensor(1.1588e-11, grad_fn=<DivBackward0>)\n",
            "98293 : avg_loss:  tensor(1.1587e-11, grad_fn=<DivBackward0>)\n",
            "98294 : avg_loss:  tensor(1.1587e-11, grad_fn=<DivBackward0>)\n",
            "98295 : avg_loss:  tensor(1.1587e-11, grad_fn=<DivBackward0>)\n",
            "98296 : avg_loss:  tensor(1.1587e-11, grad_fn=<DivBackward0>)\n",
            "98297 : avg_loss:  tensor(1.1586e-11, grad_fn=<DivBackward0>)\n",
            "98298 : avg_loss:  tensor(1.1586e-11, grad_fn=<DivBackward0>)\n",
            "98299 : avg_loss:  tensor(1.1586e-11, grad_fn=<DivBackward0>)\n",
            "98300 : avg_loss:  tensor(1.1586e-11, grad_fn=<DivBackward0>)\n",
            "98301 : avg_loss:  tensor(1.1585e-11, grad_fn=<DivBackward0>)\n",
            "98302 : avg_loss:  tensor(1.1585e-11, grad_fn=<DivBackward0>)\n",
            "98303 : avg_loss:  tensor(1.1585e-11, grad_fn=<DivBackward0>)\n",
            "98304 : avg_loss:  tensor(1.1584e-11, grad_fn=<DivBackward0>)\n",
            "98305 : avg_loss:  tensor(1.1584e-11, grad_fn=<DivBackward0>)\n",
            "98306 : avg_loss:  tensor(1.1584e-11, grad_fn=<DivBackward0>)\n",
            "98307 : avg_loss:  tensor(1.1584e-11, grad_fn=<DivBackward0>)\n",
            "98308 : avg_loss:  tensor(1.1583e-11, grad_fn=<DivBackward0>)\n",
            "98309 : avg_loss:  tensor(1.1583e-11, grad_fn=<DivBackward0>)\n",
            "98310 : avg_loss:  tensor(1.1583e-11, grad_fn=<DivBackward0>)\n",
            "98311 : avg_loss:  tensor(1.1582e-11, grad_fn=<DivBackward0>)\n",
            "98312 : avg_loss:  tensor(1.1582e-11, grad_fn=<DivBackward0>)\n",
            "98313 : avg_loss:  tensor(1.1582e-11, grad_fn=<DivBackward0>)\n",
            "98314 : avg_loss:  tensor(1.1582e-11, grad_fn=<DivBackward0>)\n",
            "98315 : avg_loss:  tensor(1.1581e-11, grad_fn=<DivBackward0>)\n",
            "98316 : avg_loss:  tensor(1.1581e-11, grad_fn=<DivBackward0>)\n",
            "98317 : avg_loss:  tensor(1.1580e-11, grad_fn=<DivBackward0>)\n",
            "98318 : avg_loss:  tensor(1.1580e-11, grad_fn=<DivBackward0>)\n",
            "98319 : avg_loss:  tensor(1.1580e-11, grad_fn=<DivBackward0>)\n",
            "98320 : avg_loss:  tensor(1.1580e-11, grad_fn=<DivBackward0>)\n",
            "98321 : avg_loss:  tensor(1.1579e-11, grad_fn=<DivBackward0>)\n",
            "98322 : avg_loss:  tensor(1.1579e-11, grad_fn=<DivBackward0>)\n",
            "98323 : avg_loss:  tensor(1.1579e-11, grad_fn=<DivBackward0>)\n",
            "98324 : avg_loss:  tensor(1.1578e-11, grad_fn=<DivBackward0>)\n",
            "98325 : avg_loss:  tensor(1.1578e-11, grad_fn=<DivBackward0>)\n",
            "98326 : avg_loss:  tensor(1.1578e-11, grad_fn=<DivBackward0>)\n",
            "98327 : avg_loss:  tensor(1.1578e-11, grad_fn=<DivBackward0>)\n",
            "98328 : avg_loss:  tensor(1.1577e-11, grad_fn=<DivBackward0>)\n",
            "98329 : avg_loss:  tensor(1.1577e-11, grad_fn=<DivBackward0>)\n",
            "98330 : avg_loss:  tensor(1.1577e-11, grad_fn=<DivBackward0>)\n",
            "98331 : avg_loss:  tensor(1.1577e-11, grad_fn=<DivBackward0>)\n",
            "98332 : avg_loss:  tensor(1.1576e-11, grad_fn=<DivBackward0>)\n",
            "98333 : avg_loss:  tensor(1.1576e-11, grad_fn=<DivBackward0>)\n",
            "98334 : avg_loss:  tensor(1.1576e-11, grad_fn=<DivBackward0>)\n",
            "98335 : avg_loss:  tensor(1.1575e-11, grad_fn=<DivBackward0>)\n",
            "98336 : avg_loss:  tensor(1.1575e-11, grad_fn=<DivBackward0>)\n",
            "98337 : avg_loss:  tensor(1.1575e-11, grad_fn=<DivBackward0>)\n",
            "98338 : avg_loss:  tensor(1.1575e-11, grad_fn=<DivBackward0>)\n",
            "98339 : avg_loss:  tensor(1.1574e-11, grad_fn=<DivBackward0>)\n",
            "98340 : avg_loss:  tensor(1.1574e-11, grad_fn=<DivBackward0>)\n",
            "98341 : avg_loss:  tensor(1.1574e-11, grad_fn=<DivBackward0>)\n",
            "98342 : avg_loss:  tensor(1.1574e-11, grad_fn=<DivBackward0>)\n",
            "98343 : avg_loss:  tensor(1.1573e-11, grad_fn=<DivBackward0>)\n",
            "98344 : avg_loss:  tensor(1.1573e-11, grad_fn=<DivBackward0>)\n",
            "98345 : avg_loss:  tensor(1.1572e-11, grad_fn=<DivBackward0>)\n",
            "98346 : avg_loss:  tensor(1.1572e-11, grad_fn=<DivBackward0>)\n",
            "98347 : avg_loss:  tensor(1.1572e-11, grad_fn=<DivBackward0>)\n",
            "98348 : avg_loss:  tensor(1.1572e-11, grad_fn=<DivBackward0>)\n",
            "98349 : avg_loss:  tensor(1.1571e-11, grad_fn=<DivBackward0>)\n",
            "98350 : avg_loss:  tensor(1.1571e-11, grad_fn=<DivBackward0>)\n",
            "98351 : avg_loss:  tensor(1.1571e-11, grad_fn=<DivBackward0>)\n",
            "98352 : avg_loss:  tensor(1.1571e-11, grad_fn=<DivBackward0>)\n",
            "98353 : avg_loss:  tensor(1.1570e-11, grad_fn=<DivBackward0>)\n",
            "98354 : avg_loss:  tensor(1.1570e-11, grad_fn=<DivBackward0>)\n",
            "98355 : avg_loss:  tensor(1.1570e-11, grad_fn=<DivBackward0>)\n",
            "98356 : avg_loss:  tensor(1.1569e-11, grad_fn=<DivBackward0>)\n",
            "98357 : avg_loss:  tensor(1.1569e-11, grad_fn=<DivBackward0>)\n",
            "98358 : avg_loss:  tensor(1.1569e-11, grad_fn=<DivBackward0>)\n",
            "98359 : avg_loss:  tensor(1.1568e-11, grad_fn=<DivBackward0>)\n",
            "98360 : avg_loss:  tensor(1.1568e-11, grad_fn=<DivBackward0>)\n",
            "98361 : avg_loss:  tensor(1.1568e-11, grad_fn=<DivBackward0>)\n",
            "98362 : avg_loss:  tensor(1.1568e-11, grad_fn=<DivBackward0>)\n",
            "98363 : avg_loss:  tensor(1.1567e-11, grad_fn=<DivBackward0>)\n",
            "98364 : avg_loss:  tensor(1.1567e-11, grad_fn=<DivBackward0>)\n",
            "98365 : avg_loss:  tensor(1.1567e-11, grad_fn=<DivBackward0>)\n",
            "98366 : avg_loss:  tensor(1.1567e-11, grad_fn=<DivBackward0>)\n",
            "98367 : avg_loss:  tensor(1.1566e-11, grad_fn=<DivBackward0>)\n",
            "98368 : avg_loss:  tensor(1.1566e-11, grad_fn=<DivBackward0>)\n",
            "98369 : avg_loss:  tensor(1.1566e-11, grad_fn=<DivBackward0>)\n",
            "98370 : avg_loss:  tensor(1.1565e-11, grad_fn=<DivBackward0>)\n",
            "98371 : avg_loss:  tensor(1.1565e-11, grad_fn=<DivBackward0>)\n",
            "98372 : avg_loss:  tensor(1.1565e-11, grad_fn=<DivBackward0>)\n",
            "98373 : avg_loss:  tensor(1.1564e-11, grad_fn=<DivBackward0>)\n",
            "98374 : avg_loss:  tensor(1.1564e-11, grad_fn=<DivBackward0>)\n",
            "98375 : avg_loss:  tensor(1.1564e-11, grad_fn=<DivBackward0>)\n",
            "98376 : avg_loss:  tensor(1.1564e-11, grad_fn=<DivBackward0>)\n",
            "98377 : avg_loss:  tensor(1.1563e-11, grad_fn=<DivBackward0>)\n",
            "98378 : avg_loss:  tensor(1.1563e-11, grad_fn=<DivBackward0>)\n",
            "98379 : avg_loss:  tensor(1.1563e-11, grad_fn=<DivBackward0>)\n",
            "98380 : avg_loss:  tensor(1.1563e-11, grad_fn=<DivBackward0>)\n",
            "98381 : avg_loss:  tensor(1.1562e-11, grad_fn=<DivBackward0>)\n",
            "98382 : avg_loss:  tensor(1.1562e-11, grad_fn=<DivBackward0>)\n",
            "98383 : avg_loss:  tensor(1.1562e-11, grad_fn=<DivBackward0>)\n",
            "98384 : avg_loss:  tensor(1.1561e-11, grad_fn=<DivBackward0>)\n",
            "98385 : avg_loss:  tensor(1.1561e-11, grad_fn=<DivBackward0>)\n",
            "98386 : avg_loss:  tensor(1.1560e-11, grad_fn=<DivBackward0>)\n",
            "98387 : avg_loss:  tensor(1.1560e-11, grad_fn=<DivBackward0>)\n",
            "98388 : avg_loss:  tensor(1.1560e-11, grad_fn=<DivBackward0>)\n",
            "98389 : avg_loss:  tensor(1.1560e-11, grad_fn=<DivBackward0>)\n",
            "98390 : avg_loss:  tensor(1.1559e-11, grad_fn=<DivBackward0>)\n",
            "98391 : avg_loss:  tensor(1.1559e-11, grad_fn=<DivBackward0>)\n",
            "98392 : avg_loss:  tensor(1.1559e-11, grad_fn=<DivBackward0>)\n",
            "98393 : avg_loss:  tensor(1.1559e-11, grad_fn=<DivBackward0>)\n",
            "98394 : avg_loss:  tensor(1.1558e-11, grad_fn=<DivBackward0>)\n",
            "98395 : avg_loss:  tensor(1.1558e-11, grad_fn=<DivBackward0>)\n",
            "98396 : avg_loss:  tensor(1.1558e-11, grad_fn=<DivBackward0>)\n",
            "98397 : avg_loss:  tensor(1.1558e-11, grad_fn=<DivBackward0>)\n",
            "98398 : avg_loss:  tensor(1.1557e-11, grad_fn=<DivBackward0>)\n",
            "98399 : avg_loss:  tensor(1.1557e-11, grad_fn=<DivBackward0>)\n",
            "98400 : avg_loss:  tensor(1.1556e-11, grad_fn=<DivBackward0>)\n",
            "98401 : avg_loss:  tensor(1.1556e-11, grad_fn=<DivBackward0>)\n",
            "98402 : avg_loss:  tensor(1.1556e-11, grad_fn=<DivBackward0>)\n",
            "98403 : avg_loss:  tensor(1.1556e-11, grad_fn=<DivBackward0>)\n",
            "98404 : avg_loss:  tensor(1.1555e-11, grad_fn=<DivBackward0>)\n",
            "98405 : avg_loss:  tensor(1.1555e-11, grad_fn=<DivBackward0>)\n",
            "98406 : avg_loss:  tensor(1.1555e-11, grad_fn=<DivBackward0>)\n",
            "98407 : avg_loss:  tensor(1.1554e-11, grad_fn=<DivBackward0>)\n",
            "98408 : avg_loss:  tensor(1.1554e-11, grad_fn=<DivBackward0>)\n",
            "98409 : avg_loss:  tensor(1.1554e-11, grad_fn=<DivBackward0>)\n",
            "98410 : avg_loss:  tensor(1.1554e-11, grad_fn=<DivBackward0>)\n",
            "98411 : avg_loss:  tensor(1.1553e-11, grad_fn=<DivBackward0>)\n",
            "98412 : avg_loss:  tensor(1.1553e-11, grad_fn=<DivBackward0>)\n",
            "98413 : avg_loss:  tensor(1.1552e-11, grad_fn=<DivBackward0>)\n",
            "98414 : avg_loss:  tensor(1.1552e-11, grad_fn=<DivBackward0>)\n",
            "98415 : avg_loss:  tensor(1.1552e-11, grad_fn=<DivBackward0>)\n",
            "98416 : avg_loss:  tensor(1.1552e-11, grad_fn=<DivBackward0>)\n",
            "98417 : avg_loss:  tensor(1.1551e-11, grad_fn=<DivBackward0>)\n",
            "98418 : avg_loss:  tensor(1.1551e-11, grad_fn=<DivBackward0>)\n",
            "98419 : avg_loss:  tensor(1.1551e-11, grad_fn=<DivBackward0>)\n",
            "98420 : avg_loss:  tensor(1.1551e-11, grad_fn=<DivBackward0>)\n",
            "98421 : avg_loss:  tensor(1.1550e-11, grad_fn=<DivBackward0>)\n",
            "98422 : avg_loss:  tensor(1.1550e-11, grad_fn=<DivBackward0>)\n",
            "98423 : avg_loss:  tensor(1.1550e-11, grad_fn=<DivBackward0>)\n",
            "98424 : avg_loss:  tensor(1.1549e-11, grad_fn=<DivBackward0>)\n",
            "98425 : avg_loss:  tensor(1.1549e-11, grad_fn=<DivBackward0>)\n",
            "98426 : avg_loss:  tensor(1.1549e-11, grad_fn=<DivBackward0>)\n",
            "98427 : avg_loss:  tensor(1.1549e-11, grad_fn=<DivBackward0>)\n",
            "98428 : avg_loss:  tensor(1.1548e-11, grad_fn=<DivBackward0>)\n",
            "98429 : avg_loss:  tensor(1.1548e-11, grad_fn=<DivBackward0>)\n",
            "98430 : avg_loss:  tensor(1.1548e-11, grad_fn=<DivBackward0>)\n",
            "98431 : avg_loss:  tensor(1.1547e-11, grad_fn=<DivBackward0>)\n",
            "98432 : avg_loss:  tensor(1.1547e-11, grad_fn=<DivBackward0>)\n",
            "98433 : avg_loss:  tensor(1.1547e-11, grad_fn=<DivBackward0>)\n",
            "98434 : avg_loss:  tensor(1.1547e-11, grad_fn=<DivBackward0>)\n",
            "98435 : avg_loss:  tensor(1.1546e-11, grad_fn=<DivBackward0>)\n",
            "98436 : avg_loss:  tensor(1.1546e-11, grad_fn=<DivBackward0>)\n",
            "98437 : avg_loss:  tensor(1.1546e-11, grad_fn=<DivBackward0>)\n",
            "98438 : avg_loss:  tensor(1.1545e-11, grad_fn=<DivBackward0>)\n",
            "98439 : avg_loss:  tensor(1.1545e-11, grad_fn=<DivBackward0>)\n",
            "98440 : avg_loss:  tensor(1.1545e-11, grad_fn=<DivBackward0>)\n",
            "98441 : avg_loss:  tensor(1.1544e-11, grad_fn=<DivBackward0>)\n",
            "98442 : avg_loss:  tensor(1.1544e-11, grad_fn=<DivBackward0>)\n",
            "98443 : avg_loss:  tensor(1.1544e-11, grad_fn=<DivBackward0>)\n",
            "98444 : avg_loss:  tensor(1.1544e-11, grad_fn=<DivBackward0>)\n",
            "98445 : avg_loss:  tensor(1.1543e-11, grad_fn=<DivBackward0>)\n",
            "98446 : avg_loss:  tensor(1.1543e-11, grad_fn=<DivBackward0>)\n",
            "98447 : avg_loss:  tensor(1.1543e-11, grad_fn=<DivBackward0>)\n",
            "98448 : avg_loss:  tensor(1.1542e-11, grad_fn=<DivBackward0>)\n",
            "98449 : avg_loss:  tensor(1.1542e-11, grad_fn=<DivBackward0>)\n",
            "98450 : avg_loss:  tensor(1.1542e-11, grad_fn=<DivBackward0>)\n",
            "98451 : avg_loss:  tensor(1.1542e-11, grad_fn=<DivBackward0>)\n",
            "98452 : avg_loss:  tensor(1.1541e-11, grad_fn=<DivBackward0>)\n",
            "98453 : avg_loss:  tensor(1.1541e-11, grad_fn=<DivBackward0>)\n",
            "98454 : avg_loss:  tensor(1.1541e-11, grad_fn=<DivBackward0>)\n",
            "98455 : avg_loss:  tensor(1.1540e-11, grad_fn=<DivBackward0>)\n",
            "98456 : avg_loss:  tensor(1.1540e-11, grad_fn=<DivBackward0>)\n",
            "98457 : avg_loss:  tensor(1.1540e-11, grad_fn=<DivBackward0>)\n",
            "98458 : avg_loss:  tensor(1.1540e-11, grad_fn=<DivBackward0>)\n",
            "98459 : avg_loss:  tensor(1.1539e-11, grad_fn=<DivBackward0>)\n",
            "98460 : avg_loss:  tensor(1.1539e-11, grad_fn=<DivBackward0>)\n",
            "98461 : avg_loss:  tensor(1.1538e-11, grad_fn=<DivBackward0>)\n",
            "98462 : avg_loss:  tensor(1.1538e-11, grad_fn=<DivBackward0>)\n",
            "98463 : avg_loss:  tensor(1.1538e-11, grad_fn=<DivBackward0>)\n",
            "98464 : avg_loss:  tensor(1.1538e-11, grad_fn=<DivBackward0>)\n",
            "98465 : avg_loss:  tensor(1.1537e-11, grad_fn=<DivBackward0>)\n",
            "98466 : avg_loss:  tensor(1.1537e-11, grad_fn=<DivBackward0>)\n",
            "98467 : avg_loss:  tensor(1.1536e-11, grad_fn=<DivBackward0>)\n",
            "98468 : avg_loss:  tensor(1.1536e-11, grad_fn=<DivBackward0>)\n",
            "98469 : avg_loss:  tensor(1.1536e-11, grad_fn=<DivBackward0>)\n",
            "98470 : avg_loss:  tensor(1.1535e-11, grad_fn=<DivBackward0>)\n",
            "98471 : avg_loss:  tensor(1.1535e-11, grad_fn=<DivBackward0>)\n",
            "98472 : avg_loss:  tensor(1.1535e-11, grad_fn=<DivBackward0>)\n",
            "98473 : avg_loss:  tensor(1.1535e-11, grad_fn=<DivBackward0>)\n",
            "98474 : avg_loss:  tensor(1.1534e-11, grad_fn=<DivBackward0>)\n",
            "98475 : avg_loss:  tensor(1.1534e-11, grad_fn=<DivBackward0>)\n",
            "98476 : avg_loss:  tensor(1.1534e-11, grad_fn=<DivBackward0>)\n",
            "98477 : avg_loss:  tensor(1.1533e-11, grad_fn=<DivBackward0>)\n",
            "98478 : avg_loss:  tensor(1.1533e-11, grad_fn=<DivBackward0>)\n",
            "98479 : avg_loss:  tensor(1.1533e-11, grad_fn=<DivBackward0>)\n",
            "98480 : avg_loss:  tensor(1.1533e-11, grad_fn=<DivBackward0>)\n",
            "98481 : avg_loss:  tensor(1.1532e-11, grad_fn=<DivBackward0>)\n",
            "98482 : avg_loss:  tensor(1.1532e-11, grad_fn=<DivBackward0>)\n",
            "98483 : avg_loss:  tensor(1.1532e-11, grad_fn=<DivBackward0>)\n",
            "98484 : avg_loss:  tensor(1.1531e-11, grad_fn=<DivBackward0>)\n",
            "98485 : avg_loss:  tensor(1.1531e-11, grad_fn=<DivBackward0>)\n",
            "98486 : avg_loss:  tensor(1.1530e-11, grad_fn=<DivBackward0>)\n",
            "98487 : avg_loss:  tensor(1.1530e-11, grad_fn=<DivBackward0>)\n",
            "98488 : avg_loss:  tensor(1.1530e-11, grad_fn=<DivBackward0>)\n",
            "98489 : avg_loss:  tensor(1.1530e-11, grad_fn=<DivBackward0>)\n",
            "98490 : avg_loss:  tensor(1.1529e-11, grad_fn=<DivBackward0>)\n",
            "98491 : avg_loss:  tensor(1.1529e-11, grad_fn=<DivBackward0>)\n",
            "98492 : avg_loss:  tensor(1.1529e-11, grad_fn=<DivBackward0>)\n",
            "98493 : avg_loss:  tensor(1.1528e-11, grad_fn=<DivBackward0>)\n",
            "98494 : avg_loss:  tensor(1.1528e-11, grad_fn=<DivBackward0>)\n",
            "98495 : avg_loss:  tensor(1.1528e-11, grad_fn=<DivBackward0>)\n",
            "98496 : avg_loss:  tensor(1.1527e-11, grad_fn=<DivBackward0>)\n",
            "98497 : avg_loss:  tensor(1.1527e-11, grad_fn=<DivBackward0>)\n",
            "98498 : avg_loss:  tensor(1.1527e-11, grad_fn=<DivBackward0>)\n",
            "98499 : avg_loss:  tensor(1.1527e-11, grad_fn=<DivBackward0>)\n",
            "98500 : avg_loss:  tensor(1.1526e-11, grad_fn=<DivBackward0>)\n",
            "98501 : avg_loss:  tensor(1.1526e-11, grad_fn=<DivBackward0>)\n",
            "98502 : avg_loss:  tensor(1.1526e-11, grad_fn=<DivBackward0>)\n",
            "98503 : avg_loss:  tensor(1.1525e-11, grad_fn=<DivBackward0>)\n",
            "98504 : avg_loss:  tensor(1.1525e-11, grad_fn=<DivBackward0>)\n",
            "98505 : avg_loss:  tensor(1.1525e-11, grad_fn=<DivBackward0>)\n",
            "98506 : avg_loss:  tensor(1.1525e-11, grad_fn=<DivBackward0>)\n",
            "98507 : avg_loss:  tensor(1.1524e-11, grad_fn=<DivBackward0>)\n",
            "98508 : avg_loss:  tensor(1.1524e-11, grad_fn=<DivBackward0>)\n",
            "98509 : avg_loss:  tensor(1.1523e-11, grad_fn=<DivBackward0>)\n",
            "98510 : avg_loss:  tensor(1.1523e-11, grad_fn=<DivBackward0>)\n",
            "98511 : avg_loss:  tensor(1.1523e-11, grad_fn=<DivBackward0>)\n",
            "98512 : avg_loss:  tensor(1.1523e-11, grad_fn=<DivBackward0>)\n",
            "98513 : avg_loss:  tensor(1.1522e-11, grad_fn=<DivBackward0>)\n",
            "98514 : avg_loss:  tensor(1.1522e-11, grad_fn=<DivBackward0>)\n",
            "98515 : avg_loss:  tensor(1.1522e-11, grad_fn=<DivBackward0>)\n",
            "98516 : avg_loss:  tensor(1.1521e-11, grad_fn=<DivBackward0>)\n",
            "98517 : avg_loss:  tensor(1.1521e-11, grad_fn=<DivBackward0>)\n",
            "98518 : avg_loss:  tensor(1.1521e-11, grad_fn=<DivBackward0>)\n",
            "98519 : avg_loss:  tensor(1.1520e-11, grad_fn=<DivBackward0>)\n",
            "98520 : avg_loss:  tensor(1.1520e-11, grad_fn=<DivBackward0>)\n",
            "98521 : avg_loss:  tensor(1.1520e-11, grad_fn=<DivBackward0>)\n",
            "98522 : avg_loss:  tensor(1.1519e-11, grad_fn=<DivBackward0>)\n",
            "98523 : avg_loss:  tensor(1.1519e-11, grad_fn=<DivBackward0>)\n",
            "98524 : avg_loss:  tensor(1.1519e-11, grad_fn=<DivBackward0>)\n",
            "98525 : avg_loss:  tensor(1.1519e-11, grad_fn=<DivBackward0>)\n",
            "98526 : avg_loss:  tensor(1.1518e-11, grad_fn=<DivBackward0>)\n",
            "98527 : avg_loss:  tensor(1.1518e-11, grad_fn=<DivBackward0>)\n",
            "98528 : avg_loss:  tensor(1.1518e-11, grad_fn=<DivBackward0>)\n",
            "98529 : avg_loss:  tensor(1.1518e-11, grad_fn=<DivBackward0>)\n",
            "98530 : avg_loss:  tensor(1.1517e-11, grad_fn=<DivBackward0>)\n",
            "98531 : avg_loss:  tensor(1.1517e-11, grad_fn=<DivBackward0>)\n",
            "98532 : avg_loss:  tensor(1.1516e-11, grad_fn=<DivBackward0>)\n",
            "98533 : avg_loss:  tensor(1.1516e-11, grad_fn=<DivBackward0>)\n",
            "98534 : avg_loss:  tensor(1.1516e-11, grad_fn=<DivBackward0>)\n",
            "98535 : avg_loss:  tensor(1.1515e-11, grad_fn=<DivBackward0>)\n",
            "98536 : avg_loss:  tensor(1.1515e-11, grad_fn=<DivBackward0>)\n",
            "98537 : avg_loss:  tensor(1.1515e-11, grad_fn=<DivBackward0>)\n",
            "98538 : avg_loss:  tensor(1.1515e-11, grad_fn=<DivBackward0>)\n",
            "98539 : avg_loss:  tensor(1.1514e-11, grad_fn=<DivBackward0>)\n",
            "98540 : avg_loss:  tensor(1.1514e-11, grad_fn=<DivBackward0>)\n",
            "98541 : avg_loss:  tensor(1.1514e-11, grad_fn=<DivBackward0>)\n",
            "98542 : avg_loss:  tensor(1.1513e-11, grad_fn=<DivBackward0>)\n",
            "98543 : avg_loss:  tensor(1.1513e-11, grad_fn=<DivBackward0>)\n",
            "98544 : avg_loss:  tensor(1.1513e-11, grad_fn=<DivBackward0>)\n",
            "98545 : avg_loss:  tensor(1.1512e-11, grad_fn=<DivBackward0>)\n",
            "98546 : avg_loss:  tensor(1.1512e-11, grad_fn=<DivBackward0>)\n",
            "98547 : avg_loss:  tensor(1.1512e-11, grad_fn=<DivBackward0>)\n",
            "98548 : avg_loss:  tensor(1.1511e-11, grad_fn=<DivBackward0>)\n",
            "98549 : avg_loss:  tensor(1.1511e-11, grad_fn=<DivBackward0>)\n",
            "98550 : avg_loss:  tensor(1.1511e-11, grad_fn=<DivBackward0>)\n",
            "98551 : avg_loss:  tensor(1.1510e-11, grad_fn=<DivBackward0>)\n",
            "98552 : avg_loss:  tensor(1.1510e-11, grad_fn=<DivBackward0>)\n",
            "98553 : avg_loss:  tensor(1.1510e-11, grad_fn=<DivBackward0>)\n",
            "98554 : avg_loss:  tensor(1.1510e-11, grad_fn=<DivBackward0>)\n",
            "98555 : avg_loss:  tensor(1.1509e-11, grad_fn=<DivBackward0>)\n",
            "98556 : avg_loss:  tensor(1.1509e-11, grad_fn=<DivBackward0>)\n",
            "98557 : avg_loss:  tensor(1.1508e-11, grad_fn=<DivBackward0>)\n",
            "98558 : avg_loss:  tensor(1.1508e-11, grad_fn=<DivBackward0>)\n",
            "98559 : avg_loss:  tensor(1.1508e-11, grad_fn=<DivBackward0>)\n",
            "98560 : avg_loss:  tensor(1.1508e-11, grad_fn=<DivBackward0>)\n",
            "98561 : avg_loss:  tensor(1.1507e-11, grad_fn=<DivBackward0>)\n",
            "98562 : avg_loss:  tensor(1.1507e-11, grad_fn=<DivBackward0>)\n",
            "98563 : avg_loss:  tensor(1.1507e-11, grad_fn=<DivBackward0>)\n",
            "98564 : avg_loss:  tensor(1.1506e-11, grad_fn=<DivBackward0>)\n",
            "98565 : avg_loss:  tensor(1.1506e-11, grad_fn=<DivBackward0>)\n",
            "98566 : avg_loss:  tensor(1.1506e-11, grad_fn=<DivBackward0>)\n",
            "98567 : avg_loss:  tensor(1.1506e-11, grad_fn=<DivBackward0>)\n",
            "98568 : avg_loss:  tensor(1.1505e-11, grad_fn=<DivBackward0>)\n",
            "98569 : avg_loss:  tensor(1.1505e-11, grad_fn=<DivBackward0>)\n",
            "98570 : avg_loss:  tensor(1.1504e-11, grad_fn=<DivBackward0>)\n",
            "98571 : avg_loss:  tensor(1.1504e-11, grad_fn=<DivBackward0>)\n",
            "98572 : avg_loss:  tensor(1.1504e-11, grad_fn=<DivBackward0>)\n",
            "98573 : avg_loss:  tensor(1.1503e-11, grad_fn=<DivBackward0>)\n",
            "98574 : avg_loss:  tensor(1.1503e-11, grad_fn=<DivBackward0>)\n",
            "98575 : avg_loss:  tensor(1.1503e-11, grad_fn=<DivBackward0>)\n",
            "98576 : avg_loss:  tensor(1.1502e-11, grad_fn=<DivBackward0>)\n",
            "98577 : avg_loss:  tensor(1.1502e-11, grad_fn=<DivBackward0>)\n",
            "98578 : avg_loss:  tensor(1.1502e-11, grad_fn=<DivBackward0>)\n",
            "98579 : avg_loss:  tensor(1.1502e-11, grad_fn=<DivBackward0>)\n",
            "98580 : avg_loss:  tensor(1.1501e-11, grad_fn=<DivBackward0>)\n",
            "98581 : avg_loss:  tensor(1.1501e-11, grad_fn=<DivBackward0>)\n",
            "98582 : avg_loss:  tensor(1.1501e-11, grad_fn=<DivBackward0>)\n",
            "98583 : avg_loss:  tensor(1.1500e-11, grad_fn=<DivBackward0>)\n",
            "98584 : avg_loss:  tensor(1.1500e-11, grad_fn=<DivBackward0>)\n",
            "98585 : avg_loss:  tensor(1.1500e-11, grad_fn=<DivBackward0>)\n",
            "98586 : avg_loss:  tensor(1.1500e-11, grad_fn=<DivBackward0>)\n",
            "98587 : avg_loss:  tensor(1.1499e-11, grad_fn=<DivBackward0>)\n",
            "98588 : avg_loss:  tensor(1.1499e-11, grad_fn=<DivBackward0>)\n",
            "98589 : avg_loss:  tensor(1.1499e-11, grad_fn=<DivBackward0>)\n",
            "98590 : avg_loss:  tensor(1.1498e-11, grad_fn=<DivBackward0>)\n",
            "98591 : avg_loss:  tensor(1.1498e-11, grad_fn=<DivBackward0>)\n",
            "98592 : avg_loss:  tensor(1.1498e-11, grad_fn=<DivBackward0>)\n",
            "98593 : avg_loss:  tensor(1.1497e-11, grad_fn=<DivBackward0>)\n",
            "98594 : avg_loss:  tensor(1.1497e-11, grad_fn=<DivBackward0>)\n",
            "98595 : avg_loss:  tensor(1.1497e-11, grad_fn=<DivBackward0>)\n",
            "98596 : avg_loss:  tensor(1.1496e-11, grad_fn=<DivBackward0>)\n",
            "98597 : avg_loss:  tensor(1.1496e-11, grad_fn=<DivBackward0>)\n",
            "98598 : avg_loss:  tensor(1.1496e-11, grad_fn=<DivBackward0>)\n",
            "98599 : avg_loss:  tensor(1.1495e-11, grad_fn=<DivBackward0>)\n",
            "98600 : avg_loss:  tensor(1.1495e-11, grad_fn=<DivBackward0>)\n",
            "98601 : avg_loss:  tensor(1.1495e-11, grad_fn=<DivBackward0>)\n",
            "98602 : avg_loss:  tensor(1.1494e-11, grad_fn=<DivBackward0>)\n",
            "98603 : avg_loss:  tensor(1.1494e-11, grad_fn=<DivBackward0>)\n",
            "98604 : avg_loss:  tensor(1.1494e-11, grad_fn=<DivBackward0>)\n",
            "98605 : avg_loss:  tensor(1.1493e-11, grad_fn=<DivBackward0>)\n",
            "98606 : avg_loss:  tensor(1.1493e-11, grad_fn=<DivBackward0>)\n",
            "98607 : avg_loss:  tensor(1.1493e-11, grad_fn=<DivBackward0>)\n",
            "98608 : avg_loss:  tensor(1.1492e-11, grad_fn=<DivBackward0>)\n",
            "98609 : avg_loss:  tensor(1.1492e-11, grad_fn=<DivBackward0>)\n",
            "98610 : avg_loss:  tensor(1.1492e-11, grad_fn=<DivBackward0>)\n",
            "98611 : avg_loss:  tensor(1.1491e-11, grad_fn=<DivBackward0>)\n",
            "98612 : avg_loss:  tensor(1.1491e-11, grad_fn=<DivBackward0>)\n",
            "98613 : avg_loss:  tensor(1.1491e-11, grad_fn=<DivBackward0>)\n",
            "98614 : avg_loss:  tensor(1.1490e-11, grad_fn=<DivBackward0>)\n",
            "98615 : avg_loss:  tensor(1.1490e-11, grad_fn=<DivBackward0>)\n",
            "98616 : avg_loss:  tensor(1.1490e-11, grad_fn=<DivBackward0>)\n",
            "98617 : avg_loss:  tensor(1.1490e-11, grad_fn=<DivBackward0>)\n",
            "98618 : avg_loss:  tensor(1.1489e-11, grad_fn=<DivBackward0>)\n",
            "98619 : avg_loss:  tensor(1.1489e-11, grad_fn=<DivBackward0>)\n",
            "98620 : avg_loss:  tensor(1.1488e-11, grad_fn=<DivBackward0>)\n",
            "98621 : avg_loss:  tensor(1.1488e-11, grad_fn=<DivBackward0>)\n",
            "98622 : avg_loss:  tensor(1.1488e-11, grad_fn=<DivBackward0>)\n",
            "98623 : avg_loss:  tensor(1.1487e-11, grad_fn=<DivBackward0>)\n",
            "98624 : avg_loss:  tensor(1.1487e-11, grad_fn=<DivBackward0>)\n",
            "98625 : avg_loss:  tensor(1.1487e-11, grad_fn=<DivBackward0>)\n",
            "98626 : avg_loss:  tensor(1.1487e-11, grad_fn=<DivBackward0>)\n",
            "98627 : avg_loss:  tensor(1.1486e-11, grad_fn=<DivBackward0>)\n",
            "98628 : avg_loss:  tensor(1.1486e-11, grad_fn=<DivBackward0>)\n",
            "98629 : avg_loss:  tensor(1.1486e-11, grad_fn=<DivBackward0>)\n",
            "98630 : avg_loss:  tensor(1.1486e-11, grad_fn=<DivBackward0>)\n",
            "98631 : avg_loss:  tensor(1.1485e-11, grad_fn=<DivBackward0>)\n",
            "98632 : avg_loss:  tensor(1.1484e-11, grad_fn=<DivBackward0>)\n",
            "98633 : avg_loss:  tensor(1.1484e-11, grad_fn=<DivBackward0>)\n",
            "98634 : avg_loss:  tensor(1.1484e-11, grad_fn=<DivBackward0>)\n",
            "98635 : avg_loss:  tensor(1.1483e-11, grad_fn=<DivBackward0>)\n",
            "98636 : avg_loss:  tensor(1.1483e-11, grad_fn=<DivBackward0>)\n",
            "98637 : avg_loss:  tensor(1.1483e-11, grad_fn=<DivBackward0>)\n",
            "98638 : avg_loss:  tensor(1.1483e-11, grad_fn=<DivBackward0>)\n",
            "98639 : avg_loss:  tensor(1.1482e-11, grad_fn=<DivBackward0>)\n",
            "98640 : avg_loss:  tensor(1.1482e-11, grad_fn=<DivBackward0>)\n",
            "98641 : avg_loss:  tensor(1.1482e-11, grad_fn=<DivBackward0>)\n",
            "98642 : avg_loss:  tensor(1.1482e-11, grad_fn=<DivBackward0>)\n",
            "98643 : avg_loss:  tensor(1.1481e-11, grad_fn=<DivBackward0>)\n",
            "98644 : avg_loss:  tensor(1.1481e-11, grad_fn=<DivBackward0>)\n",
            "98645 : avg_loss:  tensor(1.1480e-11, grad_fn=<DivBackward0>)\n",
            "98646 : avg_loss:  tensor(1.1480e-11, grad_fn=<DivBackward0>)\n",
            "98647 : avg_loss:  tensor(1.1480e-11, grad_fn=<DivBackward0>)\n",
            "98648 : avg_loss:  tensor(1.1479e-11, grad_fn=<DivBackward0>)\n",
            "98649 : avg_loss:  tensor(1.1479e-11, grad_fn=<DivBackward0>)\n",
            "98650 : avg_loss:  tensor(1.1479e-11, grad_fn=<DivBackward0>)\n",
            "98651 : avg_loss:  tensor(1.1479e-11, grad_fn=<DivBackward0>)\n",
            "98652 : avg_loss:  tensor(1.1478e-11, grad_fn=<DivBackward0>)\n",
            "98653 : avg_loss:  tensor(1.1478e-11, grad_fn=<DivBackward0>)\n",
            "98654 : avg_loss:  tensor(1.1478e-11, grad_fn=<DivBackward0>)\n",
            "98655 : avg_loss:  tensor(1.1477e-11, grad_fn=<DivBackward0>)\n",
            "98656 : avg_loss:  tensor(1.1477e-11, grad_fn=<DivBackward0>)\n",
            "98657 : avg_loss:  tensor(1.1476e-11, grad_fn=<DivBackward0>)\n",
            "98658 : avg_loss:  tensor(1.1476e-11, grad_fn=<DivBackward0>)\n",
            "98659 : avg_loss:  tensor(1.1476e-11, grad_fn=<DivBackward0>)\n",
            "98660 : avg_loss:  tensor(1.1476e-11, grad_fn=<DivBackward0>)\n",
            "98661 : avg_loss:  tensor(1.1475e-11, grad_fn=<DivBackward0>)\n",
            "98662 : avg_loss:  tensor(1.1475e-11, grad_fn=<DivBackward0>)\n",
            "98663 : avg_loss:  tensor(1.1475e-11, grad_fn=<DivBackward0>)\n",
            "98664 : avg_loss:  tensor(1.1474e-11, grad_fn=<DivBackward0>)\n",
            "98665 : avg_loss:  tensor(1.1474e-11, grad_fn=<DivBackward0>)\n",
            "98666 : avg_loss:  tensor(1.1474e-11, grad_fn=<DivBackward0>)\n",
            "98667 : avg_loss:  tensor(1.1473e-11, grad_fn=<DivBackward0>)\n",
            "98668 : avg_loss:  tensor(1.1473e-11, grad_fn=<DivBackward0>)\n",
            "98669 : avg_loss:  tensor(1.1473e-11, grad_fn=<DivBackward0>)\n",
            "98670 : avg_loss:  tensor(1.1472e-11, grad_fn=<DivBackward0>)\n",
            "98671 : avg_loss:  tensor(1.1472e-11, grad_fn=<DivBackward0>)\n",
            "98672 : avg_loss:  tensor(1.1471e-11, grad_fn=<DivBackward0>)\n",
            "98673 : avg_loss:  tensor(1.1471e-11, grad_fn=<DivBackward0>)\n",
            "98674 : avg_loss:  tensor(1.1471e-11, grad_fn=<DivBackward0>)\n",
            "98675 : avg_loss:  tensor(1.1471e-11, grad_fn=<DivBackward0>)\n",
            "98676 : avg_loss:  tensor(1.1470e-11, grad_fn=<DivBackward0>)\n",
            "98677 : avg_loss:  tensor(1.1470e-11, grad_fn=<DivBackward0>)\n",
            "98678 : avg_loss:  tensor(1.1470e-11, grad_fn=<DivBackward0>)\n",
            "98679 : avg_loss:  tensor(1.1470e-11, grad_fn=<DivBackward0>)\n",
            "98680 : avg_loss:  tensor(1.1469e-11, grad_fn=<DivBackward0>)\n",
            "98681 : avg_loss:  tensor(1.1469e-11, grad_fn=<DivBackward0>)\n",
            "98682 : avg_loss:  tensor(1.1468e-11, grad_fn=<DivBackward0>)\n",
            "98683 : avg_loss:  tensor(1.1468e-11, grad_fn=<DivBackward0>)\n",
            "98684 : avg_loss:  tensor(1.1468e-11, grad_fn=<DivBackward0>)\n",
            "98685 : avg_loss:  tensor(1.1467e-11, grad_fn=<DivBackward0>)\n",
            "98686 : avg_loss:  tensor(1.1467e-11, grad_fn=<DivBackward0>)\n",
            "98687 : avg_loss:  tensor(1.1467e-11, grad_fn=<DivBackward0>)\n",
            "98688 : avg_loss:  tensor(1.1467e-11, grad_fn=<DivBackward0>)\n",
            "98689 : avg_loss:  tensor(1.1466e-11, grad_fn=<DivBackward0>)\n",
            "98690 : avg_loss:  tensor(1.1466e-11, grad_fn=<DivBackward0>)\n",
            "98691 : avg_loss:  tensor(1.1466e-11, grad_fn=<DivBackward0>)\n",
            "98692 : avg_loss:  tensor(1.1465e-11, grad_fn=<DivBackward0>)\n",
            "98693 : avg_loss:  tensor(1.1465e-11, grad_fn=<DivBackward0>)\n",
            "98694 : avg_loss:  tensor(1.1464e-11, grad_fn=<DivBackward0>)\n",
            "98695 : avg_loss:  tensor(1.1464e-11, grad_fn=<DivBackward0>)\n",
            "98696 : avg_loss:  tensor(1.1464e-11, grad_fn=<DivBackward0>)\n",
            "98697 : avg_loss:  tensor(1.1463e-11, grad_fn=<DivBackward0>)\n",
            "98698 : avg_loss:  tensor(1.1463e-11, grad_fn=<DivBackward0>)\n",
            "98699 : avg_loss:  tensor(1.1463e-11, grad_fn=<DivBackward0>)\n",
            "98700 : avg_loss:  tensor(1.1462e-11, grad_fn=<DivBackward0>)\n",
            "98701 : avg_loss:  tensor(1.1462e-11, grad_fn=<DivBackward0>)\n",
            "98702 : avg_loss:  tensor(1.1462e-11, grad_fn=<DivBackward0>)\n",
            "98703 : avg_loss:  tensor(1.1462e-11, grad_fn=<DivBackward0>)\n",
            "98704 : avg_loss:  tensor(1.1461e-11, grad_fn=<DivBackward0>)\n",
            "98705 : avg_loss:  tensor(1.1461e-11, grad_fn=<DivBackward0>)\n",
            "98706 : avg_loss:  tensor(1.1461e-11, grad_fn=<DivBackward0>)\n",
            "98707 : avg_loss:  tensor(1.1460e-11, grad_fn=<DivBackward0>)\n",
            "98708 : avg_loss:  tensor(1.1460e-11, grad_fn=<DivBackward0>)\n",
            "98709 : avg_loss:  tensor(1.1460e-11, grad_fn=<DivBackward0>)\n",
            "98710 : avg_loss:  tensor(1.1459e-11, grad_fn=<DivBackward0>)\n",
            "98711 : avg_loss:  tensor(1.1459e-11, grad_fn=<DivBackward0>)\n",
            "98712 : avg_loss:  tensor(1.1458e-11, grad_fn=<DivBackward0>)\n",
            "98713 : avg_loss:  tensor(1.1458e-11, grad_fn=<DivBackward0>)\n",
            "98714 : avg_loss:  tensor(1.1458e-11, grad_fn=<DivBackward0>)\n",
            "98715 : avg_loss:  tensor(1.1458e-11, grad_fn=<DivBackward0>)\n",
            "98716 : avg_loss:  tensor(1.1457e-11, grad_fn=<DivBackward0>)\n",
            "98717 : avg_loss:  tensor(1.1457e-11, grad_fn=<DivBackward0>)\n",
            "98718 : avg_loss:  tensor(1.1456e-11, grad_fn=<DivBackward0>)\n",
            "98719 : avg_loss:  tensor(1.1456e-11, grad_fn=<DivBackward0>)\n",
            "98720 : avg_loss:  tensor(1.1456e-11, grad_fn=<DivBackward0>)\n",
            "98721 : avg_loss:  tensor(1.1455e-11, grad_fn=<DivBackward0>)\n",
            "98722 : avg_loss:  tensor(1.1455e-11, grad_fn=<DivBackward0>)\n",
            "98723 : avg_loss:  tensor(1.1455e-11, grad_fn=<DivBackward0>)\n",
            "98724 : avg_loss:  tensor(1.1455e-11, grad_fn=<DivBackward0>)\n",
            "98725 : avg_loss:  tensor(1.1454e-11, grad_fn=<DivBackward0>)\n",
            "98726 : avg_loss:  tensor(1.1454e-11, grad_fn=<DivBackward0>)\n",
            "98727 : avg_loss:  tensor(1.1454e-11, grad_fn=<DivBackward0>)\n",
            "98728 : avg_loss:  tensor(1.1453e-11, grad_fn=<DivBackward0>)\n",
            "98729 : avg_loss:  tensor(1.1453e-11, grad_fn=<DivBackward0>)\n",
            "98730 : avg_loss:  tensor(1.1452e-11, grad_fn=<DivBackward0>)\n",
            "98731 : avg_loss:  tensor(1.1452e-11, grad_fn=<DivBackward0>)\n",
            "98732 : avg_loss:  tensor(1.1452e-11, grad_fn=<DivBackward0>)\n",
            "98733 : avg_loss:  tensor(1.1451e-11, grad_fn=<DivBackward0>)\n",
            "98734 : avg_loss:  tensor(1.1451e-11, grad_fn=<DivBackward0>)\n",
            "98735 : avg_loss:  tensor(1.1451e-11, grad_fn=<DivBackward0>)\n",
            "98736 : avg_loss:  tensor(1.1450e-11, grad_fn=<DivBackward0>)\n",
            "98737 : avg_loss:  tensor(1.1450e-11, grad_fn=<DivBackward0>)\n",
            "98738 : avg_loss:  tensor(1.1450e-11, grad_fn=<DivBackward0>)\n",
            "98739 : avg_loss:  tensor(1.1449e-11, grad_fn=<DivBackward0>)\n",
            "98740 : avg_loss:  tensor(1.1449e-11, grad_fn=<DivBackward0>)\n",
            "98741 : avg_loss:  tensor(1.1448e-11, grad_fn=<DivBackward0>)\n",
            "98742 : avg_loss:  tensor(1.1448e-11, grad_fn=<DivBackward0>)\n",
            "98743 : avg_loss:  tensor(1.1448e-11, grad_fn=<DivBackward0>)\n",
            "98744 : avg_loss:  tensor(1.1448e-11, grad_fn=<DivBackward0>)\n",
            "98745 : avg_loss:  tensor(1.1447e-11, grad_fn=<DivBackward0>)\n",
            "98746 : avg_loss:  tensor(1.1447e-11, grad_fn=<DivBackward0>)\n",
            "98747 : avg_loss:  tensor(1.1446e-11, grad_fn=<DivBackward0>)\n",
            "98748 : avg_loss:  tensor(1.1446e-11, grad_fn=<DivBackward0>)\n",
            "98749 : avg_loss:  tensor(1.1446e-11, grad_fn=<DivBackward0>)\n",
            "98750 : avg_loss:  tensor(1.1446e-11, grad_fn=<DivBackward0>)\n",
            "98751 : avg_loss:  tensor(1.1445e-11, grad_fn=<DivBackward0>)\n",
            "98752 : avg_loss:  tensor(1.1445e-11, grad_fn=<DivBackward0>)\n",
            "98753 : avg_loss:  tensor(1.1445e-11, grad_fn=<DivBackward0>)\n",
            "98754 : avg_loss:  tensor(1.1444e-11, grad_fn=<DivBackward0>)\n",
            "98755 : avg_loss:  tensor(1.1444e-11, grad_fn=<DivBackward0>)\n",
            "98756 : avg_loss:  tensor(1.1444e-11, grad_fn=<DivBackward0>)\n",
            "98757 : avg_loss:  tensor(1.1443e-11, grad_fn=<DivBackward0>)\n",
            "98758 : avg_loss:  tensor(1.1443e-11, grad_fn=<DivBackward0>)\n",
            "98759 : avg_loss:  tensor(1.1443e-11, grad_fn=<DivBackward0>)\n",
            "98760 : avg_loss:  tensor(1.1442e-11, grad_fn=<DivBackward0>)\n",
            "98761 : avg_loss:  tensor(1.1442e-11, grad_fn=<DivBackward0>)\n",
            "98762 : avg_loss:  tensor(1.1442e-11, grad_fn=<DivBackward0>)\n",
            "98763 : avg_loss:  tensor(1.1441e-11, grad_fn=<DivBackward0>)\n",
            "98764 : avg_loss:  tensor(1.1441e-11, grad_fn=<DivBackward0>)\n",
            "98765 : avg_loss:  tensor(1.1440e-11, grad_fn=<DivBackward0>)\n",
            "98766 : avg_loss:  tensor(1.1440e-11, grad_fn=<DivBackward0>)\n",
            "98767 : avg_loss:  tensor(1.1440e-11, grad_fn=<DivBackward0>)\n",
            "98768 : avg_loss:  tensor(1.1439e-11, grad_fn=<DivBackward0>)\n",
            "98769 : avg_loss:  tensor(1.1439e-11, grad_fn=<DivBackward0>)\n",
            "98770 : avg_loss:  tensor(1.1439e-11, grad_fn=<DivBackward0>)\n",
            "98771 : avg_loss:  tensor(1.1439e-11, grad_fn=<DivBackward0>)\n",
            "98772 : avg_loss:  tensor(1.1438e-11, grad_fn=<DivBackward0>)\n",
            "98773 : avg_loss:  tensor(1.1438e-11, grad_fn=<DivBackward0>)\n",
            "98774 : avg_loss:  tensor(1.1438e-11, grad_fn=<DivBackward0>)\n",
            "98775 : avg_loss:  tensor(1.1437e-11, grad_fn=<DivBackward0>)\n",
            "98776 : avg_loss:  tensor(1.1437e-11, grad_fn=<DivBackward0>)\n",
            "98777 : avg_loss:  tensor(1.1436e-11, grad_fn=<DivBackward0>)\n",
            "98778 : avg_loss:  tensor(1.1436e-11, grad_fn=<DivBackward0>)\n",
            "98779 : avg_loss:  tensor(1.1436e-11, grad_fn=<DivBackward0>)\n",
            "98780 : avg_loss:  tensor(1.1435e-11, grad_fn=<DivBackward0>)\n",
            "98781 : avg_loss:  tensor(1.1435e-11, grad_fn=<DivBackward0>)\n",
            "98782 : avg_loss:  tensor(1.1435e-11, grad_fn=<DivBackward0>)\n",
            "98783 : avg_loss:  tensor(1.1434e-11, grad_fn=<DivBackward0>)\n",
            "98784 : avg_loss:  tensor(1.1434e-11, grad_fn=<DivBackward0>)\n",
            "98785 : avg_loss:  tensor(1.1434e-11, grad_fn=<DivBackward0>)\n",
            "98786 : avg_loss:  tensor(1.1433e-11, grad_fn=<DivBackward0>)\n",
            "98787 : avg_loss:  tensor(1.1433e-11, grad_fn=<DivBackward0>)\n",
            "98788 : avg_loss:  tensor(1.1433e-11, grad_fn=<DivBackward0>)\n",
            "98789 : avg_loss:  tensor(1.1432e-11, grad_fn=<DivBackward0>)\n",
            "98790 : avg_loss:  tensor(1.1432e-11, grad_fn=<DivBackward0>)\n",
            "98791 : avg_loss:  tensor(1.1432e-11, grad_fn=<DivBackward0>)\n",
            "98792 : avg_loss:  tensor(1.1431e-11, grad_fn=<DivBackward0>)\n",
            "98793 : avg_loss:  tensor(1.1431e-11, grad_fn=<DivBackward0>)\n",
            "98794 : avg_loss:  tensor(1.1431e-11, grad_fn=<DivBackward0>)\n",
            "98795 : avg_loss:  tensor(1.1430e-11, grad_fn=<DivBackward0>)\n",
            "98796 : avg_loss:  tensor(1.1430e-11, grad_fn=<DivBackward0>)\n",
            "98797 : avg_loss:  tensor(1.1430e-11, grad_fn=<DivBackward0>)\n",
            "98798 : avg_loss:  tensor(1.1429e-11, grad_fn=<DivBackward0>)\n",
            "98799 : avg_loss:  tensor(1.1429e-11, grad_fn=<DivBackward0>)\n",
            "98800 : avg_loss:  tensor(1.1428e-11, grad_fn=<DivBackward0>)\n",
            "98801 : avg_loss:  tensor(1.1428e-11, grad_fn=<DivBackward0>)\n",
            "98802 : avg_loss:  tensor(1.1428e-11, grad_fn=<DivBackward0>)\n",
            "98803 : avg_loss:  tensor(1.1427e-11, grad_fn=<DivBackward0>)\n",
            "98804 : avg_loss:  tensor(1.1427e-11, grad_fn=<DivBackward0>)\n",
            "98805 : avg_loss:  tensor(1.1427e-11, grad_fn=<DivBackward0>)\n",
            "98806 : avg_loss:  tensor(1.1426e-11, grad_fn=<DivBackward0>)\n",
            "98807 : avg_loss:  tensor(1.1426e-11, grad_fn=<DivBackward0>)\n",
            "98808 : avg_loss:  tensor(1.1426e-11, grad_fn=<DivBackward0>)\n",
            "98809 : avg_loss:  tensor(1.1425e-11, grad_fn=<DivBackward0>)\n",
            "98810 : avg_loss:  tensor(1.1425e-11, grad_fn=<DivBackward0>)\n",
            "98811 : avg_loss:  tensor(1.1424e-11, grad_fn=<DivBackward0>)\n",
            "98812 : avg_loss:  tensor(1.1424e-11, grad_fn=<DivBackward0>)\n",
            "98813 : avg_loss:  tensor(1.1424e-11, grad_fn=<DivBackward0>)\n",
            "98814 : avg_loss:  tensor(1.1423e-11, grad_fn=<DivBackward0>)\n",
            "98815 : avg_loss:  tensor(1.1423e-11, grad_fn=<DivBackward0>)\n",
            "98816 : avg_loss:  tensor(1.1423e-11, grad_fn=<DivBackward0>)\n",
            "98817 : avg_loss:  tensor(1.1422e-11, grad_fn=<DivBackward0>)\n",
            "98818 : avg_loss:  tensor(1.1422e-11, grad_fn=<DivBackward0>)\n",
            "98819 : avg_loss:  tensor(1.1422e-11, grad_fn=<DivBackward0>)\n",
            "98820 : avg_loss:  tensor(1.1421e-11, grad_fn=<DivBackward0>)\n",
            "98821 : avg_loss:  tensor(1.1421e-11, grad_fn=<DivBackward0>)\n",
            "98822 : avg_loss:  tensor(1.1421e-11, grad_fn=<DivBackward0>)\n",
            "98823 : avg_loss:  tensor(1.1420e-11, grad_fn=<DivBackward0>)\n",
            "98824 : avg_loss:  tensor(1.1420e-11, grad_fn=<DivBackward0>)\n",
            "98825 : avg_loss:  tensor(1.1419e-11, grad_fn=<DivBackward0>)\n",
            "98826 : avg_loss:  tensor(1.1419e-11, grad_fn=<DivBackward0>)\n",
            "98827 : avg_loss:  tensor(1.1419e-11, grad_fn=<DivBackward0>)\n",
            "98828 : avg_loss:  tensor(1.1418e-11, grad_fn=<DivBackward0>)\n",
            "98829 : avg_loss:  tensor(1.1418e-11, grad_fn=<DivBackward0>)\n",
            "98830 : avg_loss:  tensor(1.1418e-11, grad_fn=<DivBackward0>)\n",
            "98831 : avg_loss:  tensor(1.1418e-11, grad_fn=<DivBackward0>)\n",
            "98832 : avg_loss:  tensor(1.1417e-11, grad_fn=<DivBackward0>)\n",
            "98833 : avg_loss:  tensor(1.1417e-11, grad_fn=<DivBackward0>)\n",
            "98834 : avg_loss:  tensor(1.1416e-11, grad_fn=<DivBackward0>)\n",
            "98835 : avg_loss:  tensor(1.1416e-11, grad_fn=<DivBackward0>)\n",
            "98836 : avg_loss:  tensor(1.1416e-11, grad_fn=<DivBackward0>)\n",
            "98837 : avg_loss:  tensor(1.1416e-11, grad_fn=<DivBackward0>)\n",
            "98838 : avg_loss:  tensor(1.1415e-11, grad_fn=<DivBackward0>)\n",
            "98839 : avg_loss:  tensor(1.1415e-11, grad_fn=<DivBackward0>)\n",
            "98840 : avg_loss:  tensor(1.1414e-11, grad_fn=<DivBackward0>)\n",
            "98841 : avg_loss:  tensor(1.1414e-11, grad_fn=<DivBackward0>)\n",
            "98842 : avg_loss:  tensor(1.1414e-11, grad_fn=<DivBackward0>)\n",
            "98843 : avg_loss:  tensor(1.1413e-11, grad_fn=<DivBackward0>)\n",
            "98844 : avg_loss:  tensor(1.1413e-11, grad_fn=<DivBackward0>)\n",
            "98845 : avg_loss:  tensor(1.1413e-11, grad_fn=<DivBackward0>)\n",
            "98846 : avg_loss:  tensor(1.1412e-11, grad_fn=<DivBackward0>)\n",
            "98847 : avg_loss:  tensor(1.1412e-11, grad_fn=<DivBackward0>)\n",
            "98848 : avg_loss:  tensor(1.1412e-11, grad_fn=<DivBackward0>)\n",
            "98849 : avg_loss:  tensor(1.1411e-11, grad_fn=<DivBackward0>)\n",
            "98850 : avg_loss:  tensor(1.1411e-11, grad_fn=<DivBackward0>)\n",
            "98851 : avg_loss:  tensor(1.1411e-11, grad_fn=<DivBackward0>)\n",
            "98852 : avg_loss:  tensor(1.1410e-11, grad_fn=<DivBackward0>)\n",
            "98853 : avg_loss:  tensor(1.1410e-11, grad_fn=<DivBackward0>)\n",
            "98854 : avg_loss:  tensor(1.1410e-11, grad_fn=<DivBackward0>)\n",
            "98855 : avg_loss:  tensor(1.1409e-11, grad_fn=<DivBackward0>)\n",
            "98856 : avg_loss:  tensor(1.1409e-11, grad_fn=<DivBackward0>)\n",
            "98857 : avg_loss:  tensor(1.1408e-11, grad_fn=<DivBackward0>)\n",
            "98858 : avg_loss:  tensor(1.1408e-11, grad_fn=<DivBackward0>)\n",
            "98859 : avg_loss:  tensor(1.1408e-11, grad_fn=<DivBackward0>)\n",
            "98860 : avg_loss:  tensor(1.1407e-11, grad_fn=<DivBackward0>)\n",
            "98861 : avg_loss:  tensor(1.1407e-11, grad_fn=<DivBackward0>)\n",
            "98862 : avg_loss:  tensor(1.1407e-11, grad_fn=<DivBackward0>)\n",
            "98863 : avg_loss:  tensor(1.1406e-11, grad_fn=<DivBackward0>)\n",
            "98864 : avg_loss:  tensor(1.1406e-11, grad_fn=<DivBackward0>)\n",
            "98865 : avg_loss:  tensor(1.1405e-11, grad_fn=<DivBackward0>)\n",
            "98866 : avg_loss:  tensor(1.1405e-11, grad_fn=<DivBackward0>)\n",
            "98867 : avg_loss:  tensor(1.1405e-11, grad_fn=<DivBackward0>)\n",
            "98868 : avg_loss:  tensor(1.1404e-11, grad_fn=<DivBackward0>)\n",
            "98869 : avg_loss:  tensor(1.1404e-11, grad_fn=<DivBackward0>)\n",
            "98870 : avg_loss:  tensor(1.1404e-11, grad_fn=<DivBackward0>)\n",
            "98871 : avg_loss:  tensor(1.1403e-11, grad_fn=<DivBackward0>)\n",
            "98872 : avg_loss:  tensor(1.1403e-11, grad_fn=<DivBackward0>)\n",
            "98873 : avg_loss:  tensor(1.1403e-11, grad_fn=<DivBackward0>)\n",
            "98874 : avg_loss:  tensor(1.1402e-11, grad_fn=<DivBackward0>)\n",
            "98875 : avg_loss:  tensor(1.1402e-11, grad_fn=<DivBackward0>)\n",
            "98876 : avg_loss:  tensor(1.1401e-11, grad_fn=<DivBackward0>)\n",
            "98877 : avg_loss:  tensor(1.1401e-11, grad_fn=<DivBackward0>)\n",
            "98878 : avg_loss:  tensor(1.1401e-11, grad_fn=<DivBackward0>)\n",
            "98879 : avg_loss:  tensor(1.1400e-11, grad_fn=<DivBackward0>)\n",
            "98880 : avg_loss:  tensor(1.1400e-11, grad_fn=<DivBackward0>)\n",
            "98881 : avg_loss:  tensor(1.1400e-11, grad_fn=<DivBackward0>)\n",
            "98882 : avg_loss:  tensor(1.1399e-11, grad_fn=<DivBackward0>)\n",
            "98883 : avg_loss:  tensor(1.1399e-11, grad_fn=<DivBackward0>)\n",
            "98884 : avg_loss:  tensor(1.1399e-11, grad_fn=<DivBackward0>)\n",
            "98885 : avg_loss:  tensor(1.1398e-11, grad_fn=<DivBackward0>)\n",
            "98886 : avg_loss:  tensor(1.1398e-11, grad_fn=<DivBackward0>)\n",
            "98887 : avg_loss:  tensor(1.1398e-11, grad_fn=<DivBackward0>)\n",
            "98888 : avg_loss:  tensor(1.1397e-11, grad_fn=<DivBackward0>)\n",
            "98889 : avg_loss:  tensor(1.1397e-11, grad_fn=<DivBackward0>)\n",
            "98890 : avg_loss:  tensor(1.1397e-11, grad_fn=<DivBackward0>)\n",
            "98891 : avg_loss:  tensor(1.1396e-11, grad_fn=<DivBackward0>)\n",
            "98892 : avg_loss:  tensor(1.1396e-11, grad_fn=<DivBackward0>)\n",
            "98893 : avg_loss:  tensor(1.1395e-11, grad_fn=<DivBackward0>)\n",
            "98894 : avg_loss:  tensor(1.1395e-11, grad_fn=<DivBackward0>)\n",
            "98895 : avg_loss:  tensor(1.1395e-11, grad_fn=<DivBackward0>)\n",
            "98896 : avg_loss:  tensor(1.1394e-11, grad_fn=<DivBackward0>)\n",
            "98897 : avg_loss:  tensor(1.1394e-11, grad_fn=<DivBackward0>)\n",
            "98898 : avg_loss:  tensor(1.1394e-11, grad_fn=<DivBackward0>)\n",
            "98899 : avg_loss:  tensor(1.1393e-11, grad_fn=<DivBackward0>)\n",
            "98900 : avg_loss:  tensor(1.1393e-11, grad_fn=<DivBackward0>)\n",
            "98901 : avg_loss:  tensor(1.1392e-11, grad_fn=<DivBackward0>)\n",
            "98902 : avg_loss:  tensor(1.1392e-11, grad_fn=<DivBackward0>)\n",
            "98903 : avg_loss:  tensor(1.1392e-11, grad_fn=<DivBackward0>)\n",
            "98904 : avg_loss:  tensor(1.1391e-11, grad_fn=<DivBackward0>)\n",
            "98905 : avg_loss:  tensor(1.1391e-11, grad_fn=<DivBackward0>)\n",
            "98906 : avg_loss:  tensor(1.1391e-11, grad_fn=<DivBackward0>)\n",
            "98907 : avg_loss:  tensor(1.1390e-11, grad_fn=<DivBackward0>)\n",
            "98908 : avg_loss:  tensor(1.1390e-11, grad_fn=<DivBackward0>)\n",
            "98909 : avg_loss:  tensor(1.1390e-11, grad_fn=<DivBackward0>)\n",
            "98910 : avg_loss:  tensor(1.1390e-11, grad_fn=<DivBackward0>)\n",
            "98911 : avg_loss:  tensor(1.1389e-11, grad_fn=<DivBackward0>)\n",
            "98912 : avg_loss:  tensor(1.1388e-11, grad_fn=<DivBackward0>)\n",
            "98913 : avg_loss:  tensor(1.1388e-11, grad_fn=<DivBackward0>)\n",
            "98914 : avg_loss:  tensor(1.1388e-11, grad_fn=<DivBackward0>)\n",
            "98915 : avg_loss:  tensor(1.1388e-11, grad_fn=<DivBackward0>)\n",
            "98916 : avg_loss:  tensor(1.1387e-11, grad_fn=<DivBackward0>)\n",
            "98917 : avg_loss:  tensor(1.1387e-11, grad_fn=<DivBackward0>)\n",
            "98918 : avg_loss:  tensor(1.1387e-11, grad_fn=<DivBackward0>)\n",
            "98919 : avg_loss:  tensor(1.1386e-11, grad_fn=<DivBackward0>)\n",
            "98920 : avg_loss:  tensor(1.1386e-11, grad_fn=<DivBackward0>)\n",
            "98921 : avg_loss:  tensor(1.1385e-11, grad_fn=<DivBackward0>)\n",
            "98922 : avg_loss:  tensor(1.1385e-11, grad_fn=<DivBackward0>)\n",
            "98923 : avg_loss:  tensor(1.1385e-11, grad_fn=<DivBackward0>)\n",
            "98924 : avg_loss:  tensor(1.1384e-11, grad_fn=<DivBackward0>)\n",
            "98925 : avg_loss:  tensor(1.1384e-11, grad_fn=<DivBackward0>)\n",
            "98926 : avg_loss:  tensor(1.1383e-11, grad_fn=<DivBackward0>)\n",
            "98927 : avg_loss:  tensor(1.1383e-11, grad_fn=<DivBackward0>)\n",
            "98928 : avg_loss:  tensor(1.1383e-11, grad_fn=<DivBackward0>)\n",
            "98929 : avg_loss:  tensor(1.1382e-11, grad_fn=<DivBackward0>)\n",
            "98930 : avg_loss:  tensor(1.1382e-11, grad_fn=<DivBackward0>)\n",
            "98931 : avg_loss:  tensor(1.1382e-11, grad_fn=<DivBackward0>)\n",
            "98932 : avg_loss:  tensor(1.1381e-11, grad_fn=<DivBackward0>)\n",
            "98933 : avg_loss:  tensor(1.1381e-11, grad_fn=<DivBackward0>)\n",
            "98934 : avg_loss:  tensor(1.1380e-11, grad_fn=<DivBackward0>)\n",
            "98935 : avg_loss:  tensor(1.1380e-11, grad_fn=<DivBackward0>)\n",
            "98936 : avg_loss:  tensor(1.1380e-11, grad_fn=<DivBackward0>)\n",
            "98937 : avg_loss:  tensor(1.1379e-11, grad_fn=<DivBackward0>)\n",
            "98938 : avg_loss:  tensor(1.1379e-11, grad_fn=<DivBackward0>)\n",
            "98939 : avg_loss:  tensor(1.1379e-11, grad_fn=<DivBackward0>)\n",
            "98940 : avg_loss:  tensor(1.1379e-11, grad_fn=<DivBackward0>)\n",
            "98941 : avg_loss:  tensor(1.1378e-11, grad_fn=<DivBackward0>)\n",
            "98942 : avg_loss:  tensor(1.1378e-11, grad_fn=<DivBackward0>)\n",
            "98943 : avg_loss:  tensor(1.1378e-11, grad_fn=<DivBackward0>)\n",
            "98944 : avg_loss:  tensor(1.1377e-11, grad_fn=<DivBackward0>)\n",
            "98945 : avg_loss:  tensor(1.1377e-11, grad_fn=<DivBackward0>)\n",
            "98946 : avg_loss:  tensor(1.1376e-11, grad_fn=<DivBackward0>)\n",
            "98947 : avg_loss:  tensor(1.1376e-11, grad_fn=<DivBackward0>)\n",
            "98948 : avg_loss:  tensor(1.1375e-11, grad_fn=<DivBackward0>)\n",
            "98949 : avg_loss:  tensor(1.1375e-11, grad_fn=<DivBackward0>)\n",
            "98950 : avg_loss:  tensor(1.1375e-11, grad_fn=<DivBackward0>)\n",
            "98951 : avg_loss:  tensor(1.1375e-11, grad_fn=<DivBackward0>)\n",
            "98952 : avg_loss:  tensor(1.1374e-11, grad_fn=<DivBackward0>)\n",
            "98953 : avg_loss:  tensor(1.1374e-11, grad_fn=<DivBackward0>)\n",
            "98954 : avg_loss:  tensor(1.1373e-11, grad_fn=<DivBackward0>)\n",
            "98955 : avg_loss:  tensor(1.1373e-11, grad_fn=<DivBackward0>)\n",
            "98956 : avg_loss:  tensor(1.1373e-11, grad_fn=<DivBackward0>)\n",
            "98957 : avg_loss:  tensor(1.1372e-11, grad_fn=<DivBackward0>)\n",
            "98958 : avg_loss:  tensor(1.1372e-11, grad_fn=<DivBackward0>)\n",
            "98959 : avg_loss:  tensor(1.1371e-11, grad_fn=<DivBackward0>)\n",
            "98960 : avg_loss:  tensor(1.1371e-11, grad_fn=<DivBackward0>)\n",
            "98961 : avg_loss:  tensor(1.1371e-11, grad_fn=<DivBackward0>)\n",
            "98962 : avg_loss:  tensor(1.1370e-11, grad_fn=<DivBackward0>)\n",
            "98963 : avg_loss:  tensor(1.1370e-11, grad_fn=<DivBackward0>)\n",
            "98964 : avg_loss:  tensor(1.1370e-11, grad_fn=<DivBackward0>)\n",
            "98965 : avg_loss:  tensor(1.1369e-11, grad_fn=<DivBackward0>)\n",
            "98966 : avg_loss:  tensor(1.1369e-11, grad_fn=<DivBackward0>)\n",
            "98967 : avg_loss:  tensor(1.1368e-11, grad_fn=<DivBackward0>)\n",
            "98968 : avg_loss:  tensor(1.1368e-11, grad_fn=<DivBackward0>)\n",
            "98969 : avg_loss:  tensor(1.1368e-11, grad_fn=<DivBackward0>)\n",
            "98970 : avg_loss:  tensor(1.1367e-11, grad_fn=<DivBackward0>)\n",
            "98971 : avg_loss:  tensor(1.1367e-11, grad_fn=<DivBackward0>)\n",
            "98972 : avg_loss:  tensor(1.1367e-11, grad_fn=<DivBackward0>)\n",
            "98973 : avg_loss:  tensor(1.1367e-11, grad_fn=<DivBackward0>)\n",
            "98974 : avg_loss:  tensor(1.1366e-11, grad_fn=<DivBackward0>)\n",
            "98975 : avg_loss:  tensor(1.1366e-11, grad_fn=<DivBackward0>)\n",
            "98976 : avg_loss:  tensor(1.1365e-11, grad_fn=<DivBackward0>)\n",
            "98977 : avg_loss:  tensor(1.1365e-11, grad_fn=<DivBackward0>)\n",
            "98978 : avg_loss:  tensor(1.1365e-11, grad_fn=<DivBackward0>)\n",
            "98979 : avg_loss:  tensor(1.1364e-11, grad_fn=<DivBackward0>)\n",
            "98980 : avg_loss:  tensor(1.1364e-11, grad_fn=<DivBackward0>)\n",
            "98981 : avg_loss:  tensor(1.1364e-11, grad_fn=<DivBackward0>)\n",
            "98982 : avg_loss:  tensor(1.1363e-11, grad_fn=<DivBackward0>)\n",
            "98983 : avg_loss:  tensor(1.1363e-11, grad_fn=<DivBackward0>)\n",
            "98984 : avg_loss:  tensor(1.1363e-11, grad_fn=<DivBackward0>)\n",
            "98985 : avg_loss:  tensor(1.1362e-11, grad_fn=<DivBackward0>)\n",
            "98986 : avg_loss:  tensor(1.1362e-11, grad_fn=<DivBackward0>)\n",
            "98987 : avg_loss:  tensor(1.1361e-11, grad_fn=<DivBackward0>)\n",
            "98988 : avg_loss:  tensor(1.1361e-11, grad_fn=<DivBackward0>)\n",
            "98989 : avg_loss:  tensor(1.1360e-11, grad_fn=<DivBackward0>)\n",
            "98990 : avg_loss:  tensor(1.1360e-11, grad_fn=<DivBackward0>)\n",
            "98991 : avg_loss:  tensor(1.1359e-11, grad_fn=<DivBackward0>)\n",
            "98992 : avg_loss:  tensor(1.1359e-11, grad_fn=<DivBackward0>)\n",
            "98993 : avg_loss:  tensor(1.1359e-11, grad_fn=<DivBackward0>)\n",
            "98994 : avg_loss:  tensor(1.1359e-11, grad_fn=<DivBackward0>)\n",
            "98995 : avg_loss:  tensor(1.1358e-11, grad_fn=<DivBackward0>)\n",
            "98996 : avg_loss:  tensor(1.1358e-11, grad_fn=<DivBackward0>)\n",
            "98997 : avg_loss:  tensor(1.1358e-11, grad_fn=<DivBackward0>)\n",
            "98998 : avg_loss:  tensor(1.1357e-11, grad_fn=<DivBackward0>)\n",
            "98999 : avg_loss:  tensor(1.1357e-11, grad_fn=<DivBackward0>)\n",
            "99000 : avg_loss:  tensor(1.1356e-11, grad_fn=<DivBackward0>)\n",
            "99001 : avg_loss:  tensor(1.1356e-11, grad_fn=<DivBackward0>)\n",
            "99002 : avg_loss:  tensor(1.1356e-11, grad_fn=<DivBackward0>)\n",
            "99003 : avg_loss:  tensor(1.1355e-11, grad_fn=<DivBackward0>)\n",
            "99004 : avg_loss:  tensor(1.1355e-11, grad_fn=<DivBackward0>)\n",
            "99005 : avg_loss:  tensor(1.1355e-11, grad_fn=<DivBackward0>)\n",
            "99006 : avg_loss:  tensor(1.1354e-11, grad_fn=<DivBackward0>)\n",
            "99007 : avg_loss:  tensor(1.1354e-11, grad_fn=<DivBackward0>)\n",
            "99008 : avg_loss:  tensor(1.1354e-11, grad_fn=<DivBackward0>)\n",
            "99009 : avg_loss:  tensor(1.1353e-11, grad_fn=<DivBackward0>)\n",
            "99010 : avg_loss:  tensor(1.1353e-11, grad_fn=<DivBackward0>)\n",
            "99011 : avg_loss:  tensor(1.1352e-11, grad_fn=<DivBackward0>)\n",
            "99012 : avg_loss:  tensor(1.1352e-11, grad_fn=<DivBackward0>)\n",
            "99013 : avg_loss:  tensor(1.1351e-11, grad_fn=<DivBackward0>)\n",
            "99014 : avg_loss:  tensor(1.1351e-11, grad_fn=<DivBackward0>)\n",
            "99015 : avg_loss:  tensor(1.1351e-11, grad_fn=<DivBackward0>)\n",
            "99016 : avg_loss:  tensor(1.1350e-11, grad_fn=<DivBackward0>)\n",
            "99017 : avg_loss:  tensor(1.1350e-11, grad_fn=<DivBackward0>)\n",
            "99018 : avg_loss:  tensor(1.1350e-11, grad_fn=<DivBackward0>)\n",
            "99019 : avg_loss:  tensor(1.1349e-11, grad_fn=<DivBackward0>)\n",
            "99020 : avg_loss:  tensor(1.1349e-11, grad_fn=<DivBackward0>)\n",
            "99021 : avg_loss:  tensor(1.1348e-11, grad_fn=<DivBackward0>)\n",
            "99022 : avg_loss:  tensor(1.1348e-11, grad_fn=<DivBackward0>)\n",
            "99023 : avg_loss:  tensor(1.1348e-11, grad_fn=<DivBackward0>)\n",
            "99024 : avg_loss:  tensor(1.1347e-11, grad_fn=<DivBackward0>)\n",
            "99025 : avg_loss:  tensor(1.1347e-11, grad_fn=<DivBackward0>)\n",
            "99026 : avg_loss:  tensor(1.1347e-11, grad_fn=<DivBackward0>)\n",
            "99027 : avg_loss:  tensor(1.1346e-11, grad_fn=<DivBackward0>)\n",
            "99028 : avg_loss:  tensor(1.1346e-11, grad_fn=<DivBackward0>)\n",
            "99029 : avg_loss:  tensor(1.1346e-11, grad_fn=<DivBackward0>)\n",
            "99030 : avg_loss:  tensor(1.1345e-11, grad_fn=<DivBackward0>)\n",
            "99031 : avg_loss:  tensor(1.1345e-11, grad_fn=<DivBackward0>)\n",
            "99032 : avg_loss:  tensor(1.1345e-11, grad_fn=<DivBackward0>)\n",
            "99033 : avg_loss:  tensor(1.1344e-11, grad_fn=<DivBackward0>)\n",
            "99034 : avg_loss:  tensor(1.1344e-11, grad_fn=<DivBackward0>)\n",
            "99035 : avg_loss:  tensor(1.1344e-11, grad_fn=<DivBackward0>)\n",
            "99036 : avg_loss:  tensor(1.1343e-11, grad_fn=<DivBackward0>)\n",
            "99037 : avg_loss:  tensor(1.1343e-11, grad_fn=<DivBackward0>)\n",
            "99038 : avg_loss:  tensor(1.1342e-11, grad_fn=<DivBackward0>)\n",
            "99039 : avg_loss:  tensor(1.1342e-11, grad_fn=<DivBackward0>)\n",
            "99040 : avg_loss:  tensor(1.1342e-11, grad_fn=<DivBackward0>)\n",
            "99041 : avg_loss:  tensor(1.1341e-11, grad_fn=<DivBackward0>)\n",
            "99042 : avg_loss:  tensor(1.1341e-11, grad_fn=<DivBackward0>)\n",
            "99043 : avg_loss:  tensor(1.1340e-11, grad_fn=<DivBackward0>)\n",
            "99044 : avg_loss:  tensor(1.1340e-11, grad_fn=<DivBackward0>)\n",
            "99045 : avg_loss:  tensor(1.1339e-11, grad_fn=<DivBackward0>)\n",
            "99046 : avg_loss:  tensor(1.1339e-11, grad_fn=<DivBackward0>)\n",
            "99047 : avg_loss:  tensor(1.1339e-11, grad_fn=<DivBackward0>)\n",
            "99048 : avg_loss:  tensor(1.1338e-11, grad_fn=<DivBackward0>)\n",
            "99049 : avg_loss:  tensor(1.1338e-11, grad_fn=<DivBackward0>)\n",
            "99050 : avg_loss:  tensor(1.1338e-11, grad_fn=<DivBackward0>)\n",
            "99051 : avg_loss:  tensor(1.1337e-11, grad_fn=<DivBackward0>)\n",
            "99052 : avg_loss:  tensor(1.1337e-11, grad_fn=<DivBackward0>)\n",
            "99053 : avg_loss:  tensor(1.1336e-11, grad_fn=<DivBackward0>)\n",
            "99054 : avg_loss:  tensor(1.1336e-11, grad_fn=<DivBackward0>)\n",
            "99055 : avg_loss:  tensor(1.1335e-11, grad_fn=<DivBackward0>)\n",
            "99056 : avg_loss:  tensor(1.1335e-11, grad_fn=<DivBackward0>)\n",
            "99057 : avg_loss:  tensor(1.1335e-11, grad_fn=<DivBackward0>)\n",
            "99058 : avg_loss:  tensor(1.1334e-11, grad_fn=<DivBackward0>)\n",
            "99059 : avg_loss:  tensor(1.1334e-11, grad_fn=<DivBackward0>)\n",
            "99060 : avg_loss:  tensor(1.1334e-11, grad_fn=<DivBackward0>)\n",
            "99061 : avg_loss:  tensor(1.1333e-11, grad_fn=<DivBackward0>)\n",
            "99062 : avg_loss:  tensor(1.1333e-11, grad_fn=<DivBackward0>)\n",
            "99063 : avg_loss:  tensor(1.1332e-11, grad_fn=<DivBackward0>)\n",
            "99064 : avg_loss:  tensor(1.1332e-11, grad_fn=<DivBackward0>)\n",
            "99065 : avg_loss:  tensor(1.1332e-11, grad_fn=<DivBackward0>)\n",
            "99066 : avg_loss:  tensor(1.1331e-11, grad_fn=<DivBackward0>)\n",
            "99067 : avg_loss:  tensor(1.1331e-11, grad_fn=<DivBackward0>)\n",
            "99068 : avg_loss:  tensor(1.1330e-11, grad_fn=<DivBackward0>)\n",
            "99069 : avg_loss:  tensor(1.1330e-11, grad_fn=<DivBackward0>)\n",
            "99070 : avg_loss:  tensor(1.1330e-11, grad_fn=<DivBackward0>)\n",
            "99071 : avg_loss:  tensor(1.1330e-11, grad_fn=<DivBackward0>)\n",
            "99072 : avg_loss:  tensor(1.1329e-11, grad_fn=<DivBackward0>)\n",
            "99073 : avg_loss:  tensor(1.1329e-11, grad_fn=<DivBackward0>)\n",
            "99074 : avg_loss:  tensor(1.1328e-11, grad_fn=<DivBackward0>)\n",
            "99075 : avg_loss:  tensor(1.1328e-11, grad_fn=<DivBackward0>)\n",
            "99076 : avg_loss:  tensor(1.1328e-11, grad_fn=<DivBackward0>)\n",
            "99077 : avg_loss:  tensor(1.1327e-11, grad_fn=<DivBackward0>)\n",
            "99078 : avg_loss:  tensor(1.1327e-11, grad_fn=<DivBackward0>)\n",
            "99079 : avg_loss:  tensor(1.1326e-11, grad_fn=<DivBackward0>)\n",
            "99080 : avg_loss:  tensor(1.1326e-11, grad_fn=<DivBackward0>)\n",
            "99081 : avg_loss:  tensor(1.1325e-11, grad_fn=<DivBackward0>)\n",
            "99082 : avg_loss:  tensor(1.1325e-11, grad_fn=<DivBackward0>)\n",
            "99083 : avg_loss:  tensor(1.1325e-11, grad_fn=<DivBackward0>)\n",
            "99084 : avg_loss:  tensor(1.1324e-11, grad_fn=<DivBackward0>)\n",
            "99085 : avg_loss:  tensor(1.1324e-11, grad_fn=<DivBackward0>)\n",
            "99086 : avg_loss:  tensor(1.1324e-11, grad_fn=<DivBackward0>)\n",
            "99087 : avg_loss:  tensor(1.1323e-11, grad_fn=<DivBackward0>)\n",
            "99088 : avg_loss:  tensor(1.1323e-11, grad_fn=<DivBackward0>)\n",
            "99089 : avg_loss:  tensor(1.1323e-11, grad_fn=<DivBackward0>)\n",
            "99090 : avg_loss:  tensor(1.1322e-11, grad_fn=<DivBackward0>)\n",
            "99091 : avg_loss:  tensor(1.1322e-11, grad_fn=<DivBackward0>)\n",
            "99092 : avg_loss:  tensor(1.1321e-11, grad_fn=<DivBackward0>)\n",
            "99093 : avg_loss:  tensor(1.1321e-11, grad_fn=<DivBackward0>)\n",
            "99094 : avg_loss:  tensor(1.1320e-11, grad_fn=<DivBackward0>)\n",
            "99095 : avg_loss:  tensor(1.1320e-11, grad_fn=<DivBackward0>)\n",
            "99096 : avg_loss:  tensor(1.1320e-11, grad_fn=<DivBackward0>)\n",
            "99097 : avg_loss:  tensor(1.1319e-11, grad_fn=<DivBackward0>)\n",
            "99098 : avg_loss:  tensor(1.1319e-11, grad_fn=<DivBackward0>)\n",
            "99099 : avg_loss:  tensor(1.1319e-11, grad_fn=<DivBackward0>)\n",
            "99100 : avg_loss:  tensor(1.1318e-11, grad_fn=<DivBackward0>)\n",
            "99101 : avg_loss:  tensor(1.1318e-11, grad_fn=<DivBackward0>)\n",
            "99102 : avg_loss:  tensor(1.1317e-11, grad_fn=<DivBackward0>)\n",
            "99103 : avg_loss:  tensor(1.1317e-11, grad_fn=<DivBackward0>)\n",
            "99104 : avg_loss:  tensor(1.1316e-11, grad_fn=<DivBackward0>)\n",
            "99105 : avg_loss:  tensor(1.1316e-11, grad_fn=<DivBackward0>)\n",
            "99106 : avg_loss:  tensor(1.1315e-11, grad_fn=<DivBackward0>)\n",
            "99107 : avg_loss:  tensor(1.1315e-11, grad_fn=<DivBackward0>)\n",
            "99108 : avg_loss:  tensor(1.1315e-11, grad_fn=<DivBackward0>)\n",
            "99109 : avg_loss:  tensor(1.1314e-11, grad_fn=<DivBackward0>)\n",
            "99110 : avg_loss:  tensor(1.1314e-11, grad_fn=<DivBackward0>)\n",
            "99111 : avg_loss:  tensor(1.1314e-11, grad_fn=<DivBackward0>)\n",
            "99112 : avg_loss:  tensor(1.1313e-11, grad_fn=<DivBackward0>)\n",
            "99113 : avg_loss:  tensor(1.1313e-11, grad_fn=<DivBackward0>)\n",
            "99114 : avg_loss:  tensor(1.1313e-11, grad_fn=<DivBackward0>)\n",
            "99115 : avg_loss:  tensor(1.1312e-11, grad_fn=<DivBackward0>)\n",
            "99116 : avg_loss:  tensor(1.1312e-11, grad_fn=<DivBackward0>)\n",
            "99117 : avg_loss:  tensor(1.1311e-11, grad_fn=<DivBackward0>)\n",
            "99118 : avg_loss:  tensor(1.1311e-11, grad_fn=<DivBackward0>)\n",
            "99119 : avg_loss:  tensor(1.1311e-11, grad_fn=<DivBackward0>)\n",
            "99120 : avg_loss:  tensor(1.1310e-11, grad_fn=<DivBackward0>)\n",
            "99121 : avg_loss:  tensor(1.1310e-11, grad_fn=<DivBackward0>)\n",
            "99122 : avg_loss:  tensor(1.1309e-11, grad_fn=<DivBackward0>)\n",
            "99123 : avg_loss:  tensor(1.1309e-11, grad_fn=<DivBackward0>)\n",
            "99124 : avg_loss:  tensor(1.1309e-11, grad_fn=<DivBackward0>)\n",
            "99125 : avg_loss:  tensor(1.1308e-11, grad_fn=<DivBackward0>)\n",
            "99126 : avg_loss:  tensor(1.1308e-11, grad_fn=<DivBackward0>)\n",
            "99127 : avg_loss:  tensor(1.1307e-11, grad_fn=<DivBackward0>)\n",
            "99128 : avg_loss:  tensor(1.1307e-11, grad_fn=<DivBackward0>)\n",
            "99129 : avg_loss:  tensor(1.1307e-11, grad_fn=<DivBackward0>)\n",
            "99130 : avg_loss:  tensor(1.1306e-11, grad_fn=<DivBackward0>)\n",
            "99131 : avg_loss:  tensor(1.1306e-11, grad_fn=<DivBackward0>)\n",
            "99132 : avg_loss:  tensor(1.1306e-11, grad_fn=<DivBackward0>)\n",
            "99133 : avg_loss:  tensor(1.1305e-11, grad_fn=<DivBackward0>)\n",
            "99134 : avg_loss:  tensor(1.1304e-11, grad_fn=<DivBackward0>)\n",
            "99135 : avg_loss:  tensor(1.1304e-11, grad_fn=<DivBackward0>)\n",
            "99136 : avg_loss:  tensor(1.1304e-11, grad_fn=<DivBackward0>)\n",
            "99137 : avg_loss:  tensor(1.1303e-11, grad_fn=<DivBackward0>)\n",
            "99138 : avg_loss:  tensor(1.1303e-11, grad_fn=<DivBackward0>)\n",
            "99139 : avg_loss:  tensor(1.1303e-11, grad_fn=<DivBackward0>)\n",
            "99140 : avg_loss:  tensor(1.1302e-11, grad_fn=<DivBackward0>)\n",
            "99141 : avg_loss:  tensor(1.1302e-11, grad_fn=<DivBackward0>)\n",
            "99142 : avg_loss:  tensor(1.1302e-11, grad_fn=<DivBackward0>)\n",
            "99143 : avg_loss:  tensor(1.1301e-11, grad_fn=<DivBackward0>)\n",
            "99144 : avg_loss:  tensor(1.1301e-11, grad_fn=<DivBackward0>)\n",
            "99145 : avg_loss:  tensor(1.1300e-11, grad_fn=<DivBackward0>)\n",
            "99146 : avg_loss:  tensor(1.1300e-11, grad_fn=<DivBackward0>)\n",
            "99147 : avg_loss:  tensor(1.1299e-11, grad_fn=<DivBackward0>)\n",
            "99148 : avg_loss:  tensor(1.1299e-11, grad_fn=<DivBackward0>)\n",
            "99149 : avg_loss:  tensor(1.1299e-11, grad_fn=<DivBackward0>)\n",
            "99150 : avg_loss:  tensor(1.1298e-11, grad_fn=<DivBackward0>)\n",
            "99151 : avg_loss:  tensor(1.1298e-11, grad_fn=<DivBackward0>)\n",
            "99152 : avg_loss:  tensor(1.1298e-11, grad_fn=<DivBackward0>)\n",
            "99153 : avg_loss:  tensor(1.1297e-11, grad_fn=<DivBackward0>)\n",
            "99154 : avg_loss:  tensor(1.1297e-11, grad_fn=<DivBackward0>)\n",
            "99155 : avg_loss:  tensor(1.1296e-11, grad_fn=<DivBackward0>)\n",
            "99156 : avg_loss:  tensor(1.1296e-11, grad_fn=<DivBackward0>)\n",
            "99157 : avg_loss:  tensor(1.1296e-11, grad_fn=<DivBackward0>)\n",
            "99158 : avg_loss:  tensor(1.1295e-11, grad_fn=<DivBackward0>)\n",
            "99159 : avg_loss:  tensor(1.1294e-11, grad_fn=<DivBackward0>)\n",
            "99160 : avg_loss:  tensor(1.1294e-11, grad_fn=<DivBackward0>)\n",
            "99161 : avg_loss:  tensor(1.1294e-11, grad_fn=<DivBackward0>)\n",
            "99162 : avg_loss:  tensor(1.1293e-11, grad_fn=<DivBackward0>)\n",
            "99163 : avg_loss:  tensor(1.1293e-11, grad_fn=<DivBackward0>)\n",
            "99164 : avg_loss:  tensor(1.1292e-11, grad_fn=<DivBackward0>)\n",
            "99165 : avg_loss:  tensor(1.1292e-11, grad_fn=<DivBackward0>)\n",
            "99166 : avg_loss:  tensor(1.1292e-11, grad_fn=<DivBackward0>)\n",
            "99167 : avg_loss:  tensor(1.1291e-11, grad_fn=<DivBackward0>)\n",
            "99168 : avg_loss:  tensor(1.1291e-11, grad_fn=<DivBackward0>)\n",
            "99169 : avg_loss:  tensor(1.1290e-11, grad_fn=<DivBackward0>)\n",
            "99170 : avg_loss:  tensor(1.1290e-11, grad_fn=<DivBackward0>)\n",
            "99171 : avg_loss:  tensor(1.1290e-11, grad_fn=<DivBackward0>)\n",
            "99172 : avg_loss:  tensor(1.1289e-11, grad_fn=<DivBackward0>)\n",
            "99173 : avg_loss:  tensor(1.1289e-11, grad_fn=<DivBackward0>)\n",
            "99174 : avg_loss:  tensor(1.1288e-11, grad_fn=<DivBackward0>)\n",
            "99175 : avg_loss:  tensor(1.1288e-11, grad_fn=<DivBackward0>)\n",
            "99176 : avg_loss:  tensor(1.1288e-11, grad_fn=<DivBackward0>)\n",
            "99177 : avg_loss:  tensor(1.1287e-11, grad_fn=<DivBackward0>)\n",
            "99178 : avg_loss:  tensor(1.1287e-11, grad_fn=<DivBackward0>)\n",
            "99179 : avg_loss:  tensor(1.1287e-11, grad_fn=<DivBackward0>)\n",
            "99180 : avg_loss:  tensor(1.1286e-11, grad_fn=<DivBackward0>)\n",
            "99181 : avg_loss:  tensor(1.1286e-11, grad_fn=<DivBackward0>)\n",
            "99182 : avg_loss:  tensor(1.1286e-11, grad_fn=<DivBackward0>)\n",
            "99183 : avg_loss:  tensor(1.1285e-11, grad_fn=<DivBackward0>)\n",
            "99184 : avg_loss:  tensor(1.1285e-11, grad_fn=<DivBackward0>)\n",
            "99185 : avg_loss:  tensor(1.1284e-11, grad_fn=<DivBackward0>)\n",
            "99186 : avg_loss:  tensor(1.1284e-11, grad_fn=<DivBackward0>)\n",
            "99187 : avg_loss:  tensor(1.1283e-11, grad_fn=<DivBackward0>)\n",
            "99188 : avg_loss:  tensor(1.1283e-11, grad_fn=<DivBackward0>)\n",
            "99189 : avg_loss:  tensor(1.1283e-11, grad_fn=<DivBackward0>)\n",
            "99190 : avg_loss:  tensor(1.1282e-11, grad_fn=<DivBackward0>)\n",
            "99191 : avg_loss:  tensor(1.1282e-11, grad_fn=<DivBackward0>)\n",
            "99192 : avg_loss:  tensor(1.1282e-11, grad_fn=<DivBackward0>)\n",
            "99193 : avg_loss:  tensor(1.1281e-11, grad_fn=<DivBackward0>)\n",
            "99194 : avg_loss:  tensor(1.1281e-11, grad_fn=<DivBackward0>)\n",
            "99195 : avg_loss:  tensor(1.1280e-11, grad_fn=<DivBackward0>)\n",
            "99196 : avg_loss:  tensor(1.1280e-11, grad_fn=<DivBackward0>)\n",
            "99197 : avg_loss:  tensor(1.1279e-11, grad_fn=<DivBackward0>)\n",
            "99198 : avg_loss:  tensor(1.1279e-11, grad_fn=<DivBackward0>)\n",
            "99199 : avg_loss:  tensor(1.1279e-11, grad_fn=<DivBackward0>)\n",
            "99200 : avg_loss:  tensor(1.1278e-11, grad_fn=<DivBackward0>)\n",
            "99201 : avg_loss:  tensor(1.1278e-11, grad_fn=<DivBackward0>)\n",
            "99202 : avg_loss:  tensor(1.1278e-11, grad_fn=<DivBackward0>)\n",
            "99203 : avg_loss:  tensor(1.1277e-11, grad_fn=<DivBackward0>)\n",
            "99204 : avg_loss:  tensor(1.1277e-11, grad_fn=<DivBackward0>)\n",
            "99205 : avg_loss:  tensor(1.1276e-11, grad_fn=<DivBackward0>)\n",
            "99206 : avg_loss:  tensor(1.1276e-11, grad_fn=<DivBackward0>)\n",
            "99207 : avg_loss:  tensor(1.1276e-11, grad_fn=<DivBackward0>)\n",
            "99208 : avg_loss:  tensor(1.1275e-11, grad_fn=<DivBackward0>)\n",
            "99209 : avg_loss:  tensor(1.1275e-11, grad_fn=<DivBackward0>)\n",
            "99210 : avg_loss:  tensor(1.1274e-11, grad_fn=<DivBackward0>)\n",
            "99211 : avg_loss:  tensor(1.1274e-11, grad_fn=<DivBackward0>)\n",
            "99212 : avg_loss:  tensor(1.1274e-11, grad_fn=<DivBackward0>)\n",
            "99213 : avg_loss:  tensor(1.1273e-11, grad_fn=<DivBackward0>)\n",
            "99214 : avg_loss:  tensor(1.1273e-11, grad_fn=<DivBackward0>)\n",
            "99215 : avg_loss:  tensor(1.1272e-11, grad_fn=<DivBackward0>)\n",
            "99216 : avg_loss:  tensor(1.1272e-11, grad_fn=<DivBackward0>)\n",
            "99217 : avg_loss:  tensor(1.1271e-11, grad_fn=<DivBackward0>)\n",
            "99218 : avg_loss:  tensor(1.1271e-11, grad_fn=<DivBackward0>)\n",
            "99219 : avg_loss:  tensor(1.1270e-11, grad_fn=<DivBackward0>)\n",
            "99220 : avg_loss:  tensor(1.1270e-11, grad_fn=<DivBackward0>)\n",
            "99221 : avg_loss:  tensor(1.1270e-11, grad_fn=<DivBackward0>)\n",
            "99222 : avg_loss:  tensor(1.1270e-11, grad_fn=<DivBackward0>)\n",
            "99223 : avg_loss:  tensor(1.1269e-11, grad_fn=<DivBackward0>)\n",
            "99224 : avg_loss:  tensor(1.1268e-11, grad_fn=<DivBackward0>)\n",
            "99225 : avg_loss:  tensor(1.1268e-11, grad_fn=<DivBackward0>)\n",
            "99226 : avg_loss:  tensor(1.1268e-11, grad_fn=<DivBackward0>)\n",
            "99227 : avg_loss:  tensor(1.1267e-11, grad_fn=<DivBackward0>)\n",
            "99228 : avg_loss:  tensor(1.1267e-11, grad_fn=<DivBackward0>)\n",
            "99229 : avg_loss:  tensor(1.1267e-11, grad_fn=<DivBackward0>)\n",
            "99230 : avg_loss:  tensor(1.1266e-11, grad_fn=<DivBackward0>)\n",
            "99231 : avg_loss:  tensor(1.1266e-11, grad_fn=<DivBackward0>)\n",
            "99232 : avg_loss:  tensor(1.1265e-11, grad_fn=<DivBackward0>)\n",
            "99233 : avg_loss:  tensor(1.1265e-11, grad_fn=<DivBackward0>)\n",
            "99234 : avg_loss:  tensor(1.1264e-11, grad_fn=<DivBackward0>)\n",
            "99235 : avg_loss:  tensor(1.1264e-11, grad_fn=<DivBackward0>)\n",
            "99236 : avg_loss:  tensor(1.1264e-11, grad_fn=<DivBackward0>)\n",
            "99237 : avg_loss:  tensor(1.1263e-11, grad_fn=<DivBackward0>)\n",
            "99238 : avg_loss:  tensor(1.1263e-11, grad_fn=<DivBackward0>)\n",
            "99239 : avg_loss:  tensor(1.1263e-11, grad_fn=<DivBackward0>)\n",
            "99240 : avg_loss:  tensor(1.1262e-11, grad_fn=<DivBackward0>)\n",
            "99241 : avg_loss:  tensor(1.1262e-11, grad_fn=<DivBackward0>)\n",
            "99242 : avg_loss:  tensor(1.1261e-11, grad_fn=<DivBackward0>)\n",
            "99243 : avg_loss:  tensor(1.1261e-11, grad_fn=<DivBackward0>)\n",
            "99244 : avg_loss:  tensor(1.1260e-11, grad_fn=<DivBackward0>)\n",
            "99245 : avg_loss:  tensor(1.1260e-11, grad_fn=<DivBackward0>)\n",
            "99246 : avg_loss:  tensor(1.1259e-11, grad_fn=<DivBackward0>)\n",
            "99247 : avg_loss:  tensor(1.1259e-11, grad_fn=<DivBackward0>)\n",
            "99248 : avg_loss:  tensor(1.1259e-11, grad_fn=<DivBackward0>)\n",
            "99249 : avg_loss:  tensor(1.1258e-11, grad_fn=<DivBackward0>)\n",
            "99250 : avg_loss:  tensor(1.1258e-11, grad_fn=<DivBackward0>)\n",
            "99251 : avg_loss:  tensor(1.1258e-11, grad_fn=<DivBackward0>)\n",
            "99252 : avg_loss:  tensor(1.1257e-11, grad_fn=<DivBackward0>)\n",
            "99253 : avg_loss:  tensor(1.1257e-11, grad_fn=<DivBackward0>)\n",
            "99254 : avg_loss:  tensor(1.1256e-11, grad_fn=<DivBackward0>)\n",
            "99255 : avg_loss:  tensor(1.1256e-11, grad_fn=<DivBackward0>)\n",
            "99256 : avg_loss:  tensor(1.1256e-11, grad_fn=<DivBackward0>)\n",
            "99257 : avg_loss:  tensor(1.1255e-11, grad_fn=<DivBackward0>)\n",
            "99258 : avg_loss:  tensor(1.1255e-11, grad_fn=<DivBackward0>)\n",
            "99259 : avg_loss:  tensor(1.1254e-11, grad_fn=<DivBackward0>)\n",
            "99260 : avg_loss:  tensor(1.1254e-11, grad_fn=<DivBackward0>)\n",
            "99261 : avg_loss:  tensor(1.1254e-11, grad_fn=<DivBackward0>)\n",
            "99262 : avg_loss:  tensor(1.1253e-11, grad_fn=<DivBackward0>)\n",
            "99263 : avg_loss:  tensor(1.1253e-11, grad_fn=<DivBackward0>)\n",
            "99264 : avg_loss:  tensor(1.1252e-11, grad_fn=<DivBackward0>)\n",
            "99265 : avg_loss:  tensor(1.1252e-11, grad_fn=<DivBackward0>)\n",
            "99266 : avg_loss:  tensor(1.1251e-11, grad_fn=<DivBackward0>)\n",
            "99267 : avg_loss:  tensor(1.1251e-11, grad_fn=<DivBackward0>)\n",
            "99268 : avg_loss:  tensor(1.1251e-11, grad_fn=<DivBackward0>)\n",
            "99269 : avg_loss:  tensor(1.1250e-11, grad_fn=<DivBackward0>)\n",
            "99270 : avg_loss:  tensor(1.1250e-11, grad_fn=<DivBackward0>)\n",
            "99271 : avg_loss:  tensor(1.1249e-11, grad_fn=<DivBackward0>)\n",
            "99272 : avg_loss:  tensor(1.1249e-11, grad_fn=<DivBackward0>)\n",
            "99273 : avg_loss:  tensor(1.1248e-11, grad_fn=<DivBackward0>)\n",
            "99274 : avg_loss:  tensor(1.1248e-11, grad_fn=<DivBackward0>)\n",
            "99275 : avg_loss:  tensor(1.1247e-11, grad_fn=<DivBackward0>)\n",
            "99276 : avg_loss:  tensor(1.1247e-11, grad_fn=<DivBackward0>)\n",
            "99277 : avg_loss:  tensor(1.1247e-11, grad_fn=<DivBackward0>)\n",
            "99278 : avg_loss:  tensor(1.1246e-11, grad_fn=<DivBackward0>)\n",
            "99279 : avg_loss:  tensor(1.1246e-11, grad_fn=<DivBackward0>)\n",
            "99280 : avg_loss:  tensor(1.1246e-11, grad_fn=<DivBackward0>)\n",
            "99281 : avg_loss:  tensor(1.1245e-11, grad_fn=<DivBackward0>)\n",
            "99282 : avg_loss:  tensor(1.1245e-11, grad_fn=<DivBackward0>)\n",
            "99283 : avg_loss:  tensor(1.1244e-11, grad_fn=<DivBackward0>)\n",
            "99284 : avg_loss:  tensor(1.1244e-11, grad_fn=<DivBackward0>)\n",
            "99285 : avg_loss:  tensor(1.1243e-11, grad_fn=<DivBackward0>)\n",
            "99286 : avg_loss:  tensor(1.1243e-11, grad_fn=<DivBackward0>)\n",
            "99287 : avg_loss:  tensor(1.1243e-11, grad_fn=<DivBackward0>)\n",
            "99288 : avg_loss:  tensor(1.1242e-11, grad_fn=<DivBackward0>)\n",
            "99289 : avg_loss:  tensor(1.1242e-11, grad_fn=<DivBackward0>)\n",
            "99290 : avg_loss:  tensor(1.1241e-11, grad_fn=<DivBackward0>)\n",
            "99291 : avg_loss:  tensor(1.1241e-11, grad_fn=<DivBackward0>)\n",
            "99292 : avg_loss:  tensor(1.1240e-11, grad_fn=<DivBackward0>)\n",
            "99293 : avg_loss:  tensor(1.1240e-11, grad_fn=<DivBackward0>)\n",
            "99294 : avg_loss:  tensor(1.1240e-11, grad_fn=<DivBackward0>)\n",
            "99295 : avg_loss:  tensor(1.1239e-11, grad_fn=<DivBackward0>)\n",
            "99296 : avg_loss:  tensor(1.1239e-11, grad_fn=<DivBackward0>)\n",
            "99297 : avg_loss:  tensor(1.1239e-11, grad_fn=<DivBackward0>)\n",
            "99298 : avg_loss:  tensor(1.1238e-11, grad_fn=<DivBackward0>)\n",
            "99299 : avg_loss:  tensor(1.1238e-11, grad_fn=<DivBackward0>)\n",
            "99300 : avg_loss:  tensor(1.1237e-11, grad_fn=<DivBackward0>)\n",
            "99301 : avg_loss:  tensor(1.1237e-11, grad_fn=<DivBackward0>)\n",
            "99302 : avg_loss:  tensor(1.1236e-11, grad_fn=<DivBackward0>)\n",
            "99303 : avg_loss:  tensor(1.1236e-11, grad_fn=<DivBackward0>)\n",
            "99304 : avg_loss:  tensor(1.1235e-11, grad_fn=<DivBackward0>)\n",
            "99305 : avg_loss:  tensor(1.1235e-11, grad_fn=<DivBackward0>)\n",
            "99306 : avg_loss:  tensor(1.1235e-11, grad_fn=<DivBackward0>)\n",
            "99307 : avg_loss:  tensor(1.1234e-11, grad_fn=<DivBackward0>)\n",
            "99308 : avg_loss:  tensor(1.1234e-11, grad_fn=<DivBackward0>)\n",
            "99309 : avg_loss:  tensor(1.1234e-11, grad_fn=<DivBackward0>)\n",
            "99310 : avg_loss:  tensor(1.1233e-11, grad_fn=<DivBackward0>)\n",
            "99311 : avg_loss:  tensor(1.1233e-11, grad_fn=<DivBackward0>)\n",
            "99312 : avg_loss:  tensor(1.1232e-11, grad_fn=<DivBackward0>)\n",
            "99313 : avg_loss:  tensor(1.1232e-11, grad_fn=<DivBackward0>)\n",
            "99314 : avg_loss:  tensor(1.1231e-11, grad_fn=<DivBackward0>)\n",
            "99315 : avg_loss:  tensor(1.1231e-11, grad_fn=<DivBackward0>)\n",
            "99316 : avg_loss:  tensor(1.1230e-11, grad_fn=<DivBackward0>)\n",
            "99317 : avg_loss:  tensor(1.1230e-11, grad_fn=<DivBackward0>)\n",
            "99318 : avg_loss:  tensor(1.1230e-11, grad_fn=<DivBackward0>)\n",
            "99319 : avg_loss:  tensor(1.1229e-11, grad_fn=<DivBackward0>)\n",
            "99320 : avg_loss:  tensor(1.1229e-11, grad_fn=<DivBackward0>)\n",
            "99321 : avg_loss:  tensor(1.1228e-11, grad_fn=<DivBackward0>)\n",
            "99322 : avg_loss:  tensor(1.1228e-11, grad_fn=<DivBackward0>)\n",
            "99323 : avg_loss:  tensor(1.1227e-11, grad_fn=<DivBackward0>)\n",
            "99324 : avg_loss:  tensor(1.1227e-11, grad_fn=<DivBackward0>)\n",
            "99325 : avg_loss:  tensor(1.1226e-11, grad_fn=<DivBackward0>)\n",
            "99326 : avg_loss:  tensor(1.1226e-11, grad_fn=<DivBackward0>)\n",
            "99327 : avg_loss:  tensor(1.1226e-11, grad_fn=<DivBackward0>)\n",
            "99328 : avg_loss:  tensor(1.1225e-11, grad_fn=<DivBackward0>)\n",
            "99329 : avg_loss:  tensor(1.1225e-11, grad_fn=<DivBackward0>)\n",
            "99330 : avg_loss:  tensor(1.1224e-11, grad_fn=<DivBackward0>)\n",
            "99331 : avg_loss:  tensor(1.1224e-11, grad_fn=<DivBackward0>)\n",
            "99332 : avg_loss:  tensor(1.1223e-11, grad_fn=<DivBackward0>)\n",
            "99333 : avg_loss:  tensor(1.1223e-11, grad_fn=<DivBackward0>)\n",
            "99334 : avg_loss:  tensor(1.1223e-11, grad_fn=<DivBackward0>)\n",
            "99335 : avg_loss:  tensor(1.1222e-11, grad_fn=<DivBackward0>)\n",
            "99336 : avg_loss:  tensor(1.1222e-11, grad_fn=<DivBackward0>)\n",
            "99337 : avg_loss:  tensor(1.1221e-11, grad_fn=<DivBackward0>)\n",
            "99338 : avg_loss:  tensor(1.1221e-11, grad_fn=<DivBackward0>)\n",
            "99339 : avg_loss:  tensor(1.1221e-11, grad_fn=<DivBackward0>)\n",
            "99340 : avg_loss:  tensor(1.1220e-11, grad_fn=<DivBackward0>)\n",
            "99341 : avg_loss:  tensor(1.1220e-11, grad_fn=<DivBackward0>)\n",
            "99342 : avg_loss:  tensor(1.1219e-11, grad_fn=<DivBackward0>)\n",
            "99343 : avg_loss:  tensor(1.1219e-11, grad_fn=<DivBackward0>)\n",
            "99344 : avg_loss:  tensor(1.1218e-11, grad_fn=<DivBackward0>)\n",
            "99345 : avg_loss:  tensor(1.1218e-11, grad_fn=<DivBackward0>)\n",
            "99346 : avg_loss:  tensor(1.1218e-11, grad_fn=<DivBackward0>)\n",
            "99347 : avg_loss:  tensor(1.1217e-11, grad_fn=<DivBackward0>)\n",
            "99348 : avg_loss:  tensor(1.1217e-11, grad_fn=<DivBackward0>)\n",
            "99349 : avg_loss:  tensor(1.1216e-11, grad_fn=<DivBackward0>)\n",
            "99350 : avg_loss:  tensor(1.1216e-11, grad_fn=<DivBackward0>)\n",
            "99351 : avg_loss:  tensor(1.1215e-11, grad_fn=<DivBackward0>)\n",
            "99352 : avg_loss:  tensor(1.1215e-11, grad_fn=<DivBackward0>)\n",
            "99353 : avg_loss:  tensor(1.1215e-11, grad_fn=<DivBackward0>)\n",
            "99354 : avg_loss:  tensor(1.1214e-11, grad_fn=<DivBackward0>)\n",
            "99355 : avg_loss:  tensor(1.1214e-11, grad_fn=<DivBackward0>)\n",
            "99356 : avg_loss:  tensor(1.1214e-11, grad_fn=<DivBackward0>)\n",
            "99357 : avg_loss:  tensor(1.1213e-11, grad_fn=<DivBackward0>)\n",
            "99358 : avg_loss:  tensor(1.1212e-11, grad_fn=<DivBackward0>)\n",
            "99359 : avg_loss:  tensor(1.1212e-11, grad_fn=<DivBackward0>)\n",
            "99360 : avg_loss:  tensor(1.1211e-11, grad_fn=<DivBackward0>)\n",
            "99361 : avg_loss:  tensor(1.1211e-11, grad_fn=<DivBackward0>)\n",
            "99362 : avg_loss:  tensor(1.1211e-11, grad_fn=<DivBackward0>)\n",
            "99363 : avg_loss:  tensor(1.1210e-11, grad_fn=<DivBackward0>)\n",
            "99364 : avg_loss:  tensor(1.1210e-11, grad_fn=<DivBackward0>)\n",
            "99365 : avg_loss:  tensor(1.1210e-11, grad_fn=<DivBackward0>)\n",
            "99366 : avg_loss:  tensor(1.1209e-11, grad_fn=<DivBackward0>)\n",
            "99367 : avg_loss:  tensor(1.1209e-11, grad_fn=<DivBackward0>)\n",
            "99368 : avg_loss:  tensor(1.1208e-11, grad_fn=<DivBackward0>)\n",
            "99369 : avg_loss:  tensor(1.1208e-11, grad_fn=<DivBackward0>)\n",
            "99370 : avg_loss:  tensor(1.1207e-11, grad_fn=<DivBackward0>)\n",
            "99371 : avg_loss:  tensor(1.1207e-11, grad_fn=<DivBackward0>)\n",
            "99372 : avg_loss:  tensor(1.1207e-11, grad_fn=<DivBackward0>)\n",
            "99373 : avg_loss:  tensor(1.1206e-11, grad_fn=<DivBackward0>)\n",
            "99374 : avg_loss:  tensor(1.1206e-11, grad_fn=<DivBackward0>)\n",
            "99375 : avg_loss:  tensor(1.1205e-11, grad_fn=<DivBackward0>)\n",
            "99376 : avg_loss:  tensor(1.1204e-11, grad_fn=<DivBackward0>)\n",
            "99377 : avg_loss:  tensor(1.1204e-11, grad_fn=<DivBackward0>)\n",
            "99378 : avg_loss:  tensor(1.1204e-11, grad_fn=<DivBackward0>)\n",
            "99379 : avg_loss:  tensor(1.1203e-11, grad_fn=<DivBackward0>)\n",
            "99380 : avg_loss:  tensor(1.1203e-11, grad_fn=<DivBackward0>)\n",
            "99381 : avg_loss:  tensor(1.1202e-11, grad_fn=<DivBackward0>)\n",
            "99382 : avg_loss:  tensor(1.1202e-11, grad_fn=<DivBackward0>)\n",
            "99383 : avg_loss:  tensor(1.1201e-11, grad_fn=<DivBackward0>)\n",
            "99384 : avg_loss:  tensor(1.1201e-11, grad_fn=<DivBackward0>)\n",
            "99385 : avg_loss:  tensor(1.1201e-11, grad_fn=<DivBackward0>)\n",
            "99386 : avg_loss:  tensor(1.1200e-11, grad_fn=<DivBackward0>)\n",
            "99387 : avg_loss:  tensor(1.1200e-11, grad_fn=<DivBackward0>)\n",
            "99388 : avg_loss:  tensor(1.1199e-11, grad_fn=<DivBackward0>)\n",
            "99389 : avg_loss:  tensor(1.1199e-11, grad_fn=<DivBackward0>)\n",
            "99390 : avg_loss:  tensor(1.1198e-11, grad_fn=<DivBackward0>)\n",
            "99391 : avg_loss:  tensor(1.1198e-11, grad_fn=<DivBackward0>)\n",
            "99392 : avg_loss:  tensor(1.1198e-11, grad_fn=<DivBackward0>)\n",
            "99393 : avg_loss:  tensor(1.1197e-11, grad_fn=<DivBackward0>)\n",
            "99394 : avg_loss:  tensor(1.1197e-11, grad_fn=<DivBackward0>)\n",
            "99395 : avg_loss:  tensor(1.1196e-11, grad_fn=<DivBackward0>)\n",
            "99396 : avg_loss:  tensor(1.1196e-11, grad_fn=<DivBackward0>)\n",
            "99397 : avg_loss:  tensor(1.1196e-11, grad_fn=<DivBackward0>)\n",
            "99398 : avg_loss:  tensor(1.1195e-11, grad_fn=<DivBackward0>)\n",
            "99399 : avg_loss:  tensor(1.1195e-11, grad_fn=<DivBackward0>)\n",
            "99400 : avg_loss:  tensor(1.1194e-11, grad_fn=<DivBackward0>)\n",
            "99401 : avg_loss:  tensor(1.1194e-11, grad_fn=<DivBackward0>)\n",
            "99402 : avg_loss:  tensor(1.1194e-11, grad_fn=<DivBackward0>)\n",
            "99403 : avg_loss:  tensor(1.1193e-11, grad_fn=<DivBackward0>)\n",
            "99404 : avg_loss:  tensor(1.1193e-11, grad_fn=<DivBackward0>)\n",
            "99405 : avg_loss:  tensor(1.1192e-11, grad_fn=<DivBackward0>)\n",
            "99406 : avg_loss:  tensor(1.1192e-11, grad_fn=<DivBackward0>)\n",
            "99407 : avg_loss:  tensor(1.1191e-11, grad_fn=<DivBackward0>)\n",
            "99408 : avg_loss:  tensor(1.1191e-11, grad_fn=<DivBackward0>)\n",
            "99409 : avg_loss:  tensor(1.1190e-11, grad_fn=<DivBackward0>)\n",
            "99410 : avg_loss:  tensor(1.1190e-11, grad_fn=<DivBackward0>)\n",
            "99411 : avg_loss:  tensor(1.1190e-11, grad_fn=<DivBackward0>)\n",
            "99412 : avg_loss:  tensor(1.1189e-11, grad_fn=<DivBackward0>)\n",
            "99413 : avg_loss:  tensor(1.1189e-11, grad_fn=<DivBackward0>)\n",
            "99414 : avg_loss:  tensor(1.1188e-11, grad_fn=<DivBackward0>)\n",
            "99415 : avg_loss:  tensor(1.1188e-11, grad_fn=<DivBackward0>)\n",
            "99416 : avg_loss:  tensor(1.1187e-11, grad_fn=<DivBackward0>)\n",
            "99417 : avg_loss:  tensor(1.1187e-11, grad_fn=<DivBackward0>)\n",
            "99418 : avg_loss:  tensor(1.1186e-11, grad_fn=<DivBackward0>)\n",
            "99419 : avg_loss:  tensor(1.1186e-11, grad_fn=<DivBackward0>)\n",
            "99420 : avg_loss:  tensor(1.1186e-11, grad_fn=<DivBackward0>)\n",
            "99421 : avg_loss:  tensor(1.1185e-11, grad_fn=<DivBackward0>)\n",
            "99422 : avg_loss:  tensor(1.1185e-11, grad_fn=<DivBackward0>)\n",
            "99423 : avg_loss:  tensor(1.1184e-11, grad_fn=<DivBackward0>)\n",
            "99424 : avg_loss:  tensor(1.1184e-11, grad_fn=<DivBackward0>)\n",
            "99425 : avg_loss:  tensor(1.1183e-11, grad_fn=<DivBackward0>)\n",
            "99426 : avg_loss:  tensor(1.1183e-11, grad_fn=<DivBackward0>)\n",
            "99427 : avg_loss:  tensor(1.1182e-11, grad_fn=<DivBackward0>)\n",
            "99428 : avg_loss:  tensor(1.1182e-11, grad_fn=<DivBackward0>)\n",
            "99429 : avg_loss:  tensor(1.1181e-11, grad_fn=<DivBackward0>)\n",
            "99430 : avg_loss:  tensor(1.1181e-11, grad_fn=<DivBackward0>)\n",
            "99431 : avg_loss:  tensor(1.1181e-11, grad_fn=<DivBackward0>)\n",
            "99432 : avg_loss:  tensor(1.1180e-11, grad_fn=<DivBackward0>)\n",
            "99433 : avg_loss:  tensor(1.1179e-11, grad_fn=<DivBackward0>)\n",
            "99434 : avg_loss:  tensor(1.1179e-11, grad_fn=<DivBackward0>)\n",
            "99435 : avg_loss:  tensor(1.1179e-11, grad_fn=<DivBackward0>)\n",
            "99436 : avg_loss:  tensor(1.1178e-11, grad_fn=<DivBackward0>)\n",
            "99437 : avg_loss:  tensor(1.1178e-11, grad_fn=<DivBackward0>)\n",
            "99438 : avg_loss:  tensor(1.1177e-11, grad_fn=<DivBackward0>)\n",
            "99439 : avg_loss:  tensor(1.1177e-11, grad_fn=<DivBackward0>)\n",
            "99440 : avg_loss:  tensor(1.1177e-11, grad_fn=<DivBackward0>)\n",
            "99441 : avg_loss:  tensor(1.1176e-11, grad_fn=<DivBackward0>)\n",
            "99442 : avg_loss:  tensor(1.1176e-11, grad_fn=<DivBackward0>)\n",
            "99443 : avg_loss:  tensor(1.1175e-11, grad_fn=<DivBackward0>)\n",
            "99444 : avg_loss:  tensor(1.1175e-11, grad_fn=<DivBackward0>)\n",
            "99445 : avg_loss:  tensor(1.1175e-11, grad_fn=<DivBackward0>)\n",
            "99446 : avg_loss:  tensor(1.1174e-11, grad_fn=<DivBackward0>)\n",
            "99447 : avg_loss:  tensor(1.1174e-11, grad_fn=<DivBackward0>)\n",
            "99448 : avg_loss:  tensor(1.1173e-11, grad_fn=<DivBackward0>)\n",
            "99449 : avg_loss:  tensor(1.1173e-11, grad_fn=<DivBackward0>)\n",
            "99450 : avg_loss:  tensor(1.1172e-11, grad_fn=<DivBackward0>)\n",
            "99451 : avg_loss:  tensor(1.1172e-11, grad_fn=<DivBackward0>)\n",
            "99452 : avg_loss:  tensor(1.1171e-11, grad_fn=<DivBackward0>)\n",
            "99453 : avg_loss:  tensor(1.1171e-11, grad_fn=<DivBackward0>)\n",
            "99454 : avg_loss:  tensor(1.1170e-11, grad_fn=<DivBackward0>)\n",
            "99455 : avg_loss:  tensor(1.1170e-11, grad_fn=<DivBackward0>)\n",
            "99456 : avg_loss:  tensor(1.1170e-11, grad_fn=<DivBackward0>)\n",
            "99457 : avg_loss:  tensor(1.1169e-11, grad_fn=<DivBackward0>)\n",
            "99458 : avg_loss:  tensor(1.1169e-11, grad_fn=<DivBackward0>)\n",
            "99459 : avg_loss:  tensor(1.1168e-11, grad_fn=<DivBackward0>)\n",
            "99460 : avg_loss:  tensor(1.1168e-11, grad_fn=<DivBackward0>)\n",
            "99461 : avg_loss:  tensor(1.1167e-11, grad_fn=<DivBackward0>)\n",
            "99462 : avg_loss:  tensor(1.1167e-11, grad_fn=<DivBackward0>)\n",
            "99463 : avg_loss:  tensor(1.1167e-11, grad_fn=<DivBackward0>)\n",
            "99464 : avg_loss:  tensor(1.1166e-11, grad_fn=<DivBackward0>)\n",
            "99465 : avg_loss:  tensor(1.1166e-11, grad_fn=<DivBackward0>)\n",
            "99466 : avg_loss:  tensor(1.1165e-11, grad_fn=<DivBackward0>)\n",
            "99467 : avg_loss:  tensor(1.1165e-11, grad_fn=<DivBackward0>)\n",
            "99468 : avg_loss:  tensor(1.1164e-11, grad_fn=<DivBackward0>)\n",
            "99469 : avg_loss:  tensor(1.1164e-11, grad_fn=<DivBackward0>)\n",
            "99470 : avg_loss:  tensor(1.1163e-11, grad_fn=<DivBackward0>)\n",
            "99471 : avg_loss:  tensor(1.1163e-11, grad_fn=<DivBackward0>)\n",
            "99472 : avg_loss:  tensor(1.1163e-11, grad_fn=<DivBackward0>)\n",
            "99473 : avg_loss:  tensor(1.1162e-11, grad_fn=<DivBackward0>)\n",
            "99474 : avg_loss:  tensor(1.1162e-11, grad_fn=<DivBackward0>)\n",
            "99475 : avg_loss:  tensor(1.1161e-11, grad_fn=<DivBackward0>)\n",
            "99476 : avg_loss:  tensor(1.1161e-11, grad_fn=<DivBackward0>)\n",
            "99477 : avg_loss:  tensor(1.1160e-11, grad_fn=<DivBackward0>)\n",
            "99478 : avg_loss:  tensor(1.1159e-11, grad_fn=<DivBackward0>)\n",
            "99479 : avg_loss:  tensor(1.1159e-11, grad_fn=<DivBackward0>)\n",
            "99480 : avg_loss:  tensor(1.1159e-11, grad_fn=<DivBackward0>)\n",
            "99481 : avg_loss:  tensor(1.1158e-11, grad_fn=<DivBackward0>)\n",
            "99482 : avg_loss:  tensor(1.1158e-11, grad_fn=<DivBackward0>)\n",
            "99483 : avg_loss:  tensor(1.1157e-11, grad_fn=<DivBackward0>)\n",
            "99484 : avg_loss:  tensor(1.1157e-11, grad_fn=<DivBackward0>)\n",
            "99485 : avg_loss:  tensor(1.1156e-11, grad_fn=<DivBackward0>)\n",
            "99486 : avg_loss:  tensor(1.1156e-11, grad_fn=<DivBackward0>)\n",
            "99487 : avg_loss:  tensor(1.1156e-11, grad_fn=<DivBackward0>)\n",
            "99488 : avg_loss:  tensor(1.1155e-11, grad_fn=<DivBackward0>)\n",
            "99489 : avg_loss:  tensor(1.1155e-11, grad_fn=<DivBackward0>)\n",
            "99490 : avg_loss:  tensor(1.1154e-11, grad_fn=<DivBackward0>)\n",
            "99491 : avg_loss:  tensor(1.1154e-11, grad_fn=<DivBackward0>)\n",
            "99492 : avg_loss:  tensor(1.1153e-11, grad_fn=<DivBackward0>)\n",
            "99493 : avg_loss:  tensor(1.1153e-11, grad_fn=<DivBackward0>)\n",
            "99494 : avg_loss:  tensor(1.1152e-11, grad_fn=<DivBackward0>)\n",
            "99495 : avg_loss:  tensor(1.1152e-11, grad_fn=<DivBackward0>)\n",
            "99496 : avg_loss:  tensor(1.1151e-11, grad_fn=<DivBackward0>)\n",
            "99497 : avg_loss:  tensor(1.1151e-11, grad_fn=<DivBackward0>)\n",
            "99498 : avg_loss:  tensor(1.1151e-11, grad_fn=<DivBackward0>)\n",
            "99499 : avg_loss:  tensor(1.1150e-11, grad_fn=<DivBackward0>)\n",
            "99500 : avg_loss:  tensor(1.1150e-11, grad_fn=<DivBackward0>)\n",
            "99501 : avg_loss:  tensor(1.1149e-11, grad_fn=<DivBackward0>)\n",
            "99502 : avg_loss:  tensor(1.1149e-11, grad_fn=<DivBackward0>)\n",
            "99503 : avg_loss:  tensor(1.1148e-11, grad_fn=<DivBackward0>)\n",
            "99504 : avg_loss:  tensor(1.1148e-11, grad_fn=<DivBackward0>)\n",
            "99505 : avg_loss:  tensor(1.1148e-11, grad_fn=<DivBackward0>)\n",
            "99506 : avg_loss:  tensor(1.1147e-11, grad_fn=<DivBackward0>)\n",
            "99507 : avg_loss:  tensor(1.1147e-11, grad_fn=<DivBackward0>)\n",
            "99508 : avg_loss:  tensor(1.1146e-11, grad_fn=<DivBackward0>)\n",
            "99509 : avg_loss:  tensor(1.1146e-11, grad_fn=<DivBackward0>)\n",
            "99510 : avg_loss:  tensor(1.1145e-11, grad_fn=<DivBackward0>)\n",
            "99511 : avg_loss:  tensor(1.1145e-11, grad_fn=<DivBackward0>)\n",
            "99512 : avg_loss:  tensor(1.1144e-11, grad_fn=<DivBackward0>)\n",
            "99513 : avg_loss:  tensor(1.1144e-11, grad_fn=<DivBackward0>)\n",
            "99514 : avg_loss:  tensor(1.1144e-11, grad_fn=<DivBackward0>)\n",
            "99515 : avg_loss:  tensor(1.1143e-11, grad_fn=<DivBackward0>)\n",
            "99516 : avg_loss:  tensor(1.1143e-11, grad_fn=<DivBackward0>)\n",
            "99517 : avg_loss:  tensor(1.1142e-11, grad_fn=<DivBackward0>)\n",
            "99518 : avg_loss:  tensor(1.1142e-11, grad_fn=<DivBackward0>)\n",
            "99519 : avg_loss:  tensor(1.1141e-11, grad_fn=<DivBackward0>)\n",
            "99520 : avg_loss:  tensor(1.1141e-11, grad_fn=<DivBackward0>)\n",
            "99521 : avg_loss:  tensor(1.1140e-11, grad_fn=<DivBackward0>)\n",
            "99522 : avg_loss:  tensor(1.1140e-11, grad_fn=<DivBackward0>)\n",
            "99523 : avg_loss:  tensor(1.1139e-11, grad_fn=<DivBackward0>)\n",
            "99524 : avg_loss:  tensor(1.1139e-11, grad_fn=<DivBackward0>)\n",
            "99525 : avg_loss:  tensor(1.1138e-11, grad_fn=<DivBackward0>)\n",
            "99526 : avg_loss:  tensor(1.1138e-11, grad_fn=<DivBackward0>)\n",
            "99527 : avg_loss:  tensor(1.1137e-11, grad_fn=<DivBackward0>)\n",
            "99528 : avg_loss:  tensor(1.1137e-11, grad_fn=<DivBackward0>)\n",
            "99529 : avg_loss:  tensor(1.1136e-11, grad_fn=<DivBackward0>)\n",
            "99530 : avg_loss:  tensor(1.1136e-11, grad_fn=<DivBackward0>)\n",
            "99531 : avg_loss:  tensor(1.1136e-11, grad_fn=<DivBackward0>)\n",
            "99532 : avg_loss:  tensor(1.1135e-11, grad_fn=<DivBackward0>)\n",
            "99533 : avg_loss:  tensor(1.1135e-11, grad_fn=<DivBackward0>)\n",
            "99534 : avg_loss:  tensor(1.1134e-11, grad_fn=<DivBackward0>)\n",
            "99535 : avg_loss:  tensor(1.1134e-11, grad_fn=<DivBackward0>)\n",
            "99536 : avg_loss:  tensor(1.1133e-11, grad_fn=<DivBackward0>)\n",
            "99537 : avg_loss:  tensor(1.1133e-11, grad_fn=<DivBackward0>)\n",
            "99538 : avg_loss:  tensor(1.1132e-11, grad_fn=<DivBackward0>)\n",
            "99539 : avg_loss:  tensor(1.1132e-11, grad_fn=<DivBackward0>)\n",
            "99540 : avg_loss:  tensor(1.1131e-11, grad_fn=<DivBackward0>)\n",
            "99541 : avg_loss:  tensor(1.1131e-11, grad_fn=<DivBackward0>)\n",
            "99542 : avg_loss:  tensor(1.1130e-11, grad_fn=<DivBackward0>)\n",
            "99543 : avg_loss:  tensor(1.1130e-11, grad_fn=<DivBackward0>)\n",
            "99544 : avg_loss:  tensor(1.1130e-11, grad_fn=<DivBackward0>)\n",
            "99545 : avg_loss:  tensor(1.1129e-11, grad_fn=<DivBackward0>)\n",
            "99546 : avg_loss:  tensor(1.1129e-11, grad_fn=<DivBackward0>)\n",
            "99547 : avg_loss:  tensor(1.1128e-11, grad_fn=<DivBackward0>)\n",
            "99548 : avg_loss:  tensor(1.1128e-11, grad_fn=<DivBackward0>)\n",
            "99549 : avg_loss:  tensor(1.1127e-11, grad_fn=<DivBackward0>)\n",
            "99550 : avg_loss:  tensor(1.1127e-11, grad_fn=<DivBackward0>)\n",
            "99551 : avg_loss:  tensor(1.1127e-11, grad_fn=<DivBackward0>)\n",
            "99552 : avg_loss:  tensor(1.1126e-11, grad_fn=<DivBackward0>)\n",
            "99553 : avg_loss:  tensor(1.1126e-11, grad_fn=<DivBackward0>)\n",
            "99554 : avg_loss:  tensor(1.1125e-11, grad_fn=<DivBackward0>)\n",
            "99555 : avg_loss:  tensor(1.1124e-11, grad_fn=<DivBackward0>)\n",
            "99556 : avg_loss:  tensor(1.1124e-11, grad_fn=<DivBackward0>)\n",
            "99557 : avg_loss:  tensor(1.1124e-11, grad_fn=<DivBackward0>)\n",
            "99558 : avg_loss:  tensor(1.1123e-11, grad_fn=<DivBackward0>)\n",
            "99559 : avg_loss:  tensor(1.1123e-11, grad_fn=<DivBackward0>)\n",
            "99560 : avg_loss:  tensor(1.1123e-11, grad_fn=<DivBackward0>)\n",
            "99561 : avg_loss:  tensor(1.1122e-11, grad_fn=<DivBackward0>)\n",
            "99562 : avg_loss:  tensor(1.1122e-11, grad_fn=<DivBackward0>)\n",
            "99563 : avg_loss:  tensor(1.1121e-11, grad_fn=<DivBackward0>)\n",
            "99564 : avg_loss:  tensor(1.1121e-11, grad_fn=<DivBackward0>)\n",
            "99565 : avg_loss:  tensor(1.1120e-11, grad_fn=<DivBackward0>)\n",
            "99566 : avg_loss:  tensor(1.1119e-11, grad_fn=<DivBackward0>)\n",
            "99567 : avg_loss:  tensor(1.1119e-11, grad_fn=<DivBackward0>)\n",
            "99568 : avg_loss:  tensor(1.1119e-11, grad_fn=<DivBackward0>)\n",
            "99569 : avg_loss:  tensor(1.1118e-11, grad_fn=<DivBackward0>)\n",
            "99570 : avg_loss:  tensor(1.1118e-11, grad_fn=<DivBackward0>)\n",
            "99571 : avg_loss:  tensor(1.1117e-11, grad_fn=<DivBackward0>)\n",
            "99572 : avg_loss:  tensor(1.1117e-11, grad_fn=<DivBackward0>)\n",
            "99573 : avg_loss:  tensor(1.1116e-11, grad_fn=<DivBackward0>)\n",
            "99574 : avg_loss:  tensor(1.1115e-11, grad_fn=<DivBackward0>)\n",
            "99575 : avg_loss:  tensor(1.1115e-11, grad_fn=<DivBackward0>)\n",
            "99576 : avg_loss:  tensor(1.1115e-11, grad_fn=<DivBackward0>)\n",
            "99577 : avg_loss:  tensor(1.1114e-11, grad_fn=<DivBackward0>)\n",
            "99578 : avg_loss:  tensor(1.1114e-11, grad_fn=<DivBackward0>)\n",
            "99579 : avg_loss:  tensor(1.1113e-11, grad_fn=<DivBackward0>)\n",
            "99580 : avg_loss:  tensor(1.1113e-11, grad_fn=<DivBackward0>)\n",
            "99581 : avg_loss:  tensor(1.1112e-11, grad_fn=<DivBackward0>)\n",
            "99582 : avg_loss:  tensor(1.1112e-11, grad_fn=<DivBackward0>)\n",
            "99583 : avg_loss:  tensor(1.1112e-11, grad_fn=<DivBackward0>)\n",
            "99584 : avg_loss:  tensor(1.1111e-11, grad_fn=<DivBackward0>)\n",
            "99585 : avg_loss:  tensor(1.1111e-11, grad_fn=<DivBackward0>)\n",
            "99586 : avg_loss:  tensor(1.1110e-11, grad_fn=<DivBackward0>)\n",
            "99587 : avg_loss:  tensor(1.1110e-11, grad_fn=<DivBackward0>)\n",
            "99588 : avg_loss:  tensor(1.1109e-11, grad_fn=<DivBackward0>)\n",
            "99589 : avg_loss:  tensor(1.1109e-11, grad_fn=<DivBackward0>)\n",
            "99590 : avg_loss:  tensor(1.1108e-11, grad_fn=<DivBackward0>)\n",
            "99591 : avg_loss:  tensor(1.1108e-11, grad_fn=<DivBackward0>)\n",
            "99592 : avg_loss:  tensor(1.1107e-11, grad_fn=<DivBackward0>)\n",
            "99593 : avg_loss:  tensor(1.1107e-11, grad_fn=<DivBackward0>)\n",
            "99594 : avg_loss:  tensor(1.1106e-11, grad_fn=<DivBackward0>)\n",
            "99595 : avg_loss:  tensor(1.1106e-11, grad_fn=<DivBackward0>)\n",
            "99596 : avg_loss:  tensor(1.1106e-11, grad_fn=<DivBackward0>)\n",
            "99597 : avg_loss:  tensor(1.1105e-11, grad_fn=<DivBackward0>)\n",
            "99598 : avg_loss:  tensor(1.1105e-11, grad_fn=<DivBackward0>)\n",
            "99599 : avg_loss:  tensor(1.1104e-11, grad_fn=<DivBackward0>)\n",
            "99600 : avg_loss:  tensor(1.1104e-11, grad_fn=<DivBackward0>)\n",
            "99601 : avg_loss:  tensor(1.1103e-11, grad_fn=<DivBackward0>)\n",
            "99602 : avg_loss:  tensor(1.1103e-11, grad_fn=<DivBackward0>)\n",
            "99603 : avg_loss:  tensor(1.1102e-11, grad_fn=<DivBackward0>)\n",
            "99604 : avg_loss:  tensor(1.1102e-11, grad_fn=<DivBackward0>)\n",
            "99605 : avg_loss:  tensor(1.1102e-11, grad_fn=<DivBackward0>)\n",
            "99606 : avg_loss:  tensor(1.1101e-11, grad_fn=<DivBackward0>)\n",
            "99607 : avg_loss:  tensor(1.1100e-11, grad_fn=<DivBackward0>)\n",
            "99608 : avg_loss:  tensor(1.1100e-11, grad_fn=<DivBackward0>)\n",
            "99609 : avg_loss:  tensor(1.1100e-11, grad_fn=<DivBackward0>)\n",
            "99610 : avg_loss:  tensor(1.1099e-11, grad_fn=<DivBackward0>)\n",
            "99611 : avg_loss:  tensor(1.1099e-11, grad_fn=<DivBackward0>)\n",
            "99612 : avg_loss:  tensor(1.1098e-11, grad_fn=<DivBackward0>)\n",
            "99613 : avg_loss:  tensor(1.1098e-11, grad_fn=<DivBackward0>)\n",
            "99614 : avg_loss:  tensor(1.1098e-11, grad_fn=<DivBackward0>)\n",
            "99615 : avg_loss:  tensor(1.1097e-11, grad_fn=<DivBackward0>)\n",
            "99616 : avg_loss:  tensor(1.1096e-11, grad_fn=<DivBackward0>)\n",
            "99617 : avg_loss:  tensor(1.1096e-11, grad_fn=<DivBackward0>)\n",
            "99618 : avg_loss:  tensor(1.1095e-11, grad_fn=<DivBackward0>)\n",
            "99619 : avg_loss:  tensor(1.1095e-11, grad_fn=<DivBackward0>)\n",
            "99620 : avg_loss:  tensor(1.1095e-11, grad_fn=<DivBackward0>)\n",
            "99621 : avg_loss:  tensor(1.1094e-11, grad_fn=<DivBackward0>)\n",
            "99622 : avg_loss:  tensor(1.1094e-11, grad_fn=<DivBackward0>)\n",
            "99623 : avg_loss:  tensor(1.1093e-11, grad_fn=<DivBackward0>)\n",
            "99624 : avg_loss:  tensor(1.1092e-11, grad_fn=<DivBackward0>)\n",
            "99625 : avg_loss:  tensor(1.1092e-11, grad_fn=<DivBackward0>)\n",
            "99626 : avg_loss:  tensor(1.1091e-11, grad_fn=<DivBackward0>)\n",
            "99627 : avg_loss:  tensor(1.1091e-11, grad_fn=<DivBackward0>)\n",
            "99628 : avg_loss:  tensor(1.1090e-11, grad_fn=<DivBackward0>)\n",
            "99629 : avg_loss:  tensor(1.1090e-11, grad_fn=<DivBackward0>)\n",
            "99630 : avg_loss:  tensor(1.1090e-11, grad_fn=<DivBackward0>)\n",
            "99631 : avg_loss:  tensor(1.1089e-11, grad_fn=<DivBackward0>)\n",
            "99632 : avg_loss:  tensor(1.1088e-11, grad_fn=<DivBackward0>)\n",
            "99633 : avg_loss:  tensor(1.1088e-11, grad_fn=<DivBackward0>)\n",
            "99634 : avg_loss:  tensor(1.1088e-11, grad_fn=<DivBackward0>)\n",
            "99635 : avg_loss:  tensor(1.1087e-11, grad_fn=<DivBackward0>)\n",
            "99636 : avg_loss:  tensor(1.1087e-11, grad_fn=<DivBackward0>)\n",
            "99637 : avg_loss:  tensor(1.1086e-11, grad_fn=<DivBackward0>)\n",
            "99638 : avg_loss:  tensor(1.1086e-11, grad_fn=<DivBackward0>)\n",
            "99639 : avg_loss:  tensor(1.1086e-11, grad_fn=<DivBackward0>)\n",
            "99640 : avg_loss:  tensor(1.1085e-11, grad_fn=<DivBackward0>)\n",
            "99641 : avg_loss:  tensor(1.1084e-11, grad_fn=<DivBackward0>)\n",
            "99642 : avg_loss:  tensor(1.1084e-11, grad_fn=<DivBackward0>)\n",
            "99643 : avg_loss:  tensor(1.1083e-11, grad_fn=<DivBackward0>)\n",
            "99644 : avg_loss:  tensor(1.1083e-11, grad_fn=<DivBackward0>)\n",
            "99645 : avg_loss:  tensor(1.1083e-11, grad_fn=<DivBackward0>)\n",
            "99646 : avg_loss:  tensor(1.1082e-11, grad_fn=<DivBackward0>)\n",
            "99647 : avg_loss:  tensor(1.1082e-11, grad_fn=<DivBackward0>)\n",
            "99648 : avg_loss:  tensor(1.1081e-11, grad_fn=<DivBackward0>)\n",
            "99649 : avg_loss:  tensor(1.1081e-11, grad_fn=<DivBackward0>)\n",
            "99650 : avg_loss:  tensor(1.1080e-11, grad_fn=<DivBackward0>)\n",
            "99651 : avg_loss:  tensor(1.1080e-11, grad_fn=<DivBackward0>)\n",
            "99652 : avg_loss:  tensor(1.1079e-11, grad_fn=<DivBackward0>)\n",
            "99653 : avg_loss:  tensor(1.1079e-11, grad_fn=<DivBackward0>)\n",
            "99654 : avg_loss:  tensor(1.1078e-11, grad_fn=<DivBackward0>)\n",
            "99655 : avg_loss:  tensor(1.1078e-11, grad_fn=<DivBackward0>)\n",
            "99656 : avg_loss:  tensor(1.1077e-11, grad_fn=<DivBackward0>)\n",
            "99657 : avg_loss:  tensor(1.1077e-11, grad_fn=<DivBackward0>)\n",
            "99658 : avg_loss:  tensor(1.1076e-11, grad_fn=<DivBackward0>)\n",
            "99659 : avg_loss:  tensor(1.1076e-11, grad_fn=<DivBackward0>)\n",
            "99660 : avg_loss:  tensor(1.1075e-11, grad_fn=<DivBackward0>)\n",
            "99661 : avg_loss:  tensor(1.1075e-11, grad_fn=<DivBackward0>)\n",
            "99662 : avg_loss:  tensor(1.1074e-11, grad_fn=<DivBackward0>)\n",
            "99663 : avg_loss:  tensor(1.1074e-11, grad_fn=<DivBackward0>)\n",
            "99664 : avg_loss:  tensor(1.1074e-11, grad_fn=<DivBackward0>)\n",
            "99665 : avg_loss:  tensor(1.1073e-11, grad_fn=<DivBackward0>)\n",
            "99666 : avg_loss:  tensor(1.1073e-11, grad_fn=<DivBackward0>)\n",
            "99667 : avg_loss:  tensor(1.1072e-11, grad_fn=<DivBackward0>)\n",
            "99668 : avg_loss:  tensor(1.1072e-11, grad_fn=<DivBackward0>)\n",
            "99669 : avg_loss:  tensor(1.1071e-11, grad_fn=<DivBackward0>)\n",
            "99670 : avg_loss:  tensor(1.1071e-11, grad_fn=<DivBackward0>)\n",
            "99671 : avg_loss:  tensor(1.1070e-11, grad_fn=<DivBackward0>)\n",
            "99672 : avg_loss:  tensor(1.1069e-11, grad_fn=<DivBackward0>)\n",
            "99673 : avg_loss:  tensor(1.1069e-11, grad_fn=<DivBackward0>)\n",
            "99674 : avg_loss:  tensor(1.1069e-11, grad_fn=<DivBackward0>)\n",
            "99675 : avg_loss:  tensor(1.1068e-11, grad_fn=<DivBackward0>)\n",
            "99676 : avg_loss:  tensor(1.1068e-11, grad_fn=<DivBackward0>)\n",
            "99677 : avg_loss:  tensor(1.1067e-11, grad_fn=<DivBackward0>)\n",
            "99678 : avg_loss:  tensor(1.1067e-11, grad_fn=<DivBackward0>)\n",
            "99679 : avg_loss:  tensor(1.1066e-11, grad_fn=<DivBackward0>)\n",
            "99680 : avg_loss:  tensor(1.1066e-11, grad_fn=<DivBackward0>)\n",
            "99681 : avg_loss:  tensor(1.1065e-11, grad_fn=<DivBackward0>)\n",
            "99682 : avg_loss:  tensor(1.1065e-11, grad_fn=<DivBackward0>)\n",
            "99683 : avg_loss:  tensor(1.1064e-11, grad_fn=<DivBackward0>)\n",
            "99684 : avg_loss:  tensor(1.1064e-11, grad_fn=<DivBackward0>)\n",
            "99685 : avg_loss:  tensor(1.1063e-11, grad_fn=<DivBackward0>)\n",
            "99686 : avg_loss:  tensor(1.1063e-11, grad_fn=<DivBackward0>)\n",
            "99687 : avg_loss:  tensor(1.1062e-11, grad_fn=<DivBackward0>)\n",
            "99688 : avg_loss:  tensor(1.1062e-11, grad_fn=<DivBackward0>)\n",
            "99689 : avg_loss:  tensor(1.1062e-11, grad_fn=<DivBackward0>)\n",
            "99690 : avg_loss:  tensor(1.1061e-11, grad_fn=<DivBackward0>)\n",
            "99691 : avg_loss:  tensor(1.1060e-11, grad_fn=<DivBackward0>)\n",
            "99692 : avg_loss:  tensor(1.1060e-11, grad_fn=<DivBackward0>)\n",
            "99693 : avg_loss:  tensor(1.1059e-11, grad_fn=<DivBackward0>)\n",
            "99694 : avg_loss:  tensor(1.1059e-11, grad_fn=<DivBackward0>)\n",
            "99695 : avg_loss:  tensor(1.1058e-11, grad_fn=<DivBackward0>)\n",
            "99696 : avg_loss:  tensor(1.1058e-11, grad_fn=<DivBackward0>)\n",
            "99697 : avg_loss:  tensor(1.1058e-11, grad_fn=<DivBackward0>)\n",
            "99698 : avg_loss:  tensor(1.1057e-11, grad_fn=<DivBackward0>)\n",
            "99699 : avg_loss:  tensor(1.1057e-11, grad_fn=<DivBackward0>)\n",
            "99700 : avg_loss:  tensor(1.1056e-11, grad_fn=<DivBackward0>)\n",
            "99701 : avg_loss:  tensor(1.1056e-11, grad_fn=<DivBackward0>)\n",
            "99702 : avg_loss:  tensor(1.1055e-11, grad_fn=<DivBackward0>)\n",
            "99703 : avg_loss:  tensor(1.1055e-11, grad_fn=<DivBackward0>)\n",
            "99704 : avg_loss:  tensor(1.1054e-11, grad_fn=<DivBackward0>)\n",
            "99705 : avg_loss:  tensor(1.1054e-11, grad_fn=<DivBackward0>)\n",
            "99706 : avg_loss:  tensor(1.1053e-11, grad_fn=<DivBackward0>)\n",
            "99707 : avg_loss:  tensor(1.1053e-11, grad_fn=<DivBackward0>)\n",
            "99708 : avg_loss:  tensor(1.1052e-11, grad_fn=<DivBackward0>)\n",
            "99709 : avg_loss:  tensor(1.1052e-11, grad_fn=<DivBackward0>)\n",
            "99710 : avg_loss:  tensor(1.1051e-11, grad_fn=<DivBackward0>)\n",
            "99711 : avg_loss:  tensor(1.1051e-11, grad_fn=<DivBackward0>)\n",
            "99712 : avg_loss:  tensor(1.1050e-11, grad_fn=<DivBackward0>)\n",
            "99713 : avg_loss:  tensor(1.1050e-11, grad_fn=<DivBackward0>)\n",
            "99714 : avg_loss:  tensor(1.1050e-11, grad_fn=<DivBackward0>)\n",
            "99715 : avg_loss:  tensor(1.1049e-11, grad_fn=<DivBackward0>)\n",
            "99716 : avg_loss:  tensor(1.1048e-11, grad_fn=<DivBackward0>)\n",
            "99717 : avg_loss:  tensor(1.1048e-11, grad_fn=<DivBackward0>)\n",
            "99718 : avg_loss:  tensor(1.1047e-11, grad_fn=<DivBackward0>)\n",
            "99719 : avg_loss:  tensor(1.1046e-11, grad_fn=<DivBackward0>)\n",
            "99720 : avg_loss:  tensor(1.1046e-11, grad_fn=<DivBackward0>)\n",
            "99721 : avg_loss:  tensor(1.1046e-11, grad_fn=<DivBackward0>)\n",
            "99722 : avg_loss:  tensor(1.1045e-11, grad_fn=<DivBackward0>)\n",
            "99723 : avg_loss:  tensor(1.1045e-11, grad_fn=<DivBackward0>)\n",
            "99724 : avg_loss:  tensor(1.1044e-11, grad_fn=<DivBackward0>)\n",
            "99725 : avg_loss:  tensor(1.1044e-11, grad_fn=<DivBackward0>)\n",
            "99726 : avg_loss:  tensor(1.1043e-11, grad_fn=<DivBackward0>)\n",
            "99727 : avg_loss:  tensor(1.1043e-11, grad_fn=<DivBackward0>)\n",
            "99728 : avg_loss:  tensor(1.1042e-11, grad_fn=<DivBackward0>)\n",
            "99729 : avg_loss:  tensor(1.1042e-11, grad_fn=<DivBackward0>)\n",
            "99730 : avg_loss:  tensor(1.1041e-11, grad_fn=<DivBackward0>)\n",
            "99731 : avg_loss:  tensor(1.1041e-11, grad_fn=<DivBackward0>)\n",
            "99732 : avg_loss:  tensor(1.1040e-11, grad_fn=<DivBackward0>)\n",
            "99733 : avg_loss:  tensor(1.1040e-11, grad_fn=<DivBackward0>)\n",
            "99734 : avg_loss:  tensor(1.1039e-11, grad_fn=<DivBackward0>)\n",
            "99735 : avg_loss:  tensor(1.1039e-11, grad_fn=<DivBackward0>)\n",
            "99736 : avg_loss:  tensor(1.1038e-11, grad_fn=<DivBackward0>)\n",
            "99737 : avg_loss:  tensor(1.1038e-11, grad_fn=<DivBackward0>)\n",
            "99738 : avg_loss:  tensor(1.1038e-11, grad_fn=<DivBackward0>)\n",
            "99739 : avg_loss:  tensor(1.1037e-11, grad_fn=<DivBackward0>)\n",
            "99740 : avg_loss:  tensor(1.1036e-11, grad_fn=<DivBackward0>)\n",
            "99741 : avg_loss:  tensor(1.1036e-11, grad_fn=<DivBackward0>)\n",
            "99742 : avg_loss:  tensor(1.1035e-11, grad_fn=<DivBackward0>)\n",
            "99743 : avg_loss:  tensor(1.1035e-11, grad_fn=<DivBackward0>)\n",
            "99744 : avg_loss:  tensor(1.1035e-11, grad_fn=<DivBackward0>)\n",
            "99745 : avg_loss:  tensor(1.1034e-11, grad_fn=<DivBackward0>)\n",
            "99746 : avg_loss:  tensor(1.1033e-11, grad_fn=<DivBackward0>)\n",
            "99747 : avg_loss:  tensor(1.1033e-11, grad_fn=<DivBackward0>)\n",
            "99748 : avg_loss:  tensor(1.1033e-11, grad_fn=<DivBackward0>)\n",
            "99749 : avg_loss:  tensor(1.1032e-11, grad_fn=<DivBackward0>)\n",
            "99750 : avg_loss:  tensor(1.1031e-11, grad_fn=<DivBackward0>)\n",
            "99751 : avg_loss:  tensor(1.1031e-11, grad_fn=<DivBackward0>)\n",
            "99752 : avg_loss:  tensor(1.1031e-11, grad_fn=<DivBackward0>)\n",
            "99753 : avg_loss:  tensor(1.1030e-11, grad_fn=<DivBackward0>)\n",
            "99754 : avg_loss:  tensor(1.1030e-11, grad_fn=<DivBackward0>)\n",
            "99755 : avg_loss:  tensor(1.1029e-11, grad_fn=<DivBackward0>)\n",
            "99756 : avg_loss:  tensor(1.1029e-11, grad_fn=<DivBackward0>)\n",
            "99757 : avg_loss:  tensor(1.1028e-11, grad_fn=<DivBackward0>)\n",
            "99758 : avg_loss:  tensor(1.1028e-11, grad_fn=<DivBackward0>)\n",
            "99759 : avg_loss:  tensor(1.1027e-11, grad_fn=<DivBackward0>)\n",
            "99760 : avg_loss:  tensor(1.1027e-11, grad_fn=<DivBackward0>)\n",
            "99761 : avg_loss:  tensor(1.1026e-11, grad_fn=<DivBackward0>)\n",
            "99762 : avg_loss:  tensor(1.1025e-11, grad_fn=<DivBackward0>)\n",
            "99763 : avg_loss:  tensor(1.1025e-11, grad_fn=<DivBackward0>)\n",
            "99764 : avg_loss:  tensor(1.1025e-11, grad_fn=<DivBackward0>)\n",
            "99765 : avg_loss:  tensor(1.1024e-11, grad_fn=<DivBackward0>)\n",
            "99766 : avg_loss:  tensor(1.1023e-11, grad_fn=<DivBackward0>)\n",
            "99767 : avg_loss:  tensor(1.1023e-11, grad_fn=<DivBackward0>)\n",
            "99768 : avg_loss:  tensor(1.1022e-11, grad_fn=<DivBackward0>)\n",
            "99769 : avg_loss:  tensor(1.1022e-11, grad_fn=<DivBackward0>)\n",
            "99770 : avg_loss:  tensor(1.1021e-11, grad_fn=<DivBackward0>)\n",
            "99771 : avg_loss:  tensor(1.1021e-11, grad_fn=<DivBackward0>)\n",
            "99772 : avg_loss:  tensor(1.1021e-11, grad_fn=<DivBackward0>)\n",
            "99773 : avg_loss:  tensor(1.1020e-11, grad_fn=<DivBackward0>)\n",
            "99774 : avg_loss:  tensor(1.1020e-11, grad_fn=<DivBackward0>)\n",
            "99775 : avg_loss:  tensor(1.1019e-11, grad_fn=<DivBackward0>)\n",
            "99776 : avg_loss:  tensor(1.1019e-11, grad_fn=<DivBackward0>)\n",
            "99777 : avg_loss:  tensor(1.1018e-11, grad_fn=<DivBackward0>)\n",
            "99778 : avg_loss:  tensor(1.1018e-11, grad_fn=<DivBackward0>)\n",
            "99779 : avg_loss:  tensor(1.1017e-11, grad_fn=<DivBackward0>)\n",
            "99780 : avg_loss:  tensor(1.1017e-11, grad_fn=<DivBackward0>)\n",
            "99781 : avg_loss:  tensor(1.1016e-11, grad_fn=<DivBackward0>)\n",
            "99782 : avg_loss:  tensor(1.1015e-11, grad_fn=<DivBackward0>)\n",
            "99783 : avg_loss:  tensor(1.1015e-11, grad_fn=<DivBackward0>)\n",
            "99784 : avg_loss:  tensor(1.1015e-11, grad_fn=<DivBackward0>)\n",
            "99785 : avg_loss:  tensor(1.1014e-11, grad_fn=<DivBackward0>)\n",
            "99786 : avg_loss:  tensor(1.1014e-11, grad_fn=<DivBackward0>)\n",
            "99787 : avg_loss:  tensor(1.1013e-11, grad_fn=<DivBackward0>)\n",
            "99788 : avg_loss:  tensor(1.1013e-11, grad_fn=<DivBackward0>)\n",
            "99789 : avg_loss:  tensor(1.1012e-11, grad_fn=<DivBackward0>)\n",
            "99790 : avg_loss:  tensor(1.1012e-11, grad_fn=<DivBackward0>)\n",
            "99791 : avg_loss:  tensor(1.1011e-11, grad_fn=<DivBackward0>)\n",
            "99792 : avg_loss:  tensor(1.1011e-11, grad_fn=<DivBackward0>)\n",
            "99793 : avg_loss:  tensor(1.1010e-11, grad_fn=<DivBackward0>)\n",
            "99794 : avg_loss:  tensor(1.1010e-11, grad_fn=<DivBackward0>)\n",
            "99795 : avg_loss:  tensor(1.1009e-11, grad_fn=<DivBackward0>)\n",
            "99796 : avg_loss:  tensor(1.1009e-11, grad_fn=<DivBackward0>)\n",
            "99797 : avg_loss:  tensor(1.1008e-11, grad_fn=<DivBackward0>)\n",
            "99798 : avg_loss:  tensor(1.1008e-11, grad_fn=<DivBackward0>)\n",
            "99799 : avg_loss:  tensor(1.1007e-11, grad_fn=<DivBackward0>)\n",
            "99800 : avg_loss:  tensor(1.1007e-11, grad_fn=<DivBackward0>)\n",
            "99801 : avg_loss:  tensor(1.1006e-11, grad_fn=<DivBackward0>)\n",
            "99802 : avg_loss:  tensor(1.1006e-11, grad_fn=<DivBackward0>)\n",
            "99803 : avg_loss:  tensor(1.1005e-11, grad_fn=<DivBackward0>)\n",
            "99804 : avg_loss:  tensor(1.1005e-11, grad_fn=<DivBackward0>)\n",
            "99805 : avg_loss:  tensor(1.1004e-11, grad_fn=<DivBackward0>)\n",
            "99806 : avg_loss:  tensor(1.1004e-11, grad_fn=<DivBackward0>)\n",
            "99807 : avg_loss:  tensor(1.1003e-11, grad_fn=<DivBackward0>)\n",
            "99808 : avg_loss:  tensor(1.1003e-11, grad_fn=<DivBackward0>)\n",
            "99809 : avg_loss:  tensor(1.1002e-11, grad_fn=<DivBackward0>)\n",
            "99810 : avg_loss:  tensor(1.1002e-11, grad_fn=<DivBackward0>)\n",
            "99811 : avg_loss:  tensor(1.1001e-11, grad_fn=<DivBackward0>)\n",
            "99812 : avg_loss:  tensor(1.1001e-11, grad_fn=<DivBackward0>)\n",
            "99813 : avg_loss:  tensor(1.1000e-11, grad_fn=<DivBackward0>)\n",
            "99814 : avg_loss:  tensor(1.0999e-11, grad_fn=<DivBackward0>)\n",
            "99815 : avg_loss:  tensor(1.0999e-11, grad_fn=<DivBackward0>)\n",
            "99816 : avg_loss:  tensor(1.0998e-11, grad_fn=<DivBackward0>)\n",
            "99817 : avg_loss:  tensor(1.0998e-11, grad_fn=<DivBackward0>)\n",
            "99818 : avg_loss:  tensor(1.0998e-11, grad_fn=<DivBackward0>)\n",
            "99819 : avg_loss:  tensor(1.0997e-11, grad_fn=<DivBackward0>)\n",
            "99820 : avg_loss:  tensor(1.0997e-11, grad_fn=<DivBackward0>)\n",
            "99821 : avg_loss:  tensor(1.0996e-11, grad_fn=<DivBackward0>)\n",
            "99822 : avg_loss:  tensor(1.0995e-11, grad_fn=<DivBackward0>)\n",
            "99823 : avg_loss:  tensor(1.0995e-11, grad_fn=<DivBackward0>)\n",
            "99824 : avg_loss:  tensor(1.0995e-11, grad_fn=<DivBackward0>)\n",
            "99825 : avg_loss:  tensor(1.0994e-11, grad_fn=<DivBackward0>)\n",
            "99826 : avg_loss:  tensor(1.0994e-11, grad_fn=<DivBackward0>)\n",
            "99827 : avg_loss:  tensor(1.0993e-11, grad_fn=<DivBackward0>)\n",
            "99828 : avg_loss:  tensor(1.0993e-11, grad_fn=<DivBackward0>)\n",
            "99829 : avg_loss:  tensor(1.0992e-11, grad_fn=<DivBackward0>)\n",
            "99830 : avg_loss:  tensor(1.0992e-11, grad_fn=<DivBackward0>)\n",
            "99831 : avg_loss:  tensor(1.0991e-11, grad_fn=<DivBackward0>)\n",
            "99832 : avg_loss:  tensor(1.0991e-11, grad_fn=<DivBackward0>)\n",
            "99833 : avg_loss:  tensor(1.0990e-11, grad_fn=<DivBackward0>)\n",
            "99834 : avg_loss:  tensor(1.0990e-11, grad_fn=<DivBackward0>)\n",
            "99835 : avg_loss:  tensor(1.0989e-11, grad_fn=<DivBackward0>)\n",
            "99836 : avg_loss:  tensor(1.0989e-11, grad_fn=<DivBackward0>)\n",
            "99837 : avg_loss:  tensor(1.0988e-11, grad_fn=<DivBackward0>)\n",
            "99838 : avg_loss:  tensor(1.0988e-11, grad_fn=<DivBackward0>)\n",
            "99839 : avg_loss:  tensor(1.0987e-11, grad_fn=<DivBackward0>)\n",
            "99840 : avg_loss:  tensor(1.0987e-11, grad_fn=<DivBackward0>)\n",
            "99841 : avg_loss:  tensor(1.0986e-11, grad_fn=<DivBackward0>)\n",
            "99842 : avg_loss:  tensor(1.0986e-11, grad_fn=<DivBackward0>)\n",
            "99843 : avg_loss:  tensor(1.0985e-11, grad_fn=<DivBackward0>)\n",
            "99844 : avg_loss:  tensor(1.0985e-11, grad_fn=<DivBackward0>)\n",
            "99845 : avg_loss:  tensor(1.0984e-11, grad_fn=<DivBackward0>)\n",
            "99846 : avg_loss:  tensor(1.0983e-11, grad_fn=<DivBackward0>)\n",
            "99847 : avg_loss:  tensor(1.0983e-11, grad_fn=<DivBackward0>)\n",
            "99848 : avg_loss:  tensor(1.0983e-11, grad_fn=<DivBackward0>)\n",
            "99849 : avg_loss:  tensor(1.0982e-11, grad_fn=<DivBackward0>)\n",
            "99850 : avg_loss:  tensor(1.0982e-11, grad_fn=<DivBackward0>)\n",
            "99851 : avg_loss:  tensor(1.0981e-11, grad_fn=<DivBackward0>)\n",
            "99852 : avg_loss:  tensor(1.0980e-11, grad_fn=<DivBackward0>)\n",
            "99853 : avg_loss:  tensor(1.0980e-11, grad_fn=<DivBackward0>)\n",
            "99854 : avg_loss:  tensor(1.0979e-11, grad_fn=<DivBackward0>)\n",
            "99855 : avg_loss:  tensor(1.0979e-11, grad_fn=<DivBackward0>)\n",
            "99856 : avg_loss:  tensor(1.0978e-11, grad_fn=<DivBackward0>)\n",
            "99857 : avg_loss:  tensor(1.0978e-11, grad_fn=<DivBackward0>)\n",
            "99858 : avg_loss:  tensor(1.0977e-11, grad_fn=<DivBackward0>)\n",
            "99859 : avg_loss:  tensor(1.0977e-11, grad_fn=<DivBackward0>)\n",
            "99860 : avg_loss:  tensor(1.0977e-11, grad_fn=<DivBackward0>)\n",
            "99861 : avg_loss:  tensor(1.0975e-11, grad_fn=<DivBackward0>)\n",
            "99862 : avg_loss:  tensor(1.0975e-11, grad_fn=<DivBackward0>)\n",
            "99863 : avg_loss:  tensor(1.0975e-11, grad_fn=<DivBackward0>)\n",
            "99864 : avg_loss:  tensor(1.0974e-11, grad_fn=<DivBackward0>)\n",
            "99865 : avg_loss:  tensor(1.0974e-11, grad_fn=<DivBackward0>)\n",
            "99866 : avg_loss:  tensor(1.0973e-11, grad_fn=<DivBackward0>)\n",
            "99867 : avg_loss:  tensor(1.0973e-11, grad_fn=<DivBackward0>)\n",
            "99868 : avg_loss:  tensor(1.0972e-11, grad_fn=<DivBackward0>)\n",
            "99869 : avg_loss:  tensor(1.0971e-11, grad_fn=<DivBackward0>)\n",
            "99870 : avg_loss:  tensor(1.0971e-11, grad_fn=<DivBackward0>)\n",
            "99871 : avg_loss:  tensor(1.0971e-11, grad_fn=<DivBackward0>)\n",
            "99872 : avg_loss:  tensor(1.0970e-11, grad_fn=<DivBackward0>)\n",
            "99873 : avg_loss:  tensor(1.0970e-11, grad_fn=<DivBackward0>)\n",
            "99874 : avg_loss:  tensor(1.0969e-11, grad_fn=<DivBackward0>)\n",
            "99875 : avg_loss:  tensor(1.0969e-11, grad_fn=<DivBackward0>)\n",
            "99876 : avg_loss:  tensor(1.0968e-11, grad_fn=<DivBackward0>)\n",
            "99877 : avg_loss:  tensor(1.0968e-11, grad_fn=<DivBackward0>)\n",
            "99878 : avg_loss:  tensor(1.0967e-11, grad_fn=<DivBackward0>)\n",
            "99879 : avg_loss:  tensor(1.0966e-11, grad_fn=<DivBackward0>)\n",
            "99880 : avg_loss:  tensor(1.0966e-11, grad_fn=<DivBackward0>)\n",
            "99881 : avg_loss:  tensor(1.0966e-11, grad_fn=<DivBackward0>)\n",
            "99882 : avg_loss:  tensor(1.0965e-11, grad_fn=<DivBackward0>)\n",
            "99883 : avg_loss:  tensor(1.0965e-11, grad_fn=<DivBackward0>)\n",
            "99884 : avg_loss:  tensor(1.0964e-11, grad_fn=<DivBackward0>)\n",
            "99885 : avg_loss:  tensor(1.0963e-11, grad_fn=<DivBackward0>)\n",
            "99886 : avg_loss:  tensor(1.0963e-11, grad_fn=<DivBackward0>)\n",
            "99887 : avg_loss:  tensor(1.0962e-11, grad_fn=<DivBackward0>)\n",
            "99888 : avg_loss:  tensor(1.0962e-11, grad_fn=<DivBackward0>)\n",
            "99889 : avg_loss:  tensor(1.0961e-11, grad_fn=<DivBackward0>)\n",
            "99890 : avg_loss:  tensor(1.0961e-11, grad_fn=<DivBackward0>)\n",
            "99891 : avg_loss:  tensor(1.0961e-11, grad_fn=<DivBackward0>)\n",
            "99892 : avg_loss:  tensor(1.0960e-11, grad_fn=<DivBackward0>)\n",
            "99893 : avg_loss:  tensor(1.0959e-11, grad_fn=<DivBackward0>)\n",
            "99894 : avg_loss:  tensor(1.0959e-11, grad_fn=<DivBackward0>)\n",
            "99895 : avg_loss:  tensor(1.0958e-11, grad_fn=<DivBackward0>)\n",
            "99896 : avg_loss:  tensor(1.0957e-11, grad_fn=<DivBackward0>)\n",
            "99897 : avg_loss:  tensor(1.0957e-11, grad_fn=<DivBackward0>)\n",
            "99898 : avg_loss:  tensor(1.0956e-11, grad_fn=<DivBackward0>)\n",
            "99899 : avg_loss:  tensor(1.0956e-11, grad_fn=<DivBackward0>)\n",
            "99900 : avg_loss:  tensor(1.0956e-11, grad_fn=<DivBackward0>)\n",
            "99901 : avg_loss:  tensor(1.0955e-11, grad_fn=<DivBackward0>)\n",
            "99902 : avg_loss:  tensor(1.0954e-11, grad_fn=<DivBackward0>)\n",
            "99903 : avg_loss:  tensor(1.0954e-11, grad_fn=<DivBackward0>)\n",
            "99904 : avg_loss:  tensor(1.0954e-11, grad_fn=<DivBackward0>)\n",
            "99905 : avg_loss:  tensor(1.0953e-11, grad_fn=<DivBackward0>)\n",
            "99906 : avg_loss:  tensor(1.0953e-11, grad_fn=<DivBackward0>)\n",
            "99907 : avg_loss:  tensor(1.0952e-11, grad_fn=<DivBackward0>)\n",
            "99908 : avg_loss:  tensor(1.0951e-11, grad_fn=<DivBackward0>)\n",
            "99909 : avg_loss:  tensor(1.0951e-11, grad_fn=<DivBackward0>)\n",
            "99910 : avg_loss:  tensor(1.0950e-11, grad_fn=<DivBackward0>)\n",
            "99911 : avg_loss:  tensor(1.0950e-11, grad_fn=<DivBackward0>)\n",
            "99912 : avg_loss:  tensor(1.0949e-11, grad_fn=<DivBackward0>)\n",
            "99913 : avg_loss:  tensor(1.0949e-11, grad_fn=<DivBackward0>)\n",
            "99914 : avg_loss:  tensor(1.0949e-11, grad_fn=<DivBackward0>)\n",
            "99915 : avg_loss:  tensor(1.0948e-11, grad_fn=<DivBackward0>)\n",
            "99916 : avg_loss:  tensor(1.0947e-11, grad_fn=<DivBackward0>)\n",
            "99917 : avg_loss:  tensor(1.0947e-11, grad_fn=<DivBackward0>)\n",
            "99918 : avg_loss:  tensor(1.0946e-11, grad_fn=<DivBackward0>)\n",
            "99919 : avg_loss:  tensor(1.0946e-11, grad_fn=<DivBackward0>)\n",
            "99920 : avg_loss:  tensor(1.0945e-11, grad_fn=<DivBackward0>)\n",
            "99921 : avg_loss:  tensor(1.0945e-11, grad_fn=<DivBackward0>)\n",
            "99922 : avg_loss:  tensor(1.0944e-11, grad_fn=<DivBackward0>)\n",
            "99923 : avg_loss:  tensor(1.0944e-11, grad_fn=<DivBackward0>)\n",
            "99924 : avg_loss:  tensor(1.0943e-11, grad_fn=<DivBackward0>)\n",
            "99925 : avg_loss:  tensor(1.0943e-11, grad_fn=<DivBackward0>)\n",
            "99926 : avg_loss:  tensor(1.0942e-11, grad_fn=<DivBackward0>)\n",
            "99927 : avg_loss:  tensor(1.0942e-11, grad_fn=<DivBackward0>)\n",
            "99928 : avg_loss:  tensor(1.0941e-11, grad_fn=<DivBackward0>)\n",
            "99929 : avg_loss:  tensor(1.0941e-11, grad_fn=<DivBackward0>)\n",
            "99930 : avg_loss:  tensor(1.0940e-11, grad_fn=<DivBackward0>)\n",
            "99931 : avg_loss:  tensor(1.0939e-11, grad_fn=<DivBackward0>)\n",
            "99932 : avg_loss:  tensor(1.0939e-11, grad_fn=<DivBackward0>)\n",
            "99933 : avg_loss:  tensor(1.0938e-11, grad_fn=<DivBackward0>)\n",
            "99934 : avg_loss:  tensor(1.0938e-11, grad_fn=<DivBackward0>)\n",
            "99935 : avg_loss:  tensor(1.0937e-11, grad_fn=<DivBackward0>)\n",
            "99936 : avg_loss:  tensor(1.0937e-11, grad_fn=<DivBackward0>)\n",
            "99937 : avg_loss:  tensor(1.0936e-11, grad_fn=<DivBackward0>)\n",
            "99938 : avg_loss:  tensor(1.0936e-11, grad_fn=<DivBackward0>)\n",
            "99939 : avg_loss:  tensor(1.0935e-11, grad_fn=<DivBackward0>)\n",
            "99940 : avg_loss:  tensor(1.0934e-11, grad_fn=<DivBackward0>)\n",
            "99941 : avg_loss:  tensor(1.0934e-11, grad_fn=<DivBackward0>)\n",
            "99942 : avg_loss:  tensor(1.0933e-11, grad_fn=<DivBackward0>)\n",
            "99943 : avg_loss:  tensor(1.0933e-11, grad_fn=<DivBackward0>)\n",
            "99944 : avg_loss:  tensor(1.0932e-11, grad_fn=<DivBackward0>)\n",
            "99945 : avg_loss:  tensor(1.0932e-11, grad_fn=<DivBackward0>)\n",
            "99946 : avg_loss:  tensor(1.0932e-11, grad_fn=<DivBackward0>)\n",
            "99947 : avg_loss:  tensor(1.0931e-11, grad_fn=<DivBackward0>)\n",
            "99948 : avg_loss:  tensor(1.0930e-11, grad_fn=<DivBackward0>)\n",
            "99949 : avg_loss:  tensor(1.0930e-11, grad_fn=<DivBackward0>)\n",
            "99950 : avg_loss:  tensor(1.0929e-11, grad_fn=<DivBackward0>)\n",
            "99951 : avg_loss:  tensor(1.0929e-11, grad_fn=<DivBackward0>)\n",
            "99952 : avg_loss:  tensor(1.0928e-11, grad_fn=<DivBackward0>)\n",
            "99953 : avg_loss:  tensor(1.0928e-11, grad_fn=<DivBackward0>)\n",
            "99954 : avg_loss:  tensor(1.0927e-11, grad_fn=<DivBackward0>)\n",
            "99955 : avg_loss:  tensor(1.0927e-11, grad_fn=<DivBackward0>)\n",
            "99956 : avg_loss:  tensor(1.0926e-11, grad_fn=<DivBackward0>)\n",
            "99957 : avg_loss:  tensor(1.0926e-11, grad_fn=<DivBackward0>)\n",
            "99958 : avg_loss:  tensor(1.0925e-11, grad_fn=<DivBackward0>)\n",
            "99959 : avg_loss:  tensor(1.0924e-11, grad_fn=<DivBackward0>)\n",
            "99960 : avg_loss:  tensor(1.0924e-11, grad_fn=<DivBackward0>)\n",
            "99961 : avg_loss:  tensor(1.0923e-11, grad_fn=<DivBackward0>)\n",
            "99962 : avg_loss:  tensor(1.0923e-11, grad_fn=<DivBackward0>)\n",
            "99963 : avg_loss:  tensor(1.0922e-11, grad_fn=<DivBackward0>)\n",
            "99964 : avg_loss:  tensor(1.0922e-11, grad_fn=<DivBackward0>)\n",
            "99965 : avg_loss:  tensor(1.0921e-11, grad_fn=<DivBackward0>)\n",
            "99966 : avg_loss:  tensor(1.0921e-11, grad_fn=<DivBackward0>)\n",
            "99967 : avg_loss:  tensor(1.0921e-11, grad_fn=<DivBackward0>)\n",
            "99968 : avg_loss:  tensor(1.0920e-11, grad_fn=<DivBackward0>)\n",
            "99969 : avg_loss:  tensor(1.0919e-11, grad_fn=<DivBackward0>)\n",
            "99970 : avg_loss:  tensor(1.0919e-11, grad_fn=<DivBackward0>)\n",
            "99971 : avg_loss:  tensor(1.0918e-11, grad_fn=<DivBackward0>)\n",
            "99972 : avg_loss:  tensor(1.0918e-11, grad_fn=<DivBackward0>)\n",
            "99973 : avg_loss:  tensor(1.0917e-11, grad_fn=<DivBackward0>)\n",
            "99974 : avg_loss:  tensor(1.0916e-11, grad_fn=<DivBackward0>)\n",
            "99975 : avg_loss:  tensor(1.0916e-11, grad_fn=<DivBackward0>)\n",
            "99976 : avg_loss:  tensor(1.0915e-11, grad_fn=<DivBackward0>)\n",
            "99977 : avg_loss:  tensor(1.0915e-11, grad_fn=<DivBackward0>)\n",
            "99978 : avg_loss:  tensor(1.0914e-11, grad_fn=<DivBackward0>)\n",
            "99979 : avg_loss:  tensor(1.0914e-11, grad_fn=<DivBackward0>)\n",
            "99980 : avg_loss:  tensor(1.0913e-11, grad_fn=<DivBackward0>)\n",
            "99981 : avg_loss:  tensor(1.0913e-11, grad_fn=<DivBackward0>)\n",
            "99982 : avg_loss:  tensor(1.0912e-11, grad_fn=<DivBackward0>)\n",
            "99983 : avg_loss:  tensor(1.0912e-11, grad_fn=<DivBackward0>)\n",
            "99984 : avg_loss:  tensor(1.0911e-11, grad_fn=<DivBackward0>)\n",
            "99985 : avg_loss:  tensor(1.0910e-11, grad_fn=<DivBackward0>)\n",
            "99986 : avg_loss:  tensor(1.0910e-11, grad_fn=<DivBackward0>)\n",
            "99987 : avg_loss:  tensor(1.0909e-11, grad_fn=<DivBackward0>)\n",
            "99988 : avg_loss:  tensor(1.0909e-11, grad_fn=<DivBackward0>)\n",
            "99989 : avg_loss:  tensor(1.0908e-11, grad_fn=<DivBackward0>)\n",
            "99990 : avg_loss:  tensor(1.0908e-11, grad_fn=<DivBackward0>)\n",
            "99991 : avg_loss:  tensor(1.0907e-11, grad_fn=<DivBackward0>)\n",
            "99992 : avg_loss:  tensor(1.0907e-11, grad_fn=<DivBackward0>)\n",
            "99993 : avg_loss:  tensor(1.0906e-11, grad_fn=<DivBackward0>)\n",
            "99994 : avg_loss:  tensor(1.0906e-11, grad_fn=<DivBackward0>)\n",
            "99995 : avg_loss:  tensor(1.0905e-11, grad_fn=<DivBackward0>)\n",
            "99996 : avg_loss:  tensor(1.0905e-11, grad_fn=<DivBackward0>)\n",
            "99997 : avg_loss:  tensor(1.0904e-11, grad_fn=<DivBackward0>)\n",
            "99998 : avg_loss:  tensor(1.0904e-11, grad_fn=<DivBackward0>)\n",
            "99999 : avg_loss:  tensor(1.0903e-11, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-df88a908aa45>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': avg_loss: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'greater_than2.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "def generate_data(num_samples=100,range=100):\n",
        "    a_values = np.random.uniform(low=-range, high=range, size=num_samples)\n",
        "    b_values = np.random.uniform(low=-range, high=range, size=num_samples)\n",
        "    y_values = (a_values > b_values).astype(int)\n",
        "    data = np.concatenate((a_values[:, np.newaxis], b_values[:, np.newaxis], y_values[:, np.newaxis]), axis=1)\n",
        "    return data\n",
        "\n",
        "class ComparatorNetwork(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(2, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.x=None\n",
        "        self.out1 = None\n",
        "        self.out2 = None\n",
        "        self.out3 = None\n",
        "        self.out4 = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x=x\n",
        "        out = self.relu(self.linear1(x))\n",
        "        self.out1 = out\n",
        "        out = self.relu(self.linear2(out))\n",
        "        self.out2 = out\n",
        "        out = torch.sigmoid(self.linear3(out))\n",
        "        self.out3 = out\n",
        "        return out\n",
        "\n",
        "# Generate training data\n",
        "data = generate_data()\n",
        "\n",
        "data_list = []\n",
        "data_list.append(generate_data(num_samples=50000))  # Convert to float for compatibility\n",
        "\n",
        "data_list.append(generate_data(num_samples=100000,range=0.5))  # Convert to float for compatibility\n",
        "\n",
        "data_list.append(generate_data(num_samples=50000, range=1))  # Convert to float for compatibility\n",
        "\n",
        "data = np.vstack(data_list)\n",
        "np.random.shuffle(data)\n",
        "\n",
        "X = torch.tensor(data[:, :2], dtype=torch.float32)  # Input (a and b)\n",
        "Y = torch.tensor(data[:, 2], dtype=torch.float32)  # Output\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "model2 = ComparatorNetwork(hidden_dim=2)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(100000):\n",
        "  total_loss = 0\n",
        "  optimizer.zero_grad()\n",
        "  #  print(X[i])\n",
        "  result = model2(X)\n",
        "   # print(result)\n",
        "   # print(Y[i])\n",
        "  loss = nn.BCELoss()(result.squeeze(),Y)\n",
        "  total_loss+=loss\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(epoch, ': avg_loss: ',total_loss/len(X))\n",
        "\n",
        "torch.save(model,'greater_than2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1000000):\n",
        "  total_loss = 0\n",
        "  optimizer.zero_grad()\n",
        "  #  print(X[i])\n",
        "  result = model2(X)\n",
        "   # print(result)\n",
        "   # print(Y[i])\n",
        "  loss = nn.BCELoss()(result.squeeze(),Y)\n",
        "  total_loss+=loss\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch % 10000==0:\n",
        "    print(epoch, ': avg_loss: ',total_loss/len(X))\n",
        "\n",
        "\n",
        "torch.save(model2,'greater_than2.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "auWTnGV3C7QZ",
        "outputId": "a6259d2b-0628-4e20-fb86-fa80c10de9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 : avg_loss:  tensor(8.0563e-12, grad_fn=<DivBackward0>)\n",
            "10000 : avg_loss:  tensor(5.5909e-12, grad_fn=<DivBackward0>)\n",
            "20000 : avg_loss:  tensor(4.7526e-12, grad_fn=<DivBackward0>)\n",
            "30000 : avg_loss:  tensor(3.6456e-12, grad_fn=<DivBackward0>)\n",
            "40000 : avg_loss:  tensor(2.7233e-12, grad_fn=<DivBackward0>)\n",
            "50000 : avg_loss:  tensor(2.0468e-12, grad_fn=<DivBackward0>)\n",
            "60000 : avg_loss:  tensor(1.8403e-12, grad_fn=<DivBackward0>)\n",
            "70000 : avg_loss:  tensor(1.5241e-12, grad_fn=<DivBackward0>)\n",
            "80000 : avg_loss:  tensor(1.1878e-12, grad_fn=<DivBackward0>)\n",
            "90000 : avg_loss:  tensor(9.8127e-13, grad_fn=<DivBackward0>)\n",
            "100000 : avg_loss:  tensor(9.0604e-13, grad_fn=<DivBackward0>)\n",
            "110000 : avg_loss:  tensor(7.5578e-13, grad_fn=<DivBackward0>)\n",
            "120000 : avg_loss:  tensor(6.7345e-13, grad_fn=<DivBackward0>)\n",
            "130000 : avg_loss:  tensor(6.1872e-13, grad_fn=<DivBackward0>)\n",
            "140000 : avg_loss:  tensor(5.9059e-13, grad_fn=<DivBackward0>)\n",
            "150000 : avg_loss:  tensor(5.0965e-13, grad_fn=<DivBackward0>)\n",
            "160000 : avg_loss:  tensor(4.5572e-13, grad_fn=<DivBackward0>)\n",
            "170000 : avg_loss:  tensor(4.1686e-13, grad_fn=<DivBackward0>)\n",
            "180000 : avg_loss:  tensor(3.9341e-13, grad_fn=<DivBackward0>)\n",
            "190000 : avg_loss:  tensor(3.7960e-13, grad_fn=<DivBackward0>)\n",
            "200000 : avg_loss:  tensor(3.4048e-13, grad_fn=<DivBackward0>)\n",
            "210000 : avg_loss:  tensor(3.0911e-13, grad_fn=<DivBackward0>)\n",
            "220000 : avg_loss:  tensor(2.8323e-13, grad_fn=<DivBackward0>)\n",
            "230000 : avg_loss:  tensor(2.7062e-13, grad_fn=<DivBackward0>)\n",
            "240000 : avg_loss:  tensor(5.0395e-13, grad_fn=<DivBackward0>)\n",
            "250000 : avg_loss:  tensor(2.4424e-13, grad_fn=<DivBackward0>)\n",
            "260000 : avg_loss:  tensor(2.7060e-13, grad_fn=<DivBackward0>)\n",
            "270000 : avg_loss:  tensor(2.2092e-13, grad_fn=<DivBackward0>)\n",
            "280000 : avg_loss:  tensor(2.2847e-13, grad_fn=<DivBackward0>)\n",
            "290000 : avg_loss:  tensor(2.0016e-13, grad_fn=<DivBackward0>)\n",
            "300000 : avg_loss:  tensor(1.9178e-13, grad_fn=<DivBackward0>)\n",
            "310000 : avg_loss:  tensor(1.8001e-13, grad_fn=<DivBackward0>)\n",
            "320000 : avg_loss:  tensor(1.7246e-13, grad_fn=<DivBackward0>)\n",
            "330000 : avg_loss:  tensor(1.6452e-13, grad_fn=<DivBackward0>)\n",
            "340000 : avg_loss:  tensor(1.5800e-13, grad_fn=<DivBackward0>)\n",
            "350000 : avg_loss:  tensor(1.4933e-13, grad_fn=<DivBackward0>)\n",
            "360000 : avg_loss:  tensor(1.4563e-13, grad_fn=<DivBackward0>)\n",
            "370000 : avg_loss:  tensor(1.3507e-13, grad_fn=<DivBackward0>)\n",
            "380000 : avg_loss:  tensor(1.3471e-13, grad_fn=<DivBackward0>)\n",
            "390000 : avg_loss:  tensor(2.6998e-13, grad_fn=<DivBackward0>)\n",
            "400000 : avg_loss:  tensor(1.2519e-13, grad_fn=<DivBackward0>)\n",
            "410000 : avg_loss:  tensor(2.2559e-13, grad_fn=<DivBackward0>)\n",
            "420000 : avg_loss:  tensor(1.1762e-13, grad_fn=<DivBackward0>)\n",
            "430000 : avg_loss:  tensor(1.4284e-13, grad_fn=<DivBackward0>)\n",
            "440000 : avg_loss:  tensor(1.1027e-13, grad_fn=<DivBackward0>)\n",
            "450000 : avg_loss:  tensor(1.4115e-13, grad_fn=<DivBackward0>)\n",
            "460000 : avg_loss:  tensor(1.0372e-13, grad_fn=<DivBackward0>)\n",
            "470000 : avg_loss:  tensor(1.1493e-13, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-31c7f1888c70>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0;31m# print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0;31m# print(Y[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mtotal_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3125\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2,'greater_than2.pth')"
      ],
      "metadata": {
        "id": "SLUjfruse-yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc-cLCK9_Bk_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!cp 'dbn_modelv2_deepConv.pt' /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve3egHwfzPUA"
      },
      "source": [
        "Combined VAE representation - VAE encoder for continous variables, other type of encoder for categorical variables, combined into decoder.\n",
        "\n",
        "Working with this data I see why tabular data is much harder. Training a VAE on this is much more difficult than other times I've done it. Right now I've split the data into 2, categorical and continous but I'm going to have to split them into groupings of dependencies between variables.\n",
        "\n",
        "OPTICS is clustering between datapoints but we want clustering of dependencies between variables. Even then there will be large groups of disparate variables.\n",
        "\n",
        "\n",
        "CLUSTER ACCORDING TO COMBINED ENCODED LATENT SPACE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9BxN5PUWoSW"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # Provides additional layers and functions\n",
        "\n",
        "import torch\n",
        "import torch.distributions as dist\n",
        "\n",
        "\n",
        "def train_vae(num_vae, dataloader, num_epochs, optimizer_num, device):\n",
        "    num_vae.train()\n",
        "    # Train Numerical VAE\n",
        "    for epoch in range(num_epochs):\n",
        "      num_vae.train()\n",
        "      total_loss_num = 0\n",
        "      for batch_num,_ in dataloader:  # Only iterate over numerical data\n",
        "        batch_num = batch_num.to(device)\n",
        "        optimizer_num.zero_grad()\n",
        "        recon_num, mu_num, logvar_num = num_vae(batch_num)\n",
        "        loss_num = F.mse_loss(recon_num, batch_num) + \\\n",
        "                       -0.5 * torch.sum(1 + logvar_num - mu_num.pow(2) - logvar_num.exp())\n",
        "        loss_num.backward()\n",
        "        optimizer_num.step()\n",
        "        total_loss_num += loss_num.item()\n",
        "      avg_loss_num = total_loss_num / len(dataloader)\n",
        "      print(f'Epoch {epoch + 1}: Num. VAE Loss - {avg_loss_num:.4f}')\n",
        "\n",
        "\n",
        "#--- Using the loop ---\n",
        "\n",
        "# Instantiate your VAE model\n",
        "num_vae = VAE(input_size=X_num.shape[1], hidden_size=512, latent_size=16).to(device)\n",
        "\n",
        "# Optimizers for each VAE\n",
        "optimizer_num = optim.Adam(num_vae.parameters(), lr=1e-3)\n",
        "\n",
        "# Train!\n",
        "train_vae(num_vae, dataloader, num_epochs=200, optimizer_num=optimizer_num, optimizer_cat=optimizer_cat, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xVV73zMfglg"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import OPTICS\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def run_optics_and_visualize(data):\n",
        "    # Perform OPTICS clustering using the provided metric\n",
        "    optics = OPTICS(min_samples=20)\n",
        "    optics.fit(data)\n",
        "    # Get cluster labels\n",
        "    cluster_labels = optics.labels_\n",
        "\n",
        "    # Get reachability distances (useful for understanding cluster structure)\n",
        "    reachability_distances = optics.reachability_\n",
        "    # Create a dictionary for mapping cluster labels to colors\n",
        "    color_map = plt.cm.get_cmap('tab10', max(cluster_labels) + 1)  # Adjust colormap as needed\n",
        "    colors = [color_map(label) for label in cluster_labels]\n",
        "\n",
        "    # Reduce dimensionality to 2D using PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    data_reduced = pca.fit_transform(data)\n",
        "\n",
        "\n",
        "    # Plot the reduced data with cluster labels as colors\n",
        "    plt.scatter(data_reduced[:, 0], data_reduced[:, 1], c=cluster_labels)\n",
        "    plt.title('OPTICS Clusters (PCA Visualization)')\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.show()\n",
        "\n",
        "    tsne = TSNE(n_components=2)\n",
        "    data_reduced = tsne.fit_transform(data)\n",
        "\n",
        "    # Plot the reduced data with cluster labels as colors\n",
        "    plt.scatter(data_reduced[:, 0], data_reduced[:, 1], c=cluster_labels)\n",
        "    plt.title('OPTICS Clusters (t-SNE Visualization)')\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhsENycGJX9x"
      },
      "outputs": [],
      "source": [
        "run_optics_and_visualize(np.concatenate((X_num, X_cat), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqc99903JgRJ"
      },
      "outputs": [],
      "source": [
        "run_optics_and_visualize(X_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6SX9WqCJg_q"
      },
      "outputs": [],
      "source": [
        "run_optics_and_visualize(X_cat)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}