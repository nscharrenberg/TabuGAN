{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa4nnkdUKwWj",
        "outputId": "6b089732-fdc0-4e26-9bb3-d4286cf296dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install ucimlrepo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1FGcBJtfwDs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "X = pd.read_csv(\"censusData.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DhCnFMeKw_4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, attention_hidden_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(attention_hidden_size, attention_hidden_size).to(device)\n",
        "\n",
        "    def forward(self, encoder_outputs):\n",
        "      # Transform x using a linear layer; output shape will be (sq, b, hidden_size)\n",
        "      x_transformed = self.linear(encoder_outputs)\n",
        "      # Step 2: Compute attention scores using softmax across the sequence dimension (sq)\n",
        "      # Attention scores shape: (sq, b, hidden_size) -> (b, sq, hidden_size) for softmax\n",
        "      x_transposed = x_transformed.transpose(0, 1)  # Transposing for softmax operation\n",
        "      attention_scores = F.softmax(x_transposed, dim=1)  # Applying softmax; shape remains (b, sq, hidden_size)\n",
        "      # Step 3: Apply attention scores to the original input tensor\n",
        "      # For weighted sum, first transpose x back: (sq, b, hidden_size) -> (b, sq, hidden_size)\n",
        "      x = encoder_outputs.transpose(0, 1)  # Transposing x to match attention_scores shape\n",
        "      # Compute the context vector as the weighted sum of the input vectors\n",
        "      # (b, sq, hidden_size) * (b, sq, hidden_size) -> (b, hidden_size) after summing over sq dimension\n",
        "      context_vector = torch.sum(attention_scores * x, dim=1)\n",
        "      return context_vector\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, latent_size,only_z=False):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear5 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear6 = nn.Linear(hidden_size, latent_size)\n",
        "        self.linear_mu = nn.Linear(latent_size, latent_size)\n",
        "        self.linear_logvar = nn.Linear(latent_size, latent_size)\n",
        "        self.only_z = only_z\n",
        "        self.relu = nn.GELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.linear1(x))\n",
        "        out = self.relu(self.linear2(out))\n",
        "        out = self.relu(self.linear3(out))\n",
        "        out = self.relu(self.linear4(out))\n",
        "        out = self.relu(self.linear5(out))\n",
        "        out = self.relu(self.linear6(out))\n",
        "        # Replace self.linear_mu and linear_logvar with FractionalJacobiNeuralBlock for each\n",
        "        mu = self.linear_mu(out)\n",
        "        logvar = self.linear_logvar(out)\n",
        "\n",
        "        # Reparameterization trick (as before)\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = eps.mul(std).add_(mu)\n",
        "        if self.only_z:\n",
        "          return z\n",
        "        return z, mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(latent_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.relu1 = nn.GELU()\n",
        "        self.relu2 = nn.GELU()\n",
        "        self.relu3 = nn.GELU()\n",
        "        self.relu4 = nn.GELU()\n",
        "\n",
        "    def forward(self, z, sig=False):\n",
        "        out = self.relu1(self.linear1(z))\n",
        "        out = self.relu2(self.linear2(out))\n",
        "        out = self.relu3(self.linear3(out))\n",
        "        out = torch.sigmoid(self.output_layer(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, latent_size, cat=False):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size, latent_size).to(device)\n",
        "        self.decoder = Decoder(latent_size, hidden_size, input_size).to(device)\n",
        "        self.cat=cat\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.cat:\n",
        "          z, logits = self.encoder(x,True)\n",
        "          recon = self.decoder(z,True)\n",
        "          return recon, logits\n",
        "        else:\n",
        "          z, mu, logvar = self.encoder(x)\n",
        "          recon = self.decoder(z)\n",
        "          return recon, mu, logvar\n",
        "\n",
        "class ConditionalBatchNorm1d(nn.Module):\n",
        "    def __init__(self, num_features, num_conditions):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.gamma_layer = nn.Linear(num_conditions, num_features)\n",
        "        self.beta_layer = nn.Linear(num_conditions, num_features)\n",
        "\n",
        "    def forward(self, input, condition):\n",
        "\n",
        "        out = F.batch_norm(input, None, None, training=True).to(device)  # Standard batch normalization\n",
        "        gamma = self.gamma_layer(condition).to(device)\n",
        "        beta = self.beta_layer(condition).to(device)\n",
        "\n",
        "        out = gamma * out + beta\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVNvFy0Opu_x",
        "outputId": "d1a4607c-0d79-40a6-bfd0-527c58faa815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48842, 107)\n",
            "torch.Size([5671, 131])\n",
            "torch.Size([5671, 2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "# NEED: to make an stat generation pipeline, that will generate the categorical and numerical for a given dataset automatically.\n",
        "# in terms of what to do about statistical tests that can compare discrete and continuous\n",
        "# additional binary in convolutional graph structure to represent if it's a cross category variable pair.\n",
        "# feed the entire row into the convolutional layer\n",
        "# pretrain the discrete deepConv to take in as input the entire row + entire dependency graph structure and output only the categorical variables.\n",
        "# same with the continuous deepConv but outputs the continuous variables instead.\n",
        "\n",
        "rbf_hsic_matrix = torch.load('rbf_hsic_matrix_updated.pt')\n",
        "linear_hsic_matrix = torch.load('linear_hsic_matrix_updated.pt')\n",
        "mutual_information_matrix = torch.load('mutual_information_matrix.pt')\n",
        "distance_correlation_matrix = torch.load('distance_correlation_matrix.pt')\n",
        "chi2_matrix = torch.load('chi2_matrix.pt')\n",
        "theils_u_matrix = torch.load('theils_u_matrix.pt')\n",
        "cramers_v_matrix = torch.load('cramers_v_matrix.pt')\n",
        "\n",
        "def load_measure_matrix(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data['matrix'], data['feature_names']\n",
        "\n",
        "agreement_matrix, agreement_feature_names = load_measure_matrix('agreement_matrix.pkl')\n",
        "binary_matrix, binary_feature_names = load_measure_matrix('binary_matrix.pkl')\n",
        "categorical_matrix, categorical_feature_names = load_measure_matrix('categorical_matrix.pkl')\n",
        "confusion_matrix, confusion_feature_names = load_measure_matrix('confusion_matrix.pkl')\n",
        "\n",
        "num_features = rbf_hsic_matrix.shape[0]\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country','income']\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "X_encoded = encoder.fit_transform(X[categorical_columns])\n",
        "feature_names = encoder.get_feature_names_out(categorical_columns)\n",
        "\n",
        "column_mapping = {}\n",
        "start_index = 0\n",
        "for col in categorical_columns:\n",
        "    column_mapping[col] = start_index\n",
        "    start_index += len(encoder.categories_[categorical_columns.index(col)])\n",
        "\n",
        "print(X_encoded.shape)\n",
        "\n",
        "index = []\n",
        "attr = []\n",
        "\n",
        "for i in range(num_features):\n",
        "    for j in range(i + 1, num_features):\n",
        "        index.append([i,j])\n",
        "        # Find the categorical columns associated with features i and j\n",
        "        col_i = next(col for col, start_idx in column_mapping.items() if start_idx <= i < start_idx + len(encoder.categories_[categorical_columns.index(col)]))\n",
        "        col_j = next(col for col, start_idx in column_mapping.items() if start_idx <= j < start_idx + len(encoder.categories_[categorical_columns.index(col)]))\n",
        "\n",
        "        # Create the categorical column vector (1 for the corresponding column, 0 otherwise)\n",
        "        categorical_col_vec = np.zeros(len(categorical_columns))\n",
        "        categorical_col_vec[categorical_columns.index(col_i)] = 1\n",
        "        categorical_col_vec[categorical_columns.index(col_j)] = 1\n",
        "\n",
        "        list1 = [linear_hsic_matrix[i, j],\n",
        "            rbf_hsic_matrix[i, j],\n",
        "            mutual_information_matrix[i, j],\n",
        "            distance_correlation_matrix[i, j],\n",
        "            chi2_matrix[i, j],\n",
        "            theils_u_matrix[i, j],\n",
        "            cramers_v_matrix[i, j]]\n",
        "        for measure in agreement_matrix[i][j].keys():\n",
        "          list1.append(agreement_matrix[i][j][measure])\n",
        "        for measure in binary_matrix[i][j].keys():\n",
        "          if measure == 'mcnemar_test':\n",
        "            list1.append(binary_matrix[i][j][measure][0])\n",
        "          else:\n",
        "            list1.append(binary_matrix[i][j][measure])\n",
        "        for measure in categorical_matrix[i][j].keys():\n",
        "          list1.append(categorical_matrix[i][j][measure])\n",
        "        for measure in confusion_matrix[i][j].keys():\n",
        "          list1.append(confusion_matrix[i][j][measure])\n",
        "        list1.extend(categorical_col_vec)\n",
        "        attr.append(list1)\n",
        "\n",
        "\n",
        "attr = torch.tensor(attr, dtype=torch.float).to(device)\n",
        "index = torch.tensor(index, dtype=torch.int).to(device)\n",
        "print(attr.shape)\n",
        "print(index.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV8ZZHK56qhs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "X_encoded = torch.tensor(X_encoded)\n",
        "\n",
        "dataset = list(X_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJWvNSnBlXWp",
        "outputId": "a983d434-d3b9-44e0-c602-901442f309ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Bernoulli\n",
        "import random\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class DeepLinear(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "    def forward(self, x, cond=None):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DeepConv(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.num_variables = 107\n",
        "        self.e_features = attr.shape[1]\n",
        "        self.input_embedding = DeepLinear(self.num_variables,hidden_dim, hidden_dim)\n",
        "        self.attr_embedding = nn.ModuleList([nn.Linear(self.num_variables+self.e_features, hidden_dim) for _ in range(attr.shape[0])])\n",
        "        self.e_scoring_network = DeepLinear(hidden_dim * 2, hidden_dim, output_dim=self.num_variables)\n",
        "        self.attribute_scoring_network1 = DeepLinear(hidden_dim,hidden_dim,hidden_dim)\n",
        "        self.attribute_scoring_network = DeepLinear(attr.shape[0] * hidden_dim,hidden_dim,hidden_dim)\n",
        "\n",
        "    def forward(self, X_encoded):\n",
        "        batch_size = X_encoded.shape[0]\n",
        "\n",
        "        # Embed variables\n",
        "        variable_embedded = self.input_embedding(X_encoded)\n",
        "        # Embed attributes (each row separately)\n",
        "        attr_embedded = []\n",
        "        for i in range(attr.shape[0]):\n",
        "            index_vector = torch.zeros(self.num_variables).to(device)\n",
        "            index_vector[index[i][0]]=1\n",
        "            index_vector[index[i][1]]=1\n",
        "            attr_embedded.append(self.attribute_scoring_network1(self.attr_embedding[i](torch.cat((index_vector,attr[i]),dim=0))))\n",
        "        attr_embedded = torch.cat(attr_embedded, dim=0)\n",
        "        attr_scores = self.attribute_scoring_network(attr_embedded)\n",
        "        attr_embedded = attr_scores.unsqueeze(0).expand(batch_size,-1)\n",
        "        combined_embeddings = torch.cat([variable_embedded, attr_embedded], dim=-1)\n",
        "\n",
        "        # Scoring\n",
        "        e_scores = self.e_scoring_network(combined_embeddings)\n",
        "        return e_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "AIAsE8p6jh6h",
        "outputId": "08d2b456-eb83-4b18-fe33-965da8af0098"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nepochs = 1000\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nconv_model = torch.load(\"/content/drive/MyDrive/conv_trained_adam_final4.pth\").to(device)\\n#conv_model.load_state_dict(conv_dict)\\n# Use Adam optimizer\\noptimizer = optim.Adam(conv_model.parameters(), lr=0.0001)\\n\\nX_train = np.array(X_encoded)\\nloss_fn = nn.BCEWithLogitsLoss()\\n\\n# Data loader for efficient batching\\ntrain_loader = DataLoader(X_train, batch_size=16384, shuffle=True)\\n\\nfor epoch in range(epochs):\\n    start_time = time.time()\\n    conv_model.train()\\n    epoch_loss = 0.0\\n\\n    for batch_idx, data in enumerate(train_loader):\\n        data = data.to(device).float()  # Move data to the correct device\\n\\n        # Forward pass\\n        output = conv_model(data)\\n\\n        # Calculate loss\\n        loss = loss_fn(output, data)\\n\\n        # Backpropagation\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n        epoch_loss += loss.item()  # Accumulate loss\\n\\n    end_time = time.time()\\n    epoch_loss /= len(train_loader)  # Average the loss\\n    print(f\\'Epoch [{epoch+1}/{epochs}] Loss: {epoch_loss} Elapsed time (s): {end_time-start_time:.4f}\\')\\n\\ntorch.save(conv_model.state_dict(), \"conv_trained_adam_dict_final_final.pth\")\\n\\ntorch.save(conv_model, \"conv_trained_adam_final_final.pth\")\\n\\n\\n%cp conv_trained_adam_final_final.pth /content/drive/MyDrive/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import time\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "epochs = 1000\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "conv_model = torch.load(\"/content/drive/MyDrive/conv_trained_adam_final4.pth\").to(device)\n",
        "#conv_model.load_state_dict(conv_dict)\n",
        "# Use Adam optimizer\n",
        "optimizer = optim.Adam(conv_model.parameters(), lr=0.0001)\n",
        "\n",
        "X_train = np.array(X_encoded)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Data loader for efficient batching\n",
        "train_loader = DataLoader(X_train, batch_size=16384, shuffle=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    conv_model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data.to(device).float()  # Move data to the correct device\n",
        "\n",
        "        # Forward pass\n",
        "        output = conv_model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, data)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_loss /= len(train_loader)  # Average the loss\n",
        "    print(f'Epoch [{epoch+1}/{epochs}] Loss: {epoch_loss} Elapsed time (s): {end_time-start_time:.4f}')\n",
        "\n",
        "torch.save(conv_model.state_dict(), \"conv_trained_adam_dict_final_final.pth\")\n",
        "\n",
        "torch.save(conv_model, \"conv_trained_adam_final_final.pth\")\n",
        "\n",
        "\n",
        "%cp conv_trained_adam_final_final.pth /content/drive/MyDrive/\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "torch.save(conv_model, \"conv_trained_adam_final5.pth\")\n",
        "\n",
        "\n",
        "%cp conv_trained_adam_final5.pth /content/drive/MyDrive/\"\"\""
      ],
      "metadata": {
        "id": "0gkfd175bRy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e359c3fb-ab3d-44e3-a1e3-bab0ba6a2f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntorch.save(conv_model, \"conv_trained_adam_final5.pth\")\\n\\n\\n%cp conv_trained_adam_final5.pth /content/drive/MyDrive/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eWDt65p5LLx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95cd6fbd-9dfd-4ae5-9b50-213e51ad0064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
            "       dtype=torch.float64)\n",
            "tensor(9., dtype=torch.float64)\n",
            "tensor(9., dtype=torch.float64)\n",
            "tensor([-1165.3732,  -614.5994, -1261.8596,  -760.1898,   428.0468,  -460.5029,\n",
            "         -484.1636,  -852.8702,  -814.1177, -1358.2882,  -547.5659,  -458.6359,\n",
            "         -133.2256,  -170.8204,  -761.0003,  -463.4032,  -292.8042,  -228.3923,\n",
            "         -320.7100,  -449.0595,   -59.5680,  -127.8159,   -42.7083,  -606.1141,\n",
            "         -376.7446,    67.0745,  -302.0328,  -107.2058,   297.6308,  -343.3212,\n",
            "         -348.9959,  -352.9093,  -333.0502, -1247.1412,  -331.8902,  -653.6896,\n",
            "         -178.3303,    37.0879,  -170.8191,   -67.9560,   -35.0062,  -431.3792,\n",
            "         -294.8819,  -210.9730,  -251.4966,  -227.9102,   -81.8344,  -336.4218,\n",
            "        -1351.3132,   138.6983,  -282.0279,  -176.5279,   -55.7769,  -387.2864,\n",
            "         -192.4333,   -70.9898,   -71.0086,    29.3059,   -87.6931,  -307.4369,\n",
            "         -275.4777,   278.6013,  -438.6676,  -317.4156,  -312.3683,  -198.9904,\n",
            "         -212.3491,  -299.0667,  -343.0481,  -247.5891,  -311.8660,  -155.7726,\n",
            "         -373.3006,  -101.5157,  -187.5577,   -58.6655,  -117.2733,  -811.6144,\n",
            "         -227.7729,  -223.7106,  -733.9777,  -164.9520,  -286.9091,  -334.1215,\n",
            "         -512.0087,  -189.6342,  -134.7620,  -308.6227,  -356.1239,  -150.7441,\n",
            "         -214.0707,  -422.5720,   -73.2191,  -177.5722,  -326.6306,  -189.8697,\n",
            "         -143.2817,  -475.4306,  -392.4907,  -266.0244,  -438.2191,   129.6670,\n",
            "         -436.0568,  -936.7280,  -111.4082,   -65.1944,    62.3391],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor([ -135.5726,  -157.0403,   -87.1771,  -450.3405,  -332.9023,  -258.9109,\n",
            "         -103.1253,    15.4377,  -402.0497,  -717.1616,  -223.5449,   -68.6961,\n",
            "         -775.3272,  -846.6237,  -201.7104,  -289.0146,  -347.4834,  -176.7918,\n",
            "         -229.1771,    50.6518,  -370.6277,   -37.6770,  -403.5481,  -224.7751,\n",
            "          -76.8246,  -504.3908,  -115.9518,   -21.8264,    70.8165,   -85.9431,\n",
            "          -57.3766,  -114.4420,   -83.5162,  -155.8750,  -544.3164,  -861.1803,\n",
            "          -45.9835,  -233.6189,  -249.1123,  -226.8463,  -361.0718,  -730.3761,\n",
            "         -268.5148,    69.0499,  -852.6100,  -733.0972,  -105.0895,  -789.4278,\n",
            "         -623.4542,    48.0544,   -65.5664,   -30.7890,   -39.1479,  -112.7233,\n",
            "         -144.6609,  -431.2344,    76.9639,   -70.4701,  -401.3955,  -462.6600,\n",
            "         -152.4975,   153.2649,  -110.3654,   -65.7424,   -67.3032,   -24.1586,\n",
            "         -312.7100,   -84.8568,  -111.1455,  -203.8098,  -116.0430,   -79.3592,\n",
            "          -52.3468,   -52.6862,   -90.0871,  -106.7816,   -46.8306, -1056.6337,\n",
            "         -113.6123,   -96.3089,  -535.9599,    19.9577,   -22.8585,   -64.6019,\n",
            "         -757.6177,   -27.8495,    -9.2591,   -75.0695,  -255.1770,   -39.9401,\n",
            "         -131.2367,  -342.9303,   -31.6750,   -30.5294,  -206.1109,   -53.4867,\n",
            "          -31.1674,  -112.6679,   -46.0670,   -59.1503,  -149.7654,   -72.6572,\n",
            "          -95.2895,  -948.7593,   -30.8443,   -55.3586,    53.5763],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor(-33686.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(-23010.3066, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "conv_model = torch.load(\"/content/drive/MyDrive/conv_trained_adam_final4.pth\").to(device)\n",
        "print(X_encoded[10:12])\n",
        "print(sum(X_encoded[10]))\n",
        "print(sum(X_encoded[11]))\n",
        "output = conv_model(X_encoded[10:12].to(device).float())\n",
        "print(output[0])\n",
        "print(output[1])\n",
        "print(sum(output[0]))\n",
        "print(sum(output[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepConv should take in the entire input (continuous + categorical) with a complete mapping of statistics (continuous to continuous, categorical to categorical, categorical to continuous) and be pretrained to output either only the categorical or only the continuous.\n",
        "\n",
        "Experiment with fKAN in DeepConv"
      ],
      "metadata": {
        "id": "Ugv7M8RgKlP9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGIG2eEiRQPJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "hidden_layers = [2048,1024,1024,2048]\n",
        "L = len(hidden_layers)\n",
        "\n",
        "\n",
        "\n",
        "import torch.nn.utils as nn_utils\n",
        "import time\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "class GreaterThanFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, a, b):\n",
        "        return (a>b).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      toReturn1= grad_output\n",
        "      toReturn2 = -1 * grad_output\n",
        "      return toReturn1, toReturn2\n",
        "\n",
        "\n",
        "class ClampFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        return torch.clamp(x,0,1)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      return grad_output\n",
        "\n",
        "\n",
        "from torch import autograd, nn\n",
        "\n",
        "def energy(v, *params):\n",
        "  h = params[:L]\n",
        "  weight = params[L:L*2]\n",
        "  bias = params[L*2:]\n",
        "  energy = - torch.sum(v * bias[0].unsqueeze(0), 1)\n",
        "  for i in range(L):\n",
        "      logits = F.linear(v if i==0 else h[i-1], weight[i], bias[i+1])\n",
        "      energy -= torch.sum(h[i] * logits, 1)\n",
        "  return energy\n",
        "\n",
        "\n",
        "class MHStepFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, v, fix_v, rand_v, rand_h, rand_u, *params):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        h = params[:L]\n",
        "        weight = params[L:L*2]\n",
        "        bias = params[L*2:]\n",
        "        fix_v = fix_v==1.0\n",
        "        temp = []\n",
        "        for x in [rand_v,rand_h,rand_u]:\n",
        "          if isinstance(x, torch.Tensor) and x.numel() == 1 and x.item() == 0.0:\n",
        "            temp.append(None)\n",
        "          else:\n",
        "            temp.append(x)\n",
        "        rand_v = temp[0]\n",
        "        rand_h = temp[1]\n",
        "        rand_u = temp[2]\n",
        "        ctxs = []\n",
        "        if fix_v:\n",
        "            v_ = v\n",
        "        else:\n",
        "            if rand_v is None:\n",
        "                v_ = torch.empty_like(v).bernoulli_()\n",
        "            else:\n",
        "                v_ = (rand_v < 0.5).float()\n",
        "\n",
        "        if rand_h is None:\n",
        "            h_ = [torch.empty_like(h[i]).bernoulli_() for i in range(L)]\n",
        "        else:\n",
        "            h_ = [(rand_h[i] < 0.5).float() for i in range(L)]\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "            params.append(tensor)\n",
        "        for parameter in weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in bias:\n",
        "            params.append(parameter)\n",
        "        energy1 = energy(v,*params)\n",
        "        energy1CTX = tuple((v, *params))\n",
        "        ctxs.append(energy1CTX)\n",
        "        params = []\n",
        "        for tensor in h_:\n",
        "            params.append(tensor)\n",
        "        for parameter in weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in bias:\n",
        "            params.append(parameter)\n",
        "        energy2 = energy(v_,*params)\n",
        "        energy2CTX = tuple((v_, *params))\n",
        "        ctxs.append(energy2CTX)\n",
        "        log_ratio = energy1 - energy2\n",
        "        toSave = []\n",
        "        toSave.append(log_ratio)\n",
        "        if rand_u is None:\n",
        "            input1 = torch.clamp(log_ratio.exp().unsqueeze(1),0,1)\n",
        "            random_numbers = torch.rand(input1.shape,device=device).float()\n",
        "            accepted = (input1>=random_numbers)\n",
        "        else:\n",
        "            accepted = (log_ratio.exp().unsqueeze(1)>=rand_u.unsqueeze(1))\n",
        "        if not fix_v:\n",
        "            toSave.append(v_)\n",
        "            toSave.append(v)\n",
        "        for i in range(L):\n",
        "          toSave.append(h_[i])\n",
        "          toSave.append(h[i])\n",
        "\n",
        "        params = []\n",
        "        for parameter in weight:\n",
        "          params.append(parameter)\n",
        "        for parameter in bias:\n",
        "          params.append(parameter)\n",
        "        for sav in toSave:\n",
        "          params.append(sav)\n",
        "        for lis in ctxs:\n",
        "          params.append(torch.tensor(len(lis)))\n",
        "          params.extend(lis)\n",
        "        savLength = torch.tensor(len(toSave))\n",
        "        if not fix_v:\n",
        "            v = torch.where(accepted, v_, v)\n",
        "        h = [torch.where(accepted, h_[i], h[i]) for i in range(L)]\n",
        "        if rand_u is None:\n",
        "          rand_u = torch.tensor(0.0)\n",
        "        fix_v = torch.tensor(float(fix_v))\n",
        "        accepted = accepted.float()\n",
        "        ctx.save_for_backward(accepted, fix_v, rand_u,savLength, *params)\n",
        "        return v, *h\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_v, *grad_h):\n",
        "        grad_v = torch.clamp(grad_v, -10, 10)\n",
        "        for gr_h in grad_h:\n",
        "          gr_h = torch.clamp(gr_h, -10, 10)\n",
        "        accepted, fix_v, rand_u,savLength, *params = ctx.saved_tensors\n",
        "        if len(rand_u.shape)==0 :\n",
        "          rand_u = None\n",
        "        fix_v = fix_v==1.0\n",
        "        accepted = accepted.bool()\n",
        "        weight = params[:L]\n",
        "        bias = params[L:L*2+1]\n",
        "        toSave = params[L*2+1:L*2+1+savLength.item()]\n",
        "        ctxTensors = params[L*2+1+savLength.item():]\n",
        "        ctxTuples = []\n",
        "        i = 0\n",
        "        while i < len(ctxTensors):\n",
        "            tuple_length = ctxTensors[i].item()\n",
        "            start = i + 1  # Start index of tuple elements\n",
        "            end = start + tuple_length\n",
        "            ctxTuples.append(tuple(ctxTensors[start:end]))\n",
        "            i = end\n",
        "        ctx1 = ctxTuples[0]\n",
        "        ctx2 = ctxTuples[1]\n",
        "        grad_h = list(grad_h)\n",
        "        grad_weight = [torch.zeros_like(w) for w in weight]\n",
        "        grad_bias = [torch.zeros_like(b) for b in bias]\n",
        "        toSave = list(toSave)\n",
        "        if not fix_v:\n",
        "          d_accepted = torch.sum((toSave[1]-toSave[2]) * grad_v, dim=1, keepdim=True)\n",
        "          for i in range(len(grad_h)):\n",
        "            d_accepted = d_accepted + torch.sum((toSave[3+i*2]-toSave[4+(i*2)]) * grad_h[i], dim=1, keepdim=True)\n",
        "        else:\n",
        "          d_accepted = torch.sum((toSave[1]-toSave[2]) * grad_h[0], dim=1, keepdim=True)\n",
        "          for i in range(1,len(grad_h)):\n",
        "            d_accepted = d_accepted +torch.sum((toSave[1+i*2]-toSave[2+(i*2)]) * grad_h[i], dim=1, keepdim=True)\n",
        "        log_ratio = toSave[0].detach().requires_grad_()\n",
        "        if rand_u is None:\n",
        "            d_log_ratio_exp = d_accepted\n",
        "        else:\n",
        "            d_log_ratio_exp = d_accepted\n",
        "        log_ratio_exp= log_ratio.exp().unsqueeze(1).detach().requires_grad_()\n",
        "        log_ratio_exp = torch.clamp(log_ratio_exp, -100, 100)\n",
        "        d_log_ratio = d_log_ratio_exp * log_ratio_exp\n",
        "        d_log_ratio = torch.clamp(d_log_ratio, -10, 10)\n",
        "        with torch.enable_grad():\n",
        "            v1 = ctx1[0].detach().requires_grad_()\n",
        "            params1 = ctx1[1:]\n",
        "            params1 = [item.detach().requires_grad_() for item in params1]\n",
        "            input = (v1, *params1)\n",
        "            energy8 = energy(*input)\n",
        "            if d_log_ratio.shape[0]==1:\n",
        "              d_log_ratio= d_log_ratio.squeeze(1)\n",
        "            else:\n",
        "              d_log_ratio=d_log_ratio.squeeze()\n",
        "            v1, *params1 = autograd.grad(energy8, input, d_log_ratio)\n",
        "        params1 = list(params1)\n",
        "        h1 = params1[:L]\n",
        "        weight1 = params1[L:L*2]\n",
        "        bias1 = params1[L*2:]\n",
        "        with torch.enable_grad():\n",
        "            v2 = ctx2[0].detach().requires_grad_()\n",
        "            params2 = ctx2[1:]\n",
        "            params2 = [item.detach().requires_grad_() for item in params2]\n",
        "            input = (v2, *params2)\n",
        "            energy8 = energy(*input)\n",
        "            v2, *params2 = autograd.grad(energy8, input, -1*d_log_ratio)\n",
        "        params2 = list(params2)\n",
        "        weight2 = params2[L:L*2]\n",
        "        bias2 = params2[L*2:]\n",
        "        if not fix_v:\n",
        "            grad_v = torch.where(accepted,0,grad_v)\n",
        "        for i in range(len(grad_h)):\n",
        "            grad_h[i] = torch.where(accepted,0,grad_h[i])\n",
        "        grad_v += v1\n",
        "        for i in range(len(grad_h)):\n",
        "          grad_h[i]+=h1[i]\n",
        "        for i in range(len(grad_weight)):\n",
        "          grad_weight[i] += (weight1[i]-weight2[i])\n",
        "        for i in range(len(grad_bias)):\n",
        "          grad_bias[i] += (bias1[i]-bias2[i])\n",
        "        grads = []\n",
        "        grad_v = torch.clamp(grad_v, -10, 10)\n",
        "        for gr_h in grad_h:\n",
        "          gr_h = torch.clamp(gr_h, -10, 10)\n",
        "        for tensor in grad_h:\n",
        "            grads.append(tensor)\n",
        "        for parameter in grad_weight:\n",
        "          grads.append(parameter)\n",
        "        for parameter in grad_bias:\n",
        "          grads.append(parameter)\n",
        "\n",
        "        return grad_v, None, None, None, None, *grads\n",
        "\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "class GibbsStepFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, v,fix_v, rand_v, rand_h, rand_u, rand_z, T, *params):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        fix_v= fix_v==1.0\n",
        "        params = list(params)\n",
        "        h = params[:L]\n",
        "        weight = params[L:L*2]\n",
        "        bias = params[L*2:]\n",
        "        temp = []\n",
        "        for x in [rand_v,rand_h,rand_u,rand_z]:\n",
        "          if isinstance(x, torch.Tensor) and x.numel() == 1 and x.item() == 0.0:\n",
        "            temp.append(None)\n",
        "          else:\n",
        "            temp.append(x.to(device))\n",
        "        rand_v = temp[0]\n",
        "        rand_h = temp[1]\n",
        "        rand_u = temp[2]\n",
        "        rand_z = temp[3]\n",
        "        if rand_u is None:\n",
        "            rand_u = torch.rand(N, device=device)\n",
        "        even = rand_u < 0.5\n",
        "        odd = even.logical_not()\n",
        "        toSave = []\n",
        "        toSaveID = []\n",
        "        if even.sum() > 0:\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][even],\n",
        "                                  weight[0].t(), bias[0])\n",
        "                toSaveID.append(15)\n",
        "                toSave.append(h[0][even])\n",
        "\n",
        "                if T == 0:\n",
        "                    sample = (logits >= 0).float()\n",
        "                    v = torch.scatter(v, 0, even.nonzero().repeat(1,v.shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(14)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_v is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        v =  torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_v[even]).float()\n",
        "                        v = torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),sample)\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h[i-1][even], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "                    toSaveID.append(12)\n",
        "                    toSave.append(h[i+1][even])\n",
        "\n",
        "                toSaveID.append(13)\n",
        "                toSave.append(h[i-1][even])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(11)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][even]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v[even] if i==0 else h[i-1][even],\n",
        "                                  weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "                    toSaveID.append(9)\n",
        "                    toSave.append(h[i+1][even])\n",
        "\n",
        "                toSaveID.append(10)\n",
        "                toSave.append(v[even] if i==0 else h[i-1][even])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSaveID.append(8)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand(sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][even]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "        if odd.sum() > 0:\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v[odd] if i==0 else h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "                    toSaveID.append(6)\n",
        "                    toSave.append(h[i+1][odd])\n",
        "\n",
        "                toSaveID.append(7)\n",
        "                toSave.append(v[odd] if i==0 else h[i-1][odd])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(5)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][odd]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][odd], weight[0].t(), bias[0])\n",
        "                toSaveID.append(4)\n",
        "                toSave.append(h[0][odd])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0.00).float()\n",
        "                    v = torch.scatter(v, 0, odd.nonzero().repeat(1,v.shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(3)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_v is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_v[odd]).float()\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),sample)\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "                    toSaveID.append(1)\n",
        "                    toSave.append(h[i+1][odd])\n",
        "                toSaveID.append(2)\n",
        "                toSave.append(h[i-1][odd])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSaveID.append(0)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][odd]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "          params.append(tensor)\n",
        "        for parameter in weight:\n",
        "          params.append(parameter)\n",
        "        for parameter in bias:\n",
        "          params.append(parameter)\n",
        "        for sav in toSave:\n",
        "          params.append(sav)\n",
        "        toSaveID = torch.tensor(toSaveID)\n",
        "        ctx.save_for_backward(v,even, odd,torch.tensor(fix_v), rand_v, rand_h, rand_u, rand_z, torch.tensor(T),toSaveID, *params)\n",
        "        return v,  *h\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_v, *grad_h):\n",
        "        grad_v = torch.clamp(grad_v, -10, 10)\n",
        "        for gr_h in grad_h:\n",
        "          gr_h = torch.clamp(gr_h, -10, 10)\n",
        "        v,even, odd,fix_v, rand_v, rand_h, rand_u, rand_z, T, toSaveID, *params = ctx.saved_tensors\n",
        "        params = list(params)\n",
        "        h = params[:L]\n",
        "        weight = params[L:L*2]\n",
        "        bias = params[L*2:L*3+1]\n",
        "        toSave = params[L*3+1:]\n",
        "        grad_v2return = torch.zeros_like(grad_v)\n",
        "        h2return = []\n",
        "        for h5 in grad_h:\n",
        "          h2return.append(torch.zeros_like(h5))\n",
        "        grad_weight = []\n",
        "        grad_bias = []\n",
        "        for i in range(L):\n",
        "            grad_weight.append(torch.zeros_like(weight[i]))\n",
        "        for i in range(L+1):\n",
        "            grad_bias.append(torch.zeros_like(bias[i]))\n",
        "        even_v = v[even]\n",
        "        odd_v = v[odd]\n",
        "        even_h = []\n",
        "        odd_h = []\n",
        "        grad_h = list(grad_h)\n",
        "        for gh in grad_h:\n",
        "          even_h.append(gh[even])\n",
        "        for gh in grad_h:\n",
        "          odd_h.append(gh[odd])\n",
        "        h = list(h)\n",
        "        toSaveID2 = []\n",
        "        for tsID in list(toSaveID):\n",
        "          toSaveID2.append(int(tsID))\n",
        "        toSaveID = toSaveID2\n",
        "\n",
        "\n",
        "        toSave = reversed(toSave)\n",
        "        toSaveID = reversed(toSaveID)\n",
        "        save_queues = defaultdict(deque)\n",
        "        for obj, category_id in zip(toSave, toSaveID):\n",
        "                save_queues[category_id].appendleft(obj)\n",
        "\n",
        "        if odd.sum() > 0:\n",
        "          for i in reversed(range(1, len(h), 2)):\n",
        "            if T==0:\n",
        "              d_logits = odd_h[i]\n",
        "            else:\n",
        "              d_logitsSig =  odd_h[i]\n",
        "              input = save_queues[0].pop().detach().requires_grad_()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1<len(h):\n",
        "              input1 = save_queues[1].pop()\n",
        "              grad_weight[i+1] += (d_logits.t() @ input1).t()\n",
        "              odd_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            grad_weight[i] += d_logits.t() @ save_queues[2].pop()\n",
        "            odd_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "          if not fix_v:\n",
        "            if T==0:\n",
        "              d_logits = odd_v\n",
        "            else:\n",
        "              d_logitsSig =  odd_v\n",
        "              input = save_queues[3].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            grad_weight[0] += (d_logits.t() @ save_queues[4].pop()).t()\n",
        "            odd_h[0] += d_logits @ weight[0].t()\n",
        "            grad_bias[0] += d_logits.sum(0)\n",
        "          for i in reversed(range(0,len(h),2)):\n",
        "            if T==0:\n",
        "              d_logits =  odd_h[i]\n",
        "            else:\n",
        "              d_logitsSig = odd_h[i]\n",
        "              input = save_queues[5].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1 < len(h):\n",
        "              grad_weight[i+1] += (d_logits.t() @ save_queues[6].pop()).t()\n",
        "              odd_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            temp = save_queues[7].pop()\n",
        "            grad_weight[i] += d_logits.t() @ temp\n",
        "            if i==0:\n",
        "              odd_v += d_logits @ weight[i]\n",
        "            else:\n",
        "              odd_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "\n",
        "        if even.sum() > 0:\n",
        "          for i in reversed(range(0, len(h), 2)):\n",
        "            if T==0:\n",
        "              d_logits =  even_h[i]\n",
        "            else:\n",
        "              d_logitsSig =  even_h[i]\n",
        "              input = save_queues[8].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1<len(h):\n",
        "              grad_weight[i+1] += (d_logits.t() @ save_queues[9].pop()).t()\n",
        "              even_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            grad_weight[i] += d_logits.t() @ save_queues[10].pop()\n",
        "            if i==0:\n",
        "              even_v += d_logits @ weight[i]\n",
        "            else:\n",
        "              even_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "          for i in reversed(range(1, len(h), 2)):\n",
        "            if T==0:\n",
        "              d_logits =  even_h[i]\n",
        "            else:\n",
        "              d_logitsSig = even_h[i]\n",
        "              input = save_queues[11].pop()\n",
        "              d_logits =  d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1<len(h):\n",
        "              grad_weight[i+1] += (d_logits.t() @ save_queues[12].pop()).t()\n",
        "              even_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            grad_weight[i] += d_logits.t() @ save_queues[13].pop()\n",
        "            even_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "          if not fix_v:\n",
        "            if T==0:\n",
        "              d_logits = even_v\n",
        "            else:\n",
        "              d_logitsSig = even_v\n",
        "              input = save_queues[14].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            grad_weight[0] += (d_logits.t() @ save_queues[15].pop()).t()\n",
        "            even_h[0] += d_logits @ weight[0].t()\n",
        "            grad_bias[0] += d_logits.sum(0)\n",
        "        grad_v2return[even] = even_v\n",
        "        grad_v2return[odd] = odd_v\n",
        "        grad_h2return = []\n",
        "        for ind, h7 in enumerate(h2return):\n",
        "          h7[even] = even_h[ind]\n",
        "          h7[odd] = odd_h[ind]\n",
        "          grad_h2return.append(h7)\n",
        "        grads = []\n",
        "        for tensor in grad_h2return:\n",
        "            grads.append(tensor)\n",
        "        for parameter in grad_weight:\n",
        "          grads.append(parameter)\n",
        "        for parameter in grad_bias:\n",
        "          grads.append(parameter)\n",
        "        return grad_v2return, None, None, None, None, None, None, *grads\n",
        "\n",
        "\n",
        "class DBM(nn.Module):\n",
        "    def __init__(self, nv, hidden_layers,comparator=False):\n",
        "        super().__init__()\n",
        "        self.input_layer = torch.load(\"/content/drive/MyDrive/conv_trained_adam_final4.pth\")\n",
        "        self.weight = nn.ParameterList([nn.Parameter(torch.Tensor(hidden_layers[0], nv))])\n",
        "        for i in range(len(hidden_layers)-1):\n",
        "          self.weight.append(nn.Parameter(torch.Tensor(hidden_layers[i+1], hidden_layers[i])))\n",
        "        self.bias = nn.ParameterList([nn.Parameter(torch.Tensor(nv))])\n",
        "        for i in range(len(hidden_layers)):\n",
        "          self.bias.append(nn.Parameter(torch.Tensor(hidden_layers[i])))\n",
        "\n",
        "        self.nv = nv\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.L = len(hidden_layers)\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.dummy = torch.tensor(0.0).requires_grad_()\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for w in self.weight:\n",
        "            nn.init.orthogonal_(w)\n",
        "\n",
        "        for b in self.bias:\n",
        "            nn.init.zeros_(b)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #  print(\"x: \",x)\n",
        "        input = ClampFunction.apply(self.input_layer(x))\n",
        "        N = input.size(0)\n",
        "        device = x.device\n",
        "        v = input.clone().detach()\n",
        "        assert self.L != 1\n",
        "        energy_pos_samples = self.positive_phase(N, v)\n",
        "\n",
        "        energy_neg_samples = self.negative_phase(10, N)\n",
        "        pos_energy = torch.mean(torch.stack(energy_pos_samples))\n",
        "       # print(\"energy_pos: \",pos_energy)\n",
        "        neg_energy = torch.mean(torch.stack(energy_neg_samples))\n",
        "       # print(\"energy_neg: \",neg_energy)\n",
        "        energy_loss = pos_energy - neg_energy\n",
        "        output, output_rand = self.reconstruct(input)\n",
        "        return energy_loss, output, output_rand\n",
        "    def positive_phase(self, N, v):\n",
        "      energy_pos_samples = []  # Store energy samples\n",
        "      #print(\"v: \",v)\n",
        "      v2 = v\n",
        "      for _ in range(10):\n",
        "        h = []\n",
        "        for i in range(self.L):\n",
        "          h_i = torch.full((N, self.hidden_layers[i]), 0.5, device=self.device,requires_grad=True)\n",
        "          h_i = self.bernoulli_sample(h_i)\n",
        "          h.append(h_i)\n",
        "        v, h = self.local_search(v2, h, True)\n",
        "        v, h = self.gibbs_step(v, h, True)\n",
        "        energy_pos = self.coupling(v, h, True)\n",
        "        energy_pos_samples.append(energy_pos)\n",
        "      return energy_pos_samples\n",
        "\n",
        "    def negative_phase(self, num_samples, N):\n",
        "      energy_neg_samples = []\n",
        "      for _ in range(num_samples):\n",
        "        v = self.bernoulli_sample(torch.full((N, self.nv), 0.5, device=self.device, requires_grad=True))\n",
        "        h = []\n",
        "        for i in range(self.L):\n",
        "            probs = torch.full((N, self.hidden_layers[i]), 0.5, device=self.device, requires_grad=True)\n",
        "            h_i = self.bernoulli_sample(probs)\n",
        "            h.append(h_i)\n",
        "        v, h = self.local_search(v, h)\n",
        "        v, h = self.gibbs_step(v, h)\n",
        "        energy_neg = self.coupling(v, h)\n",
        "        energy_neg_samples.append(energy_neg)\n",
        "      return energy_neg_samples\n",
        "\n",
        "\n",
        "    def local_search(self, v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device= v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        rand_u = torch.rand(N, device=device)\n",
        "        v, h = self.gibbs_step(v, h, fix_v, rand_u=rand_u, T=0)\n",
        "        converged = torch.ones(N, dtype=torch.bool, device=device) if fix_v \\\n",
        "                    else torch.all(v == _v, 1)\n",
        "        for i in range(self.L):\n",
        "            converged = converged.logical_and(torch.all(h[i] == _h[i], 1))\n",
        "        count = 0\n",
        "        while not converged.all():\n",
        "            count+=1\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(self.L)]\n",
        "            M = _v.size(0)\n",
        "            v_, h_ = self.gibbs_step(_v, _h, fix_v,\n",
        "                                     rand_u=rand_u[not_converged], T=0)\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = torch.all(v_ == _v, 1)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(self.L):\n",
        "                converged_ = converged_.logical_and(torch.all(h_[i] == _h[i], 1))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "        return v, h\n",
        "\n",
        "    def coupling(self, v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        v, h = self.mh_step(v, h, fix_v)\n",
        "        energy = self.energy(v, h)\n",
        "        if fix_v:\n",
        "          converged = torch.ones(N, dtype=torch.bool, device=device)\n",
        "        else:\n",
        "          converged = torch.all(v == _v, 1)\n",
        "        for i in range(self.L):\n",
        "            converged = converged.logical_and(torch.all(h[i] == _h[i], 1))\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(self.L)]\n",
        "            M = _v.size(0)\n",
        "            rand_v = None if fix_v else torch.rand_like(_v)\n",
        "            rand_h = [torch.rand_like(_h[i]) for i in range(self.L)]\n",
        "            rand_u = torch.rand(M, device=device)\n",
        "            v_, h_ = self.mh_step(_v, _h, fix_v, rand_v, rand_h, rand_u)\n",
        "            aaa = self.energy(v_, h_)\n",
        "            bbb = self.energy(_v, _h)\n",
        "            energy[not_converged] = energy[not_converged] + (aaa - bbb)\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = torch.all(v_ == _v, 1)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(self.L):\n",
        "                converged_ = converged_.logical_and(torch.all(h_[i] == _h[i], 1))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "        return energy\n",
        "\n",
        "    def energy(self, v, h):\n",
        "        energy = - torch.sum(v * self.bias[0].unsqueeze(0), 1)\n",
        "        for i in range(self.L):\n",
        "            logits = F.linear(v if i==0 else h[i-1], self.weight[i], self.bias[i+1])\n",
        "\n",
        "            energy = energy - torch.sum(h[i] * logits, 1)\n",
        "        return energy\n",
        "\n",
        "    def bernoulli_sample(self,probabilities):\n",
        "      random_numbers = torch.rand(probabilities.shape,device=self.device)\n",
        "      return GreaterThanFunction.apply(probabilities, random_numbers)\n",
        "\n",
        "    def gibbs_step(self, v, h, fix_v=False, rand_v=None, rand_h=None, rand_u=None, rand_z=None, T=1):\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "            params.append(tensor)\n",
        "        for parameter in self.weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in self.bias:\n",
        "            params.append(parameter)\n",
        "        if rand_v is None:\n",
        "          rand_v = self.dummy\n",
        "        if rand_h is None:\n",
        "          rand_h = self.dummy\n",
        "        if rand_u is None:\n",
        "          rand_u = self.dummy\n",
        "        if rand_z is None:\n",
        "          rand_z = self.dummy\n",
        "        v, *h = GibbsStepFunction.apply(v, torch.tensor(float(fix_v)).requires_grad_(), rand_v,rand_h, rand_u, rand_z, torch.tensor(float(T)).requires_grad_(), *params)\n",
        "        return v,h\n",
        "\n",
        "\n",
        "    def mh_step(self, v, h, fix_v=False, rand_v=None, rand_h=None, rand_u=None):\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "            params.append(tensor)\n",
        "        for parameter in self.weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in self.bias:\n",
        "            params.append(parameter)\n",
        "        if rand_v is None:\n",
        "          rand_v = self.dummy\n",
        "        if rand_h is None:\n",
        "          rand_h = self.dummy\n",
        "        if rand_u is None:\n",
        "          rand_u = self.dummy\n",
        "        v, *h = MHStepFunction.apply( v,torch.tensor(float(fix_v)).requires_grad_(),rand_v,rand_h,rand_u,*params)\n",
        "        return v, h\n",
        "\n",
        "    def reconstruct(self, v):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "\n",
        "        h = [torch.empty(N, layer, device=device).bernoulli_() for layer in self.hidden_layers]\n",
        "\n",
        "        v, h = self.local_search(v, h, True)\n",
        "        v_mode, h_mode = self.gibbs_step(v, h, T=0)\n",
        "        v_rand, h_rand = self.gibbs_step(v, h)\n",
        "\n",
        "        return v_mode, v_rand\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWIPeO8AmfQZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5310914-d7c0-462a-b2ef-139a0432eae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-055bfeb1c595>:415: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  ctx.save_for_backward(v,even, odd,torch.tensor(fix_v), rand_v, rand_h, rand_u, rand_z, torch.tensor(T),toSaveID, *params)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "50\n",
            "Epoch 0 Energy Loss: 7.3147 Val loss: 29.4108 Val_rand loss 44.5150 Time: 942.9753\n",
            "25\n",
            "50\n",
            "Epoch 1 Energy Loss: 3.3694 Val loss: 28.0266 Val_rand loss 41.6090 Time: 623.4683\n",
            "25\n",
            "50\n",
            "Epoch 2 Energy Loss: 2.6700 Val loss: 20.4150 Val_rand loss 39.5960 Time: 548.4250\n",
            "25\n",
            "50\n",
            "Epoch 3 Energy Loss: 0.2914 Val loss: 14.4771 Val_rand loss 37.6361 Time: 502.9883\n",
            "25\n",
            "50\n",
            "Epoch 4 Energy Loss: -1.2714 Val loss: 11.4888 Val_rand loss 36.2250 Time: 501.8473\n",
            "25\n",
            "50\n",
            "Epoch 5 Energy Loss: -1.8113 Val loss: 9.8028 Val_rand loss 34.5845 Time: 485.1153\n",
            "25\n",
            "50\n",
            "Epoch 6 Energy Loss: -2.8414 Val loss: 8.9661 Val_rand loss 33.1920 Time: 461.9998\n",
            "25\n",
            "50\n",
            "Epoch 7 Energy Loss: -3.8799 Val loss: 7.8383 Val_rand loss 31.6855 Time: 465.9787\n",
            "25\n",
            "50\n",
            "Epoch 8 Energy Loss: -4.8161 Val loss: 8.1705 Val_rand loss 30.1213 Time: 459.3096\n",
            "25\n",
            "50\n",
            "Epoch 9 Energy Loss: -5.5855 Val loss: 8.3688 Val_rand loss 28.9251 Time: 453.2808\n",
            "25\n",
            "50\n",
            "Epoch 10 Energy Loss: -6.2613 Val loss: 8.1438 Val_rand loss 27.7594 Time: 454.7557\n",
            "25\n",
            "50\n",
            "Epoch 11 Energy Loss: -6.5484 Val loss: 7.9416 Val_rand loss 26.0037 Time: 466.6297\n",
            "25\n",
            "50\n",
            "Epoch 12 Energy Loss: -5.8544 Val loss: 8.2584 Val_rand loss 24.0006 Time: 452.2800\n",
            "25\n",
            "50\n",
            "Epoch 13 Energy Loss: -5.2532 Val loss: 8.3739 Val_rand loss 22.7147 Time: 453.6503\n",
            "25\n",
            "50\n",
            "Epoch 14 Energy Loss: -4.3815 Val loss: 8.4088 Val_rand loss 21.1789 Time: 445.6958\n",
            "25\n",
            "50\n",
            "Epoch 15 Energy Loss: -3.1624 Val loss: 8.4111 Val_rand loss 19.5845 Time: 445.8026\n",
            "25\n",
            "50\n",
            "Epoch 16 Energy Loss: -0.8621 Val loss: 8.4100 Val_rand loss 17.6143 Time: 447.1696\n",
            "25\n",
            "50\n",
            "Epoch 17 Energy Loss: 2.6848 Val loss: 8.4112 Val_rand loss 15.6529 Time: 450.1429\n",
            "25\n",
            "50\n",
            "Epoch 18 Energy Loss: 6.8071 Val loss: 8.4112 Val_rand loss 13.5566 Time: 450.3138\n",
            "25\n",
            "50\n",
            "Epoch 19 Energy Loss: 10.8531 Val loss: 8.4112 Val_rand loss 12.0750 Time: 448.8610\n",
            "25\n",
            "50\n",
            "Epoch 20 Energy Loss: 14.2681 Val loss: 8.4111 Val_rand loss 10.8270 Time: 451.1650\n",
            "25\n",
            "50\n",
            "Epoch 21 Energy Loss: 17.5071 Val loss: 8.4112 Val_rand loss 10.0335 Time: 443.2741\n",
            "25\n",
            "50\n",
            "Epoch 22 Energy Loss: 20.6159 Val loss: 8.4112 Val_rand loss 9.6421 Time: 450.3964\n",
            "25\n",
            "50\n",
            "Epoch 23 Energy Loss: 23.3659 Val loss: 8.4112 Val_rand loss 9.3169 Time: 456.8769\n",
            "25\n",
            "50\n",
            "Epoch 24 Energy Loss: 24.4287 Val loss: 8.4112 Val_rand loss 9.0181 Time: 457.5139\n",
            "25\n",
            "50\n",
            "Epoch 25 Energy Loss: 26.1315 Val loss: 8.4112 Val_rand loss 8.6919 Time: 457.2352\n",
            "25\n",
            "50\n",
            "Epoch 26 Energy Loss: 28.8797 Val loss: 8.4112 Val_rand loss 8.3020 Time: 447.8728\n",
            "25\n",
            "50\n",
            "Epoch 27 Energy Loss: 31.7810 Val loss: 8.4112 Val_rand loss 8.0540 Time: 455.8544\n",
            "25\n",
            "50\n",
            "Epoch 28 Energy Loss: 35.3957 Val loss: 8.4112 Val_rand loss 7.9699 Time: 455.1788\n",
            "25\n",
            "50\n",
            "Epoch 29 Energy Loss: 38.1544 Val loss: 8.4112 Val_rand loss 7.8849 Time: 462.0242\n",
            "25\n",
            "50\n",
            "Epoch 30 Energy Loss: 39.4474 Val loss: 8.4103 Val_rand loss 7.7464 Time: 453.2185\n",
            "25\n",
            "50\n",
            "Epoch 31 Energy Loss: 42.0008 Val loss: 8.3826 Val_rand loss 7.6635 Time: 451.7782\n",
            "25\n",
            "50\n",
            "Epoch 32 Energy Loss: 43.6076 Val loss: 7.9661 Val_rand loss 7.5664 Time: 450.5949\n",
            "25\n",
            "50\n",
            "Epoch 33 Energy Loss: 44.8372 Val loss: 7.8553 Val_rand loss 7.4069 Time: 451.0970\n",
            "25\n",
            "50\n",
            "Epoch 34 Energy Loss: 45.9195 Val loss: 8.3146 Val_rand loss 7.4031 Time: 469.2804\n",
            "25\n",
            "50\n",
            "Epoch 35 Energy Loss: 43.6816 Val loss: 7.6822 Val_rand loss 7.3427 Time: 476.9846\n",
            "25\n",
            "50\n",
            "Epoch 36 Energy Loss: 41.1448 Val loss: 7.6368 Val_rand loss 7.2731 Time: 475.6155\n",
            "25\n",
            "50\n",
            "Epoch 37 Energy Loss: 36.8675 Val loss: 7.5556 Val_rand loss 7.3014 Time: 499.9078\n",
            "25\n",
            "50\n",
            "Epoch 38 Energy Loss: 31.7787 Val loss: 7.0970 Val_rand loss 7.3885 Time: 510.0820\n",
            "25\n",
            "50\n",
            "Epoch 39 Energy Loss: 26.4825 Val loss: 6.9983 Val_rand loss 7.5109 Time: 504.4521\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-84ebe4a3a2d4>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#final_dict = torch.load(\"dbn_final_dict2.pth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#dbn_model.load_state_dict(final_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtrain_dbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-84ebe4a3a2d4>\u001b[0m in \u001b[0;36mtrain_dbn\u001b[0;34m(X_train, dbn_model, num_epochs, learning_rate, device, batch_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0menergy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m#print(\"output: \",output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mval1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-055bfeb1c595>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m       \u001b[0;31m#  print(\"x: \",x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClampFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7776b02c28fd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_encoded)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mindex_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mindex_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mattr_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_scoring_network1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mattr_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mattr_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_scoring_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7776b02c28fd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, cond)\u001b[0m\n\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def train_dbn(X_train, dbn_model, num_epochs, learning_rate, device, batch_size=700):\n",
        "    dbn_model.to(device)\n",
        "    dbn_model.train()\n",
        "    optimizer = Adam(dbn_model.parameters(), lr=learning_rate)  # Adam optimizer\n",
        "\n",
        "    # Create a TensorDataset and DataLoader\n",
        "    X_train = np.array(X_train)\n",
        "    # Data loader for efficient batching\n",
        "    train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
        "    criterion = nn.BCELoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        energy_loss = 0.0\n",
        "        total_val = 0.0\n",
        "        total_val_rand = 0.0\n",
        "        i=0\n",
        "        for data in train_loader:  # Iterate over batches\n",
        "            i+=1\n",
        "            if i%25==0:\n",
        "              print(i)\n",
        "            # Forward pass\n",
        "            data = data.float().to(device)\n",
        "            energy, output, rand_output = dbn_model(data)\n",
        "            #print(\"output: \",output)\n",
        "            val1 = criterion(output, data)\n",
        "            valRand = criterion(rand_output,data)\n",
        "            #loss = energy + val1\n",
        "            loss = energy\n",
        "            energy_loss += energy.item()\n",
        "            total_val+=val1.item()\n",
        "            total_val_rand+=valRand.item()\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        end_time = time.time()\n",
        "        energy_loss /= len(train_loader)\n",
        "        total_val /= len(train_loader)\n",
        "        total_val_rand /= len(train_loader)\n",
        "        print(f\"Epoch {epoch} Energy Loss: {energy_loss:.4f} Val loss: {total_val:.4f} Val_rand loss {total_val_rand:.4f} Time: {end_time-start_time:.4f}\")\n",
        "\n",
        "\n",
        "dbn_model = DBM(num_features, hidden_layers).to(device)\n",
        "#dbn_model = torch.load('dbm_model2.pth')\n",
        "#final_dict = torch.load(\"dbn_final_dict2.pth\")\n",
        "#dbn_model.load_state_dict(final_dict)\n",
        "train_dbn(X_encoded, dbn_model, 1000, 0.00001, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(dbn_model,'dbm_model_final.pth')\n",
        "%cp dbm_model_final.pth /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "Lim_DpXuWQOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}