{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_1FGcBJtfwDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9af792-1351-48fb-ab90-0f357398d0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Categorical:  ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n",
            "Continuous:  ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "X = pd.read_csv(\"censusData.csv\")\n",
        "drive.mount('/content/drive')\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country','income']\n",
        "print(\"Categorical: \",categorical_columns)\n",
        "continuous_columns = [col for col in X.columns if col not in categorical_columns]\n",
        "print(\"Continuous: \",continuous_columns)\n",
        "# Precompute an encoder to handle later conversions efficiently\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "X_encoded_cat = encoder.fit_transform(X[categorical_columns])\n",
        "scaler = StandardScaler()\n",
        "X_continuous = scaler.fit_transform(X[continuous_columns].values)\n",
        "X_encoded = torch.cat((torch.tensor(X_encoded_cat),torch.tensor(X_continuous)),dim=1)\n",
        "dataset = list(X_encoded)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RadialBasisFunction(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        grid_min: float = -1.5,\n",
        "        grid_max: float = 1.5,\n",
        "        num_grids: int = 8,\n",
        "        denominator: float = None,  # larger denominators lead to smoother basis\n",
        "    ):\n",
        "        super().__init__()\n",
        "        grid = torch.linspace(grid_min, grid_max, num_grids)\n",
        "        self.grid = torch.nn.Parameter(grid, requires_grad=False)\n",
        "        self.denominator = denominator or (grid_max - grid_min) / (num_grids - 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.exp(-((x[..., None] - self.grid) / self.denominator) ** 2)\n",
        "\n",
        "\n",
        "class BSRBF_KANLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        output_dim: int,\n",
        "        grid_size = 5,\n",
        "        spline_order = 3,\n",
        "        base_activation = torch.nn.SiLU,\n",
        "        grid_range=[-1.5, 1.5],\n",
        "\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.layernorm = nn.LayerNorm(input_dim)\n",
        "        self.spline_order = spline_order\n",
        "        self.grid_size = grid_size\n",
        "        self.output_dim = output_dim\n",
        "        self.base_activation = base_activation()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(self.output_dim, self.input_dim))\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5))\n",
        "\n",
        "        self.spline_weight = torch.nn.Parameter(torch.Tensor(self.output_dim, self.input_dim*(grid_size+spline_order)))\n",
        "        torch.nn.init.kaiming_uniform_(self.spline_weight, a=math.sqrt(5))\n",
        "\n",
        "        self.rbf = RadialBasisFunction(grid_range[0], grid_range[1], grid_size+spline_order)\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size # 0.45, 0.5\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(self.input_dim, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "        #self.linear = nn.Linear(self.input_dim*(grid_size+spline_order), self.output_dim)\n",
        "\n",
        "        #self.drop = nn.Dropout(p=0.01) # dropout\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.input_dim\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (input_dim, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            #print('-- k: ', k)\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.input_dim,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # layer normalization\n",
        "        device = x.device\n",
        "\n",
        "        x = self.layernorm(x)\n",
        "        #x = self.drop(x)\n",
        "\n",
        "        # base\n",
        "        #bias = torch.randn(self.output_dim)\n",
        "        #base_output = F.linear(self.base_activation(x), self.base_weight, bias)\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "\n",
        "        # b_splines\n",
        "        bs_output = self.b_splines(x).view(x.size(0), -1)\n",
        "\n",
        "        # rbf\n",
        "        rbf_output = self.rbf(x).view(x.size(0), -1)\n",
        "        #rbf_output = self.rbf(x)\n",
        "        #rbf_output = torch.reshape(rbf_output, (rbf_output.shape[0], -1))\n",
        "\n",
        "        # combine\n",
        "        bsrbf_output = bs_output + rbf_output\n",
        "        bsrbf_output = F.linear(bsrbf_output, self.spline_weight)\n",
        "\n",
        "        return base_output + bsrbf_output\n",
        "\n",
        "class BSRBF_KAN(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "    ):\n",
        "        super(BSRBF_KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        #self.drop = torch.nn.Dropout(p=0.1) # dropout\n",
        "\n",
        "        for input_dim, output_dim in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                BSRBF_KANLayer(\n",
        "                    input_dim,\n",
        "                    output_dim,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    base_activation=base_activation,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        #x = self.drop(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "OPXETRV3bnOp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aJWvNSnBlXWp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Bernoulli\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "attr = torch.load('census_attr_final.pt').to(device)\n",
        "index = torch.load('census_index_final.pt').to(device).int()\n",
        "\n",
        "class DeepLinear(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.layers = BSRBF_KAN([input_dim, hidden_dim,hidden_dim,hidden_dim,output_dim], spline_order = 6,grid_size = 12).to(device)\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x.to(device))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class DeepConv(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.num_cat_variables = 107\n",
        "        self.num_cont_variables = 5\n",
        "        self.num_variables = self.num_cat_variables + self.num_cont_variables\n",
        "        self.e_features = attr.shape[1]\n",
        "        self.input_embedding = DeepLinear(self.num_variables,hidden_dim, hidden_dim)\n",
        "        self.attr_embedding = nn.ModuleList([nn.Linear(self.num_variables+self.e_features, hidden_dim) for _ in range(attr.shape[0])])\n",
        "        self.e_scoring_network = DeepLinear(hidden_dim * 2, hidden_dim, self.num_variables)\n",
        "        self.attribute_feature_extract = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.attribute_scoring_network = DeepLinear(attr.shape[0]*16,hidden_dim,hidden_dim)\n",
        "\n",
        "    def forward(self, X_encoded):\n",
        "        # X_encoded is of shape\n",
        "        batch_size = X_encoded.shape[0]\n",
        "\n",
        "        # Embed variables\n",
        "        variable_embedded = self.input_embedding(X_encoded)\n",
        "        # Embed attributes (each row separately)\n",
        "        index_matrix = torch.zeros(attr.shape[0], self.num_variables).to(device)\n",
        "        for i in range(attr.shape[0]):\n",
        "            index_matrix[i, index[i][0]] = 1\n",
        "            index_matrix[i, index[i][1]] = 1\n",
        "        attr_input = torch.cat((index_matrix, attr), dim=1)\n",
        "        attr_embedded = torch.stack([self.attr_embedding[i](attr_input[i]) for i in range(attr.shape[0])])\n",
        "        attr_features = self.attribute_feature_extract(attr_embedded)\n",
        "        attr_features = torch.flatten(attr_features).unsqueeze(0)\n",
        "        attr_scores = self.attribute_scoring_network(attr_features)\n",
        "        attr_scores = attr_scores.expand(batch_size,-1)\n",
        "        combined_embeddings = torch.cat([variable_embedded, attr_scores], dim=-1)\n",
        "\n",
        "        # Scoring\n",
        "        scores = self.e_scoring_network(combined_embeddings)\n",
        "        cat_scores = scores[:, :self.num_cat_variables]\n",
        "        cont_scores = scores[:, self.num_cat_variables:]\n",
        "        return cat_scores,cont_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import time\n",
        "import numpy as np\n",
        "epochs = 2000\n",
        "#conv_model = DeepConv(128).to(device)\n",
        "conv_model = torch.load('/content/drive/MyDrive/conv_KANV5.pth').to(device)\n",
        "#conv_model.load_state_dict(conv_dict)\n",
        "# Use Adam optimizer\n",
        "optimizer = optim.AdamW(conv_model.parameters(), lr=0.00001)\n",
        "\n",
        "cat_loss = nn.BCEWithLogitsLoss()\n",
        "cont_loss = nn.MSELoss()\n",
        "# Data loader for efficient batching\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    conv_model.train()\n",
        "    epoch_cat_loss = 0.0\n",
        "    epoch_cont_loss = 0.0\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data.to(device).float()  # Move data to the correct device\n",
        "        # Forward pass\n",
        "        cat,cont = conv_model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss1 = cat_loss(cat, data[:,:conv_model.num_cat_variables])\n",
        "        epoch_cat_loss+=loss1.item()\n",
        "        loss2 = cont_loss(cont, data[:,conv_model.num_cat_variables:])\n",
        "        epoch_cont_loss+=loss2.item()\n",
        "        loss = loss1 + loss2\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_cat_loss /= len(train_loader)\n",
        "    epoch_cont_loss /= len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{epochs}] Cat Loss: {epoch_cat_loss} Cont loss: {epoch_cont_loss} Elapsed time (s): {end_time-start_time:.4f}')\n",
        "\n",
        "torch.save(conv_model.state_dict(), \"final_conv_dict.pth\")\n",
        "\n",
        "torch.save(conv_model, \"final_conv.pth\")\n",
        "\n",
        "\n",
        "%cp 'final_conv.pth' /content/drive/MyDrive/\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "F6GVCsg3HZhQ",
        "outputId": "8bf5445e-510b-4175-8707-a2219c683493"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import torch.optim as optim\\nfrom torch.utils.data import DataLoader\\nimport torch\\nfrom torch import nn\\nimport time\\nimport numpy as np\\nepochs = 2000\\n#conv_model = DeepConv(128).to(device)\\nconv_model = torch.load(\\'/content/drive/MyDrive/conv_KANV5.pth\\').to(device)\\n#conv_model.load_state_dict(conv_dict)\\n# Use Adam optimizer\\noptimizer = optim.AdamW(conv_model.parameters(), lr=0.00001)\\n\\ncat_loss = nn.BCEWithLogitsLoss()\\ncont_loss = nn.MSELoss()\\n# Data loader for efficient batching\\ntrain_loader = DataLoader(dataset, batch_size=128, shuffle=True)\\n\\nfor epoch in range(epochs):\\n    start_time = time.time()\\n    conv_model.train()\\n    epoch_cat_loss = 0.0\\n    epoch_cont_loss = 0.0\\n    for batch_idx, data in enumerate(train_loader):\\n        data = data.to(device).float()  # Move data to the correct device\\n        # Forward pass\\n        cat,cont = conv_model(data)\\n\\n        # Calculate loss\\n        loss1 = cat_loss(cat, data[:,:conv_model.num_cat_variables])\\n        epoch_cat_loss+=loss1.item()\\n        loss2 = cont_loss(cont, data[:,conv_model.num_cat_variables:])\\n        epoch_cont_loss+=loss2.item()\\n        loss = loss1 + loss2\\n        # Backpropagation\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n    end_time = time.time()\\n    epoch_cat_loss /= len(train_loader)\\n    epoch_cont_loss /= len(train_loader)\\n    print(f\\'Epoch [{epoch+1}/{epochs}] Cat Loss: {epoch_cat_loss} Cont loss: {epoch_cont_loss} Elapsed time (s): {end_time-start_time:.4f}\\')\\n\\ntorch.save(conv_model.state_dict(), \"final_conv_dict.pth\")\\n\\ntorch.save(conv_model, \"final_conv.pth\")\\n\\n\\n%cp \\'final_conv.pth\\' /content/drive/MyDrive/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"torch.save(conv_model, \"final_conv.pth\")\n",
        "\n",
        "\n",
        "%cp final_conv.pth /content/drive/MyDrive/\"\"\""
      ],
      "metadata": {
        "id": "0gkfd175bRy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64ba09a4-5894-425b-b723-836a31f72523"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.save(conv_model, \"final_conv.pth\")\\n\\n\\n%cp final_conv.pth /content/drive/MyDrive/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pGIG2eEiRQPJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "hidden_layers = [1024,512,512,1024]\n",
        "L = len(hidden_layers)\n",
        "\n",
        "\n",
        "\n",
        "import torch.nn.utils as nn_utils\n",
        "import time\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "class GreaterThanFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, a, b):\n",
        "        return (a>b).float()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      toReturn1= grad_output\n",
        "      toReturn2 = -1 * grad_output\n",
        "      return toReturn1, toReturn2\n",
        "\n",
        "\n",
        "class ClampFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        return torch.clamp(x,0,1)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "      return grad_output\n",
        "\n",
        "\n",
        "from torch import autograd, nn\n",
        "\n",
        "def energy(v, *params):\n",
        "  h = params[:L]\n",
        "  weight = params[L:L*2]\n",
        "  bias = params[L*2:]\n",
        "  energy = - torch.sum(v * bias[0].unsqueeze(0), 1)\n",
        "  for i in range(L):\n",
        "      logits = F.linear(v if i==0 else h[i-1], weight[i], bias[i+1])\n",
        "      energy -= torch.sum(h[i] * logits, 1)\n",
        "  return energy\n",
        "\n",
        "\n",
        "class MHStepFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, v, fix_v, rand_v, rand_h, rand_u, *params):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        h = params[:L]\n",
        "        weight = params[L:L*2]\n",
        "        bias = params[L*2:]\n",
        "        fix_v = fix_v==1.0\n",
        "        temp = []\n",
        "        for x in [rand_v,rand_h,rand_u]:\n",
        "          if isinstance(x, torch.Tensor) and x.numel() == 1 and x.item() == 0.0:\n",
        "            temp.append(None)\n",
        "          else:\n",
        "            temp.append(x)\n",
        "        rand_v = temp[0]\n",
        "        rand_h = temp[1]\n",
        "        rand_u = temp[2]\n",
        "        ctxs = []\n",
        "        if fix_v:\n",
        "            v_ = v\n",
        "        else:\n",
        "            if rand_v is None:\n",
        "                v_ = torch.empty_like(v).bernoulli_()\n",
        "            else:\n",
        "                v_ = (rand_v < 0.5).float()\n",
        "\n",
        "        if rand_h is None:\n",
        "            h_ = [torch.empty_like(h[i]).bernoulli_() for i in range(L)]\n",
        "        else:\n",
        "            h_ = [(rand_h[i] < 0.5).float() for i in range(L)]\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "            params.append(tensor)\n",
        "        for parameter in weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in bias:\n",
        "            params.append(parameter)\n",
        "        energy1 = energy(v,*params)\n",
        "        energy1CTX = tuple((v, *params))\n",
        "        ctxs.append(energy1CTX)\n",
        "        params = []\n",
        "        for tensor in h_:\n",
        "            params.append(tensor)\n",
        "        for parameter in weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in bias:\n",
        "            params.append(parameter)\n",
        "        energy2 = energy(v_,*params)\n",
        "        energy2CTX = tuple((v_, *params))\n",
        "        ctxs.append(energy2CTX)\n",
        "        log_ratio = energy1 - energy2\n",
        "        toSave = []\n",
        "        toSave.append(log_ratio)\n",
        "        if rand_u is None:\n",
        "            input1 = torch.clamp(log_ratio.exp().unsqueeze(1),0,1)\n",
        "            random_numbers = torch.rand(input1.shape,device=device).float()\n",
        "            accepted = (input1>=random_numbers)\n",
        "        else:\n",
        "            accepted = (log_ratio.exp().unsqueeze(1)>=rand_u.unsqueeze(1))\n",
        "        if not fix_v:\n",
        "            toSave.append(v_)\n",
        "            toSave.append(v)\n",
        "        for i in range(L):\n",
        "          toSave.append(h_[i])\n",
        "          toSave.append(h[i])\n",
        "\n",
        "        params = []\n",
        "        for parameter in weight:\n",
        "          params.append(parameter)\n",
        "        for parameter in bias:\n",
        "          params.append(parameter)\n",
        "        for sav in toSave:\n",
        "          params.append(sav)\n",
        "        for lis in ctxs:\n",
        "          params.append(torch.tensor(len(lis)))\n",
        "          params.extend(lis)\n",
        "        savLength = torch.tensor(len(toSave))\n",
        "        if not fix_v:\n",
        "            v = torch.where(accepted, v_, v)\n",
        "        h = [torch.where(accepted, h_[i], h[i]) for i in range(L)]\n",
        "        if rand_u is None:\n",
        "          rand_u = torch.tensor(0.0)\n",
        "        fix_v = torch.tensor(float(fix_v))\n",
        "        accepted = accepted.float()\n",
        "        ctx.save_for_backward(accepted, fix_v, rand_u,savLength, *params)\n",
        "        return v, *h\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_v, *grad_h):\n",
        "        grad_v = torch.clamp(grad_v, -10, 10)\n",
        "        for gr_h in grad_h:\n",
        "          gr_h = torch.clamp(gr_h, -10, 10)\n",
        "        accepted, fix_v, rand_u,savLength, *params = ctx.saved_tensors\n",
        "        if len(rand_u.shape)==0 :\n",
        "          rand_u = None\n",
        "        fix_v = fix_v==1.0\n",
        "        accepted = accepted.bool()\n",
        "        weight = params[:L]\n",
        "        bias = params[L:L*2+1]\n",
        "        toSave = params[L*2+1:L*2+1+savLength.item()]\n",
        "        ctxTensors = params[L*2+1+savLength.item():]\n",
        "        ctxTuples = []\n",
        "        i = 0\n",
        "        while i < len(ctxTensors):\n",
        "            tuple_length = ctxTensors[i].item()\n",
        "            start = i + 1  # Start index of tuple elements\n",
        "            end = start + tuple_length\n",
        "            ctxTuples.append(tuple(ctxTensors[start:end]))\n",
        "            i = end\n",
        "        ctx1 = ctxTuples[0]\n",
        "        ctx2 = ctxTuples[1]\n",
        "        grad_h = list(grad_h)\n",
        "        grad_weight = [torch.zeros_like(w) for w in weight]\n",
        "        grad_bias = [torch.zeros_like(b) for b in bias]\n",
        "        toSave = list(toSave)\n",
        "        if not fix_v:\n",
        "          d_accepted = torch.sum((toSave[1]-toSave[2]) * grad_v, dim=1, keepdim=True)\n",
        "          for i in range(len(grad_h)):\n",
        "            d_accepted = d_accepted + torch.sum((toSave[3+i*2]-toSave[4+(i*2)]) * grad_h[i], dim=1, keepdim=True)\n",
        "        else:\n",
        "          d_accepted = torch.sum((toSave[1]-toSave[2]) * grad_h[0], dim=1, keepdim=True)\n",
        "          for i in range(1,len(grad_h)):\n",
        "            d_accepted = d_accepted +torch.sum((toSave[1+i*2]-toSave[2+(i*2)]) * grad_h[i], dim=1, keepdim=True)\n",
        "        log_ratio = toSave[0].detach().requires_grad_()\n",
        "        if rand_u is None:\n",
        "            d_log_ratio_exp = d_accepted\n",
        "        else:\n",
        "            d_log_ratio_exp = d_accepted\n",
        "        log_ratio_exp= log_ratio.exp().unsqueeze(1).detach().requires_grad_()\n",
        "        log_ratio_exp = torch.clamp(log_ratio_exp, -100, 100)\n",
        "        d_log_ratio = d_log_ratio_exp * log_ratio_exp\n",
        "        d_log_ratio = torch.clamp(d_log_ratio, -10, 10)\n",
        "        with torch.enable_grad():\n",
        "            v1 = ctx1[0].detach().requires_grad_()\n",
        "            params1 = ctx1[1:]\n",
        "            params1 = [item.detach().requires_grad_() for item in params1]\n",
        "            input = (v1, *params1)\n",
        "            energy8 = energy(*input)\n",
        "            if d_log_ratio.shape[0]==1:\n",
        "              d_log_ratio= d_log_ratio.squeeze(1)\n",
        "            else:\n",
        "              d_log_ratio=d_log_ratio.squeeze()\n",
        "            v1, *params1 = autograd.grad(energy8, input, d_log_ratio)\n",
        "        params1 = list(params1)\n",
        "        h1 = params1[:L]\n",
        "        weight1 = params1[L:L*2]\n",
        "        bias1 = params1[L*2:]\n",
        "        with torch.enable_grad():\n",
        "            v2 = ctx2[0].detach().requires_grad_()\n",
        "            params2 = ctx2[1:]\n",
        "            params2 = [item.detach().requires_grad_() for item in params2]\n",
        "            input = (v2, *params2)\n",
        "            energy8 = energy(*input)\n",
        "            v2, *params2 = autograd.grad(energy8, input, -1*d_log_ratio)\n",
        "        params2 = list(params2)\n",
        "        weight2 = params2[L:L*2]\n",
        "        bias2 = params2[L*2:]\n",
        "        if not fix_v:\n",
        "            grad_v = torch.where(accepted,0,grad_v)\n",
        "        for i in range(len(grad_h)):\n",
        "            grad_h[i] = torch.where(accepted,0,grad_h[i])\n",
        "        grad_v += v1\n",
        "        for i in range(len(grad_h)):\n",
        "          grad_h[i]+=h1[i]\n",
        "        for i in range(len(grad_weight)):\n",
        "          grad_weight[i] += (weight1[i]-weight2[i])\n",
        "        for i in range(len(grad_bias)):\n",
        "          grad_bias[i] += (bias1[i]-bias2[i])\n",
        "        grads = []\n",
        "        grad_v = torch.clamp(grad_v, -10, 10)\n",
        "        for gr_h in grad_h:\n",
        "          gr_h = torch.clamp(gr_h, -10, 10)\n",
        "        for tensor in grad_h:\n",
        "            grads.append(tensor)\n",
        "        for parameter in grad_weight:\n",
        "          grads.append(parameter)\n",
        "        for parameter in grad_bias:\n",
        "          grads.append(parameter)\n",
        "\n",
        "        return grad_v, None, None, None, None, *grads\n",
        "\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "class GibbsStepFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, v,fix_v, rand_v, rand_h, rand_u, rand_z, T, *params):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        fix_v= fix_v==1.0\n",
        "        params = list(params)\n",
        "        h = params[:L]\n",
        "        weight = params[L:L*2]\n",
        "        bias = params[L*2:]\n",
        "        temp = []\n",
        "        for x in [rand_v,rand_h,rand_u,rand_z]:\n",
        "          if isinstance(x, torch.Tensor) and x.numel() == 1 and x.item() == 0.0:\n",
        "            temp.append(None)\n",
        "          else:\n",
        "            temp.append(x.to(device))\n",
        "        rand_v = temp[0]\n",
        "        rand_h = temp[1]\n",
        "        rand_u = temp[2]\n",
        "        rand_z = temp[3]\n",
        "        if rand_u is None:\n",
        "            rand_u = torch.rand(N, device=device)\n",
        "        even = rand_u < 0.5\n",
        "        odd = even.logical_not()\n",
        "        toSave = []\n",
        "        toSaveID = []\n",
        "        if even.sum() > 0:\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][even],\n",
        "                                  weight[0].t(), bias[0])\n",
        "                toSaveID.append(15)\n",
        "                toSave.append(h[0][even])\n",
        "\n",
        "                if T == 0:\n",
        "                    sample = (logits >= 0).float()\n",
        "                    v = torch.scatter(v, 0, even.nonzero().repeat(1,v.shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(14)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_v is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        v =  torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_v[even]).float()\n",
        "                        v = torch.scatter(v,0,even.nonzero().repeat(1,v.shape[1]),sample)\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h[i-1][even], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "                    toSaveID.append(12)\n",
        "                    toSave.append(h[i+1][even])\n",
        "\n",
        "                toSaveID.append(13)\n",
        "                toSave.append(h[i-1][even])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(11)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][even]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v[even] if i==0 else h[i-1][even],\n",
        "                                  weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][even], weight[i+1].t(), None)\n",
        "                    toSaveID.append(9)\n",
        "                    toSave.append(h[i+1][even])\n",
        "\n",
        "                toSaveID.append(10)\n",
        "                toSave.append(v[even] if i==0 else h[i-1][even])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSaveID.append(8)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand(sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][even]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, even.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "        if odd.sum() > 0:\n",
        "            for i in range(0, len(h), 2):\n",
        "                logits = F.linear(v[odd] if i==0 else h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "                    toSaveID.append(6)\n",
        "                    toSave.append(h[i+1][odd])\n",
        "\n",
        "                toSaveID.append(7)\n",
        "                toSave.append(v[odd] if i==0 else h[i-1][odd])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(5)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][odd]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "\n",
        "            if not fix_v:\n",
        "                logits = F.linear(h[0][odd], weight[0].t(), bias[0])\n",
        "                toSaveID.append(4)\n",
        "                toSave.append(h[0][odd])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0.00).float()\n",
        "                    v = torch.scatter(v, 0, odd.nonzero().repeat(1,v.shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    toSaveID.append(3)\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_v is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_v[odd]).float()\n",
        "                        v = torch.scatter(v,0,odd.nonzero().repeat(1,v.shape[1]),sample)\n",
        "\n",
        "            for i in range(1, len(h), 2):\n",
        "                logits = F.linear(h[i-1][odd], weight[i], bias[i+1])\n",
        "                if i+1 < len(h):\n",
        "                    logits = logits + F.linear(h[i+1][odd], weight[i+1].t(), None)\n",
        "                    toSaveID.append(1)\n",
        "                    toSave.append(h[i+1][odd])\n",
        "                toSaveID.append(2)\n",
        "                toSave.append(h[i-1][odd])\n",
        "                if T == 0:\n",
        "                    sample = (logits>=0).float()\n",
        "                    h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                else:\n",
        "                    logits = logits / T\n",
        "                    sigLogits = torch.sigmoid(logits)\n",
        "                    toSaveID.append(0)\n",
        "                    toSave.append(logits)\n",
        "                    if rand_h is None:\n",
        "                        random_numbers = torch.rand( sigLogits.shape,device=device).float()\n",
        "                        sample = (sigLogits>=random_numbers).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "                    else:\n",
        "                        sample = (sigLogits>=rand_h[i][odd]).float()\n",
        "                        h[i] = torch.scatter(h[i], 0, odd.nonzero().repeat(1,h[i].shape[1]), sample)\n",
        "\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "          params.append(tensor)\n",
        "        for parameter in weight:\n",
        "          params.append(parameter)\n",
        "        for parameter in bias:\n",
        "          params.append(parameter)\n",
        "        for sav in toSave:\n",
        "          params.append(sav)\n",
        "        toSaveID = torch.tensor(toSaveID)\n",
        "        ctx.save_for_backward(v,even, odd,torch.tensor(fix_v), rand_v, rand_h, rand_u, rand_z, torch.tensor(T),toSaveID, *params)\n",
        "        return v,  *h\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_v, *grad_h):\n",
        "        grad_v = torch.clamp(grad_v, -10, 10)\n",
        "        for gr_h in grad_h:\n",
        "          gr_h = torch.clamp(gr_h, -10, 10)\n",
        "        v,even, odd,fix_v, rand_v, rand_h, rand_u, rand_z, T, toSaveID, *params = ctx.saved_tensors\n",
        "        params = list(params)\n",
        "        h = params[:L]\n",
        "        weight = params[L:L*2]\n",
        "        bias = params[L*2:L*3+1]\n",
        "        toSave = params[L*3+1:]\n",
        "        grad_v2return = torch.zeros_like(grad_v)\n",
        "        h2return = []\n",
        "        for h5 in grad_h:\n",
        "          h2return.append(torch.zeros_like(h5))\n",
        "        grad_weight = []\n",
        "        grad_bias = []\n",
        "        for i in range(L):\n",
        "            grad_weight.append(torch.zeros_like(weight[i]))\n",
        "        for i in range(L+1):\n",
        "            grad_bias.append(torch.zeros_like(bias[i]))\n",
        "        even_v = v[even]\n",
        "        odd_v = v[odd]\n",
        "        even_h = []\n",
        "        odd_h = []\n",
        "        grad_h = list(grad_h)\n",
        "        for gh in grad_h:\n",
        "          even_h.append(gh[even])\n",
        "        for gh in grad_h:\n",
        "          odd_h.append(gh[odd])\n",
        "        h = list(h)\n",
        "        toSaveID2 = []\n",
        "        for tsID in list(toSaveID):\n",
        "          toSaveID2.append(int(tsID))\n",
        "        toSaveID = toSaveID2\n",
        "\n",
        "\n",
        "        toSave = reversed(toSave)\n",
        "        toSaveID = reversed(toSaveID)\n",
        "        save_queues = defaultdict(deque)\n",
        "        for obj, category_id in zip(toSave, toSaveID):\n",
        "                save_queues[category_id].appendleft(obj)\n",
        "\n",
        "        if odd.sum() > 0:\n",
        "          for i in reversed(range(1, len(h), 2)):\n",
        "            if T==0:\n",
        "              d_logits = odd_h[i]\n",
        "            else:\n",
        "              d_logitsSig =  odd_h[i]\n",
        "              input = save_queues[0].pop().detach().requires_grad_()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1<len(h):\n",
        "              input1 = save_queues[1].pop()\n",
        "              grad_weight[i+1] += (d_logits.t() @ input1).t()\n",
        "              odd_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            grad_weight[i] += d_logits.t() @ save_queues[2].pop()\n",
        "            odd_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "          if not fix_v:\n",
        "            if T==0:\n",
        "              d_logits = odd_v\n",
        "            else:\n",
        "              d_logitsSig =  odd_v\n",
        "              input = save_queues[3].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            grad_weight[0] += (d_logits.t() @ save_queues[4].pop()).t()\n",
        "            odd_h[0] += d_logits @ weight[0].t()\n",
        "            grad_bias[0] += d_logits.sum(0)\n",
        "          for i in reversed(range(0,len(h),2)):\n",
        "            if T==0:\n",
        "              d_logits =  odd_h[i]\n",
        "            else:\n",
        "              d_logitsSig = odd_h[i]\n",
        "              input = save_queues[5].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1 < len(h):\n",
        "              grad_weight[i+1] += (d_logits.t() @ save_queues[6].pop()).t()\n",
        "              odd_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            temp = save_queues[7].pop()\n",
        "            grad_weight[i] += d_logits.t() @ temp\n",
        "            if i==0:\n",
        "              odd_v += d_logits @ weight[i]\n",
        "            else:\n",
        "              odd_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "\n",
        "        if even.sum() > 0:\n",
        "          for i in reversed(range(0, len(h), 2)):\n",
        "            if T==0:\n",
        "              d_logits =  even_h[i]\n",
        "            else:\n",
        "              d_logitsSig =  even_h[i]\n",
        "              input = save_queues[8].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1<len(h):\n",
        "              grad_weight[i+1] += (d_logits.t() @ save_queues[9].pop()).t()\n",
        "              even_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            grad_weight[i] += d_logits.t() @ save_queues[10].pop()\n",
        "            if i==0:\n",
        "              even_v += d_logits @ weight[i]\n",
        "            else:\n",
        "              even_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "          for i in reversed(range(1, len(h), 2)):\n",
        "            if T==0:\n",
        "              d_logits =  even_h[i]\n",
        "            else:\n",
        "              d_logitsSig = even_h[i]\n",
        "              input = save_queues[11].pop()\n",
        "              d_logits =  d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            if i+1<len(h):\n",
        "              grad_weight[i+1] += (d_logits.t() @ save_queues[12].pop()).t()\n",
        "              even_h[i+1] += d_logits @ weight[i+1].t()\n",
        "            grad_weight[i] += d_logits.t() @ save_queues[13].pop()\n",
        "            even_h[i-1] += d_logits @ weight[i]\n",
        "            grad_bias[i+1] += d_logits.sum(0)\n",
        "          if not fix_v:\n",
        "            if T==0:\n",
        "              d_logits = even_v\n",
        "            else:\n",
        "              d_logitsSig = even_v\n",
        "              input = save_queues[14].pop()\n",
        "              d_logits = d_logitsSig * torch.sigmoid(input)*(1-torch.sigmoid(input))\n",
        "              d_logits = d_logits/T\n",
        "            d_logits = torch.clamp(d_logits, -10, 10)\n",
        "            grad_weight[0] += (d_logits.t() @ save_queues[15].pop()).t()\n",
        "            even_h[0] += d_logits @ weight[0].t()\n",
        "            grad_bias[0] += d_logits.sum(0)\n",
        "        grad_v2return[even] = even_v\n",
        "        grad_v2return[odd] = odd_v\n",
        "        grad_h2return = []\n",
        "        for ind, h7 in enumerate(h2return):\n",
        "          h7[even] = even_h[ind]\n",
        "          h7[odd] = odd_h[ind]\n",
        "          grad_h2return.append(h7)\n",
        "        grads = []\n",
        "        for tensor in grad_h2return:\n",
        "            grads.append(tensor)\n",
        "        for parameter in grad_weight:\n",
        "          grads.append(parameter)\n",
        "        for parameter in grad_bias:\n",
        "          grads.append(parameter)\n",
        "        return grad_v2return, None, None, None, None, None, None, *grads\n",
        "\n",
        "\n",
        "class DBM(nn.Module):\n",
        "    def __init__(self, nv, hidden_layers):\n",
        "        super().__init__()\n",
        "        self.weight = nn.ParameterList([nn.Parameter(torch.Tensor(hidden_layers[0], nv))])\n",
        "        for i in range(len(hidden_layers)-1):\n",
        "          self.weight.append(nn.Parameter(torch.Tensor(hidden_layers[i+1], hidden_layers[i])))\n",
        "        self.bias = nn.ParameterList([nn.Parameter(torch.Tensor(nv))])\n",
        "        for i in range(len(hidden_layers)):\n",
        "          self.bias.append(nn.Parameter(torch.Tensor(hidden_layers[i])))\n",
        "\n",
        "        self.nv = nv\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.L = len(hidden_layers)\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.dummy = torch.tensor(0.0).requires_grad_()\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for w in self.weight:\n",
        "            nn.init.orthogonal_(w)\n",
        "\n",
        "        for b in self.bias:\n",
        "            nn.init.zeros_(b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = ClampFunction.apply(x)\n",
        "        N = input.size(0)\n",
        "        device = x.device\n",
        "        v = input.clone().detach()\n",
        "        assert self.L != 1\n",
        "        energy_pos_samples = self.positive_phase(N, v)\n",
        "\n",
        "        energy_neg_samples = self.negative_phase(10, N)\n",
        "        pos_energy = torch.mean(torch.stack(energy_pos_samples))\n",
        "       # print(\"energy_pos: \",pos_energy)\n",
        "        neg_energy = torch.mean(torch.stack(energy_neg_samples))\n",
        "       # print(\"energy_neg: \",neg_energy)\n",
        "        energy_loss = pos_energy - neg_energy\n",
        "        output, output_rand = self.reconstruct(input)\n",
        "        return energy_loss, output, output_rand\n",
        "    def positive_phase(self, N, v):\n",
        "      energy_pos_samples = []  # Store energy samples\n",
        "      #print(\"v: \",v)\n",
        "      v2 = v\n",
        "      for _ in range(10):\n",
        "        h = []\n",
        "        for i in range(self.L):\n",
        "          h_i = torch.full((N, self.hidden_layers[i]), 0.5, device=self.device,requires_grad=True)\n",
        "          h_i = self.bernoulli_sample(h_i)\n",
        "          h.append(h_i)\n",
        "        v, h = self.local_search(v2, h, True)\n",
        "        v, h = self.gibbs_step(v, h, True)\n",
        "        energy_pos = self.coupling(v, h, True)\n",
        "        energy_pos_samples.append(energy_pos)\n",
        "      return energy_pos_samples\n",
        "\n",
        "    def negative_phase(self, num_samples, N):\n",
        "      energy_neg_samples = []\n",
        "      for _ in range(num_samples):\n",
        "        v = self.bernoulli_sample(torch.full((N, self.nv), 0.5, device=self.device, requires_grad=True))\n",
        "        h = []\n",
        "        for i in range(self.L):\n",
        "            probs = torch.full((N, self.hidden_layers[i]), 0.5, device=self.device, requires_grad=True)\n",
        "            h_i = self.bernoulli_sample(probs)\n",
        "            h.append(h_i)\n",
        "        v, h = self.local_search(v, h)\n",
        "        v, h = self.gibbs_step(v, h)\n",
        "        energy_neg = self.coupling(v, h)\n",
        "        energy_neg_samples.append(energy_neg)\n",
        "      return energy_neg_samples\n",
        "\n",
        "\n",
        "    def local_search(self, v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device= v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        rand_u = torch.rand(N, device=device)\n",
        "        v, h = self.gibbs_step(v, h, fix_v, rand_u=rand_u, T=0)\n",
        "        converged = torch.ones(N, dtype=torch.bool, device=device) if fix_v \\\n",
        "                    else torch.all(v == _v, 1)\n",
        "        for i in range(self.L):\n",
        "            converged = converged.logical_and(torch.all(h[i] == _h[i], 1))\n",
        "        count = 0\n",
        "        while not converged.all():\n",
        "            count+=1\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(self.L)]\n",
        "            M = _v.size(0)\n",
        "            v_, h_ = self.gibbs_step(_v, _h, fix_v,\n",
        "                                     rand_u=rand_u[not_converged], T=0)\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = torch.all(v_ == _v, 1)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(self.L):\n",
        "                converged_ = converged_.logical_and(torch.all(h_[i] == _h[i], 1))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "        return v, h\n",
        "\n",
        "    def coupling(self, v, h, fix_v=False):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "        _v = v.clone()\n",
        "        _h = []\n",
        "        for r in h:\n",
        "          _h.append(r.clone())\n",
        "        v, h = self.mh_step(v, h, fix_v)\n",
        "        energy = self.energy(v, h)\n",
        "        if fix_v:\n",
        "          converged = torch.ones(N, dtype=torch.bool, device=device)\n",
        "        else:\n",
        "          converged = torch.all(v == _v, 1)\n",
        "        for i in range(self.L):\n",
        "            converged = converged.logical_and(torch.all(h[i] == _h[i], 1))\n",
        "        while not converged.all():\n",
        "            not_converged = converged.logical_not()\n",
        "            _v = v[not_converged]\n",
        "            _h = [h[i][not_converged] for i in range(self.L)]\n",
        "            M = _v.size(0)\n",
        "            rand_v = None if fix_v else torch.rand_like(_v)\n",
        "            rand_h = [torch.rand_like(_h[i]) for i in range(self.L)]\n",
        "            rand_u = torch.rand(M, device=device)\n",
        "            v_, h_ = self.mh_step(_v, _h, fix_v, rand_v, rand_h, rand_u)\n",
        "            aaa = self.energy(v_, h_)\n",
        "            bbb = self.energy(_v, _h)\n",
        "            energy[not_converged] = energy[not_converged] + (aaa - bbb)\n",
        "            if fix_v:\n",
        "                converged_ = torch.ones(M, dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                converged_ = torch.all(v_ == _v, 1)\n",
        "                v = torch.scatter(v,0,not_converged.nonzero().repeat(1,v.shape[1]), v_)\n",
        "            for i in range(self.L):\n",
        "                converged_ = converged_.logical_and(torch.all(h_[i] == _h[i], 1))\n",
        "                h[i] = torch.scatter(h[i], 0, not_converged.nonzero().repeat(1,h_[i].shape[1]), h_[i])\n",
        "            converged[not_converged] = converged_\n",
        "        return energy\n",
        "\n",
        "    def energy(self, v, h):\n",
        "        energy = - torch.sum(v * self.bias[0].unsqueeze(0), 1)\n",
        "        for i in range(self.L):\n",
        "            logits = F.linear(v if i==0 else h[i-1], self.weight[i], self.bias[i+1])\n",
        "\n",
        "            energy = energy - torch.sum(h[i] * logits, 1)\n",
        "        return energy\n",
        "\n",
        "    def bernoulli_sample(self,probabilities):\n",
        "      random_numbers = torch.rand(probabilities.shape,device=self.device)\n",
        "      return GreaterThanFunction.apply(probabilities, random_numbers)\n",
        "\n",
        "    def gibbs_step(self, v, h, fix_v=False, rand_v=None, rand_h=None, rand_u=None, rand_z=None, T=1):\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "            params.append(tensor)\n",
        "        for parameter in self.weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in self.bias:\n",
        "            params.append(parameter)\n",
        "        if rand_v is None:\n",
        "          rand_v = self.dummy\n",
        "        if rand_h is None:\n",
        "          rand_h = self.dummy\n",
        "        if rand_u is None:\n",
        "          rand_u = self.dummy\n",
        "        if rand_z is None:\n",
        "          rand_z = self.dummy\n",
        "        v, *h = GibbsStepFunction.apply(v, torch.tensor(float(fix_v)).requires_grad_(), rand_v,rand_h, rand_u, rand_z, torch.tensor(float(T)).requires_grad_(), *params)\n",
        "        return v,h\n",
        "\n",
        "\n",
        "    def mh_step(self, v, h, fix_v=False, rand_v=None, rand_h=None, rand_u=None):\n",
        "        params = []\n",
        "        for tensor in h:\n",
        "            params.append(tensor)\n",
        "        for parameter in self.weight:\n",
        "            params.append(parameter)\n",
        "        for parameter in self.bias:\n",
        "            params.append(parameter)\n",
        "        if rand_v is None:\n",
        "          rand_v = self.dummy\n",
        "        if rand_h is None:\n",
        "          rand_h = self.dummy\n",
        "        if rand_u is None:\n",
        "          rand_u = self.dummy\n",
        "        v, *h = MHStepFunction.apply( v,torch.tensor(float(fix_v)).requires_grad_(),rand_v,rand_h,rand_u,*params)\n",
        "        return v, h\n",
        "\n",
        "    def reconstruct(self, v):\n",
        "        N = v.size(0)\n",
        "        device = v.device\n",
        "\n",
        "        h = [torch.empty(N, layer, device=device).bernoulli_() for layer in self.hidden_layers]\n",
        "\n",
        "        v, h = self.local_search(v, h, True)\n",
        "        v_mode, h_mode = self.gibbs_step(v, h, T=0)\n",
        "        v_rand, h_rand = self.gibbs_step(v, h)\n",
        "\n",
        "        return v_mode, v_rand\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, latent_size,only_z=False):\n",
        "        super().__init__()\n",
        "        self.layers = BSRBF_KAN([input_size,hidden_size,hidden_size,hidden_size,latent_size],spline_order=8, grid_size = 16)\n",
        "        self.linear_mu = nn.Linear(latent_size, latent_size)\n",
        "        self.linear_logvar = nn.Linear(latent_size, latent_size)\n",
        "        self.relu = nn.GELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        out = self.relu(out)\n",
        "        mu = self.linear_mu(out)\n",
        "        logvar = self.linear_logvar(out)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = eps.mul(std).add_(mu)\n",
        "        return z, mu, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.layers = BSRBF_KAN([latent_size,hidden_size,hidden_size,output_size],spline_order=4)\n",
        "    def forward(self, z):\n",
        "        out = self.layers(z)\n",
        "        return out\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, latent_size, cat=False):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(input_size, hidden_size, latent_size).to(device)\n",
        "    self.decoder = Decoder(latent_size, hidden_size, input_size).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z, mu, logvar = self.encoder(x)\n",
        "    recon = self.decoder(z)\n",
        "    return recon, mu, logvar\n",
        "\n",
        "\n",
        "class VAEDBM(nn.Module):\n",
        "  def __init__(self, num_cat, num_cont, DBM_Layers, hidden_size, latent_size):\n",
        "    super().__init__()\n",
        "    self.num_cat = num_cat\n",
        "    self.input_layer = torch.load(\"/content/drive/MyDrive/final_conv.pth\")\n",
        "    self.DBM_model = DBM(num_cat, DBM_Layers)\n",
        "    self.VAE_model = VAE(num_cont, hidden_size, latent_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    cat_var, cont_var = self.input_layer(x)\n",
        "    energy_loss, recon_cat, recon_cat_rand = self.DBM_model(cat_var)\n",
        "    recon_cont, mu, logvar = self.VAE_model(cont_var)\n",
        "    recon = torch.cat((recon_cat,recon_cont),dim=1)\n",
        "    recon_rand = torch.cat((recon_cat_rand,recon_cont),dim=1)\n",
        "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    vae_recon_loss = nn.MSELoss()(recon_cont, x[:,self.num_cat:])\n",
        "    return energy_loss, vae_recon_loss, kl_div, recon, recon_rand\n",
        ""
      ],
      "metadata": {
        "id": "tTjVemq7ThMU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def train_VAEDBM(dataset, model, num_epochs, learning_rate, batch_size=512):\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Data loader for efficient batching\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        total_energy_loss = 0.0\n",
        "        total_vae_rc_loss = 0.0\n",
        "        total_kl_loss = 0.0\n",
        "        total_val_cat = 0.0\n",
        "        total_val_cat_rand = 0.0\n",
        "        i=0\n",
        "        for data in train_loader:  # Iterate over batches\n",
        "            i+=1\n",
        "            if i%50==0:\n",
        "              print(i)\n",
        "            # Forward pass\n",
        "            data = data.float().to(device)\n",
        "            energy_loss, vae_recon_loss, kl_div, recon, recon_rand = model(data)\n",
        "            total_energy_loss+=energy_loss.item()\n",
        "            total_vae_rc_loss+=vae_recon_loss.item()\n",
        "            total_kl_loss+=kl_div.item()\n",
        "            total_val_cat += nn.BCELoss()(recon[:,:model.num_cat],data[:,:model.num_cat])\n",
        "            total_val_cat_rand += nn.BCELoss()(recon_rand[:,:model.num_cat],data[:,:model.num_cat])\n",
        "            # Loss\n",
        "            loss = energy_loss + vae_recon_loss + kl_div\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_energy_loss /= len(train_loader)\n",
        "        total_vae_rc_loss /= len(train_loader)\n",
        "        total_kl_loss /= len(train_loader)\n",
        "        total_val_cat /= len(train_loader)\n",
        "        total_val_cat_rand /= len(train_loader)\n",
        "        print(f\"Epoch {epoch} Energy Loss: {total_energy_loss:.4f} VAE rc loss: {total_vae_rc_loss:.4f} KL Loss: {total_kl_loss:.4f} val_cat {total_val_cat:.4f} Val_cat_rand loss {total_val_cat_rand:.4f} Time: {end_time-start_time:.4f}\")\n",
        "\n",
        "\n",
        "final_model = VAEDBM(107, 5, hidden_layers,32, 2).to(device)\n",
        "\n",
        "\n",
        "train_VAEDBM(dataset, final_model, 1000, 0.0001)"
      ],
      "metadata": {
        "id": "5JyUngbZz2D5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f724abc-5b38-4a0a-c72d-b35be9462298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-51e8adfc7fbc>:415: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  ctx.save_for_backward(v,even, odd,torch.tensor(fix_v), rand_v, rand_h, rand_u, rand_z, torch.tensor(T),toSaveID, *params)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "Epoch 0 Energy Loss: -1.1326 VAE rc loss: 1.0106 KL Loss: 37.1613 val_cat 17.2685 Val_cat_rand loss 37.6181 Time: 401.5354\n",
            "50\n",
            "Epoch 1 Energy Loss: -2.7256 VAE rc loss: 1.0019 KL Loss: 31.7112 val_cat 8.2594 Val_cat_rand loss 22.9693 Time: 293.4923\n",
            "50\n",
            "Epoch 2 Energy Loss: 10.0536 VAE rc loss: 1.0031 KL Loss: 28.4669 val_cat 8.1102 Val_cat_rand loss 11.3668 Time: 300.1847\n",
            "50\n",
            "Epoch 3 Energy Loss: 10.8184 VAE rc loss: 1.0013 KL Loss: 25.7512 val_cat 7.4272 Val_cat_rand loss 9.2784 Time: 313.2462\n",
            "50\n",
            "Epoch 4 Energy Loss: 2.5428 VAE rc loss: 1.0005 KL Loss: 23.3514 val_cat 7.1396 Val_cat_rand loss 10.0054 Time: 335.9848\n",
            "50\n",
            "Epoch 5 Energy Loss: -2.9194 VAE rc loss: 1.0000 KL Loss: 21.1468 val_cat 7.4457 Val_cat_rand loss 11.2349 Time: 341.1471\n",
            "50\n",
            "Epoch 6 Energy Loss: -8.5241 VAE rc loss: 1.0000 KL Loss: 19.0506 val_cat 7.5351 Val_cat_rand loss 13.2699 Time: 321.1276\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For generating fresh sample, the VAEDBM can at best generate 2 disconnected samples (cat and cont).\n",
        "\n",
        "A converter that takes in the categorical input and outputs its equivalent point in the VAE latent space. Trained from taking each row in the data, the categorical variables are the input, and the target value is the continuous variables after being fed through the trained encoder. Use KAN for non-linear relationship. Then to generate a sample, generate the categorical sample, then feed it through the converter, and then decode the output."
      ],
      "metadata": {
        "id": "xMD9zbgMzVv1"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}