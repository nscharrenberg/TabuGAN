{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:35:37.957027Z",
     "start_time": "2024-06-22T15:35:37.183324Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np , pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import einops\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'val_split': 20,\n 'test_split': 10,\n 'epochs': 2,\n 'n_embed': 1024,\n 'n_heads': 32,\n 'transformer_blocks': 2,\n 'batch_size': 32,\n 'random_seed': 123}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the settings file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('settings.ini')\n",
    "\n",
    "config= {key: int(value) for key, value in config['INCOME_DATASET'].items()}\n",
    "config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:35:38.539342Z",
     "start_time": "2024-06-22T15:35:38.530854Z"
    }
   },
   "id": "be414d9f50ccde34"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded variable : dict_keys(['col_code', 'df', 'tokenizer'])\n"
     ]
    }
   ],
   "source": [
    "# load the encoded variables\n",
    "file_path = 'encoded_vars/token_vars_income.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_variable = pickle.load(file)\n",
    "\n",
    "print(\"Loaded variable :\",loaded_variable.keys())\n",
    "df = loaded_variable[\"df\"]\n",
    "col_code = loaded_variable[\"col_code\"]\n",
    "tokenizer = loaded_variable[\"tokenizer\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:35:39.099034Z",
     "start_time": "2024-06-22T15:35:39.003672Z"
    }
   },
   "id": "3a784ccbf10feee9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    0,     1,     2,  ..., 21930, 21938, 21944],\n        [    0,     1,     3,  ..., 21930, 21938, 21944],\n        [    0,     1,     2,  ..., 21931, 21939, 21944],\n        ...,\n        [    0,     1,     3,  ..., 21930, 21938, 21944],\n        [    0,     1,     3,  ..., 21930, 21938, 21944],\n        [    0,     1,     3,  ..., 21930, 21938, 21944]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = torch.load(\"encoded_vars/encoded_docs_income.pt\")\n",
    "documents # 0 is blank 1 is start and 21944 is end"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:35:39.652368Z",
     "start_time": "2024-06-22T15:35:39.642078Z"
    }
   },
   "id": "c94de55c4ccfb3d3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(22793, 6512, 3256)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_test_split\n",
    "train_ratio = (100 - config[\"val_split\"] - config[\"test_split\"])/100\n",
    "val_ratio = config[\"val_split\"]/100\n",
    "test_ratio = config[\"test_split\"]/100\n",
    "splits = [train_ratio,val_ratio,test_ratio]\n",
    "\n",
    "gen = torch.Generator().manual_seed(config[\"random_seed\"])\n",
    "train_set , val_set , test_set = torch.utils.data.random_split(documents,splits,generator=gen)\n",
    "len(train_set),len(val_set),len(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:35:40.603522Z",
     "start_time": "2024-06-22T15:35:40.594842Z"
    }
   },
   "id": "4f35f33c00cc286d"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "(34, tensor(21945))"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are global variables ... dont delete cell\n",
    "context_wind , vocab_len  = train_set[0].shape[0], train_set[0][-1]\n",
    "context_wind = context_wind - 2 # you shouldnt need the blank token and start token to predict the end token\n",
    "vocab_len = vocab_len + 1\n",
    "context_wind, vocab_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:55:16.758908Z",
     "start_time": "2024-06-22T16:55:16.747879Z"
    }
   },
   "id": "383751c3fb453fc0"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AutoRegDataset(Dataset):\n",
    "    def __init__(self, train_set, context_window):\n",
    "        self.train_set = train_set\n",
    "        self.context_window = context_window\n",
    "        self.X, self.y = self.compile_dataset()\n",
    "\n",
    "    def compile_dataset(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        for row in self.train_set:\n",
    "            row_tensor = torch.tensor(row[1:], dtype=torch.long)\n",
    "            context = torch.zeros(self.context_window, dtype=torch.long)\n",
    "\n",
    "            for value in row_tensor:\n",
    "                X.append(context.clone().unsqueeze(0))\n",
    "                y.append(torch.tensor([value]))\n",
    "                context = torch.cat((context[1:], torch.tensor([value])))\n",
    "\n",
    "        X = torch.cat(X, dim=0)\n",
    "        y = torch.cat(y, dim=0)\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:55:30.003376Z",
     "start_time": "2024-06-22T16:55:29.995955Z"
    }
   },
   "id": "682d20e95b319a4"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f0/_f_gy0t91jqchv14f0hcl_gh0000gn/T/ipykernel_53317/3066447850.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  row_tensor = torch.tensor(row[1:], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Targets: tensor([1])\n",
      "Inputs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "Targets: tensor([3])\n",
      "Inputs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 1, 3]])\n",
      "Targets: tensor([12])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  3, 12]])\n",
      "Targets: tensor([30])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  3, 12, 30]])\n",
      "Targets: tensor([39])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  3, 12, 30, 39]])\n",
      "Targets: tensor([51])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  3, 12, 30, 39, 51]])\n",
      "Targets: tensor([56])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  3, 12, 30, 39, 51, 56]])\n",
      "Targets: tensor([60])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  1,  3, 12, 30, 39, 51, 56, 60]])\n",
      "Targets: tensor([62])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  1,  3, 12, 30, 39, 51, 56, 60, 62]])\n",
      "Targets: tensor([104])\n",
      "Inputs: tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,  12,  30,\n",
      "          39,  51,  56,  60,  62, 104]])\n",
      "Targets: tensor([21016])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     1,     3,    12,    30,    39,    51,    56,\n",
      "            60,    62,   104, 21016]])\n",
      "Targets: tensor([21754])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     1,     3,    12,    30,    39,    51,    56,    60,\n",
      "            62,   104, 21016, 21754]])\n",
      "Targets: tensor([21756])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     1,     3,    12,    30,    39,    51,    56,    60,    62,\n",
      "           104, 21016, 21754, 21756]])\n",
      "Targets: tensor([21768])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             1,     3,    12,    30,    39,    51,    56,    60,    62,   104,\n",
      "         21016, 21754, 21756, 21768]])\n",
      "Targets: tensor([21778])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     1,\n",
      "             3,    12,    30,    39,    51,    56,    60,    62,   104, 21016,\n",
      "         21754, 21756, 21768, 21778]])\n",
      "Targets: tensor([21786])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     1,     3,\n",
      "            12,    30,    39,    51,    56,    60,    62,   104, 21016, 21754,\n",
      "         21756, 21768, 21778, 21786]])\n",
      "Targets: tensor([21788])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     1,     3,    12,\n",
      "            30,    39,    51,    56,    60,    62,   104, 21016, 21754, 21756,\n",
      "         21768, 21778, 21786, 21788]])\n",
      "Targets: tensor([21801])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     1,     3,    12,    30,\n",
      "            39,    51,    56,    60,    62,   104, 21016, 21754, 21756, 21768,\n",
      "         21778, 21786, 21788, 21801]])\n",
      "Targets: tensor([21808])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     1,     3,    12,    30,    39,\n",
      "            51,    56,    60,    62,   104, 21016, 21754, 21756, 21768, 21778,\n",
      "         21786, 21788, 21801, 21808]])\n",
      "Targets: tensor([21818])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     1,     3,    12,    30,    39,    51,\n",
      "            56,    60,    62,   104, 21016, 21754, 21756, 21768, 21778, 21786,\n",
      "         21788, 21801, 21808, 21818]])\n",
      "Targets: tensor([21821])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     1,     3,    12,    30,    39,    51,    56,\n",
      "            60,    62,   104, 21016, 21754, 21756, 21768, 21778, 21786, 21788,\n",
      "         21801, 21808, 21818, 21821]])\n",
      "Targets: tensor([21831])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     1,     3,    12,    30,    39,    51,    56,    60,\n",
      "            62,   104, 21016, 21754, 21756, 21768, 21778, 21786, 21788, 21801,\n",
      "         21808, 21818, 21821, 21831]])\n",
      "Targets: tensor([21843])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     1,     3,    12,    30,    39,    51,    56,    60,    62,\n",
      "           104, 21016, 21754, 21756, 21768, 21778, 21786, 21788, 21801, 21808,\n",
      "         21818, 21821, 21831, 21843]])\n",
      "Targets: tensor([21855])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             1,     3,    12,    30,    39,    51,    56,    60,    62,   104,\n",
      "         21016, 21754, 21756, 21768, 21778, 21786, 21788, 21801, 21808, 21818,\n",
      "         21821, 21831, 21843, 21855]])\n",
      "Targets: tensor([21860])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     1,\n",
      "             3,    12,    30,    39,    51,    56,    60,    62,   104, 21016,\n",
      "         21754, 21756, 21768, 21778, 21786, 21788, 21801, 21808, 21818, 21821,\n",
      "         21831, 21843, 21855, 21860]])\n",
      "Targets: tensor([21862])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     1,     3,\n",
      "            12,    30,    39,    51,    56,    60,    62,   104, 21016, 21754,\n",
      "         21756, 21768, 21778, 21786, 21788, 21801, 21808, 21818, 21821, 21831,\n",
      "         21843, 21855, 21860, 21862]])\n",
      "Targets: tensor([21872])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     0,     1,     3,    12,\n",
      "            30,    39,    51,    56,    60,    62,   104, 21016, 21754, 21756,\n",
      "         21768, 21778, 21786, 21788, 21801, 21808, 21818, 21821, 21831, 21843,\n",
      "         21855, 21860, 21862, 21872]])\n",
      "Targets: tensor([21885])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     0,     1,     3,    12,    30,\n",
      "            39,    51,    56,    60,    62,   104, 21016, 21754, 21756, 21768,\n",
      "         21778, 21786, 21788, 21801, 21808, 21818, 21821, 21831, 21843, 21855,\n",
      "         21860, 21862, 21872, 21885]])\n",
      "Targets: tensor([21897])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     0,     1,     3,    12,    30,    39,\n",
      "            51,    56,    60,    62,   104, 21016, 21754, 21756, 21768, 21778,\n",
      "         21786, 21788, 21801, 21808, 21818, 21821, 21831, 21843, 21855, 21860,\n",
      "         21862, 21872, 21885, 21897]])\n",
      "Targets: tensor([21902])\n",
      "Inputs: tensor([[    0,     0,     0,     0,     1,     3,    12,    30,    39,    51,\n",
      "            56,    60,    62,   104, 21016, 21754, 21756, 21768, 21778, 21786,\n",
      "         21788, 21801, 21808, 21818, 21821, 21831, 21843, 21855, 21860, 21862,\n",
      "         21872, 21885, 21897, 21902]])\n",
      "Targets: tensor([21904])\n",
      "Inputs: tensor([[    0,     0,     0,     1,     3,    12,    30,    39,    51,    56,\n",
      "            60,    62,   104, 21016, 21754, 21756, 21768, 21778, 21786, 21788,\n",
      "         21801, 21808, 21818, 21821, 21831, 21843, 21855, 21860, 21862, 21872,\n",
      "         21885, 21897, 21902, 21904]])\n",
      "Targets: tensor([21914])\n",
      "Inputs: tensor([[    0,     0,     1,     3,    12,    30,    39,    51,    56,    60,\n",
      "            62,   104, 21016, 21754, 21756, 21768, 21778, 21786, 21788, 21801,\n",
      "         21808, 21818, 21821, 21831, 21843, 21855, 21860, 21862, 21872, 21885,\n",
      "         21897, 21902, 21904, 21914]])\n",
      "Targets: tensor([21931])\n",
      "Inputs: tensor([[    0,     1,     3,    12,    30,    39,    51,    56,    60,    62,\n",
      "           104, 21016, 21754, 21756, 21768, 21778, 21786, 21788, 21801, 21808,\n",
      "         21818, 21821, 21831, 21843, 21855, 21860, 21862, 21872, 21885, 21897,\n",
      "         21902, 21904, 21914, 21931]])\n",
      "Targets: tensor([21939])\n",
      "Inputs: tensor([[    1,     3,    12,    30,    39,    51,    56,    60,    62,   104,\n",
      "         21016, 21754, 21756, 21768, 21778, 21786, 21788, 21801, 21808, 21818,\n",
      "         21821, 21831, 21843, 21855, 21860, 21862, 21872, 21885, 21897, 21902,\n",
      "         21904, 21914, 21931, 21939]])\n",
      "Targets: tensor([21944])\n",
      "Inputs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Targets: tensor([1])\n",
      "Inputs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "Targets: tensor([3])\n",
      "Inputs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 1, 3]])\n",
      "Targets: tensor([17])\n",
      "Inputs: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  3, 17]])\n",
      "Targets: tensor([31])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = AutoRegDataset(train_set, context_wind)\n",
    "\n",
    "# inspect an entire row just to make sure with shuffle = False\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Example of iterating over the DataLoader\n",
    "i = 0\n",
    "for batch in train_dataloader:\n",
    "    i += 1\n",
    "    inputs, targets = batch\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    if i > 38:\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:55:41.664754Z",
     "start_time": "2024-06-22T16:55:30.897290Z"
    }
   },
   "id": "543179accbf3e027"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_len, config, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.n_embed = config[\"n_embed\"]\n",
    "        self.n_heads = config[\"n_heads\"]\n",
    "        \n",
    "        \n",
    "        # note x should have tokens with val <= vocab_len -1\n",
    "        self.C = torch.nn.Embedding(num_embeddings=vocab_len, embedding_dim=self.n_embed)\n",
    "        # pos emb\n",
    "        self.pe = torch.nn.Parameter(torch.randn(context_wind,self.n_embed) * 0.01)\n",
    "        \n",
    "        # no change in the size of representation happens here\n",
    "        # Stack of transformer blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                'multi_head': nn.MultiheadAttention(\n",
    "                    embed_dim=self.n_embed,\n",
    "                    num_heads=self.n_heads,\n",
    "                    batch_first=True\n",
    "                ),\n",
    "                'layer_norm1': nn.LayerNorm(self.n_embed), # one before skip connection\n",
    "                'layer_norm2': nn.LayerNorm(self.n_embed),\n",
    "                'ffn': nn.Sequential(\n",
    "                    nn.Linear(self.n_embed, self.n_embed),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(self.n_embed, self.n_embed)\n",
    "                )\n",
    "            })\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # and then a small mlp head. first with bias and second without\n",
    "        # flatten before sending\n",
    "        self.mlp_head0 = nn.Linear(in_features=context_wind*self.n_embed, out_features=self.n_embed,bias=True)\n",
    "        self.mlp_head1 = nn.Parameter(torch.randn(self.n_embed, vocab_len) * 1e-4) # this is increase in represeentation dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding the input tokens\n",
    "        emb = self.C(x)  # Shape: (B, wind, n_embed)\n",
    "        emb = emb + self.pe # add positional embedding\n",
    "\n",
    "        # Pass through each transformer block\n",
    "        for block in self.transformer_blocks:\n",
    "            # Apply multi-head attention with emb as query, key, and value\n",
    "            attn_output, _ = block['multi_head'](emb, emb, emb)  # Self-attention\n",
    "\n",
    "            # Add & Norm\n",
    "            attn_output = block['layer_norm1'](emb + attn_output)\n",
    "\n",
    "            # Feed-forward network\n",
    "            ffn_output = block['ffn'](attn_output)\n",
    "\n",
    "            # Final output with Add & Norm\n",
    "            emb = block['layer_norm2'](attn_output + ffn_output)\n",
    "            \n",
    "        # flatten the representaion\n",
    "        flat = einops.rearrange(emb, \"batch wind n_embed -> batch (wind n_embed)\")\n",
    "        mlp0 = self.mlp_head0(flat)\n",
    "        out = mlp0 @ self.mlp_head1\n",
    "\n",
    "        return out\n",
    "\n",
    "    def calculate_loss(self,x,y):\n",
    "        logits = self(x)\n",
    "        return logits , nn.functional.cross_entropy(logits,y)\n",
    "\n",
    "    def generate(self,seed = None,verbose=False):\n",
    "        seed = [0] * context_wind if seed is None else seed\n",
    "        generation = list()\n",
    "        i = 0\n",
    "        while True:\n",
    "            if verbose:\n",
    "                print(seed)\n",
    "            logits = self(torch.tensor(seed).view(1,-1))\n",
    "            probs = nn.functional.softmax(logits,dim=1)\n",
    "            prediction = torch.multinomial(probs,num_samples=1)\n",
    "            generation.append(prediction)\n",
    "            if prediction.item() == vocab_len:\n",
    "                break\n",
    "            seed = seed[1:] + [prediction.item()]\n",
    "            if verbose:\n",
    "                print(prediction.item())\n",
    "            i = i+1\n",
    "        return generation \n",
    "        \n",
    "\n",
    "model = TabTransformer(vocab_len, config, num_blocks=config[\"transformer_blocks\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:55:42.283393Z",
     "start_time": "2024-06-22T16:55:41.670121Z"
    }
   },
   "id": "e6ced658c05e5332"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 21945])"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs).shape # check if this is the correct shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:55:42.325991Z",
     "start_time": "2024-06-22T16:55:42.284737Z"
    }
   },
   "id": "e1979c1cdd06f099"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([21945])"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:55:42.334268Z",
     "start_time": "2024-06-22T16:55:42.312138Z"
    }
   },
   "id": "1eeb99710c8ae27f"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Matrics : i=28 , tot learned params learned_params=93_234_176\n"
     ]
    }
   ],
   "source": [
    "learned_params = 0\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    learned_params += p.nelement()\n",
    "\n",
    "print(f\"Tot Matrics : {i=} , tot learned params {learned_params=:_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:02.308448Z",
     "start_time": "2024-06-22T16:56:02.294219Z"
    }
   },
   "id": "5dd64776d60332ad"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0.01\n)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer ::\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=1e-3)\n",
    "optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:02.784927Z",
     "start_time": "2024-06-22T16:56:02.779637Z"
    }
   },
   "id": "e1add11adc0f1253"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "track_loss = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:02.864669Z",
     "start_time": "2024-06-22T16:56:02.861498Z"
    }
   },
   "id": "341f875431006847"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f0/_f_gy0t91jqchv14f0hcl_gh0000gn/T/ipykernel_53317/3066447850.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  row_tensor = torch.tensor(row[1:], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AutoRegDataset(train_set, context_wind)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:14.117360Z",
     "start_time": "2024-06-22T16:56:02.951613Z"
    }
   },
   "id": "c7119b0a605a99b5"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/6233 [00:39<2:15:45,  1.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[119], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# learning step\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# for plotting\u001B[39;00m\n\u001B[1;32m     15\u001B[0m track_loss\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m             )\n\u001B[0;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:187\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    174\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    176\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    177\u001B[0m         group,\n\u001B[1;32m    178\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    184\u001B[0m         state_steps,\n\u001B[1;32m    185\u001B[0m     )\n\u001B[0;32m--> 187\u001B[0m     \u001B[43madamw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:339\u001B[0m, in \u001B[0;36madamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    337\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adamw\n\u001B[0;32m--> 339\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:415\u001B[0m, in \u001B[0;36m_single_tensor_adamw\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001B[0m\n\u001B[1;32m    412\u001B[0m step_t \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;66;03m# Perform stepweight decay\u001B[39;00m\n\u001B[0;32m--> 415\u001B[0m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[1;32m    418\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mlerp_(grad, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for Xb,yb in tqdm(train_dataloader):\n",
    "    # forward pass\n",
    "    _,loss = model.calculate_loss(Xb,yb)\n",
    "\n",
    "    # flush the gradients \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # learning step\n",
    "    optimizer.step()\n",
    "\n",
    "    # for plotting\n",
    "    track_loss.append(loss.item())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:53.694789Z",
     "start_time": "2024-06-22T16:56:14.116711Z"
    }
   },
   "id": "2342827ed0af6efa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for Xb ,yb in train_dataloader:\n",
    "    if vocab_len in Xb:\n",
    "        print(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-22T16:56:53.694234Z"
    }
   },
   "id": "79ebb04060da9fd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.mlp_head1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:53.696273Z",
     "start_time": "2024-06-22T16:56:53.695683Z"
    }
   },
   "id": "dce8c3d8aace8591"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:53.697224Z",
     "start_time": "2024-06-22T16:56:53.696953Z"
    }
   },
   "id": "168efe06f43f5e1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-22T16:56:53.697809Z"
    }
   },
   "id": "dfc5c434787d5a33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T16:56:53.699136Z",
     "start_time": "2024-06-22T16:56:53.698646Z"
    }
   },
   "id": "1ba1c22eaebdf2d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6104257277fd3f1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
